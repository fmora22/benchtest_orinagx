{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4586.238, "latencies_ms": [4586.238], "images_per_second": 0.218, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image depicts a spacious, well-lit living room with a dining area, featuring a large flat-screen TV, a fireplace, and a kitchen area with a countertop and cabinets.", "error": null, "sys_before": {"cpu_percent": 10.2, "ram_used_mb": 13859.8, "ram_available_mb": 48981.1, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13864.4, "ram_available_mb": 48976.5, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 74.684}, "power_stats": {"power_gpu_soc_mean_watts": 21.304, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 74.684}, "timestamp": "2026-01-30T09:41:19.998456"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10676.043, "latencies_ms": [10676.043], "images_per_second": 0.094, "prompt_tokens": 1113, "response_tokens_est": 128, "n_tiles": 1, "output_text": " television: 1, dining table: 1, chairs: 4, vase: 1, flowers: 2, television stand: 1, window: 1, wall: 1, floor: 1, rug: 1, fireplace: 1, ceiling: 1, light: 1, wall art: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1,", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13864.4, "ram_available_mb": 48976.5, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 13867.5, "ram_available_mb": 48973.4, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 68.211}, "power_stats": {"power_gpu_soc_mean_watts": 15.268, "power_cpu_cv_mean_watts": 2.123, "power_sys_5v0_mean_watts": 7.389, "gpu_utilization_percent_mean": 68.211}, "timestamp": "2026-01-30T09:41:32.704006"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5948.27, "latencies_ms": [5948.27], "images_per_second": 0.168, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The dining table is located in the center of the room, with the woman standing near it. The television is on the left side of the room, while the fireplace is on the right side. The woman is standing near the dining table, which is in the center of the room.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13867.5, "ram_available_mb": 48973.4, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13874.8, "ram_available_mb": 48966.1, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 70.92}, "power_stats": {"power_gpu_soc_mean_watts": 18.087, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 7.62, "gpu_utilization_percent_mean": 70.92}, "timestamp": "2026-01-30T09:41:40.694441"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3281.193, "latencies_ms": [3281.193], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman is standing in a living room with a dining table and chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13875.0, "ram_available_mb": 48965.9, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13874.7, "ram_available_mb": 48966.2, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 81.538}, "power_stats": {"power_gpu_soc_mean_watts": 22.967, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 7.893, "gpu_utilization_percent_mean": 81.538}, "timestamp": "2026-01-30T09:41:46.008604"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4693.174, "latencies_ms": [4693.174], "images_per_second": 0.213, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The room is bathed in warm yellow light, with hardwood floors and a large window letting in natural light. The walls are painted a bright yellow, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 13874.7, "ram_available_mb": 48966.2, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 13875.2, "ram_available_mb": 48965.7, "ram_percent": 22.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 73.462}, "power_stats": {"power_gpu_soc_mean_watts": 19.811, "power_cpu_cv_mean_watts": 1.901, "power_sys_5v0_mean_watts": 7.681, "gpu_utilization_percent_mean": 73.462}, "timestamp": "2026-01-30T09:41:52.734534"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4796.527, "latencies_ms": [4796.527], "images_per_second": 0.208, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image features a large brown bear with a thick coat of fur, standing on a grassy field and looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 13875.2, "ram_available_mb": 48965.7, "ram_percent": 22.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14574.9, "ram_available_mb": 48266.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.35}, "power_stats": {"power_gpu_soc_mean_watts": 21.81, "power_cpu_cv_mean_watts": 1.843, "power_sys_5v0_mean_watts": 7.9, "gpu_utilization_percent_mean": 79.35}, "timestamp": "2026-01-30T09:41:59.579815"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6558.716, "latencies_ms": [6558.716], "images_per_second": 0.152, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bear: 1\n2. grass: 1\n3. fur: 1\n4. nose: 1\n5. eyes: 1\n6. mouth: 1\n7. ears: 1\n8. fur texture: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14574.9, "ram_available_mb": 48266.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14589.8, "ram_available_mb": 48251.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.075, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 7.884, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-30T09:42:08.156264"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5003.844, "latencies_ms": [5003.844], "images_per_second": 0.2, "prompt_tokens": 1450, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The bear is in the foreground, with the grass in the background. The bear is facing the camera, with its head turned slightly to the left.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14589.8, "ram_available_mb": 48251.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14619.7, "ram_available_mb": 48221.2, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.833}, "power_stats": {"power_gpu_soc_mean_watts": 22.176, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 80.833}, "timestamp": "2026-01-30T09:42:15.185732"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3572.329, "latencies_ms": [3572.329], "images_per_second": 0.28, "prompt_tokens": 1444, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A large brown bear is sitting on a grassy field.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14619.7, "ram_available_mb": 48221.2, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14618.3, "ram_available_mb": 48222.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.367}, "power_stats": {"power_gpu_soc_mean_watts": 25.382, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.282, "gpu_utilization_percent_mean": 86.367}, "timestamp": "2026-01-30T09:42:20.790725"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3735.109, "latencies_ms": [3735.109], "images_per_second": 0.268, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The bear has a brown fur, and the grass is green.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14618.3, "ram_available_mb": 48222.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14618.1, "ram_available_mb": 48222.8, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.452}, "power_stats": {"power_gpu_soc_mean_watts": 25.118, "power_cpu_cv_mean_watts": 1.215, "power_sys_5v0_mean_watts": 8.246, "gpu_utilization_percent_mean": 84.452}, "timestamp": "2026-01-30T09:42:26.543824"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5811.576, "latencies_ms": [5811.576], "images_per_second": 0.172, "prompt_tokens": 1432, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a blue comforter on the bed, a wooden dresser with a mirror, a bookshelf filled with books, and a window that offers a view of a lush green tree outside.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 14618.1, "ram_available_mb": 48222.8, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 16.3, "ram_used_mb": 14678.9, "ram_available_mb": 48162.0, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.306}, "power_stats": {"power_gpu_soc_mean_watts": 21.15, "power_cpu_cv_mean_watts": 2.936, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 78.306}, "timestamp": "2026-01-30T09:42:34.395716"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7019.413, "latencies_ms": [7019.413], "images_per_second": 0.142, "prompt_tokens": 1446, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. bed: 1\n2. dresser: 1\n3. mirror: 1\n4. bookshelf: 1\n5. books: 100\n6. potted plant: 4\n7. window: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14678.9, "ram_available_mb": 48162.0, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14691.6, "ram_available_mb": 48149.3, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.831}, "power_stats": {"power_gpu_soc_mean_watts": 19.889, "power_cpu_cv_mean_watts": 2.065, "power_sys_5v0_mean_watts": 7.886, "gpu_utilization_percent_mean": 74.831}, "timestamp": "2026-01-30T09:42:43.438992"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6772.961, "latencies_ms": [6772.961], "images_per_second": 0.148, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the window on the right side. The bookshelf is positioned in the background, while the dresser is situated near the bed. The plants are placed in the foreground, with the window being the closest object to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14691.6, "ram_available_mb": 48149.3, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14703.4, "ram_available_mb": 48137.5, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.193}, "power_stats": {"power_gpu_soc_mean_watts": 19.994, "power_cpu_cv_mean_watts": 2.052, "power_sys_5v0_mean_watts": 7.891, "gpu_utilization_percent_mean": 74.193}, "timestamp": "2026-01-30T09:42:52.236514"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5623.748, "latencies_ms": [5623.748], "images_per_second": 0.178, "prompt_tokens": 1444, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The bedroom is furnished with a bed, a dresser, a bookshelf, and a window. The room is decorated with a blue comforter, a mirror, and a plant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14703.4, "ram_available_mb": 48137.5, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14715.3, "ram_available_mb": 48125.6, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.362}, "power_stats": {"power_gpu_soc_mean_watts": 21.103, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 7.894, "gpu_utilization_percent_mean": 76.362}, "timestamp": "2026-01-30T09:42:59.916039"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4742.409, "latencies_ms": [4742.409], "images_per_second": 0.211, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The room is bathed in natural light from a window, the walls are adorned with floral wallpaper, and the floor is carpeted.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14715.3, "ram_available_mb": 48125.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14723.4, "ram_available_mb": 48117.5, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.641}, "power_stats": {"power_gpu_soc_mean_watts": 22.782, "power_cpu_cv_mean_watts": 1.993, "power_sys_5v0_mean_watts": 8.079, "gpu_utilization_percent_mean": 78.641}, "timestamp": "2026-01-30T09:43:06.670629"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3261.315, "latencies_ms": [3261.315], "images_per_second": 0.307, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A stop sign is on a pole in front of a parking lot.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14723.4, "ram_available_mb": 48117.5, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14730.8, "ram_available_mb": 48110.1, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.593}, "power_stats": {"power_gpu_soc_mean_watts": 22.38, "power_cpu_cv_mean_watts": 1.825, "power_sys_5v0_mean_watts": 7.878, "gpu_utilization_percent_mean": 83.593}, "timestamp": "2026-01-30T09:43:11.982241"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2564.576, "latencies_ms": [2564.576], "images_per_second": 0.39, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " stop sign: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14730.8, "ram_available_mb": 48110.1, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14737.5, "ram_available_mb": 48103.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.286}, "power_stats": {"power_gpu_soc_mean_watts": 24.136, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 87.286}, "timestamp": "2026-01-30T09:43:16.567580"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5355.28, "latencies_ms": [5355.28], "images_per_second": 0.187, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The stop sign is in the foreground, to the left of the street. The street is in the middle of the image, with the stop sign on the right side. The background includes trees and buildings, with the sky visible above.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14737.5, "ram_available_mb": 48103.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 14737.9, "ram_available_mb": 48103.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.111}, "power_stats": {"power_gpu_soc_mean_watts": 18.835, "power_cpu_cv_mean_watts": 1.79, "power_sys_5v0_mean_watts": 7.668, "gpu_utilization_percent_mean": 72.111}, "timestamp": "2026-01-30T09:43:23.968880"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3159.097, "latencies_ms": [3159.097], "images_per_second": 0.317, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A stop sign is on a pole in front of a parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14737.9, "ram_available_mb": 48103.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14738.2, "ram_available_mb": 48102.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.577}, "power_stats": {"power_gpu_soc_mean_watts": 22.638, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 7.933, "gpu_utilization_percent_mean": 81.577}, "timestamp": "2026-01-30T09:43:29.173064"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3168.772, "latencies_ms": [3168.772], "images_per_second": 0.316, "prompt_tokens": 1110, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The stop sign is red and white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14738.2, "ram_available_mb": 48102.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14738.5, "ram_available_mb": 48102.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.577}, "power_stats": {"power_gpu_soc_mean_watts": 23.165, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 82.577}, "timestamp": "2026-01-30T09:43:34.404115"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3246.599, "latencies_ms": [3246.599], "images_per_second": 0.308, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three teddy bears of different sizes and colors are huddled together on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14738.5, "ram_available_mb": 48102.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14739.7, "ram_available_mb": 48101.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.926}, "power_stats": {"power_gpu_soc_mean_watts": 23.183, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 77.926}, "timestamp": "2026-01-30T09:43:39.721005"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2555.762, "latencies_ms": [2555.762], "images_per_second": 0.391, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " teddy bear: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14739.7, "ram_available_mb": 48101.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14740.4, "ram_available_mb": 48100.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.238}, "power_stats": {"power_gpu_soc_mean_watts": 24.329, "power_cpu_cv_mean_watts": 1.183, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 85.238}, "timestamp": "2026-01-30T09:43:44.292910"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6886.21, "latencies_ms": [6886.21], "images_per_second": 0.145, "prompt_tokens": 1118, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The teddy bears are positioned in a close group, with the largest bear in the center and the smallest bear on the left. The largest bear is in the foreground, while the smallest bear is in the background. The teddy bears are arranged in a way that suggests they are huddled together, with the smallest bear resting its head on the largest bear's back.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14740.4, "ram_available_mb": 48100.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.724}, "power_stats": {"power_gpu_soc_mean_watts": 17.203, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 7.628, "gpu_utilization_percent_mean": 68.724}, "timestamp": "2026-01-30T09:43:53.209061"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2993.914, "latencies_ms": [2993.914], "images_per_second": 0.334, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " Three teddy bears are huddled together on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14707.4, "ram_available_mb": 48133.5, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.042}, "power_stats": {"power_gpu_soc_mean_watts": 23.239, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 84.042}, "timestamp": "2026-01-30T09:43:58.233794"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3409.621, "latencies_ms": [3409.621], "images_per_second": 0.293, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The teddy bears are brown and beige, and they are sitting on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 50.0, "ram_used_mb": 14649.9, "ram_available_mb": 48191.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.611, "power_cpu_cv_mean_watts": 1.631, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 77.286}, "timestamp": "2026-01-30T09:44:03.703835"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3578.357, "latencies_ms": [3578.357], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman wearing a red jacket and black pants is skiing down a snowy hill with ski poles in her hands.", "error": null, "sys_before": {"cpu_percent": 17.4, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14624.0, "ram_available_mb": 48216.9, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.483}, "power_stats": {"power_gpu_soc_mean_watts": 22.329, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 74.483}, "timestamp": "2026-01-30T09:44:09.310386"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6859.142, "latencies_ms": [6859.142], "images_per_second": 0.146, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. Ski pole: 2\n2. Ski: 2\n3. Ski pole: 2\n4. Ski pole: 2\n5. Ski pole: 2\n6. Ski pole: 2\n7. Ski pole: 2\n8. Ski pole: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.0, "ram_available_mb": 48216.9, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14623.6, "ram_available_mb": 48217.3, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.983}, "power_stats": {"power_gpu_soc_mean_watts": 17.723, "power_cpu_cv_mean_watts": 2.093, "power_sys_5v0_mean_watts": 7.673, "gpu_utilization_percent_mean": 70.983}, "timestamp": "2026-01-30T09:44:18.218138"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4989.098, "latencies_ms": [4989.098], "images_per_second": 0.2, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the ski slope stretching out into the background. The skier is to the left of the image, with the ski poles extending towards the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14623.6, "ram_available_mb": 48217.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14622.8, "ram_available_mb": 48218.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.415}, "power_stats": {"power_gpu_soc_mean_watts": 19.516, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.806, "gpu_utilization_percent_mean": 72.415}, "timestamp": "2026-01-30T09:44:25.218344"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3386.793, "latencies_ms": [3386.793], "images_per_second": 0.295, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman wearing a red jacket and black pants is skiing down a snowy hill.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14622.8, "ram_available_mb": 48218.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14621.9, "ram_available_mb": 48219.0, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.224, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 7.895, "gpu_utilization_percent_mean": 83.071}, "timestamp": "2026-01-30T09:44:30.639979"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3538.287, "latencies_ms": [3538.287], "images_per_second": 0.283, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a red jacket and black pants, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14621.9, "ram_available_mb": 48219.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14621.4, "ram_available_mb": 48219.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.329, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 7.919, "gpu_utilization_percent_mean": 79.207}, "timestamp": "2026-01-30T09:44:36.213674"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4451.345, "latencies_ms": [4451.345], "images_per_second": 0.225, "prompt_tokens": 1100, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a kitchen with a white refrigerator, a white stove, and a white dishwasher, all set against a backdrop of wooden cabinets and a beige tiled floor.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14621.4, "ram_available_mb": 48219.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14621.0, "ram_available_mb": 48219.9, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.162}, "power_stats": {"power_gpu_soc_mean_watts": 20.577, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 73.162}, "timestamp": "2026-01-30T09:44:42.714320"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6717.866, "latencies_ms": [6717.866], "images_per_second": 0.149, "prompt_tokens": 1114, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. white refrigerator: 1\n2. white stove: 1\n3. white oven: 1\n4. white cabinet: 2\n5. white cabinet door: 1\n6. white cabinet handle: 1\n7. white cabinet drawer: 1\n8. white cabinet knob: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14621.0, "ram_available_mb": 48219.9, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14620.5, "ram_available_mb": 48220.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.107}, "power_stats": {"power_gpu_soc_mean_watts": 17.652, "power_cpu_cv_mean_watts": 2.024, "power_sys_5v0_mean_watts": 7.666, "gpu_utilization_percent_mean": 71.107}, "timestamp": "2026-01-30T09:44:51.459322"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5510.552, "latencies_ms": [5510.552], "images_per_second": 0.181, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The white refrigerator is located to the right of the white stove, which is situated to the left of the white oven. The white cabinets are positioned above the stove and oven, while the white countertop is situated in the middle of the kitchen.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14620.5, "ram_available_mb": 48220.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14620.2, "ram_available_mb": 48220.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.973, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T09:44:58.981822"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3137.255, "latencies_ms": [3137.255], "images_per_second": 0.319, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A small kitchen with white appliances and wood cabinets is shown in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14620.2, "ram_available_mb": 48220.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14618.2, "ram_available_mb": 48222.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.64}, "power_stats": {"power_gpu_soc_mean_watts": 23.271, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 79.64}, "timestamp": "2026-01-30T09:45:04.144220"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3370.116, "latencies_ms": [3370.116], "images_per_second": 0.297, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 14618.2, "ram_available_mb": 48222.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14617.5, "ram_available_mb": 48223.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.643}, "power_stats": {"power_gpu_soc_mean_watts": 22.538, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 7.968, "gpu_utilization_percent_mean": 76.643}, "timestamp": "2026-01-30T09:45:09.558668"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4563.672, "latencies_ms": [4563.672], "images_per_second": 0.219, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " Two baseball players are running on the field, one of them is wearing a green shirt and the other is wearing a white shirt.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 14616.6, "ram_available_mb": 48224.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14618.7, "ram_available_mb": 48222.2, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.895}, "power_stats": {"power_gpu_soc_mean_watts": 23.155, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 79.895}, "timestamp": "2026-01-30T09:45:16.172422"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7321.5, "latencies_ms": [7321.5], "images_per_second": 0.137, "prompt_tokens": 1446, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. baseball player: 2\n2. baseball glove: 1\n3. baseball bat: 1\n4. baseball cap: 1\n5. baseball helmet: 1\n6. baseball field: 1\n7. baseball player's pants: 1\n8. baseball player's shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14618.7, "ram_available_mb": 48222.2, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 14619.1, "ram_available_mb": 48221.8, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.839}, "power_stats": {"power_gpu_soc_mean_watts": 19.395, "power_cpu_cv_mean_watts": 2.533, "power_sys_5v0_mean_watts": 7.932, "gpu_utilization_percent_mean": 72.839}, "timestamp": "2026-01-30T09:45:25.551735"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5801.714, "latencies_ms": [5801.714], "images_per_second": 0.172, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The baseball player in the foreground is running towards the right side of the image, while the other player is running towards the left side. The baseball player in the foreground is closer to the camera than the other player.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14619.1, "ram_available_mb": 48221.8, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14619.8, "ram_available_mb": 48221.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.438}, "power_stats": {"power_gpu_soc_mean_watts": 21.296, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 76.438}, "timestamp": "2026-01-30T09:45:33.366764"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4606.353, "latencies_ms": [4606.353], "images_per_second": 0.217, "prompt_tokens": 1444, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A baseball game is taking place on a field with a boy wearing a green shirt and a baseball glove running towards the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14619.8, "ram_available_mb": 48221.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14619.8, "ram_available_mb": 48221.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.974}, "power_stats": {"power_gpu_soc_mean_watts": 22.998, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 75.974}, "timestamp": "2026-01-30T09:45:40.032874"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5658.251, "latencies_ms": [5658.251], "images_per_second": 0.177, "prompt_tokens": 1442, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a baseball game with two players running on the field, one wearing a green shirt and the other wearing a white shirt. The field is covered in green grass, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14619.8, "ram_available_mb": 48221.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14619.5, "ram_available_mb": 48221.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.596}, "power_stats": {"power_gpu_soc_mean_watts": 21.532, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 77.596}, "timestamp": "2026-01-30T09:45:47.731099"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3748.966, "latencies_ms": [3748.966], "images_per_second": 0.267, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A tennis player is preparing to hit a ball on a court with a J.P. Morgan advertisement in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14619.5, "ram_available_mb": 48221.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14619.5, "ram_available_mb": 48221.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.032}, "power_stats": {"power_gpu_soc_mean_watts": 21.801, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 7.918, "gpu_utilization_percent_mean": 76.032}, "timestamp": "2026-01-30T09:45:53.540396"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6060.0, "latencies_ms": [6060.0], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. tennis player: 1\n2. ball: 1\n3. racket: 1\n4. person: 1\n5. wall: 1\n6. advertisement: 1\n7. spectator: 1\n8. court: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14619.5, "ram_available_mb": 48221.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14619.7, "ram_available_mb": 48221.2, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.804}, "power_stats": {"power_gpu_soc_mean_watts": 18.296, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 71.804}, "timestamp": "2026-01-30T09:46:01.632340"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4512.593, "latencies_ms": [4512.593], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground, with the ball and the umpire in the background. The player is closer to the camera than the umpire.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14619.7, "ram_available_mb": 48221.2, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 14620.0, "ram_available_mb": 48220.9, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.216, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 73.486}, "timestamp": "2026-01-30T09:46:08.183046"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3299.214, "latencies_ms": [3299.214], "images_per_second": 0.303, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A tennis player is playing on a court with a blue wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14620.0, "ram_available_mb": 48220.9, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14620.4, "ram_available_mb": 48220.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.37}, "power_stats": {"power_gpu_soc_mean_watts": 22.663, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 80.37}, "timestamp": "2026-01-30T09:46:13.522082"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6349.569, "latencies_ms": [6349.569], "images_per_second": 0.157, "prompt_tokens": 1109, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a vibrant blue tennis court, where a player in a crisp white outfit is in the midst of a powerful swing, his body leaning forward in anticipation. The court is bathed in bright sunlight, casting a sharp contrast between the blue of the court and the green of the surrounding grass.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14620.4, "ram_available_mb": 48220.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14621.4, "ram_available_mb": 48219.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.839, "power_cpu_cv_mean_watts": 2.114, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T09:46:21.892082"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3848.926, "latencies_ms": [3848.926], "images_per_second": 0.26, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court, with one of the adults holding a trophy.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 14621.4, "ram_available_mb": 48219.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14621.6, "ram_available_mb": 48219.3, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.188}, "power_stats": {"power_gpu_soc_mean_watts": 21.751, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.92, "gpu_utilization_percent_mean": 78.188}, "timestamp": "2026-01-30T09:46:27.766772"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5823.368, "latencies_ms": [5823.368], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. boy: 4\n2. girl: 3\n3. boy: 2\n4. boy: 1\n5. boy: 1\n6. boy: 1\n7. boy: 1\n8. boy: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14621.6, "ram_available_mb": 48219.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14622.4, "ram_available_mb": 48218.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.082}, "power_stats": {"power_gpu_soc_mean_watts": 18.741, "power_cpu_cv_mean_watts": 1.954, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 71.082}, "timestamp": "2026-01-30T09:46:35.635648"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6541.993, "latencies_ms": [6541.993], "images_per_second": 0.153, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The group of children and adults are standing on a tennis court, with the tennis rackets held by the children and adults. The tennis rackets are positioned in the foreground, with the group of children and adults standing behind them. The tennis court is located in the background, with the tennis net and trees visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14622.4, "ram_available_mb": 48218.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 14622.6, "ram_available_mb": 48218.3, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.836}, "power_stats": {"power_gpu_soc_mean_watts": 17.906, "power_cpu_cv_mean_watts": 2.688, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 68.836}, "timestamp": "2026-01-30T09:46:44.226744"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3212.37, "latencies_ms": [3212.37], "images_per_second": 0.311, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14622.6, "ram_available_mb": 48218.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14623.6, "ram_available_mb": 48217.3, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.115}, "power_stats": {"power_gpu_soc_mean_watts": 23.439, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 81.115}, "timestamp": "2026-01-30T09:46:49.475574"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3526.907, "latencies_ms": [3526.907], "images_per_second": 0.284, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image is taken in a sunny day with clear blue sky. The tennis court is blue in color.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14623.6, "ram_available_mb": 48217.3, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.931}, "power_stats": {"power_gpu_soc_mean_watts": 22.398, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 77.931}, "timestamp": "2026-01-30T09:46:55.039945"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5122.517, "latencies_ms": [5122.517], "images_per_second": 0.195, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " In the image, a group of people are gathered on a stone-paved walkway, with a large bridge arching above them, and a white bird is seen walking on the ground near the water's edge.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14624.8, "ram_available_mb": 48216.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.047}, "power_stats": {"power_gpu_soc_mean_watts": 19.222, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 73.047}, "timestamp": "2026-01-30T09:47:02.208002"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5822.716, "latencies_ms": [5822.716], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. people: 4\n3. birds: 1\n4. rocks: 2\n5. water: 1\n6. trees: 1\n7. buildings: 1\n8. bridge: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.8, "ram_available_mb": 48216.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14624.2, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.38}, "power_stats": {"power_gpu_soc_mean_watts": 18.327, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 7.805, "gpu_utilization_percent_mean": 72.38}, "timestamp": "2026-01-30T09:47:10.074885"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5759.621, "latencies_ms": [5759.621], "images_per_second": 0.174, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The main objects are positioned in a way that the bridge is in the foreground, with the people and the bird in the background. The bridge is located to the left of the people and the bird, and the people are sitting on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14624.2, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14622.4, "ram_available_mb": 48218.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.102}, "power_stats": {"power_gpu_soc_mean_watts": 18.604, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 72.102}, "timestamp": "2026-01-30T09:47:17.874987"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3781.218, "latencies_ms": [3781.218], "images_per_second": 0.264, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A group of people are sitting on a stone ledge by a river, watching a white bird swim in the water.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14622.4, "ram_available_mb": 48218.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14623.2, "ram_available_mb": 48217.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.161}, "power_stats": {"power_gpu_soc_mean_watts": 21.674, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 7.929, "gpu_utilization_percent_mean": 77.161}, "timestamp": "2026-01-30T09:47:23.689026"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6754.878, "latencies_ms": [6754.878], "images_per_second": 0.148, "prompt_tokens": 1109, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a bridge with a metal structure, a river with a white bird, and a group of people sitting on the bank. The lighting is natural, with the sun shining down on the scene, and the colors are vibrant, with the blue of the river contrasting with the green of the trees and the red of the people's clothing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14623.2, "ram_available_mb": 48217.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.754}, "power_stats": {"power_gpu_soc_mean_watts": 17.789, "power_cpu_cv_mean_watts": 2.101, "power_sys_5v0_mean_watts": 7.672, "gpu_utilization_percent_mean": 68.754}, "timestamp": "2026-01-30T09:47:32.477024"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3115.829, "latencies_ms": [3115.829], "images_per_second": 0.321, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman is looking at her phone with a Hello Kitty case.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14624.2, "ram_available_mb": 48216.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.414, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 79.0}, "timestamp": "2026-01-30T09:47:37.646811"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6227.682, "latencies_ms": [6227.682], "images_per_second": 0.161, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. woman: 1\n2. hair: 1\n3. earring: 1\n4. wristwatch: 1\n5. bracelet: 2\n6. phone: 1\n7. Hello Kitty: 1\n8. background: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14624.2, "ram_available_mb": 48216.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.538}, "power_stats": {"power_gpu_soc_mean_watts": 18.083, "power_cpu_cv_mean_watts": 2.234, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 71.538}, "timestamp": "2026-01-30T09:47:45.911787"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4555.727, "latencies_ms": [4555.727], "images_per_second": 0.22, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The woman is in the foreground of the image, holding a Hello Kitty phone case. The background is blurred, indicating that the focus is on the woman and her phone case.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 14623.4, "ram_available_mb": 48217.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.974}, "power_stats": {"power_gpu_soc_mean_watts": 19.991, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.871, "gpu_utilization_percent_mean": 72.974}, "timestamp": "2026-01-30T09:47:52.485554"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3277.406, "latencies_ms": [3277.406], "images_per_second": 0.305, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman is taking a picture of herself with a Hello Kitty phone case.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14623.4, "ram_available_mb": 48217.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14623.3, "ram_available_mb": 48217.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.741}, "power_stats": {"power_gpu_soc_mean_watts": 22.423, "power_cpu_cv_mean_watts": 1.617, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 81.741}, "timestamp": "2026-01-30T09:47:57.781818"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3739.439, "latencies_ms": [3739.439], "images_per_second": 0.267, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is taken in a bright and sunny day, with the woman wearing a white shirt and a green bracelet.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14623.3, "ram_available_mb": 48217.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 14624.3, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.129}, "power_stats": {"power_gpu_soc_mean_watts": 22.065, "power_cpu_cv_mean_watts": 2.339, "power_sys_5v0_mean_watts": 7.961, "gpu_utilization_percent_mean": 76.129}, "timestamp": "2026-01-30T09:48:03.548596"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3800.29, "latencies_ms": [3800.29], "images_per_second": 0.263, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of children are riding on a red and yellow train car, with a wooden wall and a black speaker in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14624.3, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.226}, "power_stats": {"power_gpu_soc_mean_watts": 21.956, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 75.226}, "timestamp": "2026-01-30T09:48:09.372281"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6339.875, "latencies_ms": [6339.875], "images_per_second": 0.158, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. children: 5\n2. train: 1\n3. track: 1\n4. wall: 1\n5. children's clothing: 5\n6. children's hair: 5\n7. children's eyes: 5\n8. children's hands: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14623.9, "ram_available_mb": 48217.0, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.222}, "power_stats": {"power_gpu_soc_mean_watts": 17.985, "power_cpu_cv_mean_watts": 2.07, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 72.222}, "timestamp": "2026-01-30T09:48:17.733220"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4917.776, "latencies_ms": [4917.776], "images_per_second": 0.203, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The children are in the foreground, riding on a train that is in the middle of the image. The train is moving towards the right side of the image, and the children are looking towards the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14623.5, "ram_available_mb": 48217.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.463}, "power_stats": {"power_gpu_soc_mean_watts": 19.533, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 7.842, "gpu_utilization_percent_mean": 72.463}, "timestamp": "2026-01-30T09:48:24.704729"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3650.789, "latencies_ms": [3650.789], "images_per_second": 0.274, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of children are riding on a train car in a room with a wooden floor and a wall.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14623.5, "ram_available_mb": 48217.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14624.3, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.725, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 7.92, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-30T09:48:30.411346"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5589.184, "latencies_ms": [5589.184], "images_per_second": 0.179, "prompt_tokens": 1110, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a group of children riding on a red and yellow train car, with the train car being the main focus of the image. The lighting in the image is dim, and the children are wearing jackets, indicating that it might be a cold day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14624.3, "ram_available_mb": 48216.6, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14624.5, "ram_available_mb": 48216.4, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.695, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 72.043}, "timestamp": "2026-01-30T09:48:38.035411"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4035.721, "latencies_ms": [4035.721], "images_per_second": 0.248, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a plate with a piece of food on it.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14624.5, "ram_available_mb": 48216.4, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14624.8, "ram_available_mb": 48216.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.364}, "power_stats": {"power_gpu_soc_mean_watts": 23.989, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.27, "gpu_utilization_percent_mean": 80.364}, "timestamp": "2026-01-30T09:48:44.123597"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6778.554, "latencies_ms": [6778.554], "images_per_second": 0.148, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. food: 1\n3. cup: 1\n4. fork: 1\n5. knife: 1\n6. table: 1\n7. background: 1\n8. glass: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14624.8, "ram_available_mb": 48216.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.241}, "power_stats": {"power_gpu_soc_mean_watts": 19.288, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.907, "gpu_utilization_percent_mean": 73.241}, "timestamp": "2026-01-30T09:48:52.949055"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6002.805, "latencies_ms": [6002.805], "images_per_second": 0.167, "prompt_tokens": 1450, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The main object, a piece of food, is in the foreground, with a small dish of sauce in the background. The food is positioned to the left of the dish, and the entire scene is set on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14624.4, "ram_available_mb": 48216.5, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 14671.2, "ram_available_mb": 48169.7, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.62}, "power_stats": {"power_gpu_soc_mean_watts": 20.953, "power_cpu_cv_mean_watts": 1.939, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 78.62}, "timestamp": "2026-01-30T09:49:00.993942"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4069.616, "latencies_ms": [4069.616], "images_per_second": 0.246, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a plate of food with a side of salad.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14671.2, "ram_available_mb": 48169.7, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14676.5, "ram_available_mb": 48164.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.303}, "power_stats": {"power_gpu_soc_mean_watts": 23.99, "power_cpu_cv_mean_watts": 1.833, "power_sys_5v0_mean_watts": 8.29, "gpu_utilization_percent_mean": 84.303}, "timestamp": "2026-01-30T09:49:07.095271"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5190.454, "latencies_ms": [5190.454], "images_per_second": 0.193, "prompt_tokens": 1442, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is in black and white, with a focus on a plate of food. The lighting is soft and natural, and the food appears to be well-cooked.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14676.5, "ram_available_mb": 48164.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 14683.5, "ram_available_mb": 48157.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.256}, "power_stats": {"power_gpu_soc_mean_watts": 22.177, "power_cpu_cv_mean_watts": 2.134, "power_sys_5v0_mean_watts": 8.117, "gpu_utilization_percent_mean": 76.256}, "timestamp": "2026-01-30T09:49:14.324403"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3168.243, "latencies_ms": [3168.243], "images_per_second": 0.316, "prompt_tokens": 766, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing a wetsuit is standing on a paddleboard in the ocean, holding a paddle in his hand.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14683.5, "ram_available_mb": 48157.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14698.5, "ram_available_mb": 48142.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5179.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.038}, "power_stats": {"power_gpu_soc_mean_watts": 19.384, "power_cpu_cv_mean_watts": 2.111, "power_sys_5v0_mean_watts": 7.597, "gpu_utilization_percent_mean": 74.038}, "timestamp": "2026-01-30T09:49:19.546144"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5322.168, "latencies_ms": [5322.168], "images_per_second": 0.188, "prompt_tokens": 780, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. paddle: 1\n3. surfboard: 1\n4. water: 1\n5. land: 1\n6. sky: 1\n7. city: 1\n8. buildings: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14698.5, "ram_available_mb": 48142.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14710.2, "ram_available_mb": 48130.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.455}, "power_stats": {"power_gpu_soc_mean_watts": 16.291, "power_cpu_cv_mean_watts": 2.349, "power_sys_5v0_mean_watts": 7.493, "gpu_utilization_percent_mean": 68.455}, "timestamp": "2026-01-30T09:49:26.884259"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5475.497, "latencies_ms": [5475.497], "images_per_second": 0.183, "prompt_tokens": 784, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The person is in the foreground of the image, paddling a paddleboard on the water. The paddleboard is in the middle of the image, and the person is paddling it towards the right side of the image. The background of the image features a shoreline with buildings and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14710.2, "ram_available_mb": 48130.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14718.2, "ram_available_mb": 48122.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.467}, "power_stats": {"power_gpu_soc_mean_watts": 16.267, "power_cpu_cv_mean_watts": 2.386, "power_sys_5v0_mean_watts": 7.501, "gpu_utilization_percent_mean": 71.467}, "timestamp": "2026-01-30T09:49:34.375146"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2604.628, "latencies_ms": [2604.628], "images_per_second": 0.384, "prompt_tokens": 778, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is standing on a paddleboard in the ocean, holding a paddle.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14718.2, "ram_available_mb": 48122.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 14725.3, "ram_available_mb": 48115.6, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.952}, "power_stats": {"power_gpu_soc_mean_watts": 20.966, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 73.952}, "timestamp": "2026-01-30T09:49:39.009800"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4605.646, "latencies_ms": [4605.646], "images_per_second": 0.217, "prompt_tokens": 776, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image is in black and white, with the water being a dark shade and the sky a lighter one. The person is wearing a wetsuit, which is black, and is holding a paddle, which is also black.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14725.3, "ram_available_mb": 48115.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 14726.4, "ram_available_mb": 48114.5, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.538}, "power_stats": {"power_gpu_soc_mean_watts": 16.748, "power_cpu_cv_mean_watts": 2.25, "power_sys_5v0_mean_watts": 7.494, "gpu_utilization_percent_mean": 68.538}, "timestamp": "2026-01-30T09:49:45.644055"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3931.074, "latencies_ms": [3931.074], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A white computer desk with a laptop, keyboard, mouse, and speakers is placed in front of a window with blinds.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14726.4, "ram_available_mb": 48114.5, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14732.5, "ram_available_mb": 48108.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.312}, "power_stats": {"power_gpu_soc_mean_watts": 21.612, "power_cpu_cv_mean_watts": 2.116, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 77.312}, "timestamp": "2026-01-30T09:49:51.590698"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4415.641, "latencies_ms": [4415.641], "images_per_second": 0.226, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 1, monitor: 1, keyboard: 1, mouse: 1, speakers: 2, printer: 1, lamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14732.5, "ram_available_mb": 48108.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 14739.1, "ram_available_mb": 48101.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.703}, "power_stats": {"power_gpu_soc_mean_watts": 20.65, "power_cpu_cv_mean_watts": 2.252, "power_sys_5v0_mean_watts": 7.948, "gpu_utilization_percent_mean": 75.703}, "timestamp": "2026-01-30T09:49:58.044088"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4183.312, "latencies_ms": [4183.312], "images_per_second": 0.239, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The laptop is to the left of the computer monitor, the keyboard is in front of the monitor, and the speakers are to the right of the monitor.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14739.1, "ram_available_mb": 48101.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 14737.9, "ram_available_mb": 48103.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.457}, "power_stats": {"power_gpu_soc_mean_watts": 20.81, "power_cpu_cv_mean_watts": 2.186, "power_sys_5v0_mean_watts": 7.957, "gpu_utilization_percent_mean": 74.457}, "timestamp": "2026-01-30T09:50:04.262809"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3082.271, "latencies_ms": [3082.271], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A white desk with a computer, laptop, and speakers on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14737.6, "ram_available_mb": 48103.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.84}, "power_stats": {"power_gpu_soc_mean_watts": 23.638, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 8.159, "gpu_utilization_percent_mean": 78.84}, "timestamp": "2026-01-30T09:50:09.369332"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3673.932, "latencies_ms": [3673.932], "images_per_second": 0.272, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the desk is made of white wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 14738.6, "ram_available_mb": 48102.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.133}, "power_stats": {"power_gpu_soc_mean_watts": 22.355, "power_cpu_cv_mean_watts": 2.377, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 75.133}, "timestamp": "2026-01-30T09:50:15.060819"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5906.452, "latencies_ms": [5906.452], "images_per_second": 0.169, "prompt_tokens": 1099, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a bustling highway scene under a concrete overpass, where a green highway sign prominently displays the directions to \"North Ventura 101\" and \"Hollywood Blvd Sunset Blvd\" in white lettering, guiding drivers through the city.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14738.6, "ram_available_mb": 48102.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14736.5, "ram_available_mb": 48104.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.673}, "power_stats": {"power_gpu_soc_mean_watts": 18.362, "power_cpu_cv_mean_watts": 2.273, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 72.673}, "timestamp": "2026-01-30T09:50:23.008076"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6162.321, "latencies_ms": [6162.321], "images_per_second": 0.162, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. sign: 4\n2. car: 3\n3. streetlamp: 1\n4. tree: 1\n5. road: 1\n6. vehicle: 1\n7. road sign: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14736.5, "ram_available_mb": 48104.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14735.6, "ram_available_mb": 48105.3, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.019}, "power_stats": {"power_gpu_soc_mean_watts": 17.889, "power_cpu_cv_mean_watts": 2.28, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 70.019}, "timestamp": "2026-01-30T09:50:31.200922"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4539.28, "latencies_ms": [4539.28], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The sign is located in the foreground of the image, while the vehicles are in the background. The sign is also above the vehicles, indicating that it is a traffic sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14735.6, "ram_available_mb": 48105.3, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14737.8, "ram_available_mb": 48103.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.622}, "power_stats": {"power_gpu_soc_mean_watts": 20.25, "power_cpu_cv_mean_watts": 2.025, "power_sys_5v0_mean_watts": 7.886, "gpu_utilization_percent_mean": 74.622}, "timestamp": "2026-01-30T09:50:37.767948"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3398.093, "latencies_ms": [3398.093], "images_per_second": 0.294, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A busy highway with cars and trucks driving under a bridge with signs pointing to different locations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14737.8, "ram_available_mb": 48103.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.464}, "power_stats": {"power_gpu_soc_mean_watts": 22.651, "power_cpu_cv_mean_watts": 2.032, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 77.464}, "timestamp": "2026-01-30T09:50:43.201129"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5261.042, "latencies_ms": [5261.042], "images_per_second": 0.19, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image depicts a busy highway with several vehicles, including a black SUV, under a green highway sign that indicates the direction to North Ventura and Hollywood Blvd. The sky is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14740.3, "ram_available_mb": 48100.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.07}, "power_stats": {"power_gpu_soc_mean_watts": 19.512, "power_cpu_cv_mean_watts": 2.273, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 72.07}, "timestamp": "2026-01-30T09:50:50.483910"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4704.013, "latencies_ms": [4704.013], "images_per_second": 0.213, "prompt_tokens": 1432, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A red double-decker bus is driving down a street with a sign on the front that says \"15 Aldwych\".", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 14740.3, "ram_available_mb": 48100.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.632}, "power_stats": {"power_gpu_soc_mean_watts": 22.985, "power_cpu_cv_mean_watts": 1.95, "power_sys_5v0_mean_watts": 8.219, "gpu_utilization_percent_mean": 79.632}, "timestamp": "2026-01-30T09:50:57.221439"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5375.487, "latencies_ms": [5375.487], "images_per_second": 0.186, "prompt_tokens": 1446, "response_tokens_est": 39, "n_tiles": 1, "output_text": " 1. red double decker bus\n2. people\n3. trees\n4. buildings\n5. street\n6. license plate\n7. bus number\n8. bus route", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14746.3, "ram_available_mb": 48094.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.4}, "power_stats": {"power_gpu_soc_mean_watts": 21.927, "power_cpu_cv_mean_watts": 2.021, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 77.4}, "timestamp": "2026-01-30T09:51:04.636976"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5661.803, "latencies_ms": [5661.803], "images_per_second": 0.177, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The red double-decker bus is in the foreground, moving towards the left side of the image. The building in the background is far away from the camera, and the trees are in the middle ground.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14746.3, "ram_available_mb": 48094.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14752.2, "ram_available_mb": 48088.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.064}, "power_stats": {"power_gpu_soc_mean_watts": 21.488, "power_cpu_cv_mean_watts": 2.062, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 77.064}, "timestamp": "2026-01-30T09:51:12.326522"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4975.581, "latencies_ms": [4975.581], "images_per_second": 0.201, "prompt_tokens": 1444, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A red double-decker bus is driving down a street in a city, passing by a park with trees and a building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14752.2, "ram_available_mb": 48088.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14757.3, "ram_available_mb": 48083.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.805}, "power_stats": {"power_gpu_soc_mean_watts": 22.522, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 8.135, "gpu_utilization_percent_mean": 80.805}, "timestamp": "2026-01-30T09:51:19.340455"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3935.077, "latencies_ms": [3935.077], "images_per_second": 0.254, "prompt_tokens": 1442, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bus is red with a yellow stripe, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14757.3, "ram_available_mb": 48083.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 14767.8, "ram_available_mb": 48073.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.906}, "power_stats": {"power_gpu_soc_mean_watts": 24.438, "power_cpu_cv_mean_watts": 2.053, "power_sys_5v0_mean_watts": 8.35, "gpu_utilization_percent_mean": 82.906}, "timestamp": "2026-01-30T09:51:25.309834"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3116.865, "latencies_ms": [3116.865], "images_per_second": 0.321, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14767.8, "ram_available_mb": 48073.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14774.9, "ram_available_mb": 48066.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.588, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 84.28}, "timestamp": "2026-01-30T09:51:30.454275"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6507.456, "latencies_ms": [6507.456], "images_per_second": 0.154, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. black and white cat: 1\n2. laptop: 1\n3. keyboard: 1\n4. white wall: 1\n5. white baseboard: 1\n6. white door frame: 1\n7. white door: 1\n8. white wall panel: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14774.9, "ram_available_mb": 48066.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 14787.1, "ram_available_mb": 48053.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.818}, "power_stats": {"power_gpu_soc_mean_watts": 17.752, "power_cpu_cv_mean_watts": 2.316, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 68.818}, "timestamp": "2026-01-30T09:51:38.973435"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5041.896, "latencies_ms": [5041.896], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The black and white cat is positioned to the left of the laptop, which is situated in the middle of the image. The laptop is located in the foreground of the image, while the cat is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14787.1, "ram_available_mb": 48053.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 14798.6, "ram_available_mb": 48042.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.61}, "power_stats": {"power_gpu_soc_mean_watts": 19.855, "power_cpu_cv_mean_watts": 2.208, "power_sys_5v0_mean_watts": 7.871, "gpu_utilization_percent_mean": 72.61}, "timestamp": "2026-01-30T09:51:46.030225"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3213.075, "latencies_ms": [3213.075], "images_per_second": 0.311, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14798.6, "ram_available_mb": 48042.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14808.6, "ram_available_mb": 48032.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.115}, "power_stats": {"power_gpu_soc_mean_watts": 22.742, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 81.115}, "timestamp": "2026-01-30T09:51:51.271047"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3077.479, "latencies_ms": [3077.479], "images_per_second": 0.325, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The cat is black and white, and the laptop is silver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14808.6, "ram_available_mb": 48032.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 14650.7, "ram_available_mb": 48190.2, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.12}, "power_stats": {"power_gpu_soc_mean_watts": 23.348, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 81.12}, "timestamp": "2026-01-30T09:51:56.385886"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3530.246, "latencies_ms": [3530.246], "images_per_second": 0.283, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Two airplanes fly over a bridge and the Sydney Opera House, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 14650.7, "ram_available_mb": 48190.2, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 14702.9, "ram_available_mb": 48138.0, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.517}, "power_stats": {"power_gpu_soc_mean_watts": 22.474, "power_cpu_cv_mean_watts": 2.182, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 76.517}, "timestamp": "2026-01-30T09:52:01.950842"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5953.834, "latencies_ms": [5953.834], "images_per_second": 0.168, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. airplane: 2\n2. bridge: 1\n3. building: 1\n4. city skyline: 1\n5. water: 1\n6. clouds: 1\n7. sky: 1\n8. flags: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14702.9, "ram_available_mb": 48138.0, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 14703.7, "ram_available_mb": 48137.2, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.7}, "power_stats": {"power_gpu_soc_mean_watts": 18.283, "power_cpu_cv_mean_watts": 2.275, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 69.7}, "timestamp": "2026-01-30T09:52:09.950005"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4742.435, "latencies_ms": [4742.435], "images_per_second": 0.211, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The two airplanes are flying above the Sydney Harbour Bridge, which is positioned in the foreground of the image. The Sydney Opera House is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14703.7, "ram_available_mb": 48137.2, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14714.3, "ram_available_mb": 48126.6, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.846}, "power_stats": {"power_gpu_soc_mean_watts": 20.019, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.857, "gpu_utilization_percent_mean": 74.846}, "timestamp": "2026-01-30T09:52:16.706783"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3594.533, "latencies_ms": [3594.533], "images_per_second": 0.278, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two airplanes fly over a large bridge and the Sydney Opera House, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14714.3, "ram_available_mb": 48126.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14721.2, "ram_available_mb": 48119.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.733}, "power_stats": {"power_gpu_soc_mean_watts": 21.97, "power_cpu_cv_mean_watts": 1.963, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 74.733}, "timestamp": "2026-01-30T09:52:22.351752"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3585.4, "latencies_ms": [3585.4], "images_per_second": 0.279, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sky is overcast with a grayish hue, and the bridge is a dark brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14721.2, "ram_available_mb": 48119.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14736.2, "ram_available_mb": 48104.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.655}, "power_stats": {"power_gpu_soc_mean_watts": 22.352, "power_cpu_cv_mean_watts": 1.989, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 77.655}, "timestamp": "2026-01-30T09:52:27.961380"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3268.549, "latencies_ms": [3268.549], "images_per_second": 0.306, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a zebra nursing its young in a grassy field.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14736.2, "ram_available_mb": 48104.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.148, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 79.37}, "timestamp": "2026-01-30T09:52:33.277755"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3147.539, "latencies_ms": [3147.539], "images_per_second": 0.318, "prompt_tokens": 1113, "response_tokens_est": 15, "n_tiles": 1, "output_text": " zebra: 1\nbaby zebra: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14754.4, "ram_available_mb": 48086.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.154}, "power_stats": {"power_gpu_soc_mean_watts": 23.466, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 8.121, "gpu_utilization_percent_mean": 79.154}, "timestamp": "2026-01-30T09:52:38.466971"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6547.568, "latencies_ms": [6547.568], "images_per_second": 0.153, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The zebra is positioned on the left side of the image, with its body facing towards the right side. The baby zebra is positioned on the right side of the image, with its body facing towards the left side. The baby zebra is positioned very close to the mother zebra, with its head near the mother's udder.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14754.4, "ram_available_mb": 48086.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14761.0, "ram_available_mb": 48079.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.145}, "power_stats": {"power_gpu_soc_mean_watts": 17.975, "power_cpu_cv_mean_watts": 2.338, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 70.145}, "timestamp": "2026-01-30T09:52:47.066834"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2993.668, "latencies_ms": [2993.668], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A zebra is nursing its young in a grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14761.0, "ram_available_mb": 48079.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14773.8, "ram_available_mb": 48067.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.417}, "power_stats": {"power_gpu_soc_mean_watts": 23.535, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.13, "gpu_utilization_percent_mean": 81.417}, "timestamp": "2026-01-30T09:52:52.095871"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5005.138, "latencies_ms": [5005.138], "images_per_second": 0.2, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image is in black and white, with the zebra's stripes standing out against the white background. The lighting is natural, coming from the side, casting shadows and highlighting the texture of the zebra's fur.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14773.8, "ram_available_mb": 48067.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14779.8, "ram_available_mb": 48061.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.262}, "power_stats": {"power_gpu_soc_mean_watts": 19.563, "power_cpu_cv_mean_watts": 2.26, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 72.262}, "timestamp": "2026-01-30T09:52:59.130379"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4464.893, "latencies_ms": [4464.893], "images_per_second": 0.224, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image shows a room with a bed, a small round table, and a chair, all placed in front of a window with a view of a building outside.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 14779.8, "ram_available_mb": 48061.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14788.8, "ram_available_mb": 48052.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.194}, "power_stats": {"power_gpu_soc_mean_watts": 20.443, "power_cpu_cv_mean_watts": 2.125, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 73.194}, "timestamp": "2026-01-30T09:53:05.634463"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5900.978, "latencies_ms": [5900.978], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. chair: 2\n3. table: 1\n4. lamp: 1\n5. window: 2\n6. door: 1\n7. wall: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14788.8, "ram_available_mb": 48052.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14797.1, "ram_available_mb": 48043.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.438, "power_cpu_cv_mean_watts": 2.235, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-30T09:53:13.564029"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5048.304, "latencies_ms": [5048.304], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the window and door to the left and right, respectively. The table and chairs are located in the foreground, while the lamp is situated in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14797.1, "ram_available_mb": 48043.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 14814.1, "ram_available_mb": 48026.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.707}, "power_stats": {"power_gpu_soc_mean_watts": 19.396, "power_cpu_cv_mean_watts": 2.286, "power_sys_5v0_mean_watts": 7.873, "gpu_utilization_percent_mean": 73.707}, "timestamp": "2026-01-30T09:53:20.633795"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3092.732, "latencies_ms": [3092.732], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A small room with a bed, a table, and a chair.", "error": null, "sys_before": {"cpu_percent": 40.0, "ram_used_mb": 14814.1, "ram_available_mb": 48026.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.308}, "power_stats": {"power_gpu_soc_mean_watts": 23.329, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.129, "gpu_utilization_percent_mean": 80.308}, "timestamp": "2026-01-30T09:53:25.770771"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3951.947, "latencies_ms": [3951.947], "images_per_second": 0.253, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The room is painted purple and has a bed with a colorful blanket. The room is lit by natural light coming through the windows.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14836.7, "ram_available_mb": 48004.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.061}, "power_stats": {"power_gpu_soc_mean_watts": 21.489, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 77.061}, "timestamp": "2026-01-30T09:53:31.763737"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3224.53, "latencies_ms": [3224.53], "images_per_second": 0.31, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A purple bus with the number 96 on it is driving down the street.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14836.7, "ram_available_mb": 48004.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14847.0, "ram_available_mb": 47993.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.038}, "power_stats": {"power_gpu_soc_mean_watts": 23.5, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.184, "gpu_utilization_percent_mean": 79.038}, "timestamp": "2026-01-30T09:53:37.015228"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5832.5, "latencies_ms": [5832.5], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. person: 1\n3. pole: 1\n4. sign: 1\n5. tree: 1\n6. building: 1\n7. street: 1\n8. sidewalk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14847.0, "ram_available_mb": 47993.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 14643.1, "ram_available_mb": 48197.8, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.102}, "power_stats": {"power_gpu_soc_mean_watts": 18.628, "power_cpu_cv_mean_watts": 2.371, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 72.102}, "timestamp": "2026-01-30T09:53:44.873754"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4634.384, "latencies_ms": [4634.384], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the driver's side facing the camera. The bus is in the foreground, with the background showing a street and buildings.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14643.1, "ram_available_mb": 48197.8, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14658.8, "ram_available_mb": 48182.1, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.658}, "power_stats": {"power_gpu_soc_mean_watts": 20.212, "power_cpu_cv_mean_watts": 2.203, "power_sys_5v0_mean_watts": 7.938, "gpu_utilization_percent_mean": 74.658}, "timestamp": "2026-01-30T09:53:51.546929"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3300.316, "latencies_ms": [3300.316], "images_per_second": 0.303, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A purple bus with the number 96 on it is driving down a street.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14658.8, "ram_available_mb": 48182.1, "ram_percent": 23.3}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14681.1, "ram_available_mb": 48159.8, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.63}, "power_stats": {"power_gpu_soc_mean_watts": 23.281, "power_cpu_cv_mean_watts": 2.122, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 82.63}, "timestamp": "2026-01-30T09:53:56.871175"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3664.298, "latencies_ms": [3664.298], "images_per_second": 0.273, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The bus is purple with a white roof and has a white license plate. The sky is clear and blue.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14681.1, "ram_available_mb": 48159.8, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 14690.6, "ram_available_mb": 48150.3, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.833}, "power_stats": {"power_gpu_soc_mean_watts": 22.357, "power_cpu_cv_mean_watts": 2.231, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 75.833}, "timestamp": "2026-01-30T09:54:02.565636"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3807.572, "latencies_ms": [3807.572], "images_per_second": 0.263, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a white bowl filled with a bunch of green apples, with the apples being the main focus of the image.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 14690.6, "ram_available_mb": 48150.3, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 14688.6, "ram_available_mb": 48152.3, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.194}, "power_stats": {"power_gpu_soc_mean_watts": 21.882, "power_cpu_cv_mean_watts": 2.262, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 77.194}, "timestamp": "2026-01-30T09:54:08.434067"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2647.836, "latencies_ms": [2647.836], "images_per_second": 0.378, "prompt_tokens": 1113, "response_tokens_est": 5, "n_tiles": 1, "output_text": " apple: 10", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14688.6, "ram_available_mb": 48152.3, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14694.1, "ram_available_mb": 48146.8, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.238}, "power_stats": {"power_gpu_soc_mean_watts": 23.56, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 87.238}, "timestamp": "2026-01-30T09:54:13.121551"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4520.532, "latencies_ms": [4520.532], "images_per_second": 0.221, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The apples are in the foreground, with the bowl placed in the middle of the image. The bowl is located in the foreground, and the apples are placed inside it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14694.1, "ram_available_mb": 48146.8, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14696.0, "ram_available_mb": 48144.9, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.868}, "power_stats": {"power_gpu_soc_mean_watts": 20.223, "power_cpu_cv_mean_watts": 2.14, "power_sys_5v0_mean_watts": 7.861, "gpu_utilization_percent_mean": 77.868}, "timestamp": "2026-01-30T09:54:19.682277"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4038.98, "latencies_ms": [4038.98], "images_per_second": 0.248, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In a dimly lit room, a white bowl cradles a collection of vibrant green apples, their glossy skins reflecting the soft light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14696.0, "ram_available_mb": 48144.9, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 14701.5, "ram_available_mb": 48139.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.394}, "power_stats": {"power_gpu_soc_mean_watts": 21.32, "power_cpu_cv_mean_watts": 2.513, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 75.394}, "timestamp": "2026-01-30T09:54:25.736032"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3151.475, "latencies_ms": [3151.475], "images_per_second": 0.317, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The apples are green and shiny, and the bowl is white.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14701.5, "ram_available_mb": 48139.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14706.8, "ram_available_mb": 48134.1, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.962}, "power_stats": {"power_gpu_soc_mean_watts": 22.9, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 83.962}, "timestamp": "2026-01-30T09:54:30.917154"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4276.744, "latencies_ms": [4276.744], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter, catcher, and umpire all in position, ready to react to the pitch.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14706.8, "ram_available_mb": 48134.1, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14708.2, "ram_available_mb": 48132.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.417}, "power_stats": {"power_gpu_soc_mean_watts": 20.867, "power_cpu_cv_mean_watts": 2.137, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 74.417}, "timestamp": "2026-01-30T09:54:37.227425"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6139.24, "latencies_ms": [6139.24], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. home plate: 1\n6. grass: 1\n7. dirt: 1\n8. net: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14708.2, "ram_available_mb": 48132.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 14708.5, "ram_available_mb": 48132.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.235}, "power_stats": {"power_gpu_soc_mean_watts": 18.391, "power_cpu_cv_mean_watts": 2.364, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 71.235}, "timestamp": "2026-01-30T09:54:45.377080"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4755.323, "latencies_ms": [4755.323], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The pitcher is standing on the mound, which is located in the middle of the field.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14708.5, "ram_available_mb": 48132.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14714.7, "ram_available_mb": 48126.2, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.154}, "power_stats": {"power_gpu_soc_mean_watts": 19.817, "power_cpu_cv_mean_watts": 2.178, "power_sys_5v0_mean_watts": 7.838, "gpu_utilization_percent_mean": 73.154}, "timestamp": "2026-01-30T09:54:52.151113"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7322.481, "latencies_ms": [7322.481], "images_per_second": 0.137, "prompt_tokens": 1111, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image captures a moment in a baseball game, with the batter, wearing a red helmet and white uniform, in the midst of swinging his bat at a pitch. The umpire, dressed in a blue shirt and black pants, stands behind the catcher, who is crouched in anticipation. The field is a vibrant green, contrasting with the brown dirt of the infield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14714.7, "ram_available_mb": 48126.2, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 14733.2, "ram_available_mb": 48107.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.328}, "power_stats": {"power_gpu_soc_mean_watts": 17.339, "power_cpu_cv_mean_watts": 2.39, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 71.328}, "timestamp": "2026-01-30T09:55:01.495959"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6785.651, "latencies_ms": [6785.651], "images_per_second": 0.147, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the lush green of the field contrasting against the brown dirt of the infield. The players are dressed in crisp white uniforms, their red helmets adding a pop of color to the scene. The lighting is natural, casting a warm glow over the field as the sun shines down on the game.", "error": null, "sys_before": {"cpu_percent": 42.9, "ram_used_mb": 14733.2, "ram_available_mb": 48107.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 14735.5, "ram_available_mb": 48105.4, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.263}, "power_stats": {"power_gpu_soc_mean_watts": 17.306, "power_cpu_cv_mean_watts": 2.692, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 69.263}, "timestamp": "2026-01-30T09:55:10.305429"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4303.783, "latencies_ms": [4303.783], "images_per_second": 0.232, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A white cake with red and blue berries is on a table with a red tablecloth, surrounded by wine glasses, plates of cheese, and bread.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14735.5, "ram_available_mb": 48105.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14738.3, "ram_available_mb": 48102.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.086}, "power_stats": {"power_gpu_soc_mean_watts": 20.823, "power_cpu_cv_mean_watts": 2.06, "power_sys_5v0_mean_watts": 7.907, "gpu_utilization_percent_mean": 78.086}, "timestamp": "2026-01-30T09:55:16.639061"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4594.833, "latencies_ms": [4594.833], "images_per_second": 0.218, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " cake: 1, glasses: 10, plates: 10, knives: 2, cups: 1, bowls: 1, grapes: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14738.3, "ram_available_mb": 48102.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14740.1, "ram_available_mb": 48100.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.237}, "power_stats": {"power_gpu_soc_mean_watts": 20.064, "power_cpu_cv_mean_watts": 2.15, "power_sys_5v0_mean_watts": 7.907, "gpu_utilization_percent_mean": 72.237}, "timestamp": "2026-01-30T09:55:23.277850"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6033.61, "latencies_ms": [6033.61], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The cake is located in the foreground, to the left of the plates of cheese and grapes. The plates of cheese and grapes are in the middle of the table, with the cake to the left of them. The glasses are located in the background, behind the plates of cheese and grapes.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14740.1, "ram_available_mb": 48100.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 14739.2, "ram_available_mb": 48101.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.72}, "power_stats": {"power_gpu_soc_mean_watts": 18.461, "power_cpu_cv_mean_watts": 2.291, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 70.72}, "timestamp": "2026-01-30T09:55:31.348966"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3329.41, "latencies_ms": [3329.41], "images_per_second": 0.3, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A table is set with a cake, plates of food, and glasses of water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14739.2, "ram_available_mb": 48101.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.259}, "power_stats": {"power_gpu_soc_mean_watts": 22.985, "power_cpu_cv_mean_watts": 1.884, "power_sys_5v0_mean_watts": 8.097, "gpu_utilization_percent_mean": 77.259}, "timestamp": "2026-01-30T09:55:36.702865"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4366.798, "latencies_ms": [4366.798], "images_per_second": 0.229, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image features a red tablecloth, with a white cake and a plate of food on it. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14741.1, "ram_available_mb": 48099.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14744.6, "ram_available_mb": 48096.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.746, "power_cpu_cv_mean_watts": 2.126, "power_sys_5v0_mean_watts": 7.931, "gpu_utilization_percent_mean": 76.444}, "timestamp": "2026-01-30T09:55:43.090751"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3246.612, "latencies_ms": [3246.612], "images_per_second": 0.308, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is riding a wave on a blue surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14744.6, "ram_available_mb": 48096.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.658, "power_cpu_cv_mean_watts": 1.914, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 81.185}, "timestamp": "2026-01-30T09:55:48.399169"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5942.243, "latencies_ms": [5942.243], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. wave: 1\n4. water: 1\n5. sky: 0\n6. clouds: 0\n7. land: 0\n8. surfboard: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14743.6, "ram_available_mb": 48097.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 14744.0, "ram_available_mb": 48096.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.84}, "power_stats": {"power_gpu_soc_mean_watts": 18.389, "power_cpu_cv_mean_watts": 2.339, "power_sys_5v0_mean_watts": 7.836, "gpu_utilization_percent_mean": 71.84}, "timestamp": "2026-01-30T09:55:56.355041"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4884.157, "latencies_ms": [4884.157], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave in the background. The surfer is on the left side of the wave, and the wave is on the right side.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14744.0, "ram_available_mb": 48096.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 14745.7, "ram_available_mb": 48095.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.394, "power_cpu_cv_mean_watts": 2.208, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T09:56:03.261795"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3112.125, "latencies_ms": [3112.125], "images_per_second": 0.321, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14745.7, "ram_available_mb": 48095.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14743.5, "ram_available_mb": 48097.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.524, "power_cpu_cv_mean_watts": 1.843, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 81.76}, "timestamp": "2026-01-30T09:56:08.395916"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6359.357, "latencies_ms": [6359.357], "images_per_second": 0.157, "prompt_tokens": 1109, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a surfer in a black wetsuit riding a wave in the ocean, with the water appearing a deep green color and the sky not visible in the frame. The lighting is natural, suggesting it is daytime, and the surfer is in the foreground, with the wave in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14743.5, "ram_available_mb": 48097.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14747.4, "ram_available_mb": 48093.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.604}, "power_stats": {"power_gpu_soc_mean_watts": 18.048, "power_cpu_cv_mean_watts": 2.268, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 72.604}, "timestamp": "2026-01-30T09:56:16.797690"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3505.535, "latencies_ms": [3505.535], "images_per_second": 0.285, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of children are posing for a black and white photo in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 14747.4, "ram_available_mb": 48093.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14753.4, "ram_available_mb": 48087.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.271, "power_cpu_cv_mean_watts": 1.961, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 76.379}, "timestamp": "2026-01-30T09:56:22.328871"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5306.47, "latencies_ms": [5306.47], "images_per_second": 0.188, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " 1. group of children\n2. brick wall\n3. children's clothing\n4. children's shoes\n5. children's hair\n6. children's faces\n7. children's eyes\n8. children's noses", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14752.9, "ram_available_mb": 48088.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 12.6, "ram_used_mb": 14751.8, "ram_available_mb": 48089.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.222}, "power_stats": {"power_gpu_soc_mean_watts": 19.3, "power_cpu_cv_mean_watts": 2.591, "power_sys_5v0_mean_watts": 7.869, "gpu_utilization_percent_mean": 72.222}, "timestamp": "2026-01-30T09:56:29.673103"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5559.772, "latencies_ms": [5559.772], "images_per_second": 0.18, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The group of children is positioned in front of a brick building, with the children sitting on the ground and standing behind them. The children are arranged in rows, with some sitting and others standing, creating a sense of depth and perspective in the image.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14751.8, "ram_available_mb": 48089.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.891}, "power_stats": {"power_gpu_soc_mean_watts": 18.6, "power_cpu_cv_mean_watts": 2.246, "power_sys_5v0_mean_watts": 7.813, "gpu_utilization_percent_mean": 73.891}, "timestamp": "2026-01-30T09:56:37.249022"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3522.267, "latencies_ms": [3522.267], "images_per_second": 0.284, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of children are posing for a black and white photo in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.172}, "power_stats": {"power_gpu_soc_mean_watts": 22.173, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 7.973, "gpu_utilization_percent_mean": 77.172}, "timestamp": "2026-01-30T09:56:42.789194"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6106.324, "latencies_ms": [6106.324], "images_per_second": 0.164, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image is a black and white photograph with a grainy texture, capturing a moment of unity among the children. The lighting is soft and diffused, creating a sense of nostalgia and warmth. The children are dressed in their school uniforms, which are predominantly white and black, suggesting a formal setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.365}, "power_stats": {"power_gpu_soc_mean_watts": 18.136, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 70.365}, "timestamp": "2026-01-30T09:56:50.946485"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3452.837, "latencies_ms": [3452.837], "images_per_second": 0.29, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate of bread and a knife on a table with a wine glass in the background.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 13980.7, "ram_available_mb": 48860.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.336, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 81.0}, "timestamp": "2026-01-30T09:56:56.445167"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4568.457, "latencies_ms": [4568.457], "images_per_second": 0.219, "prompt_tokens": 1114, "response_tokens_est": 36, "n_tiles": 1, "output_text": " knife: 1, plate: 1, bread: 1, cup: 1, wine glass: 1, napkin: 1, butter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.7, "ram_available_mb": 48860.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 13980.3, "ram_available_mb": 48860.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.658}, "power_stats": {"power_gpu_soc_mean_watts": 20.538, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 7.872, "gpu_utilization_percent_mean": 75.658}, "timestamp": "2026-01-30T09:57:03.030848"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6556.553, "latencies_ms": [6556.553], "images_per_second": 0.153, "prompt_tokens": 1118, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the bread and butter knife in the center, and the wine glass in the background. The bread is placed on the left side of the plate, while the butter knife is on the right side. The wine glass is located behind the plate, and the person is visible in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13980.3, "ram_available_mb": 48860.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13980.0, "ram_available_mb": 48860.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.218}, "power_stats": {"power_gpu_soc_mean_watts": 17.489, "power_cpu_cv_mean_watts": 2.025, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 70.218}, "timestamp": "2026-01-30T09:57:11.615611"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3834.344, "latencies_ms": [3834.344], "images_per_second": 0.261, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In a cozy restaurant, a plate of bread and cheese is served on a table, accompanied by a glass of red wine.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13980.0, "ram_available_mb": 48860.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 13979.2, "ram_available_mb": 48861.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.156}, "power_stats": {"power_gpu_soc_mean_watts": 21.584, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 78.156}, "timestamp": "2026-01-30T09:57:17.468162"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4241.802, "latencies_ms": [4241.802], "images_per_second": 0.236, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image features a wooden table with a white plate of food, a knife, and a wine glass. The lighting is natural, and the colors are warm.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13979.2, "ram_available_mb": 48861.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13978.2, "ram_available_mb": 48862.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.844, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 72.057}, "timestamp": "2026-01-30T09:57:23.726003"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4263.396, "latencies_ms": [4263.396], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A skier in a colorful outfit is jumping in the air with skis attached, while another skier in a white outfit stands nearby.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13978.2, "ram_available_mb": 48862.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13977.5, "ram_available_mb": 48863.4, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.385, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-30T09:57:30.033983"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6175.537, "latencies_ms": [6175.537], "images_per_second": 0.162, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skier: 1\n2. ski poles: 2\n3. skis: 2\n4. snow: 1\n5. trees: 4\n6. person: 1\n7. helmet: 1\n8. goggles: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13977.5, "ram_available_mb": 48863.4, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13977.1, "ram_available_mb": 48863.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.96}, "power_stats": {"power_gpu_soc_mean_watts": 18.163, "power_cpu_cv_mean_watts": 1.979, "power_sys_5v0_mean_watts": 7.825, "gpu_utilization_percent_mean": 70.96}, "timestamp": "2026-01-30T09:57:38.238433"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4576.44, "latencies_ms": [4576.44], "images_per_second": 0.219, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The skier is in the foreground, jumping over a snow ramp, while the trees are in the background. The skier is closer to the camera than the trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13977.1, "ram_available_mb": 48863.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 13977.6, "ram_available_mb": 48863.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.632}, "power_stats": {"power_gpu_soc_mean_watts": 20.011, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.819, "gpu_utilization_percent_mean": 75.632}, "timestamp": "2026-01-30T09:57:44.876440"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4028.289, "latencies_ms": [4028.289], "images_per_second": 0.248, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A skier is jumping in the air with skis while wearing a colorful outfit. There are other skiers in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13977.6, "ram_available_mb": 48863.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 13978.3, "ram_available_mb": 48862.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.121}, "power_stats": {"power_gpu_soc_mean_watts": 21.331, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.892, "gpu_utilization_percent_mean": 77.121}, "timestamp": "2026-01-30T09:57:50.947984"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5099.194, "latencies_ms": [5099.194], "images_per_second": 0.196, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a skier in mid-air against a clear blue sky, with snow-covered trees in the background. The skier is wearing a colorful jacket and pants, and is holding ski poles.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13978.3, "ram_available_mb": 48862.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 13978.3, "ram_available_mb": 48862.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.262}, "power_stats": {"power_gpu_soc_mean_watts": 19.298, "power_cpu_cv_mean_watts": 1.831, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 74.262}, "timestamp": "2026-01-30T09:57:58.066941"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3317.481, "latencies_ms": [3317.481], "images_per_second": 0.301, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is walking on a snowy mountain with ski poles and wearing a green jacket.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 13978.3, "ram_available_mb": 48862.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13978.1, "ram_available_mb": 48862.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.037}, "power_stats": {"power_gpu_soc_mean_watts": 23.07, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 77.037}, "timestamp": "2026-01-30T09:58:03.430801"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5807.242, "latencies_ms": [5807.242], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. ski poles: 2\n3. backpack: 1\n4. snow: 1\n5. rocks: 2\n6. trees: 2\n7. clouds: 2\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13978.1, "ram_available_mb": 48862.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 13978.0, "ram_available_mb": 48862.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.633}, "power_stats": {"power_gpu_soc_mean_watts": 18.478, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 72.633}, "timestamp": "2026-01-30T09:58:11.259061"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4803.985, "latencies_ms": [4803.985], "images_per_second": 0.208, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The person is in the foreground of the image, with the snow-covered landscape and mountains in the background. The person is facing away from the camera, with the mountains and sky visible behind them.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13977.8, "ram_available_mb": 48863.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13977.5, "ram_available_mb": 48863.4, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.439}, "power_stats": {"power_gpu_soc_mean_watts": 19.749, "power_cpu_cv_mean_watts": 1.847, "power_sys_5v0_mean_watts": 7.898, "gpu_utilization_percent_mean": 73.439}, "timestamp": "2026-01-30T09:58:18.095240"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3496.613, "latencies_ms": [3496.613], "images_per_second": 0.286, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is walking on a snowy mountain trail with ski poles, wearing a green shirt and black pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13977.5, "ram_available_mb": 48863.4, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 13976.9, "ram_available_mb": 48864.0, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.621}, "power_stats": {"power_gpu_soc_mean_watts": 22.312, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 77.621}, "timestamp": "2026-01-30T09:58:23.606586"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5230.001, "latencies_ms": [5230.001], "images_per_second": 0.191, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a person wearing a green jacket and black pants, standing on a snowy mountain with a clear blue sky and white clouds in the background. The snow is pristine and untouched, with the person's footprints visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13976.9, "ram_available_mb": 48864.0, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.205}, "power_stats": {"power_gpu_soc_mean_watts": 19.56, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 7.852, "gpu_utilization_percent_mean": 70.205}, "timestamp": "2026-01-30T09:58:30.848889"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3192.318, "latencies_ms": [3192.318], "images_per_second": 0.313, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A banana and a chocolate donut are placed in a plastic bag.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13976.3, "ram_available_mb": 48864.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.885}, "power_stats": {"power_gpu_soc_mean_watts": 22.865, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 80.885}, "timestamp": "2026-01-30T09:58:36.069726"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3251.074, "latencies_ms": [3251.074], "images_per_second": 0.308, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " banana: 1, donut: 1, plastic bag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13976.3, "ram_available_mb": 48864.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.519}, "power_stats": {"power_gpu_soc_mean_watts": 22.925, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 80.519}, "timestamp": "2026-01-30T09:58:41.341974"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4652.303, "latencies_ms": [4652.303], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The banana is positioned to the left of the donut, which is placed in the center of the image. The banana is in the foreground, while the donut is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.051}, "power_stats": {"power_gpu_soc_mean_watts": 20.329, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 7.908, "gpu_utilization_percent_mean": 74.051}, "timestamp": "2026-01-30T09:58:48.009946"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3060.893, "latencies_ms": [3060.893], "images_per_second": 0.327, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana and a donut are placed in a plastic bag.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.84}, "power_stats": {"power_gpu_soc_mean_watts": 23.286, "power_cpu_cv_mean_watts": 1.154, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 77.84}, "timestamp": "2026-01-30T09:58:53.129837"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4973.508, "latencies_ms": [4973.508], "images_per_second": 0.201, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a banana and a donut in a plastic bag, with the banana being yellow and the donut being brown. The lighting is dim, and the bag appears to be made of clear plastic.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.098}, "power_stats": {"power_gpu_soc_mean_watts": 19.916, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 73.098}, "timestamp": "2026-01-30T09:59:00.138026"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4767.042, "latencies_ms": [4767.042], "images_per_second": 0.21, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design and the words \"PIRATE'S TREASURES\" is placed on a glass surface next to a large knife.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 13977.1, "ram_available_mb": 48863.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.375}, "power_stats": {"power_gpu_soc_mean_watts": 19.532, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.819, "gpu_utilization_percent_mean": 72.375}, "timestamp": "2026-01-30T09:59:06.952929"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3568.789, "latencies_ms": [3568.789], "images_per_second": 0.28, "prompt_tokens": 1113, "response_tokens_est": 20, "n_tiles": 1, "output_text": " mug: 1, knife: 1, glass: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13977.1, "ram_available_mb": 48863.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.793}, "power_stats": {"power_gpu_soc_mean_watts": 22.283, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 81.793}, "timestamp": "2026-01-30T09:59:12.557969"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4481.72, "latencies_ms": [4481.72], "images_per_second": 0.223, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The mug is located to the left of the knife, which is placed in the foreground of the image. The mug is positioned closer to the camera than the knife.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13976.9, "ram_available_mb": 48864.0, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.691, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 7.924, "gpu_utilization_percent_mean": 74.054}, "timestamp": "2026-01-30T09:59:19.081246"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4349.009, "latencies_ms": [4349.009], "images_per_second": 0.23, "prompt_tokens": 1111, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design is sitting on a glass table. Next to the mug is a large knife with a black handle.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13976.9, "ram_available_mb": 48864.0, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 13977.4, "ram_available_mb": 48863.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.694}, "power_stats": {"power_gpu_soc_mean_watts": 20.577, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 74.694}, "timestamp": "2026-01-30T09:59:25.442026"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3615.531, "latencies_ms": [3615.531], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The mug is white and the knife is black. The mug is on a glass table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13977.4, "ram_available_mb": 48863.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.133}, "power_stats": {"power_gpu_soc_mean_watts": 21.796, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.919, "gpu_utilization_percent_mean": 81.133}, "timestamp": "2026-01-30T09:59:31.079366"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5055.774, "latencies_ms": [5055.774], "images_per_second": 0.198, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A group of people are gathered around a wooden counter in a wine tasting room, with a man in a white shirt and a woman in a black shirt standing out.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13976.7, "ram_available_mb": 48864.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 13976.8, "ram_available_mb": 48864.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.595}, "power_stats": {"power_gpu_soc_mean_watts": 21.922, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 78.595}, "timestamp": "2026-01-30T09:59:38.163610"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6677.61, "latencies_ms": [6677.61], "images_per_second": 0.15, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13976.8, "ram_available_mb": 48864.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.732}, "power_stats": {"power_gpu_soc_mean_watts": 20.062, "power_cpu_cv_mean_watts": 2.075, "power_sys_5v0_mean_watts": 7.949, "gpu_utilization_percent_mean": 73.732}, "timestamp": "2026-01-30T09:59:46.897908"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8133.816, "latencies_ms": [8133.816], "images_per_second": 0.123, "prompt_tokens": 1450, "response_tokens_est": 80, "n_tiles": 1, "output_text": " The man in the white cap is standing to the left of the man in the blue shirt, who is standing in front of the counter. The woman in the black shirt is standing to the right of the man in the blue shirt, and the man in the white shirt is standing behind the counter. The man in the white cap is standing closer to the camera than the man in the blue shirt.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13976.2, "ram_available_mb": 48864.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 13975.1, "ram_available_mb": 48865.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.101}, "power_stats": {"power_gpu_soc_mean_watts": 18.656, "power_cpu_cv_mean_watts": 2.072, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 76.101}, "timestamp": "2026-01-30T09:59:57.053548"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4623.249, "latencies_ms": [4623.249], "images_per_second": 0.216, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of people are gathered in a wine tasting room, standing around a wooden counter with wine bottles on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13975.1, "ram_available_mb": 48865.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13976.4, "ram_available_mb": 48864.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.132}, "power_stats": {"power_gpu_soc_mean_watts": 22.813, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 80.132}, "timestamp": "2026-01-30T10:00:03.696321"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4552.82, "latencies_ms": [4552.82], "images_per_second": 0.22, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm ambiance, and the wooden floor is polished and clean.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13976.4, "ram_available_mb": 48864.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13975.6, "ram_available_mb": 48865.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.108}, "power_stats": {"power_gpu_soc_mean_watts": 23.596, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 79.108}, "timestamp": "2026-01-30T10:00:10.269367"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4615.935, "latencies_ms": [4615.935], "images_per_second": 0.217, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, there are two white birds standing in a field of tall grass, with a large body of water and a group of boats docked nearby, under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13975.6, "ram_available_mb": 48865.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.526}, "power_stats": {"power_gpu_soc_mean_watts": 20.318, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.904, "gpu_utilization_percent_mean": 73.526}, "timestamp": "2026-01-30T10:00:16.908551"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5835.191, "latencies_ms": [5835.191], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. birds: 2\n2. grass: 1\n3. water: 1\n4. sky: 1\n5. clouds: 1\n6. boats: 1\n7. dock: 1\n8. crane: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.571}, "power_stats": {"power_gpu_soc_mean_watts": 18.364, "power_cpu_cv_mean_watts": 1.954, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 71.571}, "timestamp": "2026-01-30T10:00:24.762427"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4032.026, "latencies_ms": [4032.026], "images_per_second": 0.248, "prompt_tokens": 1117, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The two white birds are in the foreground, while the boats are in the background. The birds are closer to the camera than the boats.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13975.0, "ram_available_mb": 48865.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.97}, "power_stats": {"power_gpu_soc_mean_watts": 21.685, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 76.97}, "timestamp": "2026-01-30T10:00:30.813395"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4660.143, "latencies_ms": [4660.143], "images_per_second": 0.215, "prompt_tokens": 1111, "response_tokens_est": 38, "n_tiles": 1, "output_text": " In the foreground, two white birds are standing in a field of tall grass. In the background, there is a body of water with several boats docked, and a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13975.0, "ram_available_mb": 48865.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 13975.2, "ram_available_mb": 48865.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.538}, "power_stats": {"power_gpu_soc_mean_watts": 19.962, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.917, "gpu_utilization_percent_mean": 73.538}, "timestamp": "2026-01-30T10:00:37.492557"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3884.901, "latencies_ms": [3884.901], "images_per_second": 0.257, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a vibrant green field with two white birds, a cloudy sky, and a body of water in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13975.2, "ram_available_mb": 48865.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 13975.2, "ram_available_mb": 48865.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.938}, "power_stats": {"power_gpu_soc_mean_watts": 21.772, "power_cpu_cv_mean_watts": 1.465, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 74.938}, "timestamp": "2026-01-30T10:00:43.419569"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3683.104, "latencies_ms": [3683.104], "images_per_second": 0.272, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom with a checkered tile wall and a window.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 13975.2, "ram_available_mb": 48865.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13976.1, "ram_available_mb": 48864.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.233}, "power_stats": {"power_gpu_soc_mean_watts": 21.768, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 7.905, "gpu_utilization_percent_mean": 80.233}, "timestamp": "2026-01-30T10:00:49.138614"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6717.52, "latencies_ms": [6717.52], "images_per_second": 0.149, "prompt_tokens": 1114, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. man: 1\n2. toilet: 1\n3. man's pants: 1\n4. man's shirt: 1\n5. man's shoes: 1\n6. man's socks: 1\n7. man's belt: 1\n8. man's belt buckle: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13976.1, "ram_available_mb": 48864.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 13976.6, "ram_available_mb": 48864.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.911}, "power_stats": {"power_gpu_soc_mean_watts": 17.555, "power_cpu_cv_mean_watts": 2.031, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 70.911}, "timestamp": "2026-01-30T10:00:57.871310"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4820.113, "latencies_ms": [4820.113], "images_per_second": 0.207, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is sitting on the toilet, which is located in the foreground of the image. The sink is positioned to the left of the toilet, and the window is located above the sink.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13976.6, "ram_available_mb": 48864.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.025}, "power_stats": {"power_gpu_soc_mean_watts": 19.708, "power_cpu_cv_mean_watts": 1.763, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 75.025}, "timestamp": "2026-01-30T10:01:04.710453"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3320.785, "latencies_ms": [3320.785], "images_per_second": 0.301, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom, wearing a shirt and pants.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13976.4, "ram_available_mb": 48864.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.593}, "power_stats": {"power_gpu_soc_mean_watts": 22.851, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 8.105, "gpu_utilization_percent_mean": 79.593}, "timestamp": "2026-01-30T10:01:10.055791"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3501.789, "latencies_ms": [3501.789], "images_per_second": 0.286, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image is in black and white, and the man is wearing a black shirt and jeans.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13976.4, "ram_available_mb": 48864.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.172}, "power_stats": {"power_gpu_soc_mean_watts": 22.283, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 79.172}, "timestamp": "2026-01-30T10:01:15.602415"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3969.843, "latencies_ms": [3969.843], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a group of people are standing on a snow-covered mountain, with a large rock formation in the background.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13975.8, "ram_available_mb": 48865.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13975.3, "ram_available_mb": 48865.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.031}, "power_stats": {"power_gpu_soc_mean_watts": 21.471, "power_cpu_cv_mean_watts": 1.59, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 76.031}, "timestamp": "2026-01-30T10:01:21.597981"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6182.433, "latencies_ms": [6182.433], "images_per_second": 0.162, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. mountain: 1\n2. people: 4\n3. ski tracks: 3\n4. snow: 1\n5. rocks: 1\n6. sky: 1\n7. mountain peak: 1\n8. snow-covered slope: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13975.3, "ram_available_mb": 48865.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 13975.2, "ram_available_mb": 48865.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.717}, "power_stats": {"power_gpu_soc_mean_watts": 18.171, "power_cpu_cv_mean_watts": 2.063, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 71.717}, "timestamp": "2026-01-30T10:01:29.818877"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4973.842, "latencies_ms": [4973.842], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The group of people is positioned in the foreground of the image, with the mountain range in the background. The mountain range is located to the right of the group, and the sky is visible above the mountain range.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13976.8, "ram_available_mb": 48864.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 13846.7, "ram_available_mb": 48994.2, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.476}, "power_stats": {"power_gpu_soc_mean_watts": 19.516, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 7.877, "gpu_utilization_percent_mean": 71.476}, "timestamp": "2026-01-30T10:01:36.812482"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3500.126, "latencies_ms": [3500.126], "images_per_second": 0.286, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are standing on a snowy mountain, with a large rock formation in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13846.7, "ram_available_mb": 48994.2, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13848.3, "ram_available_mb": 48992.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.602, "power_cpu_cv_mean_watts": 1.492, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 77.552}, "timestamp": "2026-01-30T10:01:42.331427"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5530.056, "latencies_ms": [5530.056], "images_per_second": 0.181, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a group of people standing on a snow-covered mountain, with the sky above them being a clear blue. The snow is pristine white, and the mountain's surface is rugged and rocky, with some areas appearing to be covered in snow.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13848.3, "ram_available_mb": 48992.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 13848.6, "ram_available_mb": 48992.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.457}, "power_stats": {"power_gpu_soc_mean_watts": 18.943, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 73.457}, "timestamp": "2026-01-30T10:01:49.904433"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4262.9, "latencies_ms": [4262.9], "images_per_second": 0.235, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A white bowl filled with rice, broccoli, and a red bean dish is placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13848.6, "ram_available_mb": 48992.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13851.0, "ram_available_mb": 48989.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.629}, "power_stats": {"power_gpu_soc_mean_watts": 23.699, "power_cpu_cv_mean_watts": 1.27, "power_sys_5v0_mean_watts": 8.33, "gpu_utilization_percent_mean": 80.629}, "timestamp": "2026-01-30T10:01:56.214000"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4224.257, "latencies_ms": [4224.257], "images_per_second": 0.237, "prompt_tokens": 1446, "response_tokens_est": 19, "n_tiles": 1, "output_text": " broccoli: 2, rice: 1, bean: 1, vegetable: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13851.0, "ram_available_mb": 48989.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13850.4, "ram_available_mb": 48990.5, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.057}, "power_stats": {"power_gpu_soc_mean_watts": 23.89, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.239, "gpu_utilization_percent_mean": 83.057}, "timestamp": "2026-01-30T10:02:02.462458"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5627.961, "latencies_ms": [5627.961], "images_per_second": 0.178, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The broccoli is located to the left of the rice, which is in the center of the bowl. The red bean dish is on top of the rice, and the white rice is on the bottom of the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13850.4, "ram_available_mb": 48990.5, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13850.7, "ram_available_mb": 48990.2, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.488, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-30T10:02:10.151309"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3528.865, "latencies_ms": [3528.865], "images_per_second": 0.283, "prompt_tokens": 1444, "response_tokens_est": 9, "n_tiles": 1, "output_text": " A bowl of food is on a table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13850.7, "ram_available_mb": 48990.2, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13850.6, "ram_available_mb": 48990.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.897}, "power_stats": {"power_gpu_soc_mean_watts": 25.237, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.401, "gpu_utilization_percent_mean": 88.897}, "timestamp": "2026-01-30T10:02:15.721861"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3533.007, "latencies_ms": [3533.007], "images_per_second": 0.283, "prompt_tokens": 1442, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The bowl is white and the food is colorful.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13850.6, "ram_available_mb": 48990.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13854.9, "ram_available_mb": 48986.0, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.552}, "power_stats": {"power_gpu_soc_mean_watts": 25.474, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.432, "gpu_utilization_percent_mean": 85.552}, "timestamp": "2026-01-30T10:02:21.272484"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4045.581, "latencies_ms": [4045.581], "images_per_second": 0.247, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A person is riding a skateboard on a wooden ramp, wearing black and white sneakers with a checkered pattern on the bottom.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13854.9, "ram_available_mb": 48986.0, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.697}, "power_stats": {"power_gpu_soc_mean_watts": 21.186, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 77.697}, "timestamp": "2026-01-30T10:02:27.353143"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6623.917, "latencies_ms": [6623.917], "images_per_second": 0.151, "prompt_tokens": 1113, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. wooden plank: 1\n4. grass: 1\n5. wooden board: 1\n6. white letters: 1\n7. black and white checkered pattern: 1\n8. black and white shoes: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 13854.0, "ram_available_mb": 48986.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.909}, "power_stats": {"power_gpu_soc_mean_watts": 17.963, "power_cpu_cv_mean_watts": 2.054, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 68.909}, "timestamp": "2026-01-30T10:02:35.994237"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4341.25, "latencies_ms": [4341.25], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The skateboard is in the foreground, with the person's feet on it. The person is wearing jeans, and the skateboard is on a wooden ramp.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13854.0, "ram_available_mb": 48986.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.917}, "power_stats": {"power_gpu_soc_mean_watts": 20.754, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.917, "gpu_utilization_percent_mean": 75.917}, "timestamp": "2026-01-30T10:02:42.382242"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3390.581, "latencies_ms": [3390.581], "images_per_second": 0.295, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is riding a skateboard on a wooden ramp in a grassy area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13855.0, "ram_available_mb": 48985.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.296}, "power_stats": {"power_gpu_soc_mean_watts": 22.449, "power_cpu_cv_mean_watts": 1.305, "power_sys_5v0_mean_watts": 7.966, "gpu_utilization_percent_mean": 84.296}, "timestamp": "2026-01-30T10:02:47.802970"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4732.665, "latencies_ms": [4732.665], "images_per_second": 0.211, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a person wearing black and white sneakers with a checkered pattern on the bottom, standing on a wooden ramp. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13855.0, "ram_available_mb": 48985.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 13855.0, "ram_available_mb": 48985.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.718}, "power_stats": {"power_gpu_soc_mean_watts": 20.084, "power_cpu_cv_mean_watts": 1.674, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 75.718}, "timestamp": "2026-01-30T10:02:54.566493"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3335.757, "latencies_ms": [3335.757], "images_per_second": 0.3, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13855.0, "ram_available_mb": 48985.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13854.5, "ram_available_mb": 48986.4, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.852}, "power_stats": {"power_gpu_soc_mean_watts": 22.985, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 78.852}, "timestamp": "2026-01-30T10:02:59.948939"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2435.163, "latencies_ms": [2435.163], "images_per_second": 0.411, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 4", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13854.5, "ram_available_mb": 48986.4, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13855.1, "ram_available_mb": 48985.8, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 90.4}, "power_stats": {"power_gpu_soc_mean_watts": 24.595, "power_cpu_cv_mean_watts": 1.221, "power_sys_5v0_mean_watts": 8.131, "gpu_utilization_percent_mean": 90.4}, "timestamp": "2026-01-30T10:03:04.406765"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4962.425, "latencies_ms": [4962.425], "images_per_second": 0.202, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The bananas are located in the foreground of the image, with the keyboard and computer monitor in the background. The bananas are positioned to the left of the keyboard, and the computer monitor is to the right of the keyboard.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13855.1, "ram_available_mb": 48985.8, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13854.3, "ram_available_mb": 48986.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.238}, "power_stats": {"power_gpu_soc_mean_watts": 19.983, "power_cpu_cv_mean_watts": 1.888, "power_sys_5v0_mean_watts": 7.91, "gpu_utilization_percent_mean": 73.238}, "timestamp": "2026-01-30T10:03:11.401783"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3291.475, "latencies_ms": [3291.475], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13854.3, "ram_available_mb": 48986.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.464, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 80.222}, "timestamp": "2026-01-30T10:03:16.735885"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3143.255, "latencies_ms": [3143.255], "images_per_second": 0.318, "prompt_tokens": 1109, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bananas are yellow and ripe, and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13854.6, "ram_available_mb": 48986.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13854.3, "ram_available_mb": 48986.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.328, "power_cpu_cv_mean_watts": 1.248, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 79.5}, "timestamp": "2026-01-30T10:03:21.910635"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3243.369, "latencies_ms": [3243.369], "images_per_second": 0.308, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A plate of food with rice, vegetables, and chicken is on a table.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13854.3, "ram_available_mb": 48986.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 13854.1, "ram_available_mb": 48986.8, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.269, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 77.423}, "timestamp": "2026-01-30T10:03:27.176866"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4712.422, "latencies_ms": [4712.422], "images_per_second": 0.212, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " plate: 1, fork: 1, knife: 1, glass: 1, rice: 1, carrots: 1, broccoli: 1, cauliflower: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.974}, "power_stats": {"power_gpu_soc_mean_watts": 20.38, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 7.903, "gpu_utilization_percent_mean": 72.974}, "timestamp": "2026-01-30T10:03:33.912734"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4769.408, "latencies_ms": [4769.408], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The plate with the food is in the foreground, and the glass of water is in the background. The fork is on the left side of the plate, and the spoon is on the right side.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.744}, "power_stats": {"power_gpu_soc_mean_watts": 20.244, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 7.911, "gpu_utilization_percent_mean": 73.744}, "timestamp": "2026-01-30T10:03:40.696510"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3124.408, "latencies_ms": [3124.408], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate of food is on a table with a glass of water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13853.2, "ram_available_mb": 48987.7, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13852.8, "ram_available_mb": 48988.1, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.769}, "power_stats": {"power_gpu_soc_mean_watts": 23.388, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 81.769}, "timestamp": "2026-01-30T10:03:45.869456"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3863.343, "latencies_ms": [3863.343], "images_per_second": 0.259, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The plate is white and red, and the food is colorful. The lighting is natural, and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13852.8, "ram_available_mb": 48988.1, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 13852.5, "ram_available_mb": 48988.4, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.344}, "power_stats": {"power_gpu_soc_mean_watts": 21.633, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 74.344}, "timestamp": "2026-01-30T10:03:51.761273"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4303.033, "latencies_ms": [4303.033], "images_per_second": 0.232, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A young girl in a colorful dress is playing with a Wii remote in a living room with a couch, a coffee table, and a staircase in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13852.5, "ram_available_mb": 48988.4, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13851.7, "ram_available_mb": 48989.2, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.25}, "power_stats": {"power_gpu_soc_mean_watts": 20.954, "power_cpu_cv_mean_watts": 2.047, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 77.25}, "timestamp": "2026-01-30T10:03:58.115590"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5933.341, "latencies_ms": [5933.341], "images_per_second": 0.169, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. couch: 1\n2. rug: 1\n3. chair: 1\n4. table: 1\n5. sofa: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13851.7, "ram_available_mb": 48989.2, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 13851.6, "ram_available_mb": 48989.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.08}, "power_stats": {"power_gpu_soc_mean_watts": 18.276, "power_cpu_cv_mean_watts": 2.107, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 71.08}, "timestamp": "2026-01-30T10:04:06.082653"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4835.504, "latencies_ms": [4835.504], "images_per_second": 0.207, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The couch is located in the background, with the girl standing in the foreground. The person in the white dress is standing near the couch, while the person in the green shirt is standing near the bar.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13851.6, "ram_available_mb": 48989.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 13851.0, "ram_available_mb": 48989.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.641}, "power_stats": {"power_gpu_soc_mean_watts": 20.604, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 76.641}, "timestamp": "2026-01-30T10:04:12.937808"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3973.64, "latencies_ms": [3973.64], "images_per_second": 0.252, "prompt_tokens": 1112, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of people are gathered in a living room, with a young girl playing with a toy in the center of the room.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13851.0, "ram_available_mb": 48989.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 13851.3, "ram_available_mb": 48989.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.688}, "power_stats": {"power_gpu_soc_mean_watts": 21.293, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 7.937, "gpu_utilization_percent_mean": 77.688}, "timestamp": "2026-01-30T10:04:18.924627"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3632.029, "latencies_ms": [3632.029], "images_per_second": 0.275, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from the windows, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13851.3, "ram_available_mb": 48989.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 13851.5, "ram_available_mb": 48989.4, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.133}, "power_stats": {"power_gpu_soc_mean_watts": 22.074, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 77.133}, "timestamp": "2026-01-30T10:04:24.569849"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3625.337, "latencies_ms": [3625.337], "images_per_second": 0.276, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two men are shaking hands in a large room with tables and chairs, and other people in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13851.5, "ram_available_mb": 48989.4, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13852.0, "ram_available_mb": 48988.9, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.817, "power_cpu_cv_mean_watts": 1.549, "power_sys_5v0_mean_watts": 7.945, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-30T10:04:30.225521"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5887.815, "latencies_ms": [5887.815], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. man: 1\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 13852.0, "ram_available_mb": 48988.9, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 13850.3, "ram_available_mb": 48990.6, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.521}, "power_stats": {"power_gpu_soc_mean_watts": 18.426, "power_cpu_cv_mean_watts": 2.044, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 71.521}, "timestamp": "2026-01-30T10:04:38.148985"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6644.509, "latencies_ms": [6644.509], "images_per_second": 0.151, "prompt_tokens": 1117, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The man in the dark suit is standing to the right of the man in the patterned shirt, and the man in the dark suit is in the foreground of the image. The man in the patterned shirt is standing to the left of the man in the dark suit, and the man in the patterned shirt is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13850.3, "ram_available_mb": 48990.6, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 13850.9, "ram_available_mb": 48990.0, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.309}, "power_stats": {"power_gpu_soc_mean_watts": 17.77, "power_cpu_cv_mean_watts": 2.075, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 69.309}, "timestamp": "2026-01-30T10:04:46.821384"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3132.239, "latencies_ms": [3132.239], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two men are shaking hands in a large room with many other people.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13850.9, "ram_available_mb": 48990.0, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13850.9, "ram_available_mb": 48990.0, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.396, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 81.76}, "timestamp": "2026-01-30T10:04:51.977177"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3667.517, "latencies_ms": [3667.517], "images_per_second": 0.273, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with warm lighting, and the attendees are dressed in formal attire.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13850.9, "ram_available_mb": 48990.0, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13851.9, "ram_available_mb": 48989.0, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.067}, "power_stats": {"power_gpu_soc_mean_watts": 22.38, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 78.067}, "timestamp": "2026-01-30T10:04:57.664193"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3331.034, "latencies_ms": [3331.034], "images_per_second": 0.3, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a white shirt and a striped tie is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13851.9, "ram_available_mb": 48989.0, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 13851.6, "ram_available_mb": 48989.3, "ram_percent": 22.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.963}, "power_stats": {"power_gpu_soc_mean_watts": 22.892, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 76.963}, "timestamp": "2026-01-30T10:05:03.039009"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5821.853, "latencies_ms": [5821.853], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. tie: 1\n2. shirt: 1\n3. hand: 1\n4. person: 1\n5. tie: 1\n6. shirt: 1\n7. hand: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13851.6, "ram_available_mb": 48989.3, "ram_percent": 22.0}, "sys_after": {"cpu_percent": 11.9, "ram_used_mb": 14010.1, "ram_available_mb": 48830.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.286}, "power_stats": {"power_gpu_soc_mean_watts": 18.418, "power_cpu_cv_mean_watts": 2.084, "power_sys_5v0_mean_watts": 7.822, "gpu_utilization_percent_mean": 71.286}, "timestamp": "2026-01-30T10:05:10.890071"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4778.727, "latencies_ms": [4778.727], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is standing in the foreground, wearing a white shirt and a striped tie. The background is dark and out of focus, suggesting that the man is in a dimly lit room.", "error": null, "sys_before": {"cpu_percent": 42.9, "ram_used_mb": 14011.5, "ram_available_mb": 48829.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 37.5, "ram_used_mb": 14575.3, "ram_available_mb": 48265.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.275}, "power_stats": {"power_gpu_soc_mean_watts": 19.99, "power_cpu_cv_mean_watts": 5.779, "power_sys_5v0_mean_watts": 8.111, "gpu_utilization_percent_mean": 74.275}, "timestamp": "2026-01-30T10:05:17.690301"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3105.655, "latencies_ms": [3105.655], "images_per_second": 0.322, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man wearing a tie and a shirt is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14575.3, "ram_available_mb": 48265.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 20.2, "ram_used_mb": 14746.7, "ram_available_mb": 48094.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.654}, "power_stats": {"power_gpu_soc_mean_watts": 23.267, "power_cpu_cv_mean_watts": 4.191, "power_sys_5v0_mean_watts": 8.293, "gpu_utilization_percent_mean": 74.654}, "timestamp": "2026-01-30T10:05:22.820262"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3638.184, "latencies_ms": [3638.184], "images_per_second": 0.275, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The man is wearing a white shirt and a striped tie. The lighting is dim and the background is dark.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14746.7, "ram_available_mb": 48094.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 14727.3, "ram_available_mb": 48113.6, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.367}, "power_stats": {"power_gpu_soc_mean_watts": 22.193, "power_cpu_cv_mean_watts": 2.563, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 80.367}, "timestamp": "2026-01-30T10:05:28.496082"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4057.664, "latencies_ms": [4057.664], "images_per_second": 0.246, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A room with a red chair, a blue and red plaid couch, a TV on a stand, and a whiteboard with writing on it.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 14727.3, "ram_available_mb": 48113.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 14756.0, "ram_available_mb": 48084.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.265}, "power_stats": {"power_gpu_soc_mean_watts": 21.242, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 78.265}, "timestamp": "2026-01-30T10:05:34.593054"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3718.768, "latencies_ms": [3718.768], "images_per_second": 0.269, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " chair: 1, couch: 2, television: 1, whiteboard: 1, poster: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14756.0, "ram_available_mb": 48084.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14757.4, "ram_available_mb": 48083.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.871}, "power_stats": {"power_gpu_soc_mean_watts": 21.992, "power_cpu_cv_mean_watts": 1.486, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 77.871}, "timestamp": "2026-01-30T10:05:40.372652"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6040.793, "latencies_ms": [6040.793], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The red armchair is positioned to the left of the television, which is placed on a wooden stand in the center of the room. The blue and red plaid couch is located to the right of the television, and the whiteboard is mounted on the wall to the left of the television.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 14757.4, "ram_available_mb": 48083.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14762.3, "ram_available_mb": 48078.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.216}, "power_stats": {"power_gpu_soc_mean_watts": 18.418, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 72.216}, "timestamp": "2026-01-30T10:05:48.433762"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2960.22, "latencies_ms": [2960.22], "images_per_second": 0.338, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A room with a TV, chairs, and a whiteboard.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14762.3, "ram_available_mb": 48078.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14551.7, "ram_available_mb": 48289.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.13}, "power_stats": {"power_gpu_soc_mean_watts": 24.153, "power_cpu_cv_mean_watts": 1.376, "power_sys_5v0_mean_watts": 8.288, "gpu_utilization_percent_mean": 86.13}, "timestamp": "2026-01-30T10:05:53.411089"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2993.484, "latencies_ms": [2993.484], "images_per_second": 0.334, "prompt_tokens": 1109, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The room is painted yellow and has a plaid couch.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14551.7, "ram_available_mb": 48289.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14551.7, "ram_available_mb": 48289.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.667}, "power_stats": {"power_gpu_soc_mean_watts": 23.635, "power_cpu_cv_mean_watts": 1.185, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 83.667}, "timestamp": "2026-01-30T10:05:58.428287"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3977.885, "latencies_ms": [3977.885], "images_per_second": 0.251, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is riding a wave on a surfboard.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14551.7, "ram_available_mb": 48289.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14553.1, "ram_available_mb": 48287.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.939}, "power_stats": {"power_gpu_soc_mean_watts": 24.426, "power_cpu_cv_mean_watts": 1.359, "power_sys_5v0_mean_watts": 8.367, "gpu_utilization_percent_mean": 82.939}, "timestamp": "2026-01-30T10:06:04.474030"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7774.975, "latencies_ms": [7774.975], "images_per_second": 0.129, "prompt_tokens": 1446, "response_tokens_est": 76, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wetsuit: 1\n4. Wetsuit sleeve: 1\n5. Wetsuit leg: 1\n6. Wetsuit arm: 1\n7. Wetsuit chest: 1\n8. Wetsuit back: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14553.1, "ram_available_mb": 48287.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 14551.4, "ram_available_mb": 48289.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.938}, "power_stats": {"power_gpu_soc_mean_watts": 19.487, "power_cpu_cv_mean_watts": 2.644, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 74.938}, "timestamp": "2026-01-30T10:06:14.287284"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5791.821, "latencies_ms": [5791.821], "images_per_second": 0.173, "prompt_tokens": 1450, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that is in the middle of the image. The surfer is wearing a yellow shirt and black shorts, and is positioned on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14551.4, "ram_available_mb": 48289.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14551.8, "ram_available_mb": 48289.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.771}, "power_stats": {"power_gpu_soc_mean_watts": 21.194, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 8.111, "gpu_utilization_percent_mean": 77.771}, "timestamp": "2026-01-30T10:06:22.100093"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4299.01, "latencies_ms": [4299.01], "images_per_second": 0.233, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14551.8, "ram_available_mb": 48289.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14554.7, "ram_available_mb": 48286.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.167}, "power_stats": {"power_gpu_soc_mean_watts": 23.821, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 83.167}, "timestamp": "2026-01-30T10:06:28.437226"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4538.935, "latencies_ms": [4538.935], "images_per_second": 0.22, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The surfer is wearing a yellow shirt and black pants, and the water is a greenish-blue color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14554.7, "ram_available_mb": 48286.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14553.8, "ram_available_mb": 48287.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.026}, "power_stats": {"power_gpu_soc_mean_watts": 22.631, "power_cpu_cv_mean_watts": 1.486, "power_sys_5v0_mean_watts": 8.112, "gpu_utilization_percent_mean": 82.026}, "timestamp": "2026-01-30T10:06:35.020720"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3306.522, "latencies_ms": [3306.522], "images_per_second": 0.302, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14553.8, "ram_available_mb": 48287.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14551.1, "ram_available_mb": 48289.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.789, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 83.185}, "timestamp": "2026-01-30T10:06:40.360764"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4477.57, "latencies_ms": [4477.57], "images_per_second": 0.223, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. black cat\n2. laptop\n3. computer monitor\n4. keyboard\n5. mouse\n6. phone\n7. mousepad\n8. desk", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14551.1, "ram_available_mb": 48289.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 14552.1, "ram_available_mb": 48288.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.919}, "power_stats": {"power_gpu_soc_mean_watts": 20.752, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 7.903, "gpu_utilization_percent_mean": 74.919}, "timestamp": "2026-01-30T10:06:46.853606"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5017.924, "latencies_ms": [5017.924], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The cat is positioned in the foreground, with its head turned towards the computer screen, which is located in the middle ground. The laptop is situated to the left of the cat, while the phone is placed to the right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14552.1, "ram_available_mb": 48288.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 14552.6, "ram_available_mb": 48288.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.488}, "power_stats": {"power_gpu_soc_mean_watts": 19.752, "power_cpu_cv_mean_watts": 1.856, "power_sys_5v0_mean_watts": 7.946, "gpu_utilization_percent_mean": 71.488}, "timestamp": "2026-01-30T10:06:53.884563"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3285.619, "latencies_ms": [3285.619], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14552.6, "ram_available_mb": 48288.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14552.4, "ram_available_mb": 48288.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.704}, "power_stats": {"power_gpu_soc_mean_watts": 23.212, "power_cpu_cv_mean_watts": 1.364, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 78.704}, "timestamp": "2026-01-30T10:06:59.204430"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5920.429, "latencies_ms": [5920.429], "images_per_second": 0.169, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image is a close-up of a black cat sitting in front of a computer screen, with the cat's head turned to the side, and the screen displaying a webpage with text. The lighting in the image is bright, and the cat's fur appears to be soft and fluffy.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14552.4, "ram_available_mb": 48288.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14552.5, "ram_available_mb": 48288.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.86}, "power_stats": {"power_gpu_soc_mean_watts": 18.446, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 69.86}, "timestamp": "2026-01-30T10:07:07.156948"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4543.983, "latencies_ms": [4543.983], "images_per_second": 0.22, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A group of people, including a man in a blue shirt and a child in a pink jacket, are cutting a red ribbon with a pair of scissors in front of a building.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14552.5, "ram_available_mb": 48288.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14556.7, "ram_available_mb": 48284.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.605}, "power_stats": {"power_gpu_soc_mean_watts": 20.426, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 7.893, "gpu_utilization_percent_mean": 73.605}, "timestamp": "2026-01-30T10:07:13.756439"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6361.987, "latencies_ms": [6361.987], "images_per_second": 0.157, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. People: 10\n2. Balloons: 2\n3. Helmet: 2\n4. Helmet: 1\n5. Helmet: 1\n6. Helmet: 1\n7. Helmet: 1\n8. Helmet: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14556.7, "ram_available_mb": 48284.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14554.7, "ram_available_mb": 48286.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.981}, "power_stats": {"power_gpu_soc_mean_watts": 18.108, "power_cpu_cv_mean_watts": 2.093, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 71.981}, "timestamp": "2026-01-30T10:07:22.163706"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6418.029, "latencies_ms": [6418.029], "images_per_second": 0.156, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the people standing in front of the building. The ribbon is positioned in the center of the image, with the people standing on either side of it. The people are positioned in the background of the image, with the building being the main focus of the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14554.7, "ram_available_mb": 48286.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14554.0, "ram_available_mb": 48286.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.038}, "power_stats": {"power_gpu_soc_mean_watts": 18.338, "power_cpu_cv_mean_watts": 2.07, "power_sys_5v0_mean_watts": 7.814, "gpu_utilization_percent_mean": 72.038}, "timestamp": "2026-01-30T10:07:30.597747"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3570.591, "latencies_ms": [3570.591], "images_per_second": 0.28, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered outside a building, cutting a red ribbon with a pair of scissors.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14554.0, "ram_available_mb": 48286.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14554.4, "ram_available_mb": 48286.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.655}, "power_stats": {"power_gpu_soc_mean_watts": 22.333, "power_cpu_cv_mean_watts": 1.436, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 75.655}, "timestamp": "2026-01-30T10:07:36.219151"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5873.135, "latencies_ms": [5873.135], "images_per_second": 0.17, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image is a vibrant and lively scene with a mix of warm and cool colors, capturing the essence of a bustling city street. The lighting is natural, with the sun casting a soft glow on the scene, and the weather appears to be clear, with no signs of rain or wind.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14554.4, "ram_available_mb": 48286.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 14555.3, "ram_available_mb": 48285.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.714}, "power_stats": {"power_gpu_soc_mean_watts": 18.872, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 7.876, "gpu_utilization_percent_mean": 71.714}, "timestamp": "2026-01-30T10:07:44.121728"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4477.965, "latencies_ms": [4477.965], "images_per_second": 0.223, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A white and pink bus with the number 65745 on the front is driving down a street with a sign that says \"First Group\" on top.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14555.3, "ram_available_mb": 48285.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14555.4, "ram_available_mb": 48285.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.459}, "power_stats": {"power_gpu_soc_mean_watts": 20.298, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.873, "gpu_utilization_percent_mean": 74.459}, "timestamp": "2026-01-30T10:07:50.665475"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5882.485, "latencies_ms": [5882.485], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. people: 1\n3. buildings: 1\n4. flowers: 1\n5. road: 1\n6. sky: 1\n7. clouds: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14555.4, "ram_available_mb": 48285.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14555.2, "ram_available_mb": 48285.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.02}, "power_stats": {"power_gpu_soc_mean_watts": 18.74, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 72.02}, "timestamp": "2026-01-30T10:07:58.561552"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4644.637, "latencies_ms": [4644.637], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the street and buildings in the background. The bus is in the foreground, with the sidewalk and people in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14555.2, "ram_available_mb": 48285.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14556.1, "ram_available_mb": 48284.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.769}, "power_stats": {"power_gpu_soc_mean_watts": 20.202, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.872, "gpu_utilization_percent_mean": 72.769}, "timestamp": "2026-01-30T10:08:05.235694"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3456.461, "latencies_ms": [3456.461], "images_per_second": 0.289, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A white and pink bus is driving down a street with buildings and people in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14556.1, "ram_available_mb": 48284.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14554.8, "ram_available_mb": 48286.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.25}, "power_stats": {"power_gpu_soc_mean_watts": 22.313, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 80.25}, "timestamp": "2026-01-30T10:08:10.727245"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3290.273, "latencies_ms": [3290.273], "images_per_second": 0.304, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The bus is white, blue, and pink, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14554.8, "ram_available_mb": 48286.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14556.0, "ram_available_mb": 48284.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.37}, "power_stats": {"power_gpu_soc_mean_watts": 22.888, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 80.37}, "timestamp": "2026-01-30T10:08:16.075288"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3374.173, "latencies_ms": [3374.173], "images_per_second": 0.296, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man is sitting on the floor in front of a mirror, holding a cell phone.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 14556.0, "ram_available_mb": 48284.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14557.2, "ram_available_mb": 48283.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.607}, "power_stats": {"power_gpu_soc_mean_watts": 22.768, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 75.607}, "timestamp": "2026-01-30T10:08:21.505242"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5860.536, "latencies_ms": [5860.536], "images_per_second": 0.171, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Man: 1\n2. Mirror: 1\n3. Floor: 1\n4. Wall: 1\n5. Window: 1\n6. Door: 1\n7. Table: 1\n8. Chair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14557.2, "ram_available_mb": 48283.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14557.7, "ram_available_mb": 48283.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.224}, "power_stats": {"power_gpu_soc_mean_watts": 18.766, "power_cpu_cv_mean_watts": 1.994, "power_sys_5v0_mean_watts": 7.823, "gpu_utilization_percent_mean": 71.224}, "timestamp": "2026-01-30T10:08:29.386010"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5748.481, "latencies_ms": [5748.481], "images_per_second": 0.174, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man is sitting in front of the mirror, which is positioned on the left side of the image. The mirror is reflecting the room behind him, which is located in the background. The man is sitting on the floor, which is in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14557.7, "ram_available_mb": 48283.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14558.4, "ram_available_mb": 48282.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.562}, "power_stats": {"power_gpu_soc_mean_watts": 18.766, "power_cpu_cv_mean_watts": 1.961, "power_sys_5v0_mean_watts": 7.805, "gpu_utilization_percent_mean": 70.562}, "timestamp": "2026-01-30T10:08:37.148767"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3473.785, "latencies_ms": [3473.785], "images_per_second": 0.288, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is sitting on the floor in front of a mirror, taking a picture of himself.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14558.4, "ram_available_mb": 48282.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14558.6, "ram_available_mb": 48282.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.643}, "power_stats": {"power_gpu_soc_mean_watts": 22.498, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 79.643}, "timestamp": "2026-01-30T10:08:42.649293"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3477.507, "latencies_ms": [3477.507], "images_per_second": 0.288, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the wooden floor is polished and clean.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14558.6, "ram_available_mb": 48282.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14558.5, "ram_available_mb": 48282.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.793}, "power_stats": {"power_gpu_soc_mean_watts": 22.248, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 79.793}, "timestamp": "2026-01-30T10:08:48.159319"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4012.188, "latencies_ms": [4012.188], "images_per_second": 0.249, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of people, including a man holding a surfboard, are posing for a photo in a room with a door and a window.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 14558.5, "ram_available_mb": 48282.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14557.8, "ram_available_mb": 48283.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.424}, "power_stats": {"power_gpu_soc_mean_watts": 21.311, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 77.424}, "timestamp": "2026-01-30T10:08:54.197554"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5815.785, "latencies_ms": [5815.785], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. surfboard: 4\n2. person: 4\n3. person: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14557.8, "ram_available_mb": 48283.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14561.5, "ram_available_mb": 48279.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.52}, "power_stats": {"power_gpu_soc_mean_watts": 18.897, "power_cpu_cv_mean_watts": 2.043, "power_sys_5v0_mean_watts": 7.84, "gpu_utilization_percent_mean": 73.52}, "timestamp": "2026-01-30T10:09:02.038077"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5099.2, "latencies_ms": [5099.2], "images_per_second": 0.196, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The surfboards are positioned in the foreground, with the group of people standing behind them. The person taking the photo is positioned to the left of the surfboards, while the person holding the flag is positioned to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14561.5, "ram_available_mb": 48279.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14577.6, "ram_available_mb": 48263.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.738}, "power_stats": {"power_gpu_soc_mean_watts": 19.434, "power_cpu_cv_mean_watts": 2.012, "power_sys_5v0_mean_watts": 7.928, "gpu_utilization_percent_mean": 72.738}, "timestamp": "2026-01-30T10:09:09.183259"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3351.59, "latencies_ms": [3351.59], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are posing for a picture in a room with surfboards.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14577.6, "ram_available_mb": 48263.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14572.1, "ram_available_mb": 48268.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.63}, "power_stats": {"power_gpu_soc_mean_watts": 22.547, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 82.63}, "timestamp": "2026-01-30T10:09:14.576778"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4492.602, "latencies_ms": [4492.602], "images_per_second": 0.223, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a white wall and a black door. The surfboards are in various colors, including yellow, blue, and red.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14572.1, "ram_available_mb": 48268.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 14572.0, "ram_available_mb": 48268.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.568}, "power_stats": {"power_gpu_soc_mean_watts": 20.665, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 7.933, "gpu_utilization_percent_mean": 76.568}, "timestamp": "2026-01-30T10:09:21.103984"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5097.682, "latencies_ms": [5097.682], "images_per_second": 0.196, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a large, golden-colored airplane with the words \"POLSKIE LOTNIE LOTNICZE\" written on its side, parked on a runway with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14572.0, "ram_available_mb": 48268.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14572.4, "ram_available_mb": 48268.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.833}, "power_stats": {"power_gpu_soc_mean_watts": 19.495, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 73.833}, "timestamp": "2026-01-30T10:09:28.249621"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5923.981, "latencies_ms": [5923.981], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. tail: 1\n3. wing: 2\n4. engine: 2\n5. wheels: 2\n6. logo: 1\n7. clouds: 1\n8. runway: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14572.4, "ram_available_mb": 48268.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14573.5, "ram_available_mb": 48267.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.224}, "power_stats": {"power_gpu_soc_mean_watts": 18.405, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 73.224}, "timestamp": "2026-01-30T10:09:36.190859"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4693.905, "latencies_ms": [4693.905], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The airplane is positioned in the foreground, with the runway and other aircraft in the background. The airplane is facing towards the left side of the image, and the tail of the airplane is visible.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14573.5, "ram_available_mb": 48267.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 14570.8, "ram_available_mb": 48270.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.051}, "power_stats": {"power_gpu_soc_mean_watts": 20.241, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.922, "gpu_utilization_percent_mean": 74.051}, "timestamp": "2026-01-30T10:09:42.905605"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3384.633, "latencies_ms": [3384.633], "images_per_second": 0.295, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A golden-colored airplane is parked on a runway with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.8, "ram_available_mb": 48270.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14571.0, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.393}, "power_stats": {"power_gpu_soc_mean_watts": 22.66, "power_cpu_cv_mean_watts": 1.359, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 78.393}, "timestamp": "2026-01-30T10:09:48.332093"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3265.427, "latencies_ms": [3265.427], "images_per_second": 0.306, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The airplane is gold and blue, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14571.0, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14571.8, "ram_available_mb": 48269.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.858, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 79.222}, "timestamp": "2026-01-30T10:09:53.621922"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3237.546, "latencies_ms": [3237.546], "images_per_second": 0.309, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A toilet with a lid up and water in it is in a bathroom.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14571.8, "ram_available_mb": 48269.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14572.5, "ram_available_mb": 48268.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.423}, "power_stats": {"power_gpu_soc_mean_watts": 22.903, "power_cpu_cv_mean_watts": 1.247, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 82.423}, "timestamp": "2026-01-30T10:09:58.876735"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5969.575, "latencies_ms": [5969.575], "images_per_second": 0.168, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " toilet: 1\ntoilet lid: 1\ntoilet seat: 1\ntoilet bowl: 1\ntoilet tank: 1\ntoilet tank lid: 1\ntoilet tank handle: 1\ntoilet tank knob: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14572.5, "ram_available_mb": 48268.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14570.9, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.2}, "power_stats": {"power_gpu_soc_mean_watts": 18.023, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 72.2}, "timestamp": "2026-01-30T10:10:06.889817"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5170.959, "latencies_ms": [5170.959], "images_per_second": 0.193, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the sink and towel rack in the background. The person's legs are visible in the bottom left corner of the image, suggesting they are standing near the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.9, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 14571.0, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.791}, "power_stats": {"power_gpu_soc_mean_watts": 19.297, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.81, "gpu_utilization_percent_mean": 73.791}, "timestamp": "2026-01-30T10:10:14.088665"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2990.812, "latencies_ms": [2990.812], "images_per_second": 0.334, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A toilet with a lid up is in a bathroom.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14571.0, "ram_available_mb": 48269.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14571.3, "ram_available_mb": 48269.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.875}, "power_stats": {"power_gpu_soc_mean_watts": 23.077, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 82.875}, "timestamp": "2026-01-30T10:10:19.127002"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2845.463, "latencies_ms": [2845.463], "images_per_second": 0.351, "prompt_tokens": 1110, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The toilet is white and the water is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14571.3, "ram_available_mb": 48269.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 14570.2, "ram_available_mb": 48270.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.478}, "power_stats": {"power_gpu_soc_mean_watts": 23.889, "power_cpu_cv_mean_watts": 1.166, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 78.478}, "timestamp": "2026-01-30T10:10:23.996172"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3482.733, "latencies_ms": [3482.733], "images_per_second": 0.287, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person wearing a blue jacket and a white helmet is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 13.8, "ram_used_mb": 14570.2, "ram_available_mb": 48270.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14570.7, "ram_available_mb": 48270.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.679}, "power_stats": {"power_gpu_soc_mean_watts": 22.742, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 79.679}, "timestamp": "2026-01-30T10:10:29.505639"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6011.203, "latencies_ms": [6011.203], "images_per_second": 0.166, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. goggles: 1\n4. ski poles: 2\n5. skis: 2\n6. snow: 1\n7. trees: 1\n8. snowboard: 0", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14570.7, "ram_available_mb": 48270.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 14570.7, "ram_available_mb": 48270.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.66}, "power_stats": {"power_gpu_soc_mean_watts": 18.494, "power_cpu_cv_mean_watts": 2.114, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 72.66}, "timestamp": "2026-01-30T10:10:37.529174"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5259.111, "latencies_ms": [5259.111], "images_per_second": 0.19, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the snowy forest and trees in the background. The skier is skiing towards the left side of the image, with the trees and forest extending towards the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.7, "ram_available_mb": 48270.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 14571.1, "ram_available_mb": 48269.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.659}, "power_stats": {"power_gpu_soc_mean_watts": 19.223, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.839, "gpu_utilization_percent_mean": 74.659}, "timestamp": "2026-01-30T10:10:44.811404"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3010.13, "latencies_ms": [3010.13], "images_per_second": 0.332, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A person is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14571.1, "ram_available_mb": 48269.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14571.1, "ram_available_mb": 48269.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.292}, "power_stats": {"power_gpu_soc_mean_watts": 23.278, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 83.292}, "timestamp": "2026-01-30T10:10:49.840035"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3437.88, "latencies_ms": [3437.88], "images_per_second": 0.291, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a blue jacket and black pants, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14571.1, "ram_available_mb": 48269.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14570.9, "ram_available_mb": 48270.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.857}, "power_stats": {"power_gpu_soc_mean_watts": 22.927, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 76.857}, "timestamp": "2026-01-30T10:10:55.317944"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3921.234, "latencies_ms": [3921.234], "images_per_second": 0.255, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man in a yellow shirt and black shorts is playing tennis on a blue court with a crowd of people watching in the stands.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14570.6, "ram_available_mb": 48270.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 14570.9, "ram_available_mb": 48270.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.97}, "power_stats": {"power_gpu_soc_mean_watts": 21.288, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.916, "gpu_utilization_percent_mean": 75.97}, "timestamp": "2026-01-30T10:11:01.270756"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6629.173, "latencies_ms": [6629.173], "images_per_second": 0.151, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. blue court: 1\n5. white lines: 1\n6. white lines on court: 1\n7. white lines on court: 1\n8. white lines on court: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.9, "ram_available_mb": 48270.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14569.9, "ram_available_mb": 48271.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.596}, "power_stats": {"power_gpu_soc_mean_watts": 17.798, "power_cpu_cv_mean_watts": 2.129, "power_sys_5v0_mean_watts": 7.867, "gpu_utilization_percent_mean": 70.596}, "timestamp": "2026-01-30T10:11:09.943140"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4230.221, "latencies_ms": [4230.221], "images_per_second": 0.236, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The tennis player is in the foreground, with the crowd in the background. The player is near the net, while the ball is in the air.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14569.9, "ram_available_mb": 48271.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14569.1, "ram_available_mb": 48271.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.883, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.923, "gpu_utilization_percent_mean": 75.286}, "timestamp": "2026-01-30T10:11:16.201668"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3867.499, "latencies_ms": [3867.499], "images_per_second": 0.259, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a yellow shirt and black shorts is playing tennis on a blue court, with a crowd of people watching in the stands.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14569.1, "ram_available_mb": 48271.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14569.6, "ram_available_mb": 48271.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.594}, "power_stats": {"power_gpu_soc_mean_watts": 21.803, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 76.594}, "timestamp": "2026-01-30T10:11:22.126039"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5005.55, "latencies_ms": [5005.55], "images_per_second": 0.2, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a tennis court with a blue surface, white lines, and a man in a yellow shirt and black shorts playing tennis. The lighting is bright, and the court is surrounded by a crowd of spectators.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14569.6, "ram_available_mb": 48271.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14570.1, "ram_available_mb": 48270.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.167}, "power_stats": {"power_gpu_soc_mean_watts": 19.893, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 7.857, "gpu_utilization_percent_mean": 72.167}, "timestamp": "2026-01-30T10:11:29.177306"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4208.836, "latencies_ms": [4208.836], "images_per_second": 0.238, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image shows a plate with two small metal bowls, one containing a reddish-brown curry and the other filled with orange and white dumplings.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14570.1, "ram_available_mb": 48270.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.743}, "power_stats": {"power_gpu_soc_mean_watts": 20.688, "power_cpu_cv_mean_watts": 2.403, "power_sys_5v0_mean_watts": 7.925, "gpu_utilization_percent_mean": 74.743}, "timestamp": "2026-01-30T10:11:35.434307"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3835.382, "latencies_ms": [3835.382], "images_per_second": 0.261, "prompt_tokens": 1113, "response_tokens_est": 25, "n_tiles": 1, "output_text": " bowl: 2, plate: 1, napkin: 1, glass: 1, food: 3", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14569.2, "ram_available_mb": 48271.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.594}, "power_stats": {"power_gpu_soc_mean_watts": 21.564, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 77.594}, "timestamp": "2026-01-30T10:11:41.303874"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5308.583, "latencies_ms": [5308.583], "images_per_second": 0.188, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The bowl of curry is located to the left of the bowl of fruit, with the curry bowl being closer to the camera than the fruit bowl. The fruit bowl is positioned in the foreground, while the curry bowl is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14569.0, "ram_available_mb": 48271.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.178}, "power_stats": {"power_gpu_soc_mean_watts": 18.983, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 70.178}, "timestamp": "2026-01-30T10:11:48.646340"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3653.829, "latencies_ms": [3653.829], "images_per_second": 0.274, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A plate with two bowls of food on it, one with a red sauce and the other with orange food.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14568.5, "ram_available_mb": 48272.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.033}, "power_stats": {"power_gpu_soc_mean_watts": 22.067, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 77.033}, "timestamp": "2026-01-30T10:11:54.337557"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5396.122, "latencies_ms": [5396.122], "images_per_second": 0.185, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a plate with two bowls of food, one containing a reddish-brown dish and the other a bowl of orange and white food. The food is placed on a white napkin, and the background is a dark green tablecloth.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14568.5, "ram_available_mb": 48272.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 14568.1, "ram_available_mb": 48272.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.178}, "power_stats": {"power_gpu_soc_mean_watts": 19.413, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 73.178}, "timestamp": "2026-01-30T10:12:01.783455"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4233.529, "latencies_ms": [4233.529], "images_per_second": 0.236, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, there are four sheep standing in a grassy area, with one sheep looking directly at the camera, and the others facing away from it.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14568.1, "ram_available_mb": 48272.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14567.8, "ram_available_mb": 48273.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.619, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.944, "gpu_utilization_percent_mean": 75.286}, "timestamp": "2026-01-30T10:12:08.078887"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2624.366, "latencies_ms": [2624.366], "images_per_second": 0.381, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " sheep: 5", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14567.8, "ram_available_mb": 48273.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14567.3, "ram_available_mb": 48273.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.429}, "power_stats": {"power_gpu_soc_mean_watts": 23.474, "power_cpu_cv_mean_watts": 1.029, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 87.429}, "timestamp": "2026-01-30T10:12:12.764578"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4937.117, "latencies_ms": [4937.117], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground of the image, with the brick wall serving as the background. The sheep are standing close to each other, with one sheep in the foreground and the others in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14567.3, "ram_available_mb": 48273.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 14568.2, "ram_available_mb": 48272.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.634}, "power_stats": {"power_gpu_soc_mean_watts": 19.995, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.886, "gpu_utilization_percent_mean": 75.634}, "timestamp": "2026-01-30T10:12:19.745115"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3530.033, "latencies_ms": [3530.033], "images_per_second": 0.283, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " In a sunny day, a group of sheep are standing in a grassy area near a brick wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14568.2, "ram_available_mb": 48272.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14567.0, "ram_available_mb": 48273.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.69}, "power_stats": {"power_gpu_soc_mean_watts": 22.218, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 78.69}, "timestamp": "2026-01-30T10:12:25.337459"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4949.676, "latencies_ms": [4949.676], "images_per_second": 0.202, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a group of sheep with thick wool coats, standing in a grassy area with a brick wall in the background. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14567.0, "ram_available_mb": 48273.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14567.5, "ram_available_mb": 48273.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.732}, "power_stats": {"power_gpu_soc_mean_watts": 19.919, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.864, "gpu_utilization_percent_mean": 71.732}, "timestamp": "2026-01-30T10:12:32.315790"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4200.421, "latencies_ms": [4200.421], "images_per_second": 0.238, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " In the image, a bunch of bananas and an apple are placed on a blue and white patterned background.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 14567.0, "ram_available_mb": 48273.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14565.2, "ram_available_mb": 48275.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.971}, "power_stats": {"power_gpu_soc_mean_watts": 23.865, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.356, "gpu_utilization_percent_mean": 82.971}, "timestamp": "2026-01-30T10:12:38.553191"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3594.25, "latencies_ms": [3594.25], "images_per_second": 0.278, "prompt_tokens": 1446, "response_tokens_est": 9, "n_tiles": 1, "output_text": " banana: 5, apple: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14565.2, "ram_available_mb": 48275.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 14565.9, "ram_available_mb": 48275.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.793}, "power_stats": {"power_gpu_soc_mean_watts": 25.396, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.333, "gpu_utilization_percent_mean": 84.793}, "timestamp": "2026-01-30T10:12:44.178153"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6595.48, "latencies_ms": [6595.48], "images_per_second": 0.152, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The red apple is positioned in the center of the image, with the bananas surrounding it. The bananas are arranged in a circular pattern, with the red apple placed in the middle. The background is a blue and white floral pattern, which provides a contrast to the vibrant colors of the fruit.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14565.9, "ram_available_mb": 48275.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14564.6, "ram_available_mb": 48276.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.321}, "power_stats": {"power_gpu_soc_mean_watts": 20.233, "power_cpu_cv_mean_watts": 1.981, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 75.321}, "timestamp": "2026-01-30T10:12:52.792016"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6517.706, "latencies_ms": [6517.706], "images_per_second": 0.153, "prompt_tokens": 1444, "response_tokens_est": 55, "n_tiles": 1, "output_text": " In the center of the image, a vibrant red apple sits atop a bunch of bananas, which are arranged in a circular pattern around it. The bananas are a bright yellow color, and the apple's red hue stands out against the backdrop of a blue and white floral pattern.", "error": null, "sys_before": {"cpu_percent": 18.7, "ram_used_mb": 14564.6, "ram_available_mb": 48276.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14565.5, "ram_available_mb": 48275.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.39, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 8.091, "gpu_utilization_percent_mean": 76.222}, "timestamp": "2026-01-30T10:13:01.354240"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7330.039, "latencies_ms": [7330.039], "images_per_second": 0.136, "prompt_tokens": 1442, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a vibrant display of bananas and an apple, with the bananas arranged in a circular pattern around the apple. The bananas are a bright yellow color, while the apple is a striking combination of red and yellow hues. The background is a cool blue color with a floral pattern, providing a stark contrast to the warm colors of the fruit.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14564.9, "ram_available_mb": 48276.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 14563.7, "ram_available_mb": 48277.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.279}, "power_stats": {"power_gpu_soc_mean_watts": 19.488, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 75.279}, "timestamp": "2026-01-30T10:13:10.733448"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3689.981, "latencies_ms": [3689.981], "images_per_second": 0.271, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A blue and white train with red seats is parked at a station with trees and power lines in the background.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14563.7, "ram_available_mb": 48277.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14563.8, "ram_available_mb": 48277.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.833}, "power_stats": {"power_gpu_soc_mean_watts": 21.801, "power_cpu_cv_mean_watts": 1.495, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 77.833}, "timestamp": "2026-01-30T10:13:16.451332"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5947.279, "latencies_ms": [5947.279], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. train: 1\n2. windows: 12\n3. doors: 2\n4. seats: 12\n5. trolley: 1\n6. tracks: 2\n7. trees: 1\n8. wires: 1", "error": null, "sys_before": {"cpu_percent": 50.0, "ram_used_mb": 14563.8, "ram_available_mb": 48277.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14563.7, "ram_available_mb": 48277.2, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.78}, "power_stats": {"power_gpu_soc_mean_watts": 18.585, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 72.78}, "timestamp": "2026-01-30T10:13:24.442345"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4847.602, "latencies_ms": [4847.602], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, with the tracks extending towards the right. The background features a clear blue sky and trees, while the foreground includes a fence and a building.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14563.7, "ram_available_mb": 48277.2, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14561.8, "ram_available_mb": 48279.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.25}, "power_stats": {"power_gpu_soc_mean_watts": 19.994, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.85, "gpu_utilization_percent_mean": 73.25}, "timestamp": "2026-01-30T10:13:31.331381"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3567.718, "latencies_ms": [3567.718], "images_per_second": 0.28, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A blue and white train is parked at a station, with trees and other vehicles in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14561.8, "ram_available_mb": 48279.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14562.4, "ram_available_mb": 48278.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.793}, "power_stats": {"power_gpu_soc_mean_watts": 22.136, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 78.793}, "timestamp": "2026-01-30T10:13:36.926001"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3106.804, "latencies_ms": [3106.804], "images_per_second": 0.322, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The train is blue and white, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14562.4, "ram_available_mb": 48278.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14562.3, "ram_available_mb": 48278.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.245, "power_cpu_cv_mean_watts": 1.324, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 82.423}, "timestamp": "2026-01-30T10:13:42.065886"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3925.118, "latencies_ms": [3925.118], "images_per_second": 0.255, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image depicts a bathroom with a shower, a bathtub, and a double sink vanity, all with a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14562.3, "ram_available_mb": 48278.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14563.5, "ram_available_mb": 48277.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.531}, "power_stats": {"power_gpu_soc_mean_watts": 21.638, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 80.531}, "timestamp": "2026-01-30T10:13:48.010479"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6065.874, "latencies_ms": [6065.874], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Bathtub: 1\n2. Shower: 1\n3. Mirror: 2\n4. Sink: 1\n5. Cabinet: 1\n6. Towel: 1\n7. Rug: 1\n8. Light: 2", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14563.5, "ram_available_mb": 48277.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14564.0, "ram_available_mb": 48276.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.942}, "power_stats": {"power_gpu_soc_mean_watts": 18.161, "power_cpu_cv_mean_watts": 2.048, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 71.942}, "timestamp": "2026-01-30T10:13:56.110283"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4711.558, "latencies_ms": [4711.558], "images_per_second": 0.212, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The shower is located to the left of the sink, and the bathtub is situated behind the shower. The sink is positioned in the foreground, while the mirror is located in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14564.0, "ram_available_mb": 48276.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 14564.1, "ram_available_mb": 48276.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.179}, "power_stats": {"power_gpu_soc_mean_watts": 19.921, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.872, "gpu_utilization_percent_mean": 72.179}, "timestamp": "2026-01-30T10:14:02.848321"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3278.953, "latencies_ms": [3278.953], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bathroom with a shower, bathtub, and sink is shown in the image.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14564.1, "ram_available_mb": 48276.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14564.2, "ram_available_mb": 48276.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.679, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-30T10:14:08.141686"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4406.259, "latencies_ms": [4406.259], "images_per_second": 0.227, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The bathroom has a warm color scheme with beige walls and a red rug on the floor. The lighting is bright and natural, coming from a window in the background.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14564.2, "ram_available_mb": 48276.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 14564.8, "ram_available_mb": 48276.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.771, "power_cpu_cv_mean_watts": 1.753, "power_sys_5v0_mean_watts": 7.935, "gpu_utilization_percent_mean": 73.054}, "timestamp": "2026-01-30T10:14:14.568704"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4125.998, "latencies_ms": [4125.998], "images_per_second": 0.242, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A black and white photo captures a surfer skillfully riding a wave, with the word \"STAR\" prominently displayed in the top right corner.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14564.8, "ram_available_mb": 48276.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 14568.5, "ram_available_mb": 48272.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.382}, "power_stats": {"power_gpu_soc_mean_watts": 21.025, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 76.382}, "timestamp": "2026-01-30T10:14:20.730068"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5969.36, "latencies_ms": [5969.36], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wave: 1\n4. Water: 1\n5. Ocean: 1\n6. Sky: 1\n7. Clouds: 1\n8. Text: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14568.5, "ram_available_mb": 48272.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14566.2, "ram_available_mb": 48274.7, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.38}, "power_stats": {"power_gpu_soc_mean_watts": 18.846, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 74.38}, "timestamp": "2026-01-30T10:14:28.753864"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5226.995, "latencies_ms": [5226.995], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The surfer is in the middle of the wave, with the spray of water from the wave being the closest object to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14566.2, "ram_available_mb": 48274.7, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14566.8, "ram_available_mb": 48274.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.341}, "power_stats": {"power_gpu_soc_mean_watts": 19.187, "power_cpu_cv_mean_watts": 1.957, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 72.341}, "timestamp": "2026-01-30T10:14:36.007703"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3205.248, "latencies_ms": [3205.248], "images_per_second": 0.312, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14566.8, "ram_available_mb": 48274.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14566.5, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.846}, "power_stats": {"power_gpu_soc_mean_watts": 22.844, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 82.846}, "timestamp": "2026-01-30T10:14:41.238839"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5834.251, "latencies_ms": [5834.251], "images_per_second": 0.171, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image is in black and white, with the surfer's silhouette standing out against the white foam of the wave. The lighting is natural, with the sun reflecting off the water, creating a dramatic contrast between the dark silhouette of the surfer and the bright white foam.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14566.5, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14566.5, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.735}, "power_stats": {"power_gpu_soc_mean_watts": 18.564, "power_cpu_cv_mean_watts": 1.962, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 72.735}, "timestamp": "2026-01-30T10:14:49.097971"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5298.637, "latencies_ms": [5298.637], "images_per_second": 0.189, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " A baseball player in a white uniform with the number 10 on it is standing at home plate with a bat in his hand, while a catcher in a black uniform and a umpire in a blue shirt are behind him.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 14566.5, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14566.4, "ram_available_mb": 48274.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.045, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 7.84, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T10:14:56.436675"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6331.732, "latencies_ms": [6331.732], "images_per_second": 0.158, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. home plate: 1\n6. baseball: 1\n7. grass: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14566.1, "ram_available_mb": 48274.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 14566.1, "ram_available_mb": 48274.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.358}, "power_stats": {"power_gpu_soc_mean_watts": 17.732, "power_cpu_cv_mean_watts": 2.018, "power_sys_5v0_mean_watts": 7.685, "gpu_utilization_percent_mean": 71.358}, "timestamp": "2026-01-30T10:15:04.783624"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4455.076, "latencies_ms": [4455.076], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14566.1, "ram_available_mb": 48274.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 14566.4, "ram_available_mb": 48274.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.86, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 76.054}, "timestamp": "2026-01-30T10:15:11.291912"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3354.169, "latencies_ms": [3354.169], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A baseball game is taking place in a stadium with a crowd of people watching.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14566.4, "ram_available_mb": 48274.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14567.9, "ram_available_mb": 48273.0, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.259}, "power_stats": {"power_gpu_soc_mean_watts": 22.507, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 82.259}, "timestamp": "2026-01-30T10:15:16.674058"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6308.156, "latencies_ms": [6308.156], "images_per_second": 0.159, "prompt_tokens": 1109, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the players dressed in crisp white uniforms and the lush green grass of the field contrasting against the blue sky. The lighting is natural, casting a warm glow on the players and the field, while the weather appears to be clear, with no signs of rain or wind.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14567.9, "ram_available_mb": 48273.0, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14572.2, "ram_available_mb": 48268.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.094}, "power_stats": {"power_gpu_soc_mean_watts": 18.152, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 71.094}, "timestamp": "2026-01-30T10:15:24.997539"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4091.356, "latencies_ms": [4091.356], "images_per_second": 0.244, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a bunch of fruits and nuts on a white surface.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14572.2, "ram_available_mb": 48268.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14572.0, "ram_available_mb": 48268.9, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.206}, "power_stats": {"power_gpu_soc_mean_watts": 23.36, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 8.215, "gpu_utilization_percent_mean": 80.206}, "timestamp": "2026-01-30T10:15:31.144786"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5330.782, "latencies_ms": [5330.782], "images_per_second": 0.188, "prompt_tokens": 1446, "response_tokens_est": 39, "n_tiles": 1, "output_text": " apple: 2, grapes: 10, orange: 1, grapes: 10, grapes: 10, grapes: 10, grapes: 10", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14572.0, "ram_available_mb": 48268.9, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14572.4, "ram_available_mb": 48268.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.156}, "power_stats": {"power_gpu_soc_mean_watts": 22.049, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.217, "gpu_utilization_percent_mean": 77.156}, "timestamp": "2026-01-30T10:15:38.521744"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7790.989, "latencies_ms": [7790.989], "images_per_second": 0.128, "prompt_tokens": 1450, "response_tokens_est": 76, "n_tiles": 1, "output_text": " The main objects are arranged in a diagonal line from the top left to the bottom right, with the grapes and oranges placed in the foreground and the peanuts in the background. The objects are positioned in a way that creates a sense of depth and perspective, with the larger objects (grapes and oranges) in the foreground and the smaller objects (peanuts) in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14572.4, "ram_available_mb": 48268.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 14571.6, "ram_available_mb": 48269.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.677}, "power_stats": {"power_gpu_soc_mean_watts": 19.68, "power_cpu_cv_mean_watts": 2.052, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 72.677}, "timestamp": "2026-01-30T10:15:48.326108"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4041.98, "latencies_ms": [4041.98], "images_per_second": 0.247, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a bunch of fruits and nuts on a white surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14571.6, "ram_available_mb": 48269.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14570.6, "ram_available_mb": 48270.3, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.97}, "power_stats": {"power_gpu_soc_mean_watts": 24.058, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.297, "gpu_utilization_percent_mean": 79.97}, "timestamp": "2026-01-30T10:15:54.396833"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4565.008, "latencies_ms": [4565.008], "images_per_second": 0.219, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is a black and white photo with a white background, and the fruits are all in shades of white and gray.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14570.6, "ram_available_mb": 48270.3, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.649}, "power_stats": {"power_gpu_soc_mean_watts": 23.569, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.245, "gpu_utilization_percent_mean": 81.649}, "timestamp": "2026-01-30T10:16:00.974702"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8330.894, "latencies_ms": [8330.894], "images_per_second": 0.12, "prompt_tokens": 1099, "response_tokens_est": 96, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where a variety of vehicles, including cars and a bus, are in motion, while pedestrians can be seen walking along the sidewalks. The buildings lining the street are a mix of modern and older architectural styles, with some featuring balconies and others boasting large windows. The sky overhead is a clear blue, suggesting a bright and sunny day, and the street is lined with trees and greenery, adding a touch of nature to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14568.8, "ram_available_mb": 48272.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14569.8, "ram_available_mb": 48271.1, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.722}, "power_stats": {"power_gpu_soc_mean_watts": 16.412, "power_cpu_cv_mean_watts": 2.236, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 67.722}, "timestamp": "2026-01-30T10:16:11.355233"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5960.089, "latencies_ms": [5960.089], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. street: 2 lanes\n2. car: 2\n3. building: 3\n4. sidewalk: 1\n5. streetlight: 2\n6. tree: 1\n7. road: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14569.8, "ram_available_mb": 48271.1, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14570.5, "ram_available_mb": 48270.4, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.02}, "power_stats": {"power_gpu_soc_mean_watts": 18.363, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 73.02}, "timestamp": "2026-01-30T10:16:19.339873"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7023.51, "latencies_ms": [7023.51], "images_per_second": 0.142, "prompt_tokens": 1117, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The main objects in the image are positioned in a way that the street is in the foreground, with the buildings and trees in the background. The street is on the left side of the image, while the buildings and trees are on the right side. The buildings are located on both sides of the street, with the trees lining the sidewalk on the right side.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14570.5, "ram_available_mb": 48270.4, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 28.0, "ram_used_mb": 15258.4, "ram_available_mb": 47582.5, "ram_percent": 24.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.167}, "power_stats": {"power_gpu_soc_mean_watts": 17.424, "power_cpu_cv_mean_watts": 4.112, "power_sys_5v0_mean_watts": 7.897, "gpu_utilization_percent_mean": 68.167}, "timestamp": "2026-01-30T10:16:28.399897"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6800.474, "latencies_ms": [6800.474], "images_per_second": 0.147, "prompt_tokens": 1111, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where modern buildings of varying heights and designs line the street. The buildings are adorned with balconies and windows, reflecting the city's vibrant life. Cars are parked neatly along the side of the road, and a few pedestrians can be seen strolling along the sidewalk, adding to the lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 52.0, "ram_used_mb": 15259.9, "ram_available_mb": 47581.0, "ram_percent": 24.3}, "sys_after": {"cpu_percent": 29.7, "ram_used_mb": 15414.1, "ram_available_mb": 47426.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.776}, "power_stats": {"power_gpu_soc_mean_watts": 17.265, "power_cpu_cv_mean_watts": 5.621, "power_sys_5v0_mean_watts": 7.924, "gpu_utilization_percent_mean": 69.776}, "timestamp": "2026-01-30T10:16:37.233156"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4278.67, "latencies_ms": [4278.67], "images_per_second": 0.234, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image features a street with a clear blue sky and a few clouds. The buildings are made of brick and concrete, and the road is paved with asphalt.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15414.1, "ram_available_mb": 47426.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 20.1, "ram_used_mb": 15464.3, "ram_available_mb": 47376.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.833}, "power_stats": {"power_gpu_soc_mean_watts": 20.951, "power_cpu_cv_mean_watts": 4.295, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 75.833}, "timestamp": "2026-01-30T10:16:43.528977"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4472.74, "latencies_ms": [4472.74], "images_per_second": 0.224, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, there are two people standing close to each other, with one person wearing a blue shirt and the other wearing a white shirt, both smiling and embracing each other.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15464.3, "ram_available_mb": 47376.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.3, "ram_used_mb": 15486.9, "ram_available_mb": 47354.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.622, "power_cpu_cv_mean_watts": 3.67, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 75.054}, "timestamp": "2026-01-30T10:16:50.014802"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5780.806, "latencies_ms": [5780.806], "images_per_second": 0.173, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 2\n2. tie: 1\n3. television: 1\n4. wall: 1\n5. chair: 1\n6. table: 1\n7. wall clock: 1\n8. picture: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15486.9, "ram_available_mb": 47354.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 15506.1, "ram_available_mb": 47334.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.625}, "power_stats": {"power_gpu_soc_mean_watts": 19.157, "power_cpu_cv_mean_watts": 2.37, "power_sys_5v0_mean_watts": 7.896, "gpu_utilization_percent_mean": 73.625}, "timestamp": "2026-01-30T10:16:57.820296"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4636.905, "latencies_ms": [4636.905], "images_per_second": 0.216, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The woman is standing to the right of the man, with her arm around his shoulder. The man is standing in front of a bar counter, with the woman standing behind him.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15506.1, "ram_available_mb": 47334.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 15516.3, "ram_available_mb": 47324.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.184}, "power_stats": {"power_gpu_soc_mean_watts": 20.352, "power_cpu_cv_mean_watts": 2.119, "power_sys_5v0_mean_watts": 7.902, "gpu_utilization_percent_mean": 75.184}, "timestamp": "2026-01-30T10:17:04.469842"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2834.558, "latencies_ms": [2834.558], "images_per_second": 0.353, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " Two people are posing for a picture in a bar.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15516.3, "ram_available_mb": 47324.6, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 15530.9, "ram_available_mb": 47310.0, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.043}, "power_stats": {"power_gpu_soc_mean_watts": 24.119, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 82.043}, "timestamp": "2026-01-30T10:17:09.348278"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3831.644, "latencies_ms": [3831.644], "images_per_second": 0.261, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm ambiance, and the subjects are wearing formal attire.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15530.9, "ram_available_mb": 47310.0, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 15546.1, "ram_available_mb": 47294.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.781}, "power_stats": {"power_gpu_soc_mean_watts": 21.578, "power_cpu_cv_mean_watts": 1.99, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 77.781}, "timestamp": "2026-01-30T10:17:15.199097"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3439.037, "latencies_ms": [3439.037], "images_per_second": 0.291, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman in a costume is smiling at the camera while standing in a crowd of people.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 15546.1, "ram_available_mb": 47294.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 15546.6, "ram_available_mb": 47294.3, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.16, "power_cpu_cv_mean_watts": 1.473, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 81.714}, "timestamp": "2026-01-30T10:17:20.676568"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5955.162, "latencies_ms": [5955.162], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. hat: 1\n3. headband: 1\n4. earring: 1\n5. necklace: 1\n6. bracelet: 1\n7. shirt: 1\n8. pants: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15546.6, "ram_available_mb": 47294.3, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.4, "ram_used_mb": 15552.8, "ram_available_mb": 47288.1, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.28}, "power_stats": {"power_gpu_soc_mean_watts": 18.586, "power_cpu_cv_mean_watts": 2.059, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 72.28}, "timestamp": "2026-01-30T10:17:28.684634"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4751.979, "latencies_ms": [4751.979], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The woman is in the foreground, wearing a black and gold costume, while the man is in the background, wearing a white hat. The woman is closer to the camera than the man.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15552.8, "ram_available_mb": 47288.1, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 15559.0, "ram_available_mb": 47281.9, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.775}, "power_stats": {"power_gpu_soc_mean_watts": 19.724, "power_cpu_cv_mean_watts": 2.503, "power_sys_5v0_mean_watts": 7.887, "gpu_utilization_percent_mean": 74.775}, "timestamp": "2026-01-30T10:17:35.463002"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3512.19, "latencies_ms": [3512.19], "images_per_second": 0.285, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered in an outdoor setting, dressed in elaborate costumes and engaging in conversation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15559.0, "ram_available_mb": 47281.9, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 15560.4, "ram_available_mb": 47280.5, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.345}, "power_stats": {"power_gpu_soc_mean_watts": 22.401, "power_cpu_cv_mean_watts": 1.436, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 74.345}, "timestamp": "2026-01-30T10:17:41.005649"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3606.713, "latencies_ms": [3606.713], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the woman is wearing a black and gold costume.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15560.4, "ram_available_mb": 47280.5, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 15561.4, "ram_available_mb": 47279.5, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.121, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 79.1}, "timestamp": "2026-01-30T10:17:46.645326"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6624.027, "latencies_ms": [6624.027], "images_per_second": 0.151, "prompt_tokens": 1100, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image depicts a small bathroom with white tiled walls and floor, a white toilet, a white sink, a white shower head, a white pipe, a white toilet tank, a white toilet paper holder, a green bucket, a red bucket, a white soap dish, a white soap dispenser, a white window, and a white drain.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 15561.4, "ram_available_mb": 47279.5, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 15560.4, "ram_available_mb": 47280.5, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.589}, "power_stats": {"power_gpu_soc_mean_watts": 17.493, "power_cpu_cv_mean_watts": 2.131, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 70.589}, "timestamp": "2026-01-30T10:17:55.309363"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5068.477, "latencies_ms": [5068.477], "images_per_second": 0.197, "prompt_tokens": 1114, "response_tokens_est": 43, "n_tiles": 1, "output_text": " 1. white toilet\n2. white sink\n3. white bathtub\n4. white shower head\n5. white pipe\n6. white toilet tank\n7. white toilet paper\n8. white soap", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15560.4, "ram_available_mb": 47280.5, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 15560.2, "ram_available_mb": 47280.7, "ram_percent": 24.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.69}, "power_stats": {"power_gpu_soc_mean_watts": 19.385, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 73.69}, "timestamp": "2026-01-30T10:18:02.430533"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6184.009, "latencies_ms": [6184.009], "images_per_second": 0.162, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The green bucket is located in the foreground, near the sink, while the red bucket is positioned in the background, near the toilet. The white pipe is situated in the middle of the image, with the shower head on the left side and the toilet on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15560.2, "ram_available_mb": 47280.7, "ram_percent": 24.8}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15627.3, "ram_available_mb": 47213.6, "ram_percent": 24.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.706}, "power_stats": {"power_gpu_soc_mean_watts": 18.347, "power_cpu_cv_mean_watts": 2.482, "power_sys_5v0_mean_watts": 7.59, "gpu_utilization_percent_mean": 78.706}, "timestamp": "2026-01-30T10:18:10.635423"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5814.108, "latencies_ms": [5814.108], "images_per_second": 0.172, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A small bathroom with white walls and a white floor has a shower, a toilet, and a sink.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15627.3, "ram_available_mb": 47213.6, "ram_percent": 24.9}, "sys_after": {"cpu_percent": 14.7, "ram_used_mb": 15359.5, "ram_available_mb": 47481.4, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.812}, "power_stats": {"power_gpu_soc_mean_watts": 17.638, "power_cpu_cv_mean_watts": 2.111, "power_sys_5v0_mean_watts": 6.623, "gpu_utilization_percent_mean": 96.812}, "timestamp": "2026-01-30T10:18:18.477777"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3183.975, "latencies_ms": [3183.975], "images_per_second": 0.314, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bathroom is white with a blue and green bucket, and a window with a black frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15359.5, "ram_available_mb": 47481.4, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 15362.3, "ram_available_mb": 47478.6, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.885}, "power_stats": {"power_gpu_soc_mean_watts": 23.813, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 7.953, "gpu_utilization_percent_mean": 75.885}, "timestamp": "2026-01-30T10:18:23.692291"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6905.372, "latencies_ms": [6905.372], "images_per_second": 0.145, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man wearing glasses and a green shirt is standing next to a large gray elephant in a natural setting with trees in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15362.3, "ram_available_mb": 47478.6, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 13.8, "ram_used_mb": 15357.1, "ram_available_mb": 47483.8, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.534}, "power_stats": {"power_gpu_soc_mean_watts": 16.55, "power_cpu_cv_mean_watts": 2.803, "power_sys_5v0_mean_watts": 6.407, "gpu_utilization_percent_mean": 97.534}, "timestamp": "2026-01-30T10:18:32.635332"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4541.245, "latencies_ms": [4541.245], "images_per_second": 0.22, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " elephant: 1, man: 1, glasses: 1, shirt: 1, elephant's trunk: 1, elephant's ear: 1, elephant's eye: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15357.1, "ram_available_mb": 47483.8, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 15357.2, "ram_available_mb": 47483.7, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.263}, "power_stats": {"power_gpu_soc_mean_watts": 21.027, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.839, "gpu_utilization_percent_mean": 74.263}, "timestamp": "2026-01-30T10:18:39.190456"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7930.602, "latencies_ms": [7930.602], "images_per_second": 0.126, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The man is standing to the right of the elephant, with the elephant's trunk reaching towards his face. The man is in the foreground, while the elephant is in the background.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15357.2, "ram_available_mb": 47483.7, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 12.9, "ram_used_mb": 15358.0, "ram_available_mb": 47482.9, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.227}, "power_stats": {"power_gpu_soc_mean_watts": 16.134, "power_cpu_cv_mean_watts": 2.694, "power_sys_5v0_mean_watts": 6.41, "gpu_utilization_percent_mean": 97.227}, "timestamp": "2026-01-30T10:18:49.142105"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3279.909, "latencies_ms": [3279.909], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing glasses is standing next to an elephant in a natural setting with trees in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15358.0, "ram_available_mb": 47482.9, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15357.8, "ram_available_mb": 47483.1, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.889}, "power_stats": {"power_gpu_soc_mean_watts": 23.006, "power_cpu_cv_mean_watts": 1.112, "power_sys_5v0_mean_watts": 7.89, "gpu_utilization_percent_mean": 72.889}, "timestamp": "2026-01-30T10:18:54.461754"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9014.41, "latencies_ms": [9014.41], "images_per_second": 0.111, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a man wearing glasses and a green shirt standing next to a large elephant. The elephant is gray and has wrinkled skin, while the man's shirt is a solid color. The background is a lush green forest with trees and hills visible.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 15356.8, "ram_available_mb": 47484.1, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15356.9, "ram_available_mb": 47483.9, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.211}, "power_stats": {"power_gpu_soc_mean_watts": 15.91, "power_cpu_cv_mean_watts": 2.914, "power_sys_5v0_mean_watts": 6.433, "gpu_utilization_percent_mean": 94.211}, "timestamp": "2026-01-30T10:19:05.500258"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4034.175, "latencies_ms": [4034.175], "images_per_second": 0.248, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Five children are sitting on the grass holding frisbees, with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 15356.9, "ram_available_mb": 47483.9, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 15356.9, "ram_available_mb": 47484.0, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.242}, "power_stats": {"power_gpu_soc_mean_watts": 21.022, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 7.413, "gpu_utilization_percent_mean": 95.242}, "timestamp": "2026-01-30T10:19:11.562883"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5001.891, "latencies_ms": [5001.891], "images_per_second": 0.2, "prompt_tokens": 1113, "response_tokens_est": 7, "n_tiles": 1, "output_text": " 1. boy: 5", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15356.9, "ram_available_mb": 47484.0, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 15356.1, "ram_available_mb": 47484.8, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.732}, "power_stats": {"power_gpu_soc_mean_watts": 17.875, "power_cpu_cv_mean_watts": 1.963, "power_sys_5v0_mean_watts": 6.417, "gpu_utilization_percent_mean": 96.732}, "timestamp": "2026-01-30T10:19:18.580738"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7027.054, "latencies_ms": [7027.054], "images_per_second": 0.142, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The frisbees are positioned in the foreground, with the child on the left holding a white frisbee and the child on the right holding a red frisbee. The children are sitting on the grass, with the child on the left being closest to the camera and the child on the right being farthest from the camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15356.1, "ram_available_mb": 47484.8, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 14.7, "ram_used_mb": 15370.6, "ram_available_mb": 47470.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.763}, "power_stats": {"power_gpu_soc_mean_watts": 18.293, "power_cpu_cv_mean_watts": 2.64, "power_sys_5v0_mean_watts": 7.47, "gpu_utilization_percent_mean": 81.763}, "timestamp": "2026-01-30T10:19:27.665400"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4968.517, "latencies_ms": [4968.517], "images_per_second": 0.201, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " Five children are sitting on the grass playing with frisbees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15370.6, "ram_available_mb": 47470.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15382.7, "ram_available_mb": 47458.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.366}, "power_stats": {"power_gpu_soc_mean_watts": 18.669, "power_cpu_cv_mean_watts": 2.188, "power_sys_5v0_mean_watts": 6.717, "gpu_utilization_percent_mean": 95.366}, "timestamp": "2026-01-30T10:19:34.678225"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4292.233, "latencies_ms": [4292.233], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image is taken in a bright and sunny day with clear sky. The children are sitting on the grass, which is green and lush.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15382.7, "ram_available_mb": 47458.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.6, "ram_used_mb": 15379.7, "ram_available_mb": 47461.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.963, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.546, "gpu_utilization_percent_mean": 81.0}, "timestamp": "2026-01-30T10:19:40.992362"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6458.349, "latencies_ms": [6458.349], "images_per_second": 0.155, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young girl wearing a red coat and holding a black umbrella with pink designs stands on a wet sidewalk in front of a bush.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15379.7, "ram_available_mb": 47461.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 15377.6, "ram_available_mb": 47463.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.815}, "power_stats": {"power_gpu_soc_mean_watts": 16.909, "power_cpu_cv_mean_watts": 2.677, "power_sys_5v0_mean_watts": 6.406, "gpu_utilization_percent_mean": 89.815}, "timestamp": "2026-01-30T10:19:49.497740"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4816.287, "latencies_ms": [4816.287], "images_per_second": 0.208, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " umbrella: 1, child: 1, sidewalk: 1, house: 1, bush: 1, car: 1, tree: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15377.6, "ram_available_mb": 47463.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 15379.7, "ram_available_mb": 47461.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.385}, "power_stats": {"power_gpu_soc_mean_watts": 20.352, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.41, "gpu_utilization_percent_mean": 84.385}, "timestamp": "2026-01-30T10:19:56.339380"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7689.014, "latencies_ms": [7689.014], "images_per_second": 0.13, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The child is standing in the foreground of the image, with the umbrella held above her head. The umbrella is positioned to the left of the child, and the background features a hedge and a house.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15379.7, "ram_available_mb": 47461.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 15378.1, "ram_available_mb": 47462.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.922}, "power_stats": {"power_gpu_soc_mean_watts": 16.496, "power_cpu_cv_mean_watts": 2.459, "power_sys_5v0_mean_watts": 6.443, "gpu_utilization_percent_mean": 88.922}, "timestamp": "2026-01-30T10:20:06.081422"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4169.761, "latencies_ms": [4169.761], "images_per_second": 0.24, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A little girl is standing on the sidewalk with an umbrella.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15378.1, "ram_available_mb": 47462.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 15379.5, "ram_available_mb": 47461.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.152}, "power_stats": {"power_gpu_soc_mean_watts": 19.783, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 6.986, "gpu_utilization_percent_mean": 95.152}, "timestamp": "2026-01-30T10:20:12.269821"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6928.68, "latencies_ms": [6928.68], "images_per_second": 0.144, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a young girl wearing a red coat and holding a black umbrella with pink patterns. The scene is set on a rainy day with wet pavement and a gray sky.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15379.5, "ram_available_mb": 47461.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 15378.7, "ram_available_mb": 47462.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.207}, "power_stats": {"power_gpu_soc_mean_watts": 16.993, "power_cpu_cv_mean_watts": 2.506, "power_sys_5v0_mean_watts": 6.52, "gpu_utilization_percent_mean": 89.207}, "timestamp": "2026-01-30T10:20:21.249727"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7190.978, "latencies_ms": [7190.978], "images_per_second": 0.139, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In the image, a group of elephants is seen walking through a muddy area, with one elephant in the foreground prominently displayed and the others slightly blurred in the background, creating a sense of depth and movement.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 15378.7, "ram_available_mb": 47462.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 15380.4, "ram_available_mb": 47460.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.593}, "power_stats": {"power_gpu_soc_mean_watts": 16.623, "power_cpu_cv_mean_watts": 2.274, "power_sys_5v0_mean_watts": 6.613, "gpu_utilization_percent_mean": 94.593}, "timestamp": "2026-01-30T10:20:30.465821"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4166.088, "latencies_ms": [4166.088], "images_per_second": 0.24, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " elephant: 1, trunk: 1, ear: 1, eye: 1, leg: 1, tail: 1, water: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 15380.4, "ram_available_mb": 47460.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 15381.4, "ram_available_mb": 47459.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.118}, "power_stats": {"power_gpu_soc_mean_watts": 20.919, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 73.118}, "timestamp": "2026-01-30T10:20:36.665223"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7116.101, "latencies_ms": [7116.101], "images_per_second": 0.141, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The main elephant is in the foreground, with the other elephants in the background. The elephants are walking towards the camera, with the main elephant in the center of the frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15381.4, "ram_available_mb": 47459.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15381.7, "ram_available_mb": 47459.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.233}, "power_stats": {"power_gpu_soc_mean_watts": 16.559, "power_cpu_cv_mean_watts": 2.71, "power_sys_5v0_mean_watts": 6.476, "gpu_utilization_percent_mean": 96.233}, "timestamp": "2026-01-30T10:20:45.812042"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4052.176, "latencies_ms": [4052.176], "images_per_second": 0.247, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of elephants are walking through a muddy area near a body of water.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15381.7, "ram_available_mb": 47459.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 15382.1, "ram_available_mb": 47458.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.091}, "power_stats": {"power_gpu_soc_mean_watts": 20.814, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 7.112, "gpu_utilization_percent_mean": 86.091}, "timestamp": "2026-01-30T10:20:51.878985"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7014.457, "latencies_ms": [7014.457], "images_per_second": 0.143, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The elephants are in a muddy environment, with a mix of brown and red tones. The lighting is natural, and the elephants are in a natural setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15382.1, "ram_available_mb": 47458.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15382.1, "ram_available_mb": 47458.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.254}, "power_stats": {"power_gpu_soc_mean_watts": 16.398, "power_cpu_cv_mean_watts": 2.565, "power_sys_5v0_mean_watts": 6.43, "gpu_utilization_percent_mean": 96.254}, "timestamp": "2026-01-30T10:21:00.918390"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3847.277, "latencies_ms": [3847.277], "images_per_second": 0.26, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 22.6, "ram_used_mb": 15382.1, "ram_available_mb": 47458.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 15382.8, "ram_available_mb": 47458.1, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.656}, "power_stats": {"power_gpu_soc_mean_watts": 25.955, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 83.656}, "timestamp": "2026-01-30T10:21:06.793903"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11365.932, "latencies_ms": [11365.932], "images_per_second": 0.088, "prompt_tokens": 1446, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. wave: 1\n3. surfboard: 1\n4. water: 1\n5. sky: 0\n6. surfboard deck: 1\n7. surfboard leash: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15382.8, "ram_available_mb": 47458.1, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15383.5, "ram_available_mb": 47457.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.229}, "power_stats": {"power_gpu_soc_mean_watts": 16.248, "power_cpu_cv_mean_watts": 2.932, "power_sys_5v0_mean_watts": 6.477, "gpu_utilization_percent_mean": 95.229}, "timestamp": "2026-01-30T10:21:20.187146"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7891.842, "latencies_ms": [7891.842], "images_per_second": 0.127, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave dominating the background. The surfer is leaning into the wave, with the surfboard positioned in the lower right corner of the image, close to the surfer.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15383.5, "ram_available_mb": 47457.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15381.9, "ram_available_mb": 47459.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.53}, "power_stats": {"power_gpu_soc_mean_watts": 18.725, "power_cpu_cv_mean_watts": 2.457, "power_sys_5v0_mean_watts": 7.083, "gpu_utilization_percent_mean": 96.53}, "timestamp": "2026-01-30T10:21:30.109946"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4859.906, "latencies_ms": [4859.906], "images_per_second": 0.206, "prompt_tokens": 1444, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15381.9, "ram_available_mb": 47459.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 15382.7, "ram_available_mb": 47458.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.375}, "power_stats": {"power_gpu_soc_mean_watts": 21.764, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 7.209, "gpu_utilization_percent_mean": 91.375}, "timestamp": "2026-01-30T10:21:37.002557"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8187.809, "latencies_ms": [8187.809], "images_per_second": 0.122, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The surfer is wearing a red and green wetsuit, and the wave is a deep green color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15382.7, "ram_available_mb": 47458.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15383.0, "ram_available_mb": 47457.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.333}, "power_stats": {"power_gpu_soc_mean_watts": 16.61, "power_cpu_cv_mean_watts": 2.344, "power_sys_5v0_mean_watts": 6.306, "gpu_utilization_percent_mean": 95.333}, "timestamp": "2026-01-30T10:21:47.225374"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3580.093, "latencies_ms": [3580.093], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean and a few people in the background.", "error": null, "sys_before": {"cpu_percent": 21.1, "ram_used_mb": 15383.0, "ram_available_mb": 47457.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 15382.3, "ram_available_mb": 47458.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.2}, "power_stats": {"power_gpu_soc_mean_watts": 22.773, "power_cpu_cv_mean_watts": 1.375, "power_sys_5v0_mean_watts": 7.691, "gpu_utilization_percent_mean": 77.2}, "timestamp": "2026-01-30T10:21:52.855869"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9719.663, "latencies_ms": [9719.663], "images_per_second": 0.103, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 2\n2. rider: 2\n3. rider: 1\n4. rider: 1\n5. rider: 1\n6. rider: 1\n7. rider: 1\n8. rider: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15382.3, "ram_available_mb": 47458.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.0, "ram_used_mb": 15383.4, "ram_available_mb": 47457.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.671}, "power_stats": {"power_gpu_soc_mean_watts": 15.696, "power_cpu_cv_mean_watts": 2.998, "power_sys_5v0_mean_watts": 6.377, "gpu_utilization_percent_mean": 97.671}, "timestamp": "2026-01-30T10:22:04.604599"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7298.19, "latencies_ms": [7298.19], "images_per_second": 0.137, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The two men on horseback are positioned in the foreground, with the ocean and beach extending into the background. The man on the left is closer to the camera, while the man on the right is farther away. The man on the left is also closer to the camera than the man on the right.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15383.4, "ram_available_mb": 47457.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.3, "ram_used_mb": 15384.4, "ram_available_mb": 47456.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 90.557}, "power_stats": {"power_gpu_soc_mean_watts": 17.955, "power_cpu_cv_mean_watts": 2.514, "power_sys_5v0_mean_watts": 7.074, "gpu_utilization_percent_mean": 90.557}, "timestamp": "2026-01-30T10:22:13.937748"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4409.922, "latencies_ms": [4409.922], "images_per_second": 0.227, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15384.4, "ram_available_mb": 47456.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 15385.4, "ram_available_mb": 47455.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.108}, "power_stats": {"power_gpu_soc_mean_watts": 19.841, "power_cpu_cv_mean_watts": 2.024, "power_sys_5v0_mean_watts": 6.918, "gpu_utilization_percent_mean": 84.108}, "timestamp": "2026-01-30T10:22:20.398294"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5692.621, "latencies_ms": [5692.621], "images_per_second": 0.176, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a sandy beach with a clear blue sky and ocean in the background. The two men are dressed in white traditional clothing and are riding horses, which are kicking up dust as they move.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15385.4, "ram_available_mb": 47455.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 15385.9, "ram_available_mb": 47455.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.976, "power_cpu_cv_mean_watts": 2.096, "power_sys_5v0_mean_watts": 7.154, "gpu_utilization_percent_mean": 95.021}, "timestamp": "2026-01-30T10:22:28.102759"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4936.426, "latencies_ms": [4936.426], "images_per_second": 0.203, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A small dog is standing in front of a motorcycle that is parked in a driveway.", "error": null, "sys_before": {"cpu_percent": 20.8, "ram_used_mb": 15385.9, "ram_available_mb": 47455.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15387.1, "ram_available_mb": 47453.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.024}, "power_stats": {"power_gpu_soc_mean_watts": 18.735, "power_cpu_cv_mean_watts": 2.207, "power_sys_5v0_mean_watts": 6.686, "gpu_utilization_percent_mean": 87.024}, "timestamp": "2026-01-30T10:22:35.074510"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7518.78, "latencies_ms": [7518.78], "images_per_second": 0.133, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. dog: 1\n3. tire: 1\n4. handlebar: 1\n5. seat: 1\n6. front wheel: 1\n7. rear wheel: 1\n8. garage door: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15387.1, "ram_available_mb": 47453.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.7, "ram_used_mb": 15385.7, "ram_available_mb": 47455.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.016}, "power_stats": {"power_gpu_soc_mean_watts": 17.667, "power_cpu_cv_mean_watts": 2.504, "power_sys_5v0_mean_watts": 6.988, "gpu_utilization_percent_mean": 93.016}, "timestamp": "2026-01-30T10:22:44.640674"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6037.022, "latencies_ms": [6037.022], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The motorcycle is positioned to the left of the garage door, with the dog standing in front of it. The motorcycle is in the foreground, while the garage door is in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 15385.7, "ram_available_mb": 47455.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 15383.9, "ram_available_mb": 47457.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.4}, "power_stats": {"power_gpu_soc_mean_watts": 17.702, "power_cpu_cv_mean_watts": 2.122, "power_sys_5v0_mean_watts": 6.853, "gpu_utilization_percent_mean": 82.4}, "timestamp": "2026-01-30T10:22:52.694862"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5955.397, "latencies_ms": [5955.397], "images_per_second": 0.168, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A motorcycle is parked outside a garage with a dog standing next to it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15383.9, "ram_available_mb": 47457.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 15383.9, "ram_available_mb": 47457.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.06}, "power_stats": {"power_gpu_soc_mean_watts": 16.9, "power_cpu_cv_mean_watts": 2.763, "power_sys_5v0_mean_watts": 6.295, "gpu_utilization_percent_mean": 98.06}, "timestamp": "2026-01-30T10:23:00.676866"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4632.209, "latencies_ms": [4632.209], "images_per_second": 0.216, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The motorcycle is red and silver, and the garage is beige. The sky is blue and the grass is green.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15383.9, "ram_available_mb": 47457.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 15384.3, "ram_available_mb": 47456.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.474}, "power_stats": {"power_gpu_soc_mean_watts": 19.867, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.083, "gpu_utilization_percent_mean": 82.474}, "timestamp": "2026-01-30T10:23:07.340390"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5634.06, "latencies_ms": [5634.06], "images_per_second": 0.177, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is flying a kite on the beach, with a few other people in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 15384.3, "ram_available_mb": 47456.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 15382.9, "ram_available_mb": 47458.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.404}, "power_stats": {"power_gpu_soc_mean_watts": 17.162, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 6.402, "gpu_utilization_percent_mean": 88.404}, "timestamp": "2026-01-30T10:23:15.045063"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5518.907, "latencies_ms": [5518.907], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. kite: 1\n3. sand: 1\n4. water: 1\n5. trees: 1\n6. buildings: 1\n7. clouds: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15382.9, "ram_available_mb": 47458.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 15383.3, "ram_available_mb": 47457.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.543, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.658, "gpu_utilization_percent_mean": 70.957}, "timestamp": "2026-01-30T10:23:22.617258"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8438.643, "latencies_ms": [8438.643], "images_per_second": 0.119, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man is in the foreground, flying the kite in the middle of the beach. The kite is in the background, flying high in the sky. The beach is in the background, with people and trees.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15383.3, "ram_available_mb": 47457.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 14.3, "ram_used_mb": 15384.1, "ram_available_mb": 47456.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.871}, "power_stats": {"power_gpu_soc_mean_watts": 15.984, "power_cpu_cv_mean_watts": 2.111, "power_sys_5v0_mean_watts": 6.346, "gpu_utilization_percent_mean": 97.871}, "timestamp": "2026-01-30T10:23:33.107455"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2930.623, "latencies_ms": [2930.623], "images_per_second": 0.341, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is flying a kite on a beach with a lake in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15384.1, "ram_available_mb": 47456.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 15384.0, "ram_available_mb": 47456.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.583}, "power_stats": {"power_gpu_soc_mean_watts": 25.096, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 74.583}, "timestamp": "2026-01-30T10:23:38.086812"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6648.181, "latencies_ms": [6648.181], "images_per_second": 0.15, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The sky is blue and the kite is blue and black. The beach is sandy and the water is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15384.0, "ram_available_mb": 47456.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.9, "ram_used_mb": 15384.5, "ram_available_mb": 47456.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.909}, "power_stats": {"power_gpu_soc_mean_watts": 16.652, "power_cpu_cv_mean_watts": 2.395, "power_sys_5v0_mean_watts": 6.306, "gpu_utilization_percent_mean": 97.909}, "timestamp": "2026-01-30T10:23:46.748263"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5193.947, "latencies_ms": [5193.947], "images_per_second": 0.193, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image depicts a kitchen with wooden cabinets, a stainless steel refrigerator, and a black countertop, with various items such as a green bottle, a red bow, and a blue bottle placed on the countertop.", "error": null, "sys_before": {"cpu_percent": 26.9, "ram_used_mb": 15384.5, "ram_available_mb": 47456.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 15386.4, "ram_available_mb": 47454.5, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.512}, "power_stats": {"power_gpu_soc_mean_watts": 19.375, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.404, "gpu_utilization_percent_mean": 74.512}, "timestamp": "2026-01-30T10:23:53.987236"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7719.489, "latencies_ms": [7719.489], "images_per_second": 0.13, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " sink: 1, bottle: 2, bowl: 1, cup: 1, dish: 1, bottle: 1, bottle: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15386.4, "ram_available_mb": 47454.5, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 15386.5, "ram_available_mb": 47454.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.677}, "power_stats": {"power_gpu_soc_mean_watts": 16.305, "power_cpu_cv_mean_watts": 2.859, "power_sys_5v0_mean_watts": 6.359, "gpu_utilization_percent_mean": 96.677}, "timestamp": "2026-01-30T10:24:03.749513"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4885.54, "latencies_ms": [4885.54], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The green dish soap bottle is located near the sink, while the blue dish soap bottle is placed further back on the counter. The red bow is positioned in the foreground, close to the camera.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15386.5, "ram_available_mb": 47454.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 15386.0, "ram_available_mb": 47454.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.9}, "power_stats": {"power_gpu_soc_mean_watts": 19.849, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 7.497, "gpu_utilization_percent_mean": 77.9}, "timestamp": "2026-01-30T10:24:10.668532"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6129.131, "latencies_ms": [6129.131], "images_per_second": 0.163, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A kitchen with wooden cabinets, a black countertop, and a stainless steel refrigerator.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15386.0, "ram_available_mb": 47454.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.3, "ram_used_mb": 15387.0, "ram_available_mb": 47453.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.863}, "power_stats": {"power_gpu_soc_mean_watts": 17.015, "power_cpu_cv_mean_watts": 2.506, "power_sys_5v0_mean_watts": 6.324, "gpu_utilization_percent_mean": 96.863}, "timestamp": "2026-01-30T10:24:18.843550"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3094.146, "latencies_ms": [3094.146], "images_per_second": 0.323, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15387.0, "ram_available_mb": 47453.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 15388.1, "ram_available_mb": 47452.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.462}, "power_stats": {"power_gpu_soc_mean_watts": 23.725, "power_cpu_cv_mean_watts": 1.093, "power_sys_5v0_mean_watts": 7.908, "gpu_utilization_percent_mean": 74.462}, "timestamp": "2026-01-30T10:24:23.988209"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5766.153, "latencies_ms": [5766.153], "images_per_second": 0.173, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white design is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 18.8, "ram_used_mb": 15388.1, "ram_available_mb": 47452.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.4, "ram_used_mb": 15404.1, "ram_available_mb": 47436.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.265, "power_cpu_cv_mean_watts": 2.378, "power_sys_5v0_mean_watts": 6.35, "gpu_utilization_percent_mean": 98.0}, "timestamp": "2026-01-30T10:24:31.803396"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2761.84, "latencies_ms": [2761.84], "images_per_second": 0.362, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " kite: 1", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 15404.1, "ram_available_mb": 47436.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 15395.9, "ram_available_mb": 47445.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.043}, "power_stats": {"power_gpu_soc_mean_watts": 23.597, "power_cpu_cv_mean_watts": 1.48, "power_sys_5v0_mean_watts": 7.475, "gpu_utilization_percent_mean": 92.043}, "timestamp": "2026-01-30T10:24:36.599327"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8274.848, "latencies_ms": [8274.848], "images_per_second": 0.121, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The kite is in the foreground, flying in the sky, and the background is the clear blue sky. The kite is positioned to the left of the frame, and the strings are attached to the kite, which is the main object in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15395.9, "ram_available_mb": 47445.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15369.9, "ram_available_mb": 47471.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.114}, "power_stats": {"power_gpu_soc_mean_watts": 16.237, "power_cpu_cv_mean_watts": 2.838, "power_sys_5v0_mean_watts": 6.538, "gpu_utilization_percent_mean": 96.114}, "timestamp": "2026-01-30T10:24:46.911317"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2809.699, "latencies_ms": [2809.699], "images_per_second": 0.356, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white design is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15369.9, "ram_available_mb": 47471.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 15368.7, "ram_available_mb": 47472.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.304}, "power_stats": {"power_gpu_soc_mean_watts": 25.145, "power_cpu_cv_mean_watts": 1.01, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 76.304}, "timestamp": "2026-01-30T10:24:51.746552"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5391.084, "latencies_ms": [5391.084], "images_per_second": 0.185, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The kite is white with red and black patterns, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15368.7, "ram_available_mb": 47472.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.9, "ram_used_mb": 15368.1, "ram_available_mb": 47472.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.267}, "power_stats": {"power_gpu_soc_mean_watts": 17.451, "power_cpu_cv_mean_watts": 2.029, "power_sys_5v0_mean_watts": 6.467, "gpu_utilization_percent_mean": 95.267}, "timestamp": "2026-01-30T10:24:59.160951"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7020.738, "latencies_ms": [7020.738], "images_per_second": 0.142, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image depicts a spacious hotel room with two queen-sized beds, each adorned with white linens and a dark-colored bedspread, positioned side by side, with a window in the background allowing natural light to filter into the room.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15368.1, "ram_available_mb": 47472.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 15367.7, "ram_available_mb": 47473.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.102}, "power_stats": {"power_gpu_soc_mean_watts": 16.579, "power_cpu_cv_mean_watts": 2.335, "power_sys_5v0_mean_watts": 6.762, "gpu_utilization_percent_mean": 80.102}, "timestamp": "2026-01-30T10:25:08.253488"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9274.352, "latencies_ms": [9274.352], "images_per_second": 0.108, "prompt_tokens": 1113, "response_tokens_est": 55, "n_tiles": 1, "output_text": " 1. beds: 2\n2. pillows: 12\n3. lamps: 2\n4. paintings: 2\n5. window: 1\n6. door: 1\n7. floor: wooden\n8. ceiling: white", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15367.7, "ram_available_mb": 47473.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15368.5, "ram_available_mb": 47472.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.269}, "power_stats": {"power_gpu_soc_mean_watts": 15.845, "power_cpu_cv_mean_watts": 2.86, "power_sys_5v0_mean_watts": 6.393, "gpu_utilization_percent_mean": 92.269}, "timestamp": "2026-01-30T10:25:19.549315"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8023.242, "latencies_ms": [8023.242], "images_per_second": 0.125, "prompt_tokens": 1117, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The beds are positioned on the left side of the room, with the window and door located on the right side. The lamp on the left bedside table is positioned closer to the camera than the lamp on the right bedside table. The artwork is positioned above the beds, with the window and door being further away from the beds.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15368.5, "ram_available_mb": 47472.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.7, "ram_used_mb": 15370.6, "ram_available_mb": 47470.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.576}, "power_stats": {"power_gpu_soc_mean_watts": 17.495, "power_cpu_cv_mean_watts": 2.5, "power_sys_5v0_mean_watts": 7.039, "gpu_utilization_percent_mean": 91.576}, "timestamp": "2026-01-30T10:25:29.600915"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7631.481, "latencies_ms": [7631.481], "images_per_second": 0.131, "prompt_tokens": 1111, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a serene hotel room bathed in soft light, where two queen-sized beds rest against a wall adorned with a vibrant abstract painting. The room exudes a sense of tranquility, with each bed neatly made and a lamp perched on the nightstand, ready to bathe the room in a warm glow.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15370.6, "ram_available_mb": 47470.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 15371.2, "ram_available_mb": 47469.7, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.359}, "power_stats": {"power_gpu_soc_mean_watts": 16.302, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 6.937, "gpu_utilization_percent_mean": 77.359}, "timestamp": "2026-01-30T10:25:39.271840"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7893.005, "latencies_ms": [7893.005], "images_per_second": 0.127, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The room is bathed in warm light, with a mix of natural and artificial light illuminating the space. The walls are painted in a soothing shade of green, and the wooden floor adds a touch of rustic charm.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15371.2, "ram_available_mb": 47469.7, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.9, "ram_used_mb": 15371.5, "ram_available_mb": 47469.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.031}, "power_stats": {"power_gpu_soc_mean_watts": 16.692, "power_cpu_cv_mean_watts": 2.162, "power_sys_5v0_mean_watts": 6.541, "gpu_utilization_percent_mean": 97.031}, "timestamp": "2026-01-30T10:25:49.185292"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4469.083, "latencies_ms": [4469.083], "images_per_second": 0.224, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a white helmet and a white and green racing suit is riding a white motorcycle on a road with a crowd of people watching from behind a fence.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 15371.5, "ram_available_mb": 47469.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.638, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 7.529, "gpu_utilization_percent_mean": 80.639}, "timestamp": "2026-01-30T10:25:55.686313"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4784.962, "latencies_ms": [4784.962], "images_per_second": 0.209, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. rider: 1\n3. helmet: 1\n4. fence: 2\n5. people: 8", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 15370.9, "ram_available_mb": 47470.0, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.55}, "power_stats": {"power_gpu_soc_mean_watts": 20.057, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 7.375, "gpu_utilization_percent_mean": 74.55}, "timestamp": "2026-01-30T10:26:02.499237"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4705.827, "latencies_ms": [4705.827], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the rider leaning into a turn. The spectators are located in the background, on the right side of the image, and are positioned behind a fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15370.9, "ram_available_mb": 47470.0, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 15369.2, "ram_available_mb": 47471.7, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.974}, "power_stats": {"power_gpu_soc_mean_watts": 19.596, "power_cpu_cv_mean_watts": 1.489, "power_sys_5v0_mean_watts": 7.619, "gpu_utilization_percent_mean": 67.974}, "timestamp": "2026-01-30T10:26:09.232215"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7549.968, "latencies_ms": [7549.968], "images_per_second": 0.132, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a white helmet and a white and green racing suit is riding a white motorcycle on a road. There are people standing behind a fence watching him.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15369.2, "ram_available_mb": 47471.7, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 15369.3, "ram_available_mb": 47471.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.778}, "power_stats": {"power_gpu_soc_mean_watts": 16.336, "power_cpu_cv_mean_watts": 2.683, "power_sys_5v0_mean_watts": 6.334, "gpu_utilization_percent_mean": 96.778}, "timestamp": "2026-01-30T10:26:18.841052"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2908.913, "latencies_ms": [2908.913], "images_per_second": 0.344, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The motorcycle is white and green, and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15369.3, "ram_available_mb": 47471.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 15369.3, "ram_available_mb": 47471.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.164, "power_cpu_cv_mean_watts": 0.984, "power_sys_5v0_mean_watts": 7.879, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T10:26:23.809091"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6405.309, "latencies_ms": [6405.309], "images_per_second": 0.156, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A table set with a vase of white flowers and wine glasses is illuminated by a soft light.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 15369.3, "ram_available_mb": 47471.6, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.0, "ram_used_mb": 15371.7, "ram_available_mb": 47469.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.981}, "power_stats": {"power_gpu_soc_mean_watts": 16.824, "power_cpu_cv_mean_watts": 2.501, "power_sys_5v0_mean_watts": 6.306, "gpu_utilization_percent_mean": 97.981}, "timestamp": "2026-01-30T10:26:32.239400"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4262.185, "latencies_ms": [4262.185], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " table: 1\nflowers: 1\nglass: 4\nwine glass: 2\nspoon: 1\nplate: 1\ncloth: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15371.7, "ram_available_mb": 47469.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 15372.8, "ram_available_mb": 47468.1, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.68, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 7.689, "gpu_utilization_percent_mean": 69.8}, "timestamp": "2026-01-30T10:26:38.528386"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8143.981, "latencies_ms": [8143.981], "images_per_second": 0.123, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The vase with flowers is placed in the center of the table, with the glasses arranged around it. The table is set against a dark background, with the lights reflecting off the glassware.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15372.8, "ram_available_mb": 47468.1, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.5, "ram_used_mb": 15371.0, "ram_available_mb": 47469.9, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.162}, "power_stats": {"power_gpu_soc_mean_watts": 16.091, "power_cpu_cv_mean_watts": 2.627, "power_sys_5v0_mean_watts": 6.349, "gpu_utilization_percent_mean": 97.162}, "timestamp": "2026-01-30T10:26:48.702298"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3145.751, "latencies_ms": [3145.751], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A table set for a dinner party with a centerpiece of white flowers and wine glasses.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15371.0, "ram_available_mb": 47469.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.779, "power_cpu_cv_mean_watts": 1.009, "power_sys_5v0_mean_watts": 7.882, "gpu_utilization_percent_mean": 77.56}, "timestamp": "2026-01-30T10:26:53.868054"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7340.238, "latencies_ms": [7340.238], "images_per_second": 0.136, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The table is covered with a white tablecloth, and the glasses are clear. The lighting is dim, and the table is set for a formal dinner.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 13.5, "ram_used_mb": 15371.4, "ram_available_mb": 47469.4, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.839}, "power_stats": {"power_gpu_soc_mean_watts": 16.537, "power_cpu_cv_mean_watts": 2.681, "power_sys_5v0_mean_watts": 6.374, "gpu_utilization_percent_mean": 97.839}, "timestamp": "2026-01-30T10:27:03.246576"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3731.915, "latencies_ms": [3731.915], "images_per_second": 0.268, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15371.4, "ram_available_mb": 47469.4, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 15372.1, "ram_available_mb": 47468.8, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.065}, "power_stats": {"power_gpu_soc_mean_watts": 25.675, "power_cpu_cv_mean_watts": 1.137, "power_sys_5v0_mean_watts": 8.248, "gpu_utilization_percent_mean": 75.065}, "timestamp": "2026-01-30T10:27:09.033685"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8686.457, "latencies_ms": [8686.457], "images_per_second": 0.115, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. clock: 2\n2. pole: 1\n3. sky: 1\n4. clouds: 1\n5. bird: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15372.1, "ram_available_mb": 47468.8, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 15372.6, "ram_available_mb": 47468.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.589}, "power_stats": {"power_gpu_soc_mean_watts": 17.225, "power_cpu_cv_mean_watts": 2.474, "power_sys_5v0_mean_watts": 6.481, "gpu_utilization_percent_mean": 91.589}, "timestamp": "2026-01-30T10:27:19.731771"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6387.633, "latencies_ms": [6387.633], "images_per_second": 0.157, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The clock is positioned in the center of the image, with the pole extending upwards and the sky in the background. The clock is relatively close to the camera, while the sky is farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15372.6, "ram_available_mb": 47468.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 15373.3, "ram_available_mb": 47467.6, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.385}, "power_stats": {"power_gpu_soc_mean_watts": 20.598, "power_cpu_cv_mean_watts": 1.617, "power_sys_5v0_mean_watts": 7.432, "gpu_utilization_percent_mean": 93.385}, "timestamp": "2026-01-30T10:27:28.151257"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6437.095, "latencies_ms": [6437.095], "images_per_second": 0.155, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15373.0, "ram_available_mb": 47467.9, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 15372.7, "ram_available_mb": 47468.2, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.352}, "power_stats": {"power_gpu_soc_mean_watts": 18.899, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 6.717, "gpu_utilization_percent_mean": 89.352}, "timestamp": "2026-01-30T10:27:36.634313"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6733.388, "latencies_ms": [6733.388], "images_per_second": 0.149, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The clock is black and white, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15372.7, "ram_available_mb": 47468.2, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.607}, "power_stats": {"power_gpu_soc_mean_watts": 17.66, "power_cpu_cv_mean_watts": 1.988, "power_sys_5v0_mean_watts": 6.433, "gpu_utilization_percent_mean": 94.607}, "timestamp": "2026-01-30T10:27:45.407943"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3734.267, "latencies_ms": [3734.267], "images_per_second": 0.268, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a black shirt and a cap is riding a skateboard on a red and gray surface.", "error": null, "sys_before": {"cpu_percent": 23.5, "ram_used_mb": 15371.6, "ram_available_mb": 47469.3, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 15369.8, "ram_available_mb": 47471.1, "ram_percent": 24.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.839}, "power_stats": {"power_gpu_soc_mean_watts": 22.288, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 7.582, "gpu_utilization_percent_mean": 81.839}, "timestamp": "2026-01-30T10:27:51.177215"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8116.484, "latencies_ms": [8116.484], "images_per_second": 0.123, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. cap: 1\n4. pants: 1\n5. shoes: 1\n6. trees: 1\n7. ground: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15369.8, "ram_available_mb": 47471.1, "ram_percent": 24.5}, "sys_after": {"cpu_percent": 14.1, "ram_used_mb": 15434.3, "ram_available_mb": 47406.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.449}, "power_stats": {"power_gpu_soc_mean_watts": 16.835, "power_cpu_cv_mean_watts": 2.833, "power_sys_5v0_mean_watts": 6.751, "gpu_utilization_percent_mean": 95.449}, "timestamp": "2026-01-30T10:28:01.331608"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3626.662, "latencies_ms": [3626.662], "images_per_second": 0.276, "prompt_tokens": 1118, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on the skateboard. The background features a park with trees and a building.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15434.3, "ram_available_mb": 47406.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 15434.8, "ram_available_mb": 47406.1, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.267}, "power_stats": {"power_gpu_soc_mean_watts": 23.456, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 72.267}, "timestamp": "2026-01-30T10:28:06.995111"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6703.703, "latencies_ms": [6703.703], "images_per_second": 0.149, "prompt_tokens": 1112, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A young man wearing a black t-shirt and a blue baseball cap is skateboarding on a red and gray concrete surface in a park.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 15434.8, "ram_available_mb": 47406.1, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.5, "ram_used_mb": 15436.7, "ram_available_mb": 47404.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.321}, "power_stats": {"power_gpu_soc_mean_watts": 16.451, "power_cpu_cv_mean_watts": 2.374, "power_sys_5v0_mean_watts": 6.386, "gpu_utilization_percent_mean": 95.321}, "timestamp": "2026-01-30T10:28:15.716176"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3997.04, "latencies_ms": [3997.04], "images_per_second": 0.25, "prompt_tokens": 1110, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a red and gray concrete surface, with a backdrop of trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15436.7, "ram_available_mb": 47404.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 15436.3, "ram_available_mb": 47404.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.818}, "power_stats": {"power_gpu_soc_mean_watts": 21.992, "power_cpu_cv_mean_watts": 1.492, "power_sys_5v0_mean_watts": 7.661, "gpu_utilization_percent_mean": 73.818}, "timestamp": "2026-01-30T10:28:21.756505"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5710.98, "latencies_ms": [5710.98], "images_per_second": 0.175, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A white plate filled with orange carrots and green beans is placed on a kitchen counter.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15436.3, "ram_available_mb": 47404.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 15435.7, "ram_available_mb": 47405.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.021}, "power_stats": {"power_gpu_soc_mean_watts": 16.82, "power_cpu_cv_mean_watts": 2.062, "power_sys_5v0_mean_watts": 6.374, "gpu_utilization_percent_mean": 95.021}, "timestamp": "2026-01-30T10:28:29.511796"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6711.4, "latencies_ms": [6711.4], "images_per_second": 0.149, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15435.7, "ram_available_mb": 47405.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.554}, "power_stats": {"power_gpu_soc_mean_watts": 16.935, "power_cpu_cv_mean_watts": 2.124, "power_sys_5v0_mean_watts": 6.857, "gpu_utilization_percent_mean": 79.554}, "timestamp": "2026-01-30T10:28:38.254752"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7161.268, "latencies_ms": [7161.268], "images_per_second": 0.14, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The carrots are in the foreground, with the blue scissors and the white container in the background. The carrots are to the left of the scissors, and the white container is to the right of the scissors.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15436.7, "ram_available_mb": 47404.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.77}, "power_stats": {"power_gpu_soc_mean_watts": 16.744, "power_cpu_cv_mean_watts": 2.547, "power_sys_5v0_mean_watts": 6.56, "gpu_utilization_percent_mean": 85.77}, "timestamp": "2026-01-30T10:28:47.471568"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4689.018, "latencies_ms": [4689.018], "images_per_second": 0.213, "prompt_tokens": 1111, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In a kitchen, a white plate is filled with fresh carrots and beets, ready to be cooked. The carrots are bright orange and the beets are a deep red, indicating they are ripe and ready to be used.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15436.7, "ram_available_mb": 47404.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.026}, "power_stats": {"power_gpu_soc_mean_watts": 19.896, "power_cpu_cv_mean_watts": 1.54, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 69.026}, "timestamp": "2026-01-30T10:28:54.191266"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7522.704, "latencies_ms": [7522.704], "images_per_second": 0.133, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a white plate filled with orange carrots and green beans, placed on a kitchen counter. The lighting is bright and natural, illuminating the vibrant colors of the vegetables.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 15436.6, "ram_available_mb": 47404.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.222}, "power_stats": {"power_gpu_soc_mean_watts": 16.516, "power_cpu_cv_mean_watts": 2.498, "power_sys_5v0_mean_watts": 6.409, "gpu_utilization_percent_mean": 96.222}, "timestamp": "2026-01-30T10:29:03.752616"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3375.338, "latencies_ms": [3375.338], "images_per_second": 0.296, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a suit and tie is giving a presentation on a large screen in front of an audience.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 15436.0, "ram_available_mb": 47404.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 15438.9, "ram_available_mb": 47402.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.37}, "power_stats": {"power_gpu_soc_mean_watts": 22.977, "power_cpu_cv_mean_watts": 1.142, "power_sys_5v0_mean_watts": 7.869, "gpu_utilization_percent_mean": 78.37}, "timestamp": "2026-01-30T10:29:09.183600"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9453.873, "latencies_ms": [9453.873], "images_per_second": 0.106, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. head: 2\n4. neck: 1\n5. shoulder: 1\n6. arm: 1\n7. hand: 1\n8. screen: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15438.9, "ram_available_mb": 47402.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.7, "ram_used_mb": 15438.5, "ram_available_mb": 47402.4, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.241}, "power_stats": {"power_gpu_soc_mean_watts": 15.869, "power_cpu_cv_mean_watts": 2.616, "power_sys_5v0_mean_watts": 6.402, "gpu_utilization_percent_mean": 93.241}, "timestamp": "2026-01-30T10:29:20.687791"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7612.276, "latencies_ms": [7612.276], "images_per_second": 0.131, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man is standing in front of a large screen, which is positioned to the left of the image. The audience is seated in front of the screen, with their heads visible in the foreground. The stage is located in the background, with the man standing on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15438.5, "ram_available_mb": 47402.4, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 16.2, "ram_used_mb": 15459.9, "ram_available_mb": 47380.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.048}, "power_stats": {"power_gpu_soc_mean_watts": 17.21, "power_cpu_cv_mean_watts": 2.587, "power_sys_5v0_mean_watts": 6.898, "gpu_utilization_percent_mean": 96.048}, "timestamp": "2026-01-30T10:29:30.328821"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4721.709, "latencies_ms": [4721.709], "images_per_second": 0.212, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man in a suit is giving a presentation on a large screen. People are watching him from the audience.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15460.1, "ram_available_mb": 47380.8, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 15460.6, "ram_available_mb": 47380.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.897}, "power_stats": {"power_gpu_soc_mean_watts": 19.48, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 6.955, "gpu_utilization_percent_mean": 81.897}, "timestamp": "2026-01-30T10:29:37.100556"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9296.231, "latencies_ms": [9296.231], "images_per_second": 0.108, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a man in a suit and tie standing on a stage, with a large screen behind him displaying a presentation. The lighting is bright and focused on the speaker, while the audience is seated in front of the screen, with their heads visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15460.6, "ram_available_mb": 47380.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 15461.1, "ram_available_mb": 47379.8, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.925}, "power_stats": {"power_gpu_soc_mean_watts": 15.729, "power_cpu_cv_mean_watts": 2.888, "power_sys_5v0_mean_watts": 6.369, "gpu_utilization_percent_mean": 95.925}, "timestamp": "2026-01-30T10:29:48.416577"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3859.581, "latencies_ms": [3859.581], "images_per_second": 0.259, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " Three workers in blue uniforms are standing on a street corner, with a motorcycle parked nearby, and a billboard with Chinese text in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15461.1, "ram_available_mb": 47379.8, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15460.2, "ram_available_mb": 47380.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.71}, "power_stats": {"power_gpu_soc_mean_watts": 21.912, "power_cpu_cv_mean_watts": 1.279, "power_sys_5v0_mean_watts": 7.797, "gpu_utilization_percent_mean": 73.71}, "timestamp": "2026-01-30T10:29:54.304427"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9918.625, "latencies_ms": [9918.625], "images_per_second": 0.101, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Scooters: 3\n2. Motorcycles: 2\n3. Banners: 2\n4. Posters: 1\n5. Signboards: 2\n6. People: 3\n7. Banners: 1\n8. Banners: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15460.2, "ram_available_mb": 47380.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.4, "ram_used_mb": 15460.0, "ram_available_mb": 47380.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.542}, "power_stats": {"power_gpu_soc_mean_watts": 15.837, "power_cpu_cv_mean_watts": 2.881, "power_sys_5v0_mean_watts": 6.425, "gpu_utilization_percent_mean": 91.542}, "timestamp": "2026-01-30T10:30:06.241683"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8235.985, "latencies_ms": [8235.985], "images_per_second": 0.121, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The three men are standing on the sidewalk, with the motorcycles parked on the left side of the image. The motorcycles are positioned in the foreground, while the men are in the middle ground. The men are standing near the motorcycles, and the motorcycles are near the wall.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15460.0, "ram_available_mb": 47380.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 14.0, "ram_used_mb": 15459.7, "ram_available_mb": 47381.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.171}, "power_stats": {"power_gpu_soc_mean_watts": 16.5, "power_cpu_cv_mean_watts": 2.82, "power_sys_5v0_mean_watts": 6.644, "gpu_utilization_percent_mean": 96.171}, "timestamp": "2026-01-30T10:30:16.498075"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3749.2, "latencies_ms": [3749.2], "images_per_second": 0.267, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three workers in blue uniforms are standing on a street corner, talking to each other.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15459.7, "ram_available_mb": 47381.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 15460.7, "ram_available_mb": 47380.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.355}, "power_stats": {"power_gpu_soc_mean_watts": 21.835, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 7.345, "gpu_utilization_percent_mean": 83.355}, "timestamp": "2026-01-30T10:30:22.293168"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8616.755, "latencies_ms": [8616.755], "images_per_second": 0.116, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image depicts a group of three individuals dressed in blue uniforms, standing on a street corner. The sky is overcast, and the lighting is natural, suggesting it is daytime. The pavement is wet, indicating recent rain.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15460.7, "ram_available_mb": 47380.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 15461.7, "ram_available_mb": 47379.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.37}, "power_stats": {"power_gpu_soc_mean_watts": 15.868, "power_cpu_cv_mean_watts": 2.897, "power_sys_5v0_mean_watts": 6.315, "gpu_utilization_percent_mean": 96.37}, "timestamp": "2026-01-30T10:30:32.950943"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4669.534, "latencies_ms": [4669.534], "images_per_second": 0.214, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A black plastic container filled with a green and yellow mixture of vegetables and meat is placed on a white paper plate, which is also holding a pile of shredded chicken.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 15461.7, "ram_available_mb": 47379.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 15463.2, "ram_available_mb": 47377.7, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.553}, "power_stats": {"power_gpu_soc_mean_watts": 23.343, "power_cpu_cv_mean_watts": 1.328, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 76.553}, "timestamp": "2026-01-30T10:30:39.668500"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9837.242, "latencies_ms": [9837.242], "images_per_second": 0.102, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. plate: 1\n2. bowl: 1\n3. fork: 1\n4. shredded chicken: 1\n5. broccoli: 1\n6. mashed potatoes: 1\n7. sauce: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15463.2, "ram_available_mb": 47377.7, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 15463.9, "ram_available_mb": 47377.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.869}, "power_stats": {"power_gpu_soc_mean_watts": 16.597, "power_cpu_cv_mean_watts": 2.317, "power_sys_5v0_mean_watts": 6.654, "gpu_utilization_percent_mean": 85.869}, "timestamp": "2026-01-30T10:30:51.532283"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10639.059, "latencies_ms": [10639.059], "images_per_second": 0.094, "prompt_tokens": 1450, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The black bowl of food is located in the upper left corner of the image, while the white plate with shredded chicken is situated in the lower right corner. The shredded chicken is placed directly in front of the bowl, and the plate is positioned slightly to the right of the bowl.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15463.9, "ram_available_mb": 47377.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.4, "ram_used_mb": 15469.3, "ram_available_mb": 47371.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.483}, "power_stats": {"power_gpu_soc_mean_watts": 16.475, "power_cpu_cv_mean_watts": 2.853, "power_sys_5v0_mean_watts": 6.54, "gpu_utilization_percent_mean": 96.483}, "timestamp": "2026-01-30T10:31:04.208835"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4157.959, "latencies_ms": [4157.959], "images_per_second": 0.241, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate with a bowl of food and a fork on it is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15469.3, "ram_available_mb": 47371.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 15470.3, "ram_available_mb": 47370.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.206}, "power_stats": {"power_gpu_soc_mean_watts": 24.536, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 86.206}, "timestamp": "2026-01-30T10:31:10.387602"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9676.421, "latencies_ms": [9676.421], "images_per_second": 0.103, "prompt_tokens": 1442, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a black plastic container filled with a green and yellow mixture of vegetables and chicken, placed on a white paper plate. The food is served on a beige carpeted floor, and the lighting is natural, coming from an unseen source.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15470.3, "ram_available_mb": 47370.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 15471.3, "ram_available_mb": 47369.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.573}, "power_stats": {"power_gpu_soc_mean_watts": 16.774, "power_cpu_cv_mean_watts": 2.701, "power_sys_5v0_mean_watts": 6.538, "gpu_utilization_percent_mean": 87.573}, "timestamp": "2026-01-30T10:31:22.080083"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6005.35, "latencies_ms": [6005.35], "images_per_second": 0.167, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man with glasses and a plaid hat is smiling in front of a building.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15471.3, "ram_available_mb": 47369.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 15472.0, "ram_available_mb": 47368.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.367}, "power_stats": {"power_gpu_soc_mean_watts": 16.535, "power_cpu_cv_mean_watts": 2.239, "power_sys_5v0_mean_watts": 6.278, "gpu_utilization_percent_mean": 93.367}, "timestamp": "2026-01-30T10:31:30.120001"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5534.837, "latencies_ms": [5534.837], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. glasses: 1\n3. tie: 1\n4. shirt: 1\n5. cap: 1\n6. building: 1\n7. window: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 15472.0, "ram_available_mb": 47368.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 15476.2, "ram_available_mb": 47364.7, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.174}, "power_stats": {"power_gpu_soc_mean_watts": 18.362, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 7.59, "gpu_utilization_percent_mean": 69.174}, "timestamp": "2026-01-30T10:31:37.696788"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8728.191, "latencies_ms": [8728.191], "images_per_second": 0.115, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The man is positioned in the foreground of the image, with the background consisting of a building and a pool. The man is wearing a blue shirt and a red tie, and he is also wearing a plaid hat.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15476.2, "ram_available_mb": 47364.7, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 15478.6, "ram_available_mb": 47362.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.836}, "power_stats": {"power_gpu_soc_mean_watts": 15.807, "power_cpu_cv_mean_watts": 2.551, "power_sys_5v0_mean_watts": 6.324, "gpu_utilization_percent_mean": 97.836}, "timestamp": "2026-01-30T10:31:48.467634"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3100.56, "latencies_ms": [3100.56], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a plaid hat and glasses is standing in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15478.6, "ram_available_mb": 47362.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 15479.5, "ram_available_mb": 47361.4, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.32}, "power_stats": {"power_gpu_soc_mean_watts": 23.629, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 7.879, "gpu_utilization_percent_mean": 76.32}, "timestamp": "2026-01-30T10:31:53.618864"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6619.443, "latencies_ms": [6619.443], "images_per_second": 0.151, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The man is wearing a blue shirt and a red tie, and the picture was taken in bright daylight.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15479.5, "ram_available_mb": 47361.4, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 14.1, "ram_used_mb": 15480.3, "ram_available_mb": 47360.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.091}, "power_stats": {"power_gpu_soc_mean_watts": 16.623, "power_cpu_cv_mean_watts": 2.075, "power_sys_5v0_mean_watts": 6.304, "gpu_utilization_percent_mean": 98.091}, "timestamp": "2026-01-30T10:32:02.270061"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4823.907, "latencies_ms": [4823.907], "images_per_second": 0.207, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza, with the top left photo being the most detailed and the bottom right photo being the least detailed.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15480.3, "ram_available_mb": 47360.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15480.8, "ram_available_mb": 47360.1, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.098}, "power_stats": {"power_gpu_soc_mean_watts": 23.035, "power_cpu_cv_mean_watts": 1.436, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 77.098}, "timestamp": "2026-01-30T10:32:09.139129"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6432.595, "latencies_ms": [6432.595], "images_per_second": 0.155, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " pizza: 6", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 15480.8, "ram_available_mb": 47360.1, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 15479.9, "ram_available_mb": 47361.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.151}, "power_stats": {"power_gpu_soc_mean_watts": 18.076, "power_cpu_cv_mean_watts": 2.047, "power_sys_5v0_mean_watts": 6.361, "gpu_utilization_percent_mean": 98.151}, "timestamp": "2026-01-30T10:32:17.587714"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7238.457, "latencies_ms": [7238.457], "images_per_second": 0.138, "prompt_tokens": 1450, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The main objects are arranged in a grid pattern, with the largest image in the top left corner and the smallest in the bottom right. The slices of pizza are positioned in a way that creates a sense of depth, with the largest slice in the top left and the smallest in the bottom right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15479.9, "ram_available_mb": 47361.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 15480.0, "ram_available_mb": 47360.9, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.933}, "power_stats": {"power_gpu_soc_mean_watts": 19.673, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 7.554, "gpu_utilization_percent_mean": 82.933}, "timestamp": "2026-01-30T10:32:26.848595"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6878.805, "latencies_ms": [6878.805], "images_per_second": 0.145, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15480.0, "ram_available_mb": 47360.9, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15479.1, "ram_available_mb": 47361.8, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.741}, "power_stats": {"power_gpu_soc_mean_watts": 18.024, "power_cpu_cv_mean_watts": 2.348, "power_sys_5v0_mean_watts": 6.446, "gpu_utilization_percent_mean": 91.741}, "timestamp": "2026-01-30T10:32:35.759083"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5706.435, "latencies_ms": [5706.435], "images_per_second": 0.175, "prompt_tokens": 1442, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The pizza has a yellow and orange color, and the lighting is bright.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15479.1, "ram_available_mb": 47361.8, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 15479.6, "ram_available_mb": 47361.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.043}, "power_stats": {"power_gpu_soc_mean_watts": 19.719, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 6.935, "gpu_utilization_percent_mean": 96.043}, "timestamp": "2026-01-30T10:32:43.505228"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5433.585, "latencies_ms": [5433.585], "images_per_second": 0.184, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two young girls are petting a goat and a sheep in a fenced area.", "error": null, "sys_before": {"cpu_percent": 25.9, "ram_used_mb": 15479.6, "ram_available_mb": 47361.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 15479.9, "ram_available_mb": 47361.0, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.356}, "power_stats": {"power_gpu_soc_mean_watts": 17.767, "power_cpu_cv_mean_watts": 1.895, "power_sys_5v0_mean_watts": 6.467, "gpu_utilization_percent_mean": 88.356}, "timestamp": "2026-01-30T10:32:50.982963"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4571.434, "latencies_ms": [4571.434], "images_per_second": 0.219, "prompt_tokens": 1113, "response_tokens_est": 19, "n_tiles": 1, "output_text": " goat: 2, girl: 2, fence: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15479.9, "ram_available_mb": 47361.0, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15480.6, "ram_available_mb": 47360.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.921}, "power_stats": {"power_gpu_soc_mean_watts": 19.478, "power_cpu_cv_mean_watts": 2.076, "power_sys_5v0_mean_watts": 6.993, "gpu_utilization_percent_mean": 94.921}, "timestamp": "2026-01-30T10:32:57.582825"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8560.141, "latencies_ms": [8560.141], "images_per_second": 0.117, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The two girls are standing on the left side of the image, with the goat in the middle and the other goat on the right side. The goat on the left is being petted by the girl in the pink dress, while the girl in the blue dress is petting the goat on the right.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15480.6, "ram_available_mb": 47360.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 15481.3, "ram_available_mb": 47359.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.352}, "power_stats": {"power_gpu_soc_mean_watts": 15.779, "power_cpu_cv_mean_watts": 2.104, "power_sys_5v0_mean_watts": 6.615, "gpu_utilization_percent_mean": 82.352}, "timestamp": "2026-01-30T10:33:08.157283"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6090.871, "latencies_ms": [6090.871], "images_per_second": 0.164, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two young girls are petting a goat and a sheep in a fenced area.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15481.3, "ram_available_mb": 47359.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.6, "ram_used_mb": 15487.2, "ram_available_mb": 47353.7, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.059}, "power_stats": {"power_gpu_soc_mean_watts": 17.018, "power_cpu_cv_mean_watts": 2.317, "power_sys_5v0_mean_watts": 6.332, "gpu_utilization_percent_mean": 98.059}, "timestamp": "2026-01-30T10:33:16.293438"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4706.216, "latencies_ms": [4706.216], "images_per_second": 0.212, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image is taken in bright daylight with a clear blue sky in the background. The girls are wearing colorful dresses, and the goats are black and white.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 15487.2, "ram_available_mb": 47353.7, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.1, "ram_used_mb": 15488.6, "ram_available_mb": 47352.3, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.45}, "power_stats": {"power_gpu_soc_mean_watts": 19.967, "power_cpu_cv_mean_watts": 3.485, "power_sys_5v0_mean_watts": 7.44, "gpu_utilization_percent_mean": 76.45}, "timestamp": "2026-01-30T10:33:23.046329"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8106.994, "latencies_ms": [8106.994], "images_per_second": 0.123, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a nighttime scene at a street intersection, where a traffic light is illuminated by a green light, and a street sign is visible in the background, indicating the name of the street.", "error": null, "sys_before": {"cpu_percent": 28.6, "ram_used_mb": 15488.6, "ram_available_mb": 47352.3, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 13.7, "ram_used_mb": 15489.5, "ram_available_mb": 47351.4, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.794}, "power_stats": {"power_gpu_soc_mean_watts": 16.146, "power_cpu_cv_mean_watts": 2.921, "power_sys_5v0_mean_watts": 6.353, "gpu_utilization_percent_mean": 97.794}, "timestamp": "2026-01-30T10:33:33.196029"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6405.975, "latencies_ms": [6405.975], "images_per_second": 0.156, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. traffic light: 2\n2. street sign: 1\n3. street light: 1\n4. car: 1\n5. mountain: 1\n6. road: 1\n7. sky: 1\n8. road sign: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15489.5, "ram_available_mb": 47351.4, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 15488.7, "ram_available_mb": 47352.2, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.963}, "power_stats": {"power_gpu_soc_mean_watts": 18.341, "power_cpu_cv_mean_watts": 2.039, "power_sys_5v0_mean_watts": 7.392, "gpu_utilization_percent_mean": 80.963}, "timestamp": "2026-01-30T10:33:41.650473"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8113.148, "latencies_ms": [8113.148], "images_per_second": 0.123, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The traffic light is on the left side of the image, while the street sign is on the right side. The traffic light is closer to the viewer, while the street sign is farther away. The traffic light is in the foreground, while the street sign is in the background.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 15488.7, "ram_available_mb": 47352.2, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15488.2, "ram_available_mb": 47352.7, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.029}, "power_stats": {"power_gpu_soc_mean_watts": 15.732, "power_cpu_cv_mean_watts": 2.344, "power_sys_5v0_mean_watts": 6.617, "gpu_utilization_percent_mean": 80.029}, "timestamp": "2026-01-30T10:33:51.821256"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9334.907, "latencies_ms": [9334.907], "images_per_second": 0.107, "prompt_tokens": 1111, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a night scene at a street intersection, where a traffic light is illuminated by a green light, signaling vehicles to proceed. The sky is dark, suggesting it is either early morning or late evening, and the street is lined with buildings and mountains in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15488.2, "ram_available_mb": 47352.7, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 14.3, "ram_used_mb": 15491.4, "ram_available_mb": 47349.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.584}, "power_stats": {"power_gpu_soc_mean_watts": 15.627, "power_cpu_cv_mean_watts": 2.413, "power_sys_5v0_mean_watts": 6.452, "gpu_utilization_percent_mean": 96.584}, "timestamp": "2026-01-30T10:34:03.185940"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8255.001, "latencies_ms": [8255.001], "images_per_second": 0.121, "prompt_tokens": 1109, "response_tokens_est": 80, "n_tiles": 1, "output_text": " The image captures a serene night scene at a street intersection, where the sky is painted in hues of deep blue, and the moon is partially visible. The traffic lights, glowing in a soft green, stand as silent sentinels guiding the flow of vehicles. The street, bathed in the glow of streetlights, is lined with buildings and trees, their silhouettes adding depth to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15491.4, "ram_available_mb": 47349.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 11.9, "ram_used_mb": 15490.4, "ram_available_mb": 47350.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.871}, "power_stats": {"power_gpu_soc_mean_watts": 17.284, "power_cpu_cv_mean_watts": 2.403, "power_sys_5v0_mean_watts": 7.151, "gpu_utilization_percent_mean": 83.871}, "timestamp": "2026-01-30T10:34:13.453815"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3289.745, "latencies_ms": [3289.745], "images_per_second": 0.304, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman wearing a patterned dress stands in front of a building with a bunch of bananas in front of her.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 15490.4, "ram_available_mb": 47350.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 15490.3, "ram_available_mb": 47350.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.223, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T10:34:18.779713"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6540.459, "latencies_ms": [6540.459], "images_per_second": 0.153, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. bananas: 2\n3. building: 1\n4. door: 1\n5. wall: 1\n6. window: 1\n7. sign: 1\n8. wall decoration: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15490.3, "ram_available_mb": 47350.6, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15488.3, "ram_available_mb": 47352.6, "ram_percent": 24.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.709}, "power_stats": {"power_gpu_soc_mean_watts": 18.19, "power_cpu_cv_mean_watts": 2.228, "power_sys_5v0_mean_watts": 7.211, "gpu_utilization_percent_mean": 83.709}, "timestamp": "2026-01-30T10:34:27.361187"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6902.245, "latencies_ms": [6902.245], "images_per_second": 0.145, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bananas are in the foreground, with the woman standing behind them. The woman is positioned to the right of the bananas, and the building is in the background.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 15489.3, "ram_available_mb": 47351.6, "ram_percent": 24.6}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 15502.0, "ram_available_mb": 47338.9, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.259}, "power_stats": {"power_gpu_soc_mean_watts": 16.793, "power_cpu_cv_mean_watts": 2.665, "power_sys_5v0_mean_watts": 6.505, "gpu_utilization_percent_mean": 89.259}, "timestamp": "2026-01-30T10:34:36.295159"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4847.093, "latencies_ms": [4847.093], "images_per_second": 0.206, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman is standing in front of a building with bananas on a table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15502.0, "ram_available_mb": 47338.9, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15501.5, "ram_available_mb": 47339.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.65}, "power_stats": {"power_gpu_soc_mean_watts": 18.245, "power_cpu_cv_mean_watts": 2.023, "power_sys_5v0_mean_watts": 6.677, "gpu_utilization_percent_mean": 95.65}, "timestamp": "2026-01-30T10:34:43.172548"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6158.675, "latencies_ms": [6158.675], "images_per_second": 0.162, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image is taken in a sunny day with a warm color tone. The woman is wearing a colorful dress and the bananas are yellow.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15501.5, "ram_available_mb": 47339.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15501.8, "ram_available_mb": 47339.1, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.392}, "power_stats": {"power_gpu_soc_mean_watts": 17.348, "power_cpu_cv_mean_watts": 2.505, "power_sys_5v0_mean_watts": 6.498, "gpu_utilization_percent_mean": 86.392}, "timestamp": "2026-01-30T10:34:51.368393"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 11632.568, "latencies_ms": [11632.568], "images_per_second": 0.086, "prompt_tokens": 1432, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene, featuring a red brick building adorned with a green awning and a green fire escape. The building's facade is a canvas of graffiti, with various tags and markings adorning the shuttered windows and doors. A fire hydrant stands guard on the sidewalk, adding a touch of urban grit to the scene.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 15501.8, "ram_available_mb": 47339.1, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 15502.5, "ram_available_mb": 47338.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.51}, "power_stats": {"power_gpu_soc_mean_watts": 16.307, "power_cpu_cv_mean_watts": 2.918, "power_sys_5v0_mean_watts": 6.58, "gpu_utilization_percent_mean": 95.51}, "timestamp": "2026-01-30T10:35:05.075144"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5062.993, "latencies_ms": [5062.993], "images_per_second": 0.198, "prompt_tokens": 1446, "response_tokens_est": 20, "n_tiles": 1, "output_text": " fire hydrant: 1\nbike rack: 1\ngraffiti: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15502.5, "ram_available_mb": 47338.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 15502.7, "ram_available_mb": 47338.2, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.81}, "power_stats": {"power_gpu_soc_mean_watts": 21.771, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 7.453, "gpu_utilization_percent_mean": 94.81}, "timestamp": "2026-01-30T10:35:12.165670"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9307.179, "latencies_ms": [9307.179], "images_per_second": 0.107, "prompt_tokens": 1450, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The fire hydrant is located on the left side of the image, in the foreground. The building is in the background, with the sidewalk in front of it. The graffiti on the shutters is located in the middle ground, between the fire hydrant and the building.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15502.7, "ram_available_mb": 47338.2, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 15504.6, "ram_available_mb": 47336.3, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.051}, "power_stats": {"power_gpu_soc_mean_watts": 16.681, "power_cpu_cv_mean_watts": 2.264, "power_sys_5v0_mean_watts": 6.707, "gpu_utilization_percent_mean": 83.051}, "timestamp": "2026-01-30T10:35:23.506258"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 12121.372, "latencies_ms": [12121.372], "images_per_second": 0.082, "prompt_tokens": 1444, "response_tokens_est": 79, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene, where a red brick building stands proudly on a city street corner. The building's green awning and shuttered windows add a splash of color to the otherwise monochrome facade. A fire hydrant, a common sight on city streets, stands guard on the sidewalk, while a tree in the background adds a touch of nature to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15504.6, "ram_available_mb": 47336.3, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15505.6, "ram_available_mb": 47335.3, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.66}, "power_stats": {"power_gpu_soc_mean_watts": 16.143, "power_cpu_cv_mean_watts": 2.885, "power_sys_5v0_mean_watts": 6.605, "gpu_utilization_percent_mean": 88.66}, "timestamp": "2026-01-30T10:35:37.652279"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9029.596, "latencies_ms": [9029.596], "images_per_second": 0.111, "prompt_tokens": 1442, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a red brick building with green shutters and a fire escape. The building is covered in graffiti, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15505.6, "ram_available_mb": 47335.3, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 15505.7, "ram_available_mb": 47335.2, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.803}, "power_stats": {"power_gpu_soc_mean_watts": 16.722, "power_cpu_cv_mean_watts": 2.793, "power_sys_5v0_mean_watts": 6.355, "gpu_utilization_percent_mean": 96.803}, "timestamp": "2026-01-30T10:35:48.713555"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3385.645, "latencies_ms": [3385.645], "images_per_second": 0.295, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a blue and white striped beanie is holding a yellow frisbee in his hand.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 15505.7, "ram_available_mb": 47335.2, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 15505.9, "ram_available_mb": 47335.0, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.753, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T10:35:54.141393"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9683.887, "latencies_ms": [9683.887], "images_per_second": 0.103, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. head: 1\n3. hair: 1\n4. shirt: 1\n5. hand: 1\n6. frisbee: 1\n7. ceiling: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 15505.9, "ram_available_mb": 47335.0, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.4, "ram_used_mb": 15507.1, "ram_available_mb": 47333.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.951}, "power_stats": {"power_gpu_soc_mean_watts": 15.788, "power_cpu_cv_mean_watts": 2.635, "power_sys_5v0_mean_watts": 6.376, "gpu_utilization_percent_mean": 92.951}, "timestamp": "2026-01-30T10:36:05.873064"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7049.987, "latencies_ms": [7049.987], "images_per_second": 0.142, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The man is in the foreground, holding a frisbee in his hand. The frisbee is in front of him, and the background is blurred, indicating that the focus is on the man and the frisbee.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 15507.1, "ram_available_mb": 47333.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 13.1, "ram_used_mb": 15511.8, "ram_available_mb": 47329.1, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.831}, "power_stats": {"power_gpu_soc_mean_watts": 17.362, "power_cpu_cv_mean_watts": 2.681, "power_sys_5v0_mean_watts": 6.812, "gpu_utilization_percent_mean": 95.831}, "timestamp": "2026-01-30T10:36:14.949932"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3968.224, "latencies_ms": [3968.224], "images_per_second": 0.252, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing a blue hat and a black shirt is playing frisbee in a dark room.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15511.8, "ram_available_mb": 47329.1, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 15511.3, "ram_available_mb": 47329.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.576}, "power_stats": {"power_gpu_soc_mean_watts": 21.36, "power_cpu_cv_mean_watts": 1.577, "power_sys_5v0_mean_watts": 7.357, "gpu_utilization_percent_mean": 82.576}, "timestamp": "2026-01-30T10:36:20.949306"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5581.659, "latencies_ms": [5581.659], "images_per_second": 0.179, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is a black and white photo with a blue and white striped hat. The lighting is dim, and the subject is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15511.0, "ram_available_mb": 47329.9, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 15510.0, "ram_available_mb": 47330.9, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.587}, "power_stats": {"power_gpu_soc_mean_watts": 18.16, "power_cpu_cv_mean_watts": 2.342, "power_sys_5v0_mean_watts": 6.842, "gpu_utilization_percent_mean": 95.587}, "timestamp": "2026-01-30T10:36:28.556574"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5933.411, "latencies_ms": [5933.411], "images_per_second": 0.169, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A group of people are sitting around a table with laptops and books, and they are all looking at the laptop screens.", "error": null, "sys_before": {"cpu_percent": 21.1, "ram_used_mb": 15510.0, "ram_available_mb": 47330.9, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15510.5, "ram_available_mb": 47330.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.653}, "power_stats": {"power_gpu_soc_mean_watts": 17.335, "power_cpu_cv_mean_watts": 2.46, "power_sys_5v0_mean_watts": 6.463, "gpu_utilization_percent_mean": 84.653}, "timestamp": "2026-01-30T10:36:36.517917"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6822.662, "latencies_ms": [6822.662], "images_per_second": 0.147, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 3, keyboard: 1, mouse: 1, cup: 1, bottle: 1, book: 1, person: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15510.5, "ram_available_mb": 47330.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 15512.3, "ram_available_mb": 47328.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.281}, "power_stats": {"power_gpu_soc_mean_watts": 16.826, "power_cpu_cv_mean_watts": 2.487, "power_sys_5v0_mean_watts": 6.547, "gpu_utilization_percent_mean": 97.281}, "timestamp": "2026-01-30T10:36:45.369146"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5855.113, "latencies_ms": [5855.113], "images_per_second": 0.171, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The laptop is on the left side of the table, the woman is on the right side of the table, and the man is in the middle of the table. The laptop is in the foreground, the woman is in the middle, and the man is in the background.", "error": null, "sys_before": {"cpu_percent": 40.0, "ram_used_mb": 15512.3, "ram_available_mb": 47328.6, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 15514.4, "ram_available_mb": 47326.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.204}, "power_stats": {"power_gpu_soc_mean_watts": 18.481, "power_cpu_cv_mean_watts": 2.043, "power_sys_5v0_mean_watts": 7.459, "gpu_utilization_percent_mean": 75.204}, "timestamp": "2026-01-30T10:36:53.270464"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5770.786, "latencies_ms": [5770.786], "images_per_second": 0.173, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, working on their laptops.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15514.4, "ram_available_mb": 47326.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 15510.6, "ram_available_mb": 47330.3, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.25}, "power_stats": {"power_gpu_soc_mean_watts": 17.364, "power_cpu_cv_mean_watts": 2.728, "power_sys_5v0_mean_watts": 6.413, "gpu_utilization_percent_mean": 92.25}, "timestamp": "2026-01-30T10:37:01.092162"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5148.697, "latencies_ms": [5148.697], "images_per_second": 0.194, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm yellow light. The people are using laptops and computers, and there are many objects on the table, including a glass of water, a cup, and a bottle of ketchup.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15510.6, "ram_available_mb": 47330.3, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 15511.4, "ram_available_mb": 47329.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.905}, "power_stats": {"power_gpu_soc_mean_watts": 19.167, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 7.632, "gpu_utilization_percent_mean": 70.905}, "timestamp": "2026-01-30T10:37:08.276540"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7853.422, "latencies_ms": [7853.422], "images_per_second": 0.127, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is holding a brown teddy bear and a blue umbrella.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15511.4, "ram_available_mb": 47329.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.6, "ram_used_mb": 15512.3, "ram_available_mb": 47328.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.106}, "power_stats": {"power_gpu_soc_mean_watts": 17.196, "power_cpu_cv_mean_watts": 2.688, "power_sys_5v0_mean_watts": 6.444, "gpu_utilization_percent_mean": 98.106}, "timestamp": "2026-01-30T10:37:18.181511"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8495.939, "latencies_ms": [8495.939], "images_per_second": 0.118, "prompt_tokens": 1446, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. girl: 1\n2. blue umbrella: 1\n3. girl's hand: 1\n4. girl's leg: 1\n5. girl's foot: 1\n6. girl's hand: 1\n7. girl's leg: 1\n8. girl's foot: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15512.3, "ram_available_mb": 47328.6, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 11.6, "ram_used_mb": 15513.5, "ram_available_mb": 47327.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.817}, "power_stats": {"power_gpu_soc_mean_watts": 18.998, "power_cpu_cv_mean_watts": 2.047, "power_sys_5v0_mean_watts": 7.311, "gpu_utilization_percent_mean": 86.817}, "timestamp": "2026-01-30T10:37:28.708526"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5845.354, "latencies_ms": [5845.354], "images_per_second": 0.171, "prompt_tokens": 1450, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The girl is standing in the foreground of the image, holding the umbrella in her right hand. The umbrella is positioned above her, providing shade.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15513.5, "ram_available_mb": 47327.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 15513.4, "ram_available_mb": 47327.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.688}, "power_stats": {"power_gpu_soc_mean_watts": 20.727, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.247, "gpu_utilization_percent_mean": 83.688}, "timestamp": "2026-01-30T10:37:36.569292"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7415.204, "latencies_ms": [7415.204], "images_per_second": 0.135, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is standing on a gravel surface holding a blue umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15513.4, "ram_available_mb": 47327.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 15513.4, "ram_available_mb": 47327.5, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.295}, "power_stats": {"power_gpu_soc_mean_watts": 17.384, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 6.479, "gpu_utilization_percent_mean": 95.295}, "timestamp": "2026-01-30T10:37:46.014571"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5200.317, "latencies_ms": [5200.317], "images_per_second": 0.192, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The girl is wearing a pink jacket and blue jeans, and the umbrella is blue. The lighting is natural and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15513.4, "ram_available_mb": 47327.5, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 15514.9, "ram_available_mb": 47326.0, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.279}, "power_stats": {"power_gpu_soc_mean_watts": 22.141, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 7.542, "gpu_utilization_percent_mean": 84.279}, "timestamp": "2026-01-30T10:37:53.231906"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7544.992, "latencies_ms": [7544.992], "images_per_second": 0.133, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A man in a suit stands in front of a window with a reflection of another man in it, with a desk in front of him that has a computer monitor and keyboard.", "error": null, "sys_before": {"cpu_percent": 22.7, "ram_used_mb": 15514.9, "ram_available_mb": 47326.0, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 17.6, "ram_used_mb": 15495.5, "ram_available_mb": 47345.4, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.656}, "power_stats": {"power_gpu_soc_mean_watts": 16.519, "power_cpu_cv_mean_watts": 3.222, "power_sys_5v0_mean_watts": 6.517, "gpu_utilization_percent_mean": 97.656}, "timestamp": "2026-01-30T10:38:02.819650"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4355.061, "latencies_ms": [4355.061], "images_per_second": 0.23, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " man: 1, chair: 1, computer: 2, monitor: 1, keyboard: 1, mouse: 1, tv: 1, tv screen: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15495.5, "ram_available_mb": 47345.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 15496.1, "ram_available_mb": 47344.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.946}, "power_stats": {"power_gpu_soc_mean_watts": 21.207, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 7.892, "gpu_utilization_percent_mean": 70.946}, "timestamp": "2026-01-30T10:38:09.219867"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8003.57, "latencies_ms": [8003.57], "images_per_second": 0.125, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is standing to the left of the desk, which is in the foreground of the image. The desk is positioned in front of a window, which is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15496.1, "ram_available_mb": 47344.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 16.4, "ram_used_mb": 15506.8, "ram_available_mb": 47334.1, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.97}, "power_stats": {"power_gpu_soc_mean_watts": 16.409, "power_cpu_cv_mean_watts": 2.899, "power_sys_5v0_mean_watts": 6.492, "gpu_utilization_percent_mean": 96.97}, "timestamp": "2026-01-30T10:38:19.278484"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3291.341, "latencies_ms": [3291.341], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a suit is standing in front of a window with a computer setup on a desk.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15506.5, "ram_available_mb": 47334.4, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 15511.1, "ram_available_mb": 47329.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.741}, "power_stats": {"power_gpu_soc_mean_watts": 23.171, "power_cpu_cv_mean_watts": 1.172, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 77.741}, "timestamp": "2026-01-30T10:38:24.604497"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6746.697, "latencies_ms": [6746.697], "images_per_second": 0.148, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from a window. The man is wearing a black suit and tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15511.1, "ram_available_mb": 47329.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 14.6, "ram_used_mb": 15542.1, "ram_available_mb": 47298.8, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.912}, "power_stats": {"power_gpu_soc_mean_watts": 16.745, "power_cpu_cv_mean_watts": 2.846, "power_sys_5v0_mean_watts": 6.389, "gpu_utilization_percent_mean": 97.912}, "timestamp": "2026-01-30T10:38:33.390204"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3628.742, "latencies_ms": [3628.742], "images_per_second": 0.276, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of people are sitting around a table in a room with wooden walls and a window with curtains, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 15542.1, "ram_available_mb": 47298.8, "ram_percent": 24.7}, "sys_after": {"cpu_percent": 14.3, "ram_used_mb": 14881.3, "ram_available_mb": 47959.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.467}, "power_stats": {"power_gpu_soc_mean_watts": 22.428, "power_cpu_cv_mean_watts": 2.336, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 72.467}, "timestamp": "2026-01-30T10:38:39.086899"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8441.007, "latencies_ms": [8441.007], "images_per_second": 0.118, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " table: 1\nclock: 1\nwindow: 1\ncurtain: 1\ncup: 1\nbottle: 1\nbowl: 1\nplate: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14881.3, "ram_available_mb": 47959.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.0, "ram_used_mb": 14881.3, "ram_available_mb": 47959.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.314}, "power_stats": {"power_gpu_soc_mean_watts": 16.112, "power_cpu_cv_mean_watts": 2.666, "power_sys_5v0_mean_watts": 6.374, "gpu_utilization_percent_mean": 97.314}, "timestamp": "2026-01-30T10:38:49.547347"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5526.068, "latencies_ms": [5526.068], "images_per_second": 0.181, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the table is in the foreground, with the people sitting around it. The window is in the background, and the clock is on the wall above the table.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14881.3, "ram_available_mb": 47959.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 14881.8, "ram_available_mb": 47959.1, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.178}, "power_stats": {"power_gpu_soc_mean_watts": 19.199, "power_cpu_cv_mean_watts": 1.798, "power_sys_5v0_mean_watts": 7.262, "gpu_utilization_percent_mean": 84.178}, "timestamp": "2026-01-30T10:38:57.098414"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7153.317, "latencies_ms": [7153.317], "images_per_second": 0.14, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A group of friends are gathered around a wooden table in a cozy room with a large window. They are enjoying a meal together, with plates of food and drinks on the table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14881.8, "ram_available_mb": 47959.1, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 14875.3, "ram_available_mb": 47965.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.492}, "power_stats": {"power_gpu_soc_mean_watts": 16.783, "power_cpu_cv_mean_watts": 2.009, "power_sys_5v0_mean_watts": 6.468, "gpu_utilization_percent_mean": 89.492}, "timestamp": "2026-01-30T10:39:06.289014"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5573.481, "latencies_ms": [5573.481], "images_per_second": 0.179, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is dimly lit with natural light coming through the window, and the wooden table is made of dark wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14875.3, "ram_available_mb": 47965.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.9, "ram_used_mb": 14875.3, "ram_available_mb": 47965.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.674}, "power_stats": {"power_gpu_soc_mean_watts": 17.787, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 6.665, "gpu_utilization_percent_mean": 94.674}, "timestamp": "2026-01-30T10:39:13.915185"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5666.438, "latencies_ms": [5666.438], "images_per_second": 0.176, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A red truck with a snow plow attached to the front is driving down a snowy street, with a person standing nearby.", "error": null, "sys_before": {"cpu_percent": 21.2, "ram_used_mb": 14875.3, "ram_available_mb": 47965.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14875.4, "ram_available_mb": 47965.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.66}, "power_stats": {"power_gpu_soc_mean_watts": 17.682, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 6.564, "gpu_utilization_percent_mean": 83.66}, "timestamp": "2026-01-30T10:39:21.638820"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9291.101, "latencies_ms": [9291.101], "images_per_second": 0.108, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. red truck: 1\n2. snowplow: 1\n3. snow: 1\n4. house: 1\n5. tree: 1\n6. person: 1\n7. road: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14875.4, "ram_available_mb": 47965.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 14.3, "ram_used_mb": 14875.3, "ram_available_mb": 47965.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.494}, "power_stats": {"power_gpu_soc_mean_watts": 15.961, "power_cpu_cv_mean_watts": 2.35, "power_sys_5v0_mean_watts": 6.5, "gpu_utilization_percent_mean": 96.494}, "timestamp": "2026-01-30T10:39:32.973050"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5761.061, "latencies_ms": [5761.061], "images_per_second": 0.174, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The red truck is in the foreground, driving down the street. The snowplow is attached to the front of the truck, and it is in the middle of the image. The houses are in the background, and the trees are on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14875.3, "ram_available_mb": 47965.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 14875.9, "ram_available_mb": 47965.0, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.729}, "power_stats": {"power_gpu_soc_mean_watts": 19.19, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 7.56, "gpu_utilization_percent_mean": 74.729}, "timestamp": "2026-01-30T10:39:40.763881"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7262.767, "latencies_ms": [7262.767], "images_per_second": 0.138, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A red truck is driving down a snowy street with a snowplow attached to the front. The truck is passing by a row of houses and trees.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14875.9, "ram_available_mb": 47965.0, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 14876.2, "ram_available_mb": 47964.7, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.213}, "power_stats": {"power_gpu_soc_mean_watts": 16.564, "power_cpu_cv_mean_watts": 2.409, "power_sys_5v0_mean_watts": 6.376, "gpu_utilization_percent_mean": 96.213}, "timestamp": "2026-01-30T10:39:50.075430"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5776.244, "latencies_ms": [5776.244], "images_per_second": 0.173, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a red truck with a snowplow attached to the front, driving down a snowy street. The sky is overcast, and the snow is piled up on the sides of the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14876.2, "ram_available_mb": 47964.7, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.9, "ram_used_mb": 14876.2, "ram_available_mb": 47964.7, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.896}, "power_stats": {"power_gpu_soc_mean_watts": 18.872, "power_cpu_cv_mean_watts": 2.135, "power_sys_5v0_mean_watts": 7.112, "gpu_utilization_percent_mean": 91.896}, "timestamp": "2026-01-30T10:39:57.883955"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7074.292, "latencies_ms": [7074.292], "images_per_second": 0.141, "prompt_tokens": 1432, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image depicts a luxurious bathroom with a large mirror, a television mounted on the wall, and a sink with a green soap dispenser.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14876.2, "ram_available_mb": 47964.7, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 14876.1, "ram_available_mb": 47964.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.39}, "power_stats": {"power_gpu_soc_mean_watts": 18.232, "power_cpu_cv_mean_watts": 2.226, "power_sys_5v0_mean_watts": 6.71, "gpu_utilization_percent_mean": 86.39}, "timestamp": "2026-01-30T10:40:07.017800"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11278.922, "latencies_ms": [11278.922], "images_per_second": 0.089, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. mirror: 2\n2. television: 1\n3. towel: 3\n4. bath tub: 1\n5. sink: 2\n6. counter: 1\n7. wall: 1\n8. floor: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14876.1, "ram_available_mb": 47964.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.7, "ram_used_mb": 14878.4, "ram_available_mb": 47962.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.16}, "power_stats": {"power_gpu_soc_mean_watts": 15.964, "power_cpu_cv_mean_watts": 2.386, "power_sys_5v0_mean_watts": 6.389, "gpu_utilization_percent_mean": 94.16}, "timestamp": "2026-01-30T10:40:20.330518"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10199.217, "latencies_ms": [10199.217], "images_per_second": 0.098, "prompt_tokens": 1450, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The sink is located in the center of the bathroom, with the mirror above it reflecting the person taking the photo. The towels are hanging on the wall to the left of the sink, while the television is mounted on the wall above the sink. The person is standing in front of the mirror, which is positioned to the right of the sink.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14878.4, "ram_available_mb": 47962.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 14.2, "ram_used_mb": 14906.1, "ram_available_mb": 47934.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.082}, "power_stats": {"power_gpu_soc_mean_watts": 17.537, "power_cpu_cv_mean_watts": 2.615, "power_sys_5v0_mean_watts": 6.885, "gpu_utilization_percent_mean": 96.082}, "timestamp": "2026-01-30T10:40:32.566094"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3487.32, "latencies_ms": [3487.32], "images_per_second": 0.287, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A man is taking a picture of himself in a bathroom mirror.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14906.1, "ram_available_mb": 47934.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 14909.3, "ram_available_mb": 47931.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.862}, "power_stats": {"power_gpu_soc_mean_watts": 27.138, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.391, "gpu_utilization_percent_mean": 87.862}, "timestamp": "2026-01-30T10:40:38.083253"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10491.443, "latencies_ms": [10491.443], "images_per_second": 0.095, "prompt_tokens": 1442, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The bathroom is well-lit with warm lighting, and the walls are adorned with a mix of beige and white tiles. The countertop is made of dark green marble, and the floor is covered with a white and red patterned rug.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14909.1, "ram_available_mb": 47931.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 17.7, "ram_used_mb": 14920.5, "ram_available_mb": 47920.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.977}, "power_stats": {"power_gpu_soc_mean_watts": 16.366, "power_cpu_cv_mean_watts": 3.278, "power_sys_5v0_mean_watts": 6.475, "gpu_utilization_percent_mean": 94.977}, "timestamp": "2026-01-30T10:40:50.624792"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3858.256, "latencies_ms": [3858.256], "images_per_second": 0.259, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two men are unloading luggage from a cart in an airport parking garage.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14920.3, "ram_available_mb": 47920.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 16.1, "ram_used_mb": 14926.7, "ram_available_mb": 47914.2, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.367}, "power_stats": {"power_gpu_soc_mean_watts": 21.186, "power_cpu_cv_mean_watts": 2.016, "power_sys_5v0_mean_watts": 7.842, "gpu_utilization_percent_mean": 97.367}, "timestamp": "2026-01-30T10:40:56.527450"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7990.519, "latencies_ms": [7990.519], "images_per_second": 0.125, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. luggage: 4\n2. luggage: 1\n3. luggage: 1\n4. luggage: 1\n5. luggage: 1\n6. luggage: 1\n7. luggage: 1\n8. luggage: 1", "error": null, "sys_before": {"cpu_percent": 14.2, "ram_used_mb": 14919.9, "ram_available_mb": 47921.0, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 17.6, "ram_used_mb": 14928.6, "ram_available_mb": 47912.2, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.864}, "power_stats": {"power_gpu_soc_mean_watts": 15.717, "power_cpu_cv_mean_watts": 2.943, "power_sys_5v0_mean_watts": 7.136, "gpu_utilization_percent_mean": 77.864}, "timestamp": "2026-01-30T10:41:08.544709"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8924.96, "latencies_ms": [8924.96], "images_per_second": 0.112, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The man with the luggage is positioned in the foreground, while the man with the shopping cart is in the background. The luggage is placed near the man with the shopping cart, and the car is positioned further back in the parking lot.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14928.9, "ram_available_mb": 47912.0, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 17.8, "ram_used_mb": 14929.7, "ram_available_mb": 47911.2, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.187}, "power_stats": {"power_gpu_soc_mean_watts": 15.961, "power_cpu_cv_mean_watts": 3.358, "power_sys_5v0_mean_watts": 6.413, "gpu_utilization_percent_mean": 97.187}, "timestamp": "2026-01-30T10:41:19.510942"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3064.257, "latencies_ms": [3064.257], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two men are unloading luggage from a car in an airport parking garage.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14929.7, "ram_available_mb": 47911.2, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 15.3, "ram_used_mb": 14939.4, "ram_available_mb": 47901.5, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.52}, "power_stats": {"power_gpu_soc_mean_watts": 23.357, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.902, "gpu_utilization_percent_mean": 78.52}, "timestamp": "2026-01-30T10:41:24.607166"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7464.795, "latencies_ms": [7464.795], "images_per_second": 0.134, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image depicts a man in a parking garage with a white car and a black suitcase. The lighting is dim, and the man is wearing a brown shirt.", "error": null, "sys_before": {"cpu_percent": 15.9, "ram_used_mb": 14929.5, "ram_available_mb": 47911.4, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 17.3, "ram_used_mb": 14936.8, "ram_available_mb": 47904.1, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.934}, "power_stats": {"power_gpu_soc_mean_watts": 16.579, "power_cpu_cv_mean_watts": 3.099, "power_sys_5v0_mean_watts": 6.922, "gpu_utilization_percent_mean": 95.934}, "timestamp": "2026-01-30T10:41:35.216592"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3584.143, "latencies_ms": [3584.143], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate with a sandwich, fries, and a side of ketchup and onions.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14937.3, "ram_available_mb": 47903.6, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 13.9, "ram_used_mb": 14953.9, "ram_available_mb": 47887.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.517}, "power_stats": {"power_gpu_soc_mean_watts": 22.33, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 89.517}, "timestamp": "2026-01-30T10:41:40.850696"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7347.93, "latencies_ms": [7347.93], "images_per_second": 0.136, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " chicken sandwich: 2\nfries: 1\nlettuce: 1\nonion: 1\nketchup: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14953.8, "ram_available_mb": 47887.1, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 17.7, "ram_used_mb": 14963.3, "ram_available_mb": 47877.6, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.817}, "power_stats": {"power_gpu_soc_mean_watts": 16.406, "power_cpu_cv_mean_watts": 3.097, "power_sys_5v0_mean_watts": 6.75, "gpu_utilization_percent_mean": 95.817}, "timestamp": "2026-01-30T10:41:50.227587"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5813.452, "latencies_ms": [5813.452], "images_per_second": 0.172, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The sandwich is located in the foreground of the plate, with the fries and ketchup in the background. The lettuce and onion are placed near the sandwich, while the knife is positioned near the fries.", "error": null, "sys_before": {"cpu_percent": 30.8, "ram_used_mb": 14963.9, "ram_available_mb": 47877.0, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 14.1, "ram_used_mb": 14968.7, "ram_available_mb": 47872.2, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.787}, "power_stats": {"power_gpu_soc_mean_watts": 19.231, "power_cpu_cv_mean_watts": 2.581, "power_sys_5v0_mean_watts": 7.687, "gpu_utilization_percent_mean": 94.787}, "timestamp": "2026-01-30T10:41:58.061642"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3826.558, "latencies_ms": [3826.558], "images_per_second": 0.261, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A plate of food with a sandwich, fries, and ketchup is on a table.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14966.5, "ram_available_mb": 47874.4, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 14961.1, "ram_available_mb": 47879.8, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.448}, "power_stats": {"power_gpu_soc_mean_watts": 22.799, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 8.079, "gpu_utilization_percent_mean": 82.448}, "timestamp": "2026-01-30T10:42:07.458313"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6460.459, "latencies_ms": [6460.459], "images_per_second": 0.155, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The plate is white and the food is colorful. The lighting is bright and the food is well-lit.", "error": null, "sys_before": {"cpu_percent": 12.6, "ram_used_mb": 14962.1, "ram_available_mb": 47878.8, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 14.3, "ram_used_mb": 14958.7, "ram_available_mb": 47882.2, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.907}, "power_stats": {"power_gpu_soc_mean_watts": 16.988, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 6.97, "gpu_utilization_percent_mean": 97.907}, "timestamp": "2026-01-30T10:42:18.162914"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3869.124, "latencies_ms": [3869.124], "images_per_second": 0.258, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a large bed covered by a green mosquito net, a wooden table with a candle, and a window with curtains.", "error": null, "sys_before": {"cpu_percent": 12.1, "ram_used_mb": 14958.8, "ram_available_mb": 47882.1, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 16.1, "ram_used_mb": 14959.0, "ram_available_mb": 47881.9, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.719}, "power_stats": {"power_gpu_soc_mean_watts": 22.113, "power_cpu_cv_mean_watts": 2.928, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 71.719}, "timestamp": "2026-01-30T10:42:24.089066"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9415.578, "latencies_ms": [9415.578], "images_per_second": 0.106, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. curtains: 2\n3. table: 1\n4. chair: 1\n5. floor: 1\n6. wall: 1\n7. candle: 1\n8. painting: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14959.4, "ram_available_mb": 47881.5, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 19.3, "ram_used_mb": 14958.0, "ram_available_mb": 47882.9, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.225}, "power_stats": {"power_gpu_soc_mean_watts": 16.039, "power_cpu_cv_mean_watts": 4.375, "power_sys_5v0_mean_watts": 6.657, "gpu_utilization_percent_mean": 95.225}, "timestamp": "2026-01-30T10:42:35.537283"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10725.402, "latencies_ms": [10725.402], "images_per_second": 0.093, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the mosquito net draped over it, creating a sense of intimacy and seclusion. The table and chairs are situated in the foreground, providing a comfortable seating area for guests. The windows and paintings are located in the background, allowing natural light to flood the room and creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 2.7, "ram_used_mb": 14958.6, "ram_available_mb": 47882.3, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 21.3, "ram_used_mb": 14969.4, "ram_available_mb": 47871.5, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.099}, "power_stats": {"power_gpu_soc_mean_watts": 15.685, "power_cpu_cv_mean_watts": 4.211, "power_sys_5v0_mean_watts": 6.68, "gpu_utilization_percent_mean": 95.099}, "timestamp": "2026-01-30T10:42:49.440540"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7030.91, "latencies_ms": [7030.91], "images_per_second": 0.142, "prompt_tokens": 1111, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image captures a serene bedroom bathed in natural light, with a large bed draped in a green mosquito net, a wooden table and chairs, and a candle on a side table. The room is adorned with yellow walls and a thatched roof, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14969.9, "ram_available_mb": 47870.9, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 17.4, "ram_used_mb": 14976.0, "ram_available_mb": 47864.9, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.733}, "power_stats": {"power_gpu_soc_mean_watts": 18.042, "power_cpu_cv_mean_watts": 3.317, "power_sys_5v0_mean_watts": 7.525, "gpu_utilization_percent_mean": 87.733}, "timestamp": "2026-01-30T10:42:58.506023"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5822.666, "latencies_ms": [5822.666], "images_per_second": 0.172, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The room is bathed in warm yellow light, with a canopy of green fabric draped over the bed, and the walls are adorned with paintings of trees and plants.", "error": null, "sys_before": {"cpu_percent": 20.9, "ram_used_mb": 14978.0, "ram_available_mb": 47862.9, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 12.7, "ram_used_mb": 14894.1, "ram_available_mb": 47946.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.833}, "power_stats": {"power_gpu_soc_mean_watts": 18.037, "power_cpu_cv_mean_watts": 2.97, "power_sys_5v0_mean_watts": 7.493, "gpu_utilization_percent_mean": 79.833}, "timestamp": "2026-01-30T10:43:07.688090"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6458.063, "latencies_ms": [6458.063], "images_per_second": 0.155, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A gray and white cat with a blue collar is standing on the hood of a black car in a garage.", "error": null, "sys_before": {"cpu_percent": 11.0, "ram_used_mb": 14894.1, "ram_available_mb": 47946.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 14896.0, "ram_available_mb": 47944.9, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.963}, "power_stats": {"power_gpu_soc_mean_watts": 17.05, "power_cpu_cv_mean_watts": 2.618, "power_sys_5v0_mean_watts": 6.862, "gpu_utilization_percent_mean": 97.963}, "timestamp": "2026-01-30T10:43:18.306358"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9830.954, "latencies_ms": [9830.954], "images_per_second": 0.102, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. cat: 1\n2. car: 1\n3. lamp: 1\n4. box: 1\n5. bicycle: 1\n6. gas cylinder: 1\n7. floor: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 1.5, "ram_used_mb": 14896.3, "ram_available_mb": 47944.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.7, "ram_used_mb": 14896.4, "ram_available_mb": 47944.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.58}, "power_stats": {"power_gpu_soc_mean_watts": 15.575, "power_cpu_cv_mean_watts": 2.605, "power_sys_5v0_mean_watts": 6.825, "gpu_utilization_percent_mean": 95.58}, "timestamp": "2026-01-30T10:43:33.524071"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7022.83, "latencies_ms": [7022.83], "images_per_second": 0.142, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The cat is positioned in the foreground, near the center of the image, on top of the car. The lamp is located to the left of the cat, while the box is situated in the background, behind the cat.", "error": null, "sys_before": {"cpu_percent": 1.6, "ram_used_mb": 14896.1, "ram_available_mb": 47944.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 14899.7, "ram_available_mb": 47941.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.5}, "power_stats": {"power_gpu_soc_mean_watts": 17.53, "power_cpu_cv_mean_watts": 2.389, "power_sys_5v0_mean_watts": 7.254, "gpu_utilization_percent_mean": 94.5}, "timestamp": "2026-01-30T10:43:44.704885"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3993.139, "latencies_ms": [3993.139], "images_per_second": 0.25, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A cat with a collar is standing on the hood of a car in a garage.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 14903.2, "ram_available_mb": 47937.7, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 14904.7, "ram_available_mb": 47936.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.303}, "power_stats": {"power_gpu_soc_mean_watts": 21.165, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 7.684, "gpu_utilization_percent_mean": 84.303}, "timestamp": "2026-01-30T10:43:52.054349"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6710.76, "latencies_ms": [6710.76], "images_per_second": 0.149, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The cat is gray and white, and the car is black. The room is well-lit with natural light.", "error": null, "sys_before": {"cpu_percent": 10.6, "ram_used_mb": 14904.6, "ram_available_mb": 47936.3, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 14905.3, "ram_available_mb": 47935.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.839}, "power_stats": {"power_gpu_soc_mean_watts": 16.684, "power_cpu_cv_mean_watts": 2.424, "power_sys_5v0_mean_watts": 6.836, "gpu_utilization_percent_mean": 97.839}, "timestamp": "2026-01-30T10:44:03.763763"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5532.577, "latencies_ms": [5532.577], "images_per_second": 0.181, "prompt_tokens": 1432, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate of food with a knife on it is on a table.", "error": null, "sys_before": {"cpu_percent": 1.6, "ram_used_mb": 14905.5, "ram_available_mb": 47935.4, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.8, "ram_used_mb": 14906.2, "ram_available_mb": 47934.7, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.289}, "power_stats": {"power_gpu_soc_mean_watts": 19.874, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.39, "gpu_utilization_percent_mean": 91.289}, "timestamp": "2026-01-30T10:44:13.194897"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7647.776, "latencies_ms": [7647.776], "images_per_second": 0.131, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. knife: 1\n3. food: 1\n4. table: 1\n5. fork: 1\n6. sandwich: 1\n7. sauce: 1\n8. bread: 1", "error": null, "sys_before": {"cpu_percent": 12.6, "ram_used_mb": 14906.2, "ram_available_mb": 47934.7, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 14906.2, "ram_available_mb": 47934.7, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.359}, "power_stats": {"power_gpu_soc_mean_watts": 18.629, "power_cpu_cv_mean_watts": 1.946, "power_sys_5v0_mean_watts": 7.814, "gpu_utilization_percent_mean": 80.359}, "timestamp": "2026-01-30T10:44:24.996931"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8133.909, "latencies_ms": [8133.909], "images_per_second": 0.123, "prompt_tokens": 1450, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The plate with the food is in the foreground, and the knife is on the plate. The food is on the plate, and the table is in the background.", "error": null, "sys_before": {"cpu_percent": 11.4, "ram_used_mb": 14906.2, "ram_available_mb": 47934.7, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 14905.5, "ram_available_mb": 47935.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.537}, "power_stats": {"power_gpu_soc_mean_watts": 17.609, "power_cpu_cv_mean_watts": 1.984, "power_sys_5v0_mean_watts": 7.103, "gpu_utilization_percent_mean": 88.537}, "timestamp": "2026-01-30T10:44:36.714816"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7349.696, "latencies_ms": [7349.696], "images_per_second": 0.136, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate of food is on a table with a knife on it.", "error": null, "sys_before": {"cpu_percent": 9.0, "ram_used_mb": 14905.4, "ram_available_mb": 47935.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 14905.4, "ram_available_mb": 47935.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.419}, "power_stats": {"power_gpu_soc_mean_watts": 17.634, "power_cpu_cv_mean_watts": 2.725, "power_sys_5v0_mean_watts": 6.919, "gpu_utilization_percent_mean": 97.419}, "timestamp": "2026-01-30T10:44:49.090836"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7292.472, "latencies_ms": [7292.472], "images_per_second": 0.137, "prompt_tokens": 1442, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image has a warm and inviting atmosphere, with the colors of the food and the table contrasting nicely. The lighting is natural, coming from the window in the background, and the table is made of metal with a black and white checkered pattern.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14905.4, "ram_available_mb": 47935.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 14905.6, "ram_available_mb": 47935.3, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.183}, "power_stats": {"power_gpu_soc_mean_watts": 19.963, "power_cpu_cv_mean_watts": 2.042, "power_sys_5v0_mean_watts": 7.344, "gpu_utilization_percent_mean": 91.183}, "timestamp": "2026-01-30T10:44:58.401116"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7021.706, "latencies_ms": [7021.706], "images_per_second": 0.142, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In the image, there are three men in a living room, with one man standing and the other two sitting on a couch. The standing man is holding a camera, while the two seated men are holding cans.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14905.6, "ram_available_mb": 47935.3, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14906.3, "ram_available_mb": 47934.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.61}, "power_stats": {"power_gpu_soc_mean_watts": 16.596, "power_cpu_cv_mean_watts": 2.05, "power_sys_5v0_mean_watts": 6.618, "gpu_utilization_percent_mean": 83.61}, "timestamp": "2026-01-30T10:45:07.443024"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7899.11, "latencies_ms": [7899.11], "images_per_second": 0.127, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " table: 1\ncouch: 1\nwindow: 1\nlamp: 1\ntable: 1\nsofa: 1\nperson: 3", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14906.3, "ram_available_mb": 47934.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 14.0, "ram_used_mb": 14906.7, "ram_available_mb": 47934.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.773}, "power_stats": {"power_gpu_soc_mean_watts": 16.149, "power_cpu_cv_mean_watts": 2.615, "power_sys_5v0_mean_watts": 6.318, "gpu_utilization_percent_mean": 97.773}, "timestamp": "2026-01-30T10:45:17.370696"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7141.342, "latencies_ms": [7141.342], "images_per_second": 0.14, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The man in the white shirt is standing to the right of the man in the blue shirt, who is sitting on the couch. The man in the white shirt is also standing closer to the camera than the man in the blue shirt. The man in the blue shirt is sitting on the couch, while the man in the white shirt is standing.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14906.7, "ram_available_mb": 47934.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 14906.5, "ram_available_mb": 47934.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.967}, "power_stats": {"power_gpu_soc_mean_watts": 17.897, "power_cpu_cv_mean_watts": 1.989, "power_sys_5v0_mean_watts": 7.362, "gpu_utilization_percent_mean": 79.967}, "timestamp": "2026-01-30T10:45:26.533334"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7641.261, "latencies_ms": [7641.261], "images_per_second": 0.131, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " A group of friends are gathered in a living room, enjoying a casual get-together. The room is furnished with a comfortable couch, a coffee table, and a lamp, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 14906.5, "ram_available_mb": 47934.4, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 14906.4, "ram_available_mb": 47934.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.778}, "power_stats": {"power_gpu_soc_mean_watts": 16.51, "power_cpu_cv_mean_watts": 2.32, "power_sys_5v0_mean_watts": 6.409, "gpu_utilization_percent_mean": 89.778}, "timestamp": "2026-01-30T10:45:36.187945"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5550.92, "latencies_ms": [5550.92], "images_per_second": 0.18, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is lit by a lamp and has a warm yellow light. The walls are painted white and the floor is wooden.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14906.4, "ram_available_mb": 47934.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.3, "ram_used_mb": 14906.4, "ram_available_mb": 47934.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.304}, "power_stats": {"power_gpu_soc_mean_watts": 17.795, "power_cpu_cv_mean_watts": 2.15, "power_sys_5v0_mean_watts": 6.699, "gpu_utilization_percent_mean": 94.304}, "timestamp": "2026-01-30T10:45:43.772330"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6797.753, "latencies_ms": [6797.753], "images_per_second": 0.147, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a baseball catcher in a crouched position, wearing a black helmet, black and white uniform, and a black and yellow glove, poised to catch a ball during a game.", "error": null, "sys_before": {"cpu_percent": 21.7, "ram_used_mb": 14906.4, "ram_available_mb": 47934.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 14905.7, "ram_available_mb": 47935.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.789}, "power_stats": {"power_gpu_soc_mean_watts": 16.592, "power_cpu_cv_mean_watts": 2.586, "power_sys_5v0_mean_watts": 6.608, "gpu_utilization_percent_mean": 82.789}, "timestamp": "2026-01-30T10:45:52.621984"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11717.346, "latencies_ms": [11717.346], "images_per_second": 0.085, "prompt_tokens": 1113, "response_tokens_est": 86, "n_tiles": 1, "output_text": " 1. catcher's mitt: 1\n2. catcher's helmet: 1\n3. catcher's mask: 1\n4. catcher's chest protector: 1\n5. catcher's leg guards: 1\n6. catcher's leg pads: 1\n7. catcher's leg guards: 1\n8. catcher's leg pads: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14905.7, "ram_available_mb": 47935.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 14905.2, "ram_available_mb": 47935.7, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.697}, "power_stats": {"power_gpu_soc_mean_watts": 15.464, "power_cpu_cv_mean_watts": 2.561, "power_sys_5v0_mean_watts": 6.439, "gpu_utilization_percent_mean": 91.697}, "timestamp": "2026-01-30T10:46:06.402494"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8554.901, "latencies_ms": [8554.901], "images_per_second": 0.117, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The catcher is positioned in the foreground, squatting behind home plate, while the batter is in the background, standing in the batter's box. The catcher's glove is near the catcher, and the batter's bat is far away from the catcher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14905.2, "ram_available_mb": 47935.7, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 14.0, "ram_used_mb": 14905.5, "ram_available_mb": 47935.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.507}, "power_stats": {"power_gpu_soc_mean_watts": 16.372, "power_cpu_cv_mean_watts": 2.488, "power_sys_5v0_mean_watts": 6.571, "gpu_utilization_percent_mean": 96.507}, "timestamp": "2026-01-30T10:46:16.987580"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3831.996, "latencies_ms": [3831.996], "images_per_second": 0.261, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A baseball player is crouched in the batter's box, wearing a black helmet and catcher's gear.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14905.5, "ram_available_mb": 47935.4, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14906.8, "ram_available_mb": 47934.1, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.969}, "power_stats": {"power_gpu_soc_mean_watts": 22.142, "power_cpu_cv_mean_watts": 1.451, "power_sys_5v0_mean_watts": 7.575, "gpu_utilization_percent_mean": 77.969}, "timestamp": "2026-01-30T10:46:22.852247"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11204.812, "latencies_ms": [11204.812], "images_per_second": 0.089, "prompt_tokens": 1109, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image captures a moment of intense focus and concentration, with the catcher crouched in the batter's box, his body poised and ready for action. The warm glow of the stadium lights illuminates the scene, casting long shadows and highlighting the vibrant colors of the catcher's uniform. The grass surrounding the field is a lush green, contrasting with the brown dirt of the infield.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14906.8, "ram_available_mb": 47934.1, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.4, "ram_used_mb": 14906.7, "ram_available_mb": 47934.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.223}, "power_stats": {"power_gpu_soc_mean_watts": 15.557, "power_cpu_cv_mean_watts": 2.931, "power_sys_5v0_mean_watts": 6.419, "gpu_utilization_percent_mean": 93.223}, "timestamp": "2026-01-30T10:46:36.081463"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5941.013, "latencies_ms": [5941.013], "images_per_second": 0.168, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a bathroom with a pink and white color scheme, featuring a bathtub, a toilet, and a wooden vanity with a mirror above it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14906.7, "ram_available_mb": 47934.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 14906.9, "ram_available_mb": 47934.0, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.122}, "power_stats": {"power_gpu_soc_mean_watts": 17.631, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 6.715, "gpu_utilization_percent_mean": 96.122}, "timestamp": "2026-01-30T10:46:44.046896"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6392.99, "latencies_ms": [6392.99], "images_per_second": 0.156, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " 1. Bathtub\n2. Toilet\n3. Window\n4. Shower curtain\n5. Sink\n6. Counter\n7. Mirror\n8. Door", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14906.9, "ram_available_mb": 47934.0, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14906.5, "ram_available_mb": 47934.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.17}, "power_stats": {"power_gpu_soc_mean_watts": 17.146, "power_cpu_cv_mean_watts": 2.146, "power_sys_5v0_mean_watts": 6.681, "gpu_utilization_percent_mean": 83.17}, "timestamp": "2026-01-30T10:46:52.468683"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10728.011, "latencies_ms": [10728.011], "images_per_second": 0.093, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The shower curtain is located in the middle of the bathroom, with the sink and toilet positioned to the right of it. The bathtub is situated on the left side of the room, with the window above it. The door is located on the left side of the room, with the sink and toilet positioned to the right of it.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14906.5, "ram_available_mb": 47934.4, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.9, "ram_used_mb": 14906.8, "ram_available_mb": 47934.1, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.344}, "power_stats": {"power_gpu_soc_mean_watts": 15.348, "power_cpu_cv_mean_watts": 2.745, "power_sys_5v0_mean_watts": 6.315, "gpu_utilization_percent_mean": 96.344}, "timestamp": "2026-01-30T10:47:05.222636"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3394.111, "latencies_ms": [3394.111], "images_per_second": 0.295, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A bathroom with pink tiles and a white toilet is shown in the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14906.8, "ram_available_mb": 47934.1, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 14907.1, "ram_available_mb": 47933.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.858, "power_cpu_cv_mean_watts": 1.127, "power_sys_5v0_mean_watts": 7.645, "gpu_utilization_percent_mean": 89.0}, "timestamp": "2026-01-30T10:47:10.641976"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7667.065, "latencies_ms": [7667.065], "images_per_second": 0.13, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bathroom is painted in a light blue color with pink tiles on the walls and floor. The lighting is bright and natural, coming from a window above the bathtub.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14907.1, "ram_available_mb": 47933.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 14907.0, "ram_available_mb": 47933.9, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.781}, "power_stats": {"power_gpu_soc_mean_watts": 16.183, "power_cpu_cv_mean_watts": 2.722, "power_sys_5v0_mean_watts": 6.295, "gpu_utilization_percent_mean": 94.781}, "timestamp": "2026-01-30T10:47:20.336465"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6299.486, "latencies_ms": [6299.486], "images_per_second": 0.159, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered in a yellow and white plaid bedspread, positioned in the center of the room, and a window with a white curtain on the left side, allowing natural light to enter the room.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14907.0, "ram_available_mb": 47933.9, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.3, "ram_used_mb": 14906.6, "ram_available_mb": 47934.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.212}, "power_stats": {"power_gpu_soc_mean_watts": 18.684, "power_cpu_cv_mean_watts": 2.472, "power_sys_5v0_mean_watts": 7.151, "gpu_utilization_percent_mean": 96.212}, "timestamp": "2026-01-30T10:47:28.672878"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7192.036, "latencies_ms": [7192.036], "images_per_second": 0.139, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. bed: 1\n2. window: 1\n3. curtain: 2\n4. wall: 1\n5. lamp: 1\n6. bedside table: 1\n7. bed sheet: 1\n8. bed frame: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14906.6, "ram_available_mb": 47934.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14906.0, "ram_available_mb": 47934.9, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.517}, "power_stats": {"power_gpu_soc_mean_watts": 16.658, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 6.975, "gpu_utilization_percent_mean": 75.517}, "timestamp": "2026-01-30T10:47:37.894608"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8357.736, "latencies_ms": [8357.736], "images_per_second": 0.12, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The bed is located in the foreground of the image, with the window and curtains in the background. The lamp is positioned on the right side of the bed, while the window is on the left side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14906.0, "ram_available_mb": 47934.9, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.8, "ram_used_mb": 14905.1, "ram_available_mb": 47935.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.943}, "power_stats": {"power_gpu_soc_mean_watts": 16.041, "power_cpu_cv_mean_watts": 2.86, "power_sys_5v0_mean_watts": 6.334, "gpu_utilization_percent_mean": 97.943}, "timestamp": "2026-01-30T10:47:48.283039"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6028.62, "latencies_ms": [6028.62], "images_per_second": 0.166, "prompt_tokens": 1111, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered in a yellow and white plaid bedspread, positioned in the center of the room. The room is illuminated by natural light coming through a window with white curtains, and there is a lamp on a nightstand next to the bed.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14905.1, "ram_available_mb": 47935.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 14899.2, "ram_available_mb": 47941.7, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.353}, "power_stats": {"power_gpu_soc_mean_watts": 18.744, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 7.431, "gpu_utilization_percent_mean": 77.353}, "timestamp": "2026-01-30T10:47:56.337551"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6166.235, "latencies_ms": [6166.235], "images_per_second": 0.162, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is dimly lit with a yellow wall and a bed with a yellow and white plaid comforter.", "error": null, "sys_before": {"cpu_percent": 15.1, "ram_used_mb": 14904.3, "ram_available_mb": 47936.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 14894.5, "ram_available_mb": 47946.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.941}, "power_stats": {"power_gpu_soc_mean_watts": 17.173, "power_cpu_cv_mean_watts": 2.748, "power_sys_5v0_mean_watts": 6.447, "gpu_utilization_percent_mean": 89.941}, "timestamp": "2026-01-30T10:48:04.558478"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4253.633, "latencies_ms": [4253.633], "images_per_second": 0.235, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A woman in a black dress is pinning a white flower to a man's suit jacket.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14894.5, "ram_available_mb": 47946.4, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14893.6, "ram_available_mb": 47947.3, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.229}, "power_stats": {"power_gpu_soc_mean_watts": 23.902, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 7.912, "gpu_utilization_percent_mean": 92.229}, "timestamp": "2026-01-30T10:48:10.875498"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9946.737, "latencies_ms": [9946.737], "images_per_second": 0.101, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. Man: 1\n2. Woman: 1\n3. Flower: 1\n4. Tie: 1\n5. Suit: 1\n6. Dress: 1\n7. Shoes: 1\n8. Wall: 1", "error": null, "sys_before": {"cpu_percent": 30.8, "ram_used_mb": 14893.6, "ram_available_mb": 47947.3, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 17.5, "ram_used_mb": 14893.7, "ram_available_mb": 47947.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.262}, "power_stats": {"power_gpu_soc_mean_watts": 16.677, "power_cpu_cv_mean_watts": 3.07, "power_sys_5v0_mean_watts": 6.819, "gpu_utilization_percent_mean": 86.262}, "timestamp": "2026-01-30T10:48:22.859821"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10156.762, "latencies_ms": [10156.762], "images_per_second": 0.098, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The woman is standing to the right of the man, and she is closer to the camera than the man. The woman is holding the man's tie, and the tie is positioned in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14893.7, "ram_available_mb": 47947.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 20.3, "ram_used_mb": 14893.9, "ram_available_mb": 47947.0, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.424}, "power_stats": {"power_gpu_soc_mean_watts": 16.55, "power_cpu_cv_mean_watts": 3.467, "power_sys_5v0_mean_watts": 6.621, "gpu_utilization_percent_mean": 97.424}, "timestamp": "2026-01-30T10:48:35.041428"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5627.602, "latencies_ms": [5627.602], "images_per_second": 0.178, "prompt_tokens": 1444, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man in a suit and tie is getting a boutonniere pinned to his lapel by a woman in a black dress.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14893.9, "ram_available_mb": 47947.0, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 19.1, "ram_used_mb": 14894.1, "ram_available_mb": 47946.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.617}, "power_stats": {"power_gpu_soc_mean_watts": 21.19, "power_cpu_cv_mean_watts": 2.939, "power_sys_5v0_mean_watts": 7.594, "gpu_utilization_percent_mean": 95.617}, "timestamp": "2026-01-30T10:48:42.694196"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8294.465, "latencies_ms": [8294.465], "images_per_second": 0.121, "prompt_tokens": 1442, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is well-lit with natural light, and the colors are vibrant and warm. The man is wearing a black suit and tie, while the woman is dressed in a black dress with a beige ribbon.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14894.1, "ram_available_mb": 47946.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 18.2, "ram_used_mb": 14903.9, "ram_available_mb": 47937.0, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.127}, "power_stats": {"power_gpu_soc_mean_watts": 17.372, "power_cpu_cv_mean_watts": 3.135, "power_sys_5v0_mean_watts": 6.964, "gpu_utilization_percent_mean": 84.127}, "timestamp": "2026-01-30T10:48:53.049013"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7367.736, "latencies_ms": [7367.736], "images_per_second": 0.136, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image shows a chain-link fence with a stop sign attached to it, situated in a grassy area with palm trees and a building in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14903.9, "ram_available_mb": 47937.0, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 14.8, "ram_used_mb": 14917.2, "ram_available_mb": 47923.7, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.871}, "power_stats": {"power_gpu_soc_mean_watts": 16.432, "power_cpu_cv_mean_watts": 3.048, "power_sys_5v0_mean_watts": 6.397, "gpu_utilization_percent_mean": 97.871}, "timestamp": "2026-01-30T10:49:02.482617"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4522.543, "latencies_ms": [4522.543], "images_per_second": 0.221, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " 1. chain link fence\n2. stop sign\n3. palm tree\n4. building\n5. trash\n6. sidewalk\n7. green bush\n8. chain link fence", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 14917.2, "ram_available_mb": 47923.7, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14918.5, "ram_available_mb": 47922.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.316}, "power_stats": {"power_gpu_soc_mean_watts": 20.844, "power_cpu_cv_mean_watts": 1.591, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 74.316}, "timestamp": "2026-01-30T10:49:09.024269"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6135.079, "latencies_ms": [6135.079], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The stop sign is located in the foreground of the image, on the left side, and is positioned near a chain link fence. The background of the image features a grassy area with palm trees and a building.", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 14918.5, "ram_available_mb": 47922.4, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14918.7, "ram_available_mb": 47922.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.706}, "power_stats": {"power_gpu_soc_mean_watts": 17.657, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 6.961, "gpu_utilization_percent_mean": 79.706}, "timestamp": "2026-01-30T10:49:17.185585"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5231.918, "latencies_ms": [5231.918], "images_per_second": 0.191, "prompt_tokens": 1111, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image captures a scene of a chain-link fence with a stop sign attached to it, set against a backdrop of a grassy area and palm trees. The stop sign, with its bold red color and white letters, stands out prominently against the natural surroundings.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14918.7, "ram_available_mb": 47922.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14923.6, "ram_available_mb": 47917.3, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.953}, "power_stats": {"power_gpu_soc_mean_watts": 19.028, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.634, "gpu_utilization_percent_mean": 68.953}, "timestamp": "2026-01-30T10:49:24.444146"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7717.376, "latencies_ms": [7717.376], "images_per_second": 0.13, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a red and white stop sign, a chain link fence, and a grassy area with palm trees. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14923.6, "ram_available_mb": 47917.3, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 14935.9, "ram_available_mb": 47905.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.688}, "power_stats": {"power_gpu_soc_mean_watts": 16.431, "power_cpu_cv_mean_watts": 2.884, "power_sys_5v0_mean_watts": 6.371, "gpu_utilization_percent_mean": 97.688}, "timestamp": "2026-01-30T10:49:34.175534"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4674.63, "latencies_ms": [4674.63], "images_per_second": 0.214, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A man wearing a helmet is riding a motorcycle next to a black bicycle with a basket on the back, while a man in a gray shirt and khaki shorts stands nearby.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 14935.2, "ram_available_mb": 47905.6, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 14934.6, "ram_available_mb": 47906.3, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.615}, "power_stats": {"power_gpu_soc_mean_watts": 20.185, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.461, "gpu_utilization_percent_mean": 81.615}, "timestamp": "2026-01-30T10:49:40.892204"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7525.884, "latencies_ms": [7525.884], "images_per_second": 0.133, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. yellow bicycle\n2. black bicycle\n3. motorcycle\n4. person\n5. person's hand\n6. person's leg\n7. person's foot\n8. person's shoe", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14934.6, "ram_available_mb": 47906.3, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 14933.5, "ram_available_mb": 47907.4, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.79}, "power_stats": {"power_gpu_soc_mean_watts": 16.413, "power_cpu_cv_mean_watts": 2.073, "power_sys_5v0_mean_watts": 6.487, "gpu_utilization_percent_mean": 85.79}, "timestamp": "2026-01-30T10:49:50.431998"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6478.061, "latencies_ms": [6478.061], "images_per_second": 0.154, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The yellow bicycle is positioned to the left of the black bicycle, which is in the foreground of the image. The person standing next to the black bicycle is positioned in the background, while the motorcycle is positioned to the left of the bicycles.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14933.5, "ram_available_mb": 47907.4, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 14932.0, "ram_available_mb": 47908.9, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.056}, "power_stats": {"power_gpu_soc_mean_watts": 18.494, "power_cpu_cv_mean_watts": 2.454, "power_sys_5v0_mean_watts": 7.072, "gpu_utilization_percent_mean": 96.056}, "timestamp": "2026-01-30T10:49:58.933476"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4891.765, "latencies_ms": [4891.765], "images_per_second": 0.204, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A man is standing next to a bike and a motorcycle.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14932.0, "ram_available_mb": 47908.9, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 14933.2, "ram_available_mb": 47907.7, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.951}, "power_stats": {"power_gpu_soc_mean_watts": 18.37, "power_cpu_cv_mean_watts": 2.373, "power_sys_5v0_mean_watts": 6.507, "gpu_utilization_percent_mean": 88.951}, "timestamp": "2026-01-30T10:50:05.888693"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7957.883, "latencies_ms": [7957.883], "images_per_second": 0.126, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a man wearing a helmet and a black leather jacket, standing next to a black bicycle with a brown basket on the back. The bicycle is parked on a street with a yellow bicycle parked next to it. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14933.2, "ram_available_mb": 47907.7, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 16.4, "ram_used_mb": 14920.4, "ram_available_mb": 47920.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.167}, "power_stats": {"power_gpu_soc_mean_watts": 17.098, "power_cpu_cv_mean_watts": 3.058, "power_sys_5v0_mean_watts": 6.962, "gpu_utilization_percent_mean": 97.167}, "timestamp": "2026-01-30T10:50:15.866150"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4993.265, "latencies_ms": [4993.265], "images_per_second": 0.2, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, there are two people standing on the sidewalk, with a traffic light and a street sign nearby, and a red car parked on the street.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14920.4, "ram_available_mb": 47920.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14920.2, "ram_available_mb": 47920.7, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.485, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 7.14, "gpu_utilization_percent_mean": 77.244}, "timestamp": "2026-01-30T10:50:22.907803"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8362.8, "latencies_ms": [8362.8], "images_per_second": 0.12, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. black pole\n2. yellow sign\n3. black trash can\n4. traffic light\n5. street sign\n6. pedestrian crossing\n7. red car\n8. person", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 14920.2, "ram_available_mb": 47920.7, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 14.0, "ram_used_mb": 14920.3, "ram_available_mb": 47920.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.899}, "power_stats": {"power_gpu_soc_mean_watts": 15.995, "power_cpu_cv_mean_watts": 2.518, "power_sys_5v0_mean_watts": 6.321, "gpu_utilization_percent_mean": 97.899}, "timestamp": "2026-01-30T10:50:33.295601"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4814.282, "latencies_ms": [4814.282], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The two individuals are standing on the sidewalk, which is located in the foreground of the image. The traffic light is positioned in the background, and the street sign is situated to the left of the traffic light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14920.3, "ram_available_mb": 47920.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 14921.2, "ram_available_mb": 47919.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.775}, "power_stats": {"power_gpu_soc_mean_watts": 20.181, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 7.663, "gpu_utilization_percent_mean": 74.775}, "timestamp": "2026-01-30T10:50:40.135542"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8132.031, "latencies_ms": [8132.031], "images_per_second": 0.123, "prompt_tokens": 1111, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image captures a bustling city intersection with two pedestrians standing on the sidewalk, engaged in conversation. The street is lined with buildings and trees, and there are traffic lights and street signs visible in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14921.2, "ram_available_mb": 47919.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 14921.0, "ram_available_mb": 47919.9, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.485}, "power_stats": {"power_gpu_soc_mean_watts": 16.289, "power_cpu_cv_mean_watts": 2.449, "power_sys_5v0_mean_watts": 6.374, "gpu_utilization_percent_mean": 96.485}, "timestamp": "2026-01-30T10:50:50.291905"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7581.49, "latencies_ms": [7581.49], "images_per_second": 0.132, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image depicts a city street with a mix of natural and artificial lighting. The colors are predominantly muted with the exception of the red car and the yellow sign, which stand out against the urban backdrop. The weather appears to be overcast, as there are no strong shadows cast on the ground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14921.0, "ram_available_mb": 47919.9, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 14921.1, "ram_available_mb": 47919.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.397}, "power_stats": {"power_gpu_soc_mean_watts": 17.703, "power_cpu_cv_mean_watts": 2.479, "power_sys_5v0_mean_watts": 6.966, "gpu_utilization_percent_mean": 94.397}, "timestamp": "2026-01-30T10:50:59.915726"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5335.254, "latencies_ms": [5335.254], "images_per_second": 0.187, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A bronze statue of two people sitting on a bench with a handbag next to them is in front of a building with a closed shutter.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 14921.1, "ram_available_mb": 47919.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 14921.3, "ram_available_mb": 47919.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.386}, "power_stats": {"power_gpu_soc_mean_watts": 18.502, "power_cpu_cv_mean_watts": 2.056, "power_sys_5v0_mean_watts": 6.816, "gpu_utilization_percent_mean": 82.386}, "timestamp": "2026-01-30T10:51:07.295971"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9616.655, "latencies_ms": [9616.655], "images_per_second": 0.104, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. statue: 2\n2. bench: 1\n3. bag: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14921.3, "ram_available_mb": 47919.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 14921.0, "ram_available_mb": 47919.9, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.864}, "power_stats": {"power_gpu_soc_mean_watts": 15.515, "power_cpu_cv_mean_watts": 2.941, "power_sys_5v0_mean_watts": 6.298, "gpu_utilization_percent_mean": 94.864}, "timestamp": "2026-01-30T10:51:18.949473"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5814.846, "latencies_ms": [5814.846], "images_per_second": 0.172, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The statue of two people is positioned on the left side of the image, with the bench and handbag placed in the foreground. The background features a group of people standing near a closed shop, with the statue's shadow cast on the ground.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14921.0, "ram_available_mb": 47919.9, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 14921.5, "ram_available_mb": 47919.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.271}, "power_stats": {"power_gpu_soc_mean_watts": 19.063, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 7.32, "gpu_utilization_percent_mean": 83.271}, "timestamp": "2026-01-30T10:51:26.790928"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6340.728, "latencies_ms": [6340.728], "images_per_second": 0.158, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A bronze statue of two people sitting on a bench, with a handbag on the ground next to them.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14921.5, "ram_available_mb": 47919.4, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 14922.3, "ram_available_mb": 47918.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.075}, "power_stats": {"power_gpu_soc_mean_watts": 17.053, "power_cpu_cv_mean_watts": 1.904, "power_sys_5v0_mean_watts": 6.379, "gpu_utilization_percent_mean": 96.075}, "timestamp": "2026-01-30T10:51:35.149583"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4242.937, "latencies_ms": [4242.937], "images_per_second": 0.236, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The statue is made of bronze and is located in a public square. The lighting is natural and the weather is overcast.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14922.3, "ram_available_mb": 47918.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 14922.3, "ram_available_mb": 47918.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.206}, "power_stats": {"power_gpu_soc_mean_watts": 21.351, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 7.509, "gpu_utilization_percent_mean": 92.206}, "timestamp": "2026-01-30T10:51:41.429122"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8285.081, "latencies_ms": [8285.081], "images_per_second": 0.121, "prompt_tokens": 1100, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image shows a series of road signs, including a blue sign with white text and symbols, a green sign with white text and symbols, a red and white circular sign with a truck symbol, and a blue and white sign with a parking symbol.", "error": null, "sys_before": {"cpu_percent": 19.0, "ram_used_mb": 14922.3, "ram_available_mb": 47918.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 14922.5, "ram_available_mb": 47918.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.014}, "power_stats": {"power_gpu_soc_mean_watts": 16.215, "power_cpu_cv_mean_watts": 2.663, "power_sys_5v0_mean_watts": 6.455, "gpu_utilization_percent_mean": 88.014}, "timestamp": "2026-01-30T10:51:51.751611"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8112.341, "latencies_ms": [8112.341], "images_per_second": 0.123, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. signpost\n2. blue sign\n3. green sign\n4. white sign\n5. red and blue sign\n6. white arrow\n7. blue arrow\n8. white text", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14922.5, "ram_available_mb": 47918.4, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.7, "ram_used_mb": 14923.7, "ram_available_mb": 47917.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.149}, "power_stats": {"power_gpu_soc_mean_watts": 16.042, "power_cpu_cv_mean_watts": 2.743, "power_sys_5v0_mean_watts": 6.404, "gpu_utilization_percent_mean": 97.149}, "timestamp": "2026-01-30T10:52:01.886441"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6128.121, "latencies_ms": [6128.121], "images_per_second": 0.163, "prompt_tokens": 1118, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The blue sign is on the left, the green sign is in the middle, and the red and blue signs are on the right. The blue sign is in the foreground, while the green sign is in the middle ground, and the red and blue signs are in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14923.7, "ram_available_mb": 47917.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 14923.7, "ram_available_mb": 47917.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.373}, "power_stats": {"power_gpu_soc_mean_watts": 18.286, "power_cpu_cv_mean_watts": 1.97, "power_sys_5v0_mean_watts": 7.399, "gpu_utilization_percent_mean": 76.373}, "timestamp": "2026-01-30T10:52:10.036491"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10546.362, "latencies_ms": [10546.362], "images_per_second": 0.095, "prompt_tokens": 1112, "response_tokens_est": 80, "n_tiles": 1, "output_text": " The image captures a scene of a road signpost, standing tall against the backdrop of a cloudy sky. The signpost, adorned with four distinct signs, each with its own unique color and symbol, guides travelers on their journey. The signs, in German, read \"Severins-br\u00fccke\" and \"Koelnnesse,\" indicating the names of nearby bridges and roads.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14923.7, "ram_available_mb": 47917.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.022}, "power_stats": {"power_gpu_soc_mean_watts": 15.506, "power_cpu_cv_mean_watts": 2.627, "power_sys_5v0_mean_watts": 6.552, "gpu_utilization_percent_mean": 87.022}, "timestamp": "2026-01-30T10:52:22.617982"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9050.89, "latencies_ms": [9050.89], "images_per_second": 0.11, "prompt_tokens": 1110, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a blue and white sign with a yellow truck icon, a green and white sign with a yellow bus icon, and a red and white sign with a blue truck icon. The signs are set against a cloudy sky and surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 14924.4, "ram_available_mb": 47916.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.237}, "power_stats": {"power_gpu_soc_mean_watts": 15.919, "power_cpu_cv_mean_watts": 2.94, "power_sys_5v0_mean_watts": 6.362, "gpu_utilization_percent_mean": 97.237}, "timestamp": "2026-01-30T10:52:33.721078"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4210.237, "latencies_ms": [4210.237], "images_per_second": 0.238, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " Two women, one in a red shirt and the other in a blue shirt, are standing on a train platform with their luggage, with a woman in the background.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 14924.4, "ram_available_mb": 47916.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 14924.4, "ram_available_mb": 47916.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.971}, "power_stats": {"power_gpu_soc_mean_watts": 20.904, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.638, "gpu_utilization_percent_mean": 74.971}, "timestamp": "2026-01-30T10:52:39.975172"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9403.131, "latencies_ms": [9403.131], "images_per_second": 0.106, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. suitcase: 1\n2. woman: 2\n3. girl: 1\n4. backpack: 1\n5. handbag: 1\n6. suitcase tag: 1\n7. platform: 1\n8. train: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14924.4, "ram_available_mb": 47916.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.684}, "power_stats": {"power_gpu_soc_mean_watts": 15.978, "power_cpu_cv_mean_watts": 2.96, "power_sys_5v0_mean_watts": 6.426, "gpu_utilization_percent_mean": 89.684}, "timestamp": "2026-01-30T10:52:51.416876"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12158.569, "latencies_ms": [12158.569], "images_per_second": 0.082, "prompt_tokens": 1118, "response_tokens_est": 94, "n_tiles": 1, "output_text": " The woman in the red shirt is standing to the left of the woman in the blue shirt, with the woman in the blue shirt being closer to the camera. The woman in the blue shirt is standing in front of the woman in the red shirt, with the woman in the blue shirt being closer to the camera. The woman in the blue shirt is standing in front of the woman in the red shirt, with the woman in the blue shirt being closer to the camera.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.7, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.525}, "power_stats": {"power_gpu_soc_mean_watts": 15.522, "power_cpu_cv_mean_watts": 2.942, "power_sys_5v0_mean_watts": 6.509, "gpu_utilization_percent_mean": 94.525}, "timestamp": "2026-01-30T10:53:05.611528"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3999.738, "latencies_ms": [3999.738], "images_per_second": 0.25, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two women are standing on a train platform, one of them is holding a suitcase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.844}, "power_stats": {"power_gpu_soc_mean_watts": 20.708, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 7.263, "gpu_utilization_percent_mean": 91.844}, "timestamp": "2026-01-30T10:53:11.624692"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7640.449, "latencies_ms": [7640.449], "images_per_second": 0.131, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image is taken during daytime with natural light illuminating the scene. The colors in the image are vibrant, with the red of the woman's shirt standing out against the blue of the girl's t-shirt.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 14924.2, "ram_available_mb": 47916.7, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.922}, "power_stats": {"power_gpu_soc_mean_watts": 16.599, "power_cpu_cv_mean_watts": 2.477, "power_sys_5v0_mean_watts": 6.476, "gpu_utilization_percent_mean": 88.922}, "timestamp": "2026-01-30T10:53:21.298883"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5108.039, "latencies_ms": [5108.039], "images_per_second": 0.196, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Three zebras with black and white stripes are walking on a dirt path in a forest with purple flowers.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 14923.9, "ram_available_mb": 47916.9, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.6, "ram_used_mb": 14923.9, "ram_available_mb": 47916.9, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.048}, "power_stats": {"power_gpu_soc_mean_watts": 18.458, "power_cpu_cv_mean_watts": 1.83, "power_sys_5v0_mean_watts": 6.746, "gpu_utilization_percent_mean": 94.048}, "timestamp": "2026-01-30T10:53:28.439759"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4634.113, "latencies_ms": [4634.113], "images_per_second": 0.216, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 3", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14923.9, "ram_available_mb": 47916.9, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14924.9, "ram_available_mb": 47916.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.816}, "power_stats": {"power_gpu_soc_mean_watts": 18.199, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 6.364, "gpu_utilization_percent_mean": 96.816}, "timestamp": "2026-01-30T10:53:35.106248"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6272.96, "latencies_ms": [6272.96], "images_per_second": 0.159, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the trees and bushes serving as a backdrop in the background. The zebras are facing the camera, with the tree with purple flowers located to the right of the zebras.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14924.9, "ram_available_mb": 47916.0, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 14925.9, "ram_available_mb": 47915.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 93.538}, "power_stats": {"power_gpu_soc_mean_watts": 18.79, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.141, "gpu_utilization_percent_mean": 93.538}, "timestamp": "2026-01-30T10:53:43.431652"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5674.335, "latencies_ms": [5674.335], "images_per_second": 0.176, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Three zebras are walking in a line on a dirt path, surrounded by trees with purple flowers.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14925.9, "ram_available_mb": 47915.0, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14926.9, "ram_available_mb": 47914.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.542}, "power_stats": {"power_gpu_soc_mean_watts": 17.536, "power_cpu_cv_mean_watts": 2.494, "power_sys_5v0_mean_watts": 6.461, "gpu_utilization_percent_mean": 88.542}, "timestamp": "2026-01-30T10:53:51.135961"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6472.141, "latencies_ms": [6472.141], "images_per_second": 0.155, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features three zebras with black and white stripes walking on a dirt path. The zebras are surrounded by trees with purple flowers, and the lighting is bright and sunny.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14926.9, "ram_available_mb": 47914.0, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 13.0, "ram_used_mb": 14926.6, "ram_available_mb": 47914.3, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.151}, "power_stats": {"power_gpu_soc_mean_watts": 17.523, "power_cpu_cv_mean_watts": 2.478, "power_sys_5v0_mean_watts": 6.746, "gpu_utilization_percent_mean": 96.151}, "timestamp": "2026-01-30T10:53:59.621237"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5192.99, "latencies_ms": [5192.99], "images_per_second": 0.193, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A camera is mounted on a tripod in a room with a vending machine and a laptop on a table.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 14926.6, "ram_available_mb": 47914.3, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14926.9, "ram_available_mb": 47914.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.504, "power_cpu_cv_mean_watts": 1.871, "power_sys_5v0_mean_watts": 6.729, "gpu_utilization_percent_mean": 85.0}, "timestamp": "2026-01-30T10:54:06.859332"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4612.456, "latencies_ms": [4612.456], "images_per_second": 0.217, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " tripod: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14926.9, "ram_available_mb": 47914.0, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 14924.9, "ram_available_mb": 47916.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 94.237}, "power_stats": {"power_gpu_soc_mean_watts": 17.62, "power_cpu_cv_mean_watts": 1.759, "power_sys_5v0_mean_watts": 6.326, "gpu_utilization_percent_mean": 94.237}, "timestamp": "2026-01-30T10:54:13.508043"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7350.531, "latencies_ms": [7350.531], "images_per_second": 0.136, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The camera is positioned to the right of the tripod, which is in the foreground of the image. The laptop is placed on the tripod, and the vending machine is located in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14924.9, "ram_available_mb": 47916.0, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 14924.9, "ram_available_mb": 47916.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.377}, "power_stats": {"power_gpu_soc_mean_watts": 16.241, "power_cpu_cv_mean_watts": 1.884, "power_sys_5v0_mean_watts": 6.62, "gpu_utilization_percent_mean": 81.377}, "timestamp": "2026-01-30T10:54:22.875944"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6210.33, "latencies_ms": [6210.33], "images_per_second": 0.161, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A camera is on a tripod in a room with a vending machine and a laptop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14924.9, "ram_available_mb": 47916.0, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 14924.0, "ram_available_mb": 47916.9, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.765, "power_cpu_cv_mean_watts": 2.526, "power_sys_5v0_mean_watts": 6.33, "gpu_utilization_percent_mean": 98.0}, "timestamp": "2026-01-30T10:54:31.106538"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4791.083, "latencies_ms": [4791.083], "images_per_second": 0.209, "prompt_tokens": 1110, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image is taken in a room with a blue and white vending machine in the background. The lighting is natural, and the colors are muted.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 14924.0, "ram_available_mb": 47916.9, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 14923.9, "ram_available_mb": 47917.0, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 19.862, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 7.233, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-30T10:54:37.919086"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7274.451, "latencies_ms": [7274.451], "images_per_second": 0.137, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A sheep with a white wool coat is standing in a pen with a pile of wool on the ground, and there is a metal fence in the background.", "error": null, "sys_before": {"cpu_percent": 23.8, "ram_used_mb": 14923.9, "ram_available_mb": 47917.0, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 12.7, "ram_used_mb": 14923.9, "ram_available_mb": 47917.0, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.803}, "power_stats": {"power_gpu_soc_mean_watts": 16.419, "power_cpu_cv_mean_watts": 2.626, "power_sys_5v0_mean_watts": 6.36, "gpu_utilization_percent_mean": 97.803}, "timestamp": "2026-01-30T10:54:47.263108"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4326.843, "latencies_ms": [4326.843], "images_per_second": 0.231, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " sheep: 1, fence: 1, ball: 1, metal: 1, ground: 1, sheep's wool: 1, fence post: 1", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 14923.9, "ram_available_mb": 47917.0, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.528}, "power_stats": {"power_gpu_soc_mean_watts": 20.512, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 7.683, "gpu_utilization_percent_mean": 70.528}, "timestamp": "2026-01-30T10:54:53.611989"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7844.68, "latencies_ms": [7844.68], "images_per_second": 0.127, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The sheep is in the foreground, standing in front of a metal fence. The sheep is eating the wool, which is in the middle ground. The background is a concrete surface.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14924.1, "ram_available_mb": 47916.8, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 11.8, "ram_used_mb": 14924.8, "ram_available_mb": 47916.1, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.615}, "power_stats": {"power_gpu_soc_mean_watts": 16.296, "power_cpu_cv_mean_watts": 2.458, "power_sys_5v0_mean_watts": 6.367, "gpu_utilization_percent_mean": 97.615}, "timestamp": "2026-01-30T10:55:03.474802"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3039.954, "latencies_ms": [3039.954], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A sheep is eating a pile of wool in a fenced-in area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14924.8, "ram_available_mb": 47916.1, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14925.3, "ram_available_mb": 47915.6, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.96}, "power_stats": {"power_gpu_soc_mean_watts": 23.689, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 7.822, "gpu_utilization_percent_mean": 74.96}, "timestamp": "2026-01-30T10:55:08.548561"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6426.493, "latencies_ms": [6426.493], "images_per_second": 0.156, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sheep is white and the fence is grey. The lighting is natural and the weather is cloudy.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14925.3, "ram_available_mb": 47915.6, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 13.7, "ram_used_mb": 14925.6, "ram_available_mb": 47915.3, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.962}, "power_stats": {"power_gpu_soc_mean_watts": 16.895, "power_cpu_cv_mean_watts": 2.387, "power_sys_5v0_mean_watts": 6.314, "gpu_utilization_percent_mean": 97.962}, "timestamp": "2026-01-30T10:55:16.998508"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7953.914, "latencies_ms": [7953.914], "images_per_second": 0.126, "prompt_tokens": 1099, "response_tokens_est": 75, "n_tiles": 1, "output_text": " In the image, a tennis match is taking place on a blue court, with a player in a pink outfit preparing to serve the ball, while the opposing team, wearing red, is positioned near the net. The court is surrounded by a crowd of spectators, and various advertisements are visible in the background, including those for Lexus, Mirvac, and Sony Ericsson.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14925.6, "ram_available_mb": 47915.3, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 14925.6, "ram_available_mb": 47915.3, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.197}, "power_stats": {"power_gpu_soc_mean_watts": 17.153, "power_cpu_cv_mean_watts": 2.044, "power_sys_5v0_mean_watts": 7.179, "gpu_utilization_percent_mean": 80.197}, "timestamp": "2026-01-30T10:55:26.973533"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7548.747, "latencies_ms": [7548.747], "images_per_second": 0.132, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. tennis court\n2. net\n3. ball\n4. racket\n5. player\n6. player's outfit\n7. player's shoes\n8. player's hair", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14925.6, "ram_available_mb": 47915.3, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 13.4, "ram_used_mb": 14980.5, "ram_available_mb": 47860.4, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.603}, "power_stats": {"power_gpu_soc_mean_watts": 16.437, "power_cpu_cv_mean_watts": 2.472, "power_sys_5v0_mean_watts": 6.451, "gpu_utilization_percent_mean": 88.603}, "timestamp": "2026-01-30T10:55:36.579042"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8694.271, "latencies_ms": [8694.271], "images_per_second": 0.115, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground, with the net and the ball in the middle ground, and the crowd in the background. The player is near the net, while the ball is in the air, and the crowd is far away from the camera.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14981.7, "ram_available_mb": 47859.2, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 15.1, "ram_used_mb": 14916.8, "ram_available_mb": 47924.1, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 96.192}, "power_stats": {"power_gpu_soc_mean_watts": 16.062, "power_cpu_cv_mean_watts": 3.083, "power_sys_5v0_mean_watts": 6.52, "gpu_utilization_percent_mean": 96.192}, "timestamp": "2026-01-30T10:55:47.307388"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3519.97, "latencies_ms": [3519.97], "images_per_second": 0.284, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A tennis match is taking place in a large stadium with a blue court, surrounded by spectators and advertisements.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14916.8, "ram_available_mb": 47924.1, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14916.3, "ram_available_mb": 47924.6, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.655}, "power_stats": {"power_gpu_soc_mean_watts": 23.391, "power_cpu_cv_mean_watts": 1.339, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 80.655}, "timestamp": "2026-01-30T10:55:52.842043"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6472.495, "latencies_ms": [6472.495], "images_per_second": 0.154, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The court is blue, the players are wearing red and pink, and the crowd is watching intently.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14916.3, "ram_available_mb": 47924.6, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 14916.7, "ram_available_mb": 47924.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.056}, "power_stats": {"power_gpu_soc_mean_watts": 16.682, "power_cpu_cv_mean_watts": 2.595, "power_sys_5v0_mean_watts": 6.299, "gpu_utilization_percent_mean": 98.056}, "timestamp": "2026-01-30T10:56:01.361830"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4501.128, "latencies_ms": [4501.128], "images_per_second": 0.222, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A person is walking through a modern airport terminal with a suitcase, and there are signs for the escalator and other directions on the walls.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14916.7, "ram_available_mb": 47924.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14916.7, "ram_available_mb": 47924.2, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.973}, "power_stats": {"power_gpu_soc_mean_watts": 20.498, "power_cpu_cv_mean_watts": 1.558, "power_sys_5v0_mean_watts": 7.324, "gpu_utilization_percent_mean": 76.973}, "timestamp": "2026-01-30T10:56:07.906105"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9998.604, "latencies_ms": [9998.604], "images_per_second": 0.1, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. suitcase: 1\n3. glass door: 1\n4. pillar: 1\n5. sign: 1\n6. wall: 1\n7. floor: 1\n8. ceiling: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14916.7, "ram_available_mb": 47924.2, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 14.5, "ram_used_mb": 14920.4, "ram_available_mb": 47920.5, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.238}, "power_stats": {"power_gpu_soc_mean_watts": 15.646, "power_cpu_cv_mean_watts": 2.989, "power_sys_5v0_mean_watts": 6.445, "gpu_utilization_percent_mean": 97.238}, "timestamp": "2026-01-30T10:56:19.930724"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6657.25, "latencies_ms": [6657.25], "images_per_second": 0.15, "prompt_tokens": 1118, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The main object, a person, is positioned in the foreground, walking towards the camera. The glass door is located in the middle ground, partially obscuring the view of the person. The escalator is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14920.4, "ram_available_mb": 47920.5, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 14.9, "ram_used_mb": 14954.3, "ram_available_mb": 47886.6, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 92.273}, "power_stats": {"power_gpu_soc_mean_watts": 18.498, "power_cpu_cv_mean_watts": 2.621, "power_sys_5v0_mean_watts": 7.147, "gpu_utilization_percent_mean": 92.273}, "timestamp": "2026-01-30T10:56:28.618801"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5278.538, "latencies_ms": [5278.538], "images_per_second": 0.189, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is walking through a modern airport terminal with a suitcase.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14954.3, "ram_available_mb": 47886.6, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 16.3, "ram_used_mb": 14951.5, "ram_available_mb": 47889.4, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.023}, "power_stats": {"power_gpu_soc_mean_watts": 17.601, "power_cpu_cv_mean_watts": 2.71, "power_sys_5v0_mean_watts": 6.491, "gpu_utilization_percent_mean": 88.023}, "timestamp": "2026-01-30T10:56:35.954709"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5981.27, "latencies_ms": [5981.27], "images_per_second": 0.167, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is taken in a well-lit indoor space with a grey floor and white walls. The lighting is bright and natural, coming from the ceiling lights.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14951.0, "ram_available_mb": 47889.9, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 18.1, "ram_used_mb": 14951.1, "ram_available_mb": 47889.8, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.122}, "power_stats": {"power_gpu_soc_mean_watts": 18.028, "power_cpu_cv_mean_watts": 2.909, "power_sys_5v0_mean_watts": 7.059, "gpu_utilization_percent_mean": 97.122}, "timestamp": "2026-01-30T10:56:43.980211"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4633.702, "latencies_ms": [4633.702], "images_per_second": 0.216, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A dining table is set with two large pizzas, a few glasses of water, and a few forks and knives.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 14951.6, "ram_available_mb": 47889.3, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 16.1, "ram_used_mb": 14963.2, "ram_available_mb": 47877.7, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.947}, "power_stats": {"power_gpu_soc_mean_watts": 19.823, "power_cpu_cv_mean_watts": 2.539, "power_sys_5v0_mean_watts": 7.55, "gpu_utilization_percent_mean": 81.947}, "timestamp": "2026-01-30T10:56:52.464375"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7716.94, "latencies_ms": [7716.94], "images_per_second": 0.13, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " pizza: 2, glasses: 2, fork: 1, knife: 1, spoon: 1, television: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 14963.2, "ram_available_mb": 47877.7, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 18.7, "ram_used_mb": 14971.5, "ram_available_mb": 47869.4, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.109}, "power_stats": {"power_gpu_soc_mean_watts": 16.087, "power_cpu_cv_mean_watts": 3.178, "power_sys_5v0_mean_watts": 6.361, "gpu_utilization_percent_mean": 98.109}, "timestamp": "2026-01-30T10:57:02.213435"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7484.813, "latencies_ms": [7484.813], "images_per_second": 0.134, "prompt_tokens": 1118, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The large pizza boxes are placed on the table, with one box in the foreground and the other in the background. The glasses of water are positioned near the pizza boxes, with one glass closer to the foreground and the other further back. The fork and knife are placed on the table, with the fork closer to the foreground and the knife further back.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14971.8, "ram_available_mb": 47869.1, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 17.9, "ram_used_mb": 14973.4, "ram_available_mb": 47867.5, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.661}, "power_stats": {"power_gpu_soc_mean_watts": 17.451, "power_cpu_cv_mean_watts": 2.964, "power_sys_5v0_mean_watts": 7.408, "gpu_utilization_percent_mean": 81.661}, "timestamp": "2026-01-30T10:57:11.723528"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6052.401, "latencies_ms": [6052.401], "images_per_second": 0.165, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A dining room with a table set for a pizza party, with two large pizzas and a few glasses of water.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 14976.0, "ram_available_mb": 47864.9, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 16.7, "ram_used_mb": 14975.6, "ram_available_mb": 47865.3, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.18}, "power_stats": {"power_gpu_soc_mean_watts": 17.323, "power_cpu_cv_mean_watts": 3.067, "power_sys_5v0_mean_watts": 7.1, "gpu_utilization_percent_mean": 88.18}, "timestamp": "2026-01-30T10:57:21.240014"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7780.898, "latencies_ms": [7780.898], "images_per_second": 0.129, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm and cozy atmosphere. The colors in the image are vibrant and inviting, with the red of the pizza boxes standing out against the blue of the television screen in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14975.4, "ram_available_mb": 47865.5, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 17.7, "ram_used_mb": 14995.7, "ram_available_mb": 47845.2, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 95.877}, "power_stats": {"power_gpu_soc_mean_watts": 16.548, "power_cpu_cv_mean_watts": 2.809, "power_sys_5v0_mean_watts": 6.993, "gpu_utilization_percent_mean": 95.877}, "timestamp": "2026-01-30T10:57:31.038598"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6133.598, "latencies_ms": [6133.598], "images_per_second": 0.163, "prompt_tokens": 1100, "response_tokens_est": 49, "n_tiles": 1, "output_text": " A young boy wearing a helmet and a gray shirt is standing at home plate, holding a baseball bat, while a catcher in a red shirt and a catcher's mitt is crouched behind him, ready to catch the ball.", "error": null, "sys_before": {"cpu_percent": 28.6, "ram_used_mb": 14995.4, "ram_available_mb": 47845.5, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 16.2, "ram_used_mb": 14996.7, "ram_available_mb": 47844.2, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.151}, "power_stats": {"power_gpu_soc_mean_watts": 17.553, "power_cpu_cv_mean_watts": 3.219, "power_sys_5v0_mean_watts": 7.594, "gpu_utilization_percent_mean": 74.151}, "timestamp": "2026-01-30T10:57:39.224901"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8537.802, "latencies_ms": [8537.802], "images_per_second": 0.117, "prompt_tokens": 1114, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball glove: 1\n3. baseball: 1\n4. baseball player: 1\n5. catcher: 1\n6. umpire: 1\n7. spectator: 1\n8. spectator chair: 1", "error": null, "sys_before": {"cpu_percent": 17.3, "ram_used_mb": 15000.1, "ram_available_mb": 47840.8, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 13.9, "ram_used_mb": 14992.8, "ram_available_mb": 47848.1, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.114}, "power_stats": {"power_gpu_soc_mean_watts": 15.786, "power_cpu_cv_mean_watts": 3.381, "power_sys_5v0_mean_watts": 7.358, "gpu_utilization_percent_mean": 77.114}, "timestamp": "2026-01-30T10:57:52.581719"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7854.307, "latencies_ms": [7854.307], "images_per_second": 0.127, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 12.1, "ram_used_mb": 14992.7, "ram_available_mb": 47848.2, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 18.5, "ram_used_mb": 15004.0, "ram_available_mb": 47836.9, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.242}, "power_stats": {"power_gpu_soc_mean_watts": 16.395, "power_cpu_cv_mean_watts": 3.604, "power_sys_5v0_mean_watts": 6.817, "gpu_utilization_percent_mean": 97.242}, "timestamp": "2026-01-30T10:58:03.571545"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3631.871, "latencies_ms": [3631.871], "images_per_second": 0.275, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young boy is playing baseball in a park with a group of people watching.", "error": null, "sys_before": {"cpu_percent": 2.1, "ram_used_mb": 15003.7, "ram_available_mb": 47837.2, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 13.2, "ram_used_mb": 15007.0, "ram_available_mb": 47833.9, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.448}, "power_stats": {"power_gpu_soc_mean_watts": 22.064, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 91.448}, "timestamp": "2026-01-30T10:58:10.987252"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7162.669, "latencies_ms": [7162.669], "images_per_second": 0.14, "prompt_tokens": 1110, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken during a sunny day with clear blue skies. The colors in the image are vibrant, with the green of the grass and trees contrasting against the blue of the sky.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15007.4, "ram_available_mb": 47833.5, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 15011.7, "ram_available_mb": 47829.2, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.117}, "power_stats": {"power_gpu_soc_mean_watts": 16.666, "power_cpu_cv_mean_watts": 2.569, "power_sys_5v0_mean_watts": 7.0, "gpu_utilization_percent_mean": 87.117}, "timestamp": "2026-01-30T10:58:21.544520"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5722.905, "latencies_ms": [5722.905], "images_per_second": 0.175, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana is on top of a black phone on a desk.", "error": null, "sys_before": {"cpu_percent": 8.4, "ram_used_mb": 15011.9, "ram_available_mb": 47829.0, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 14.6, "ram_used_mb": 15006.8, "ram_available_mb": 47834.1, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.025}, "power_stats": {"power_gpu_soc_mean_watts": 18.242, "power_cpu_cv_mean_watts": 2.593, "power_sys_5v0_mean_watts": 7.088, "gpu_utilization_percent_mean": 98.025}, "timestamp": "2026-01-30T10:58:31.990901"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2460.517, "latencies_ms": [2460.517], "images_per_second": 0.406, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 1", "error": null, "sys_before": {"cpu_percent": 7.0, "ram_used_mb": 15007.2, "ram_available_mb": 47833.7, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 15008.4, "ram_available_mb": 47832.5, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.684}, "power_stats": {"power_gpu_soc_mean_watts": 25.057, "power_cpu_cv_mean_watts": 0.674, "power_sys_5v0_mean_watts": 8.256, "gpu_utilization_percent_mean": 83.684}, "timestamp": "2026-01-30T10:58:39.563254"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7225.61, "latencies_ms": [7225.61], "images_per_second": 0.138, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The banana is located in the foreground, to the right of the phone, and the phone is on the desk. The banana is near the phone, and the desk is in the background.", "error": null, "sys_before": {"cpu_percent": 17.5, "ram_used_mb": 15008.7, "ram_available_mb": 47832.2, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 15008.0, "ram_available_mb": 47832.9, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.6}, "power_stats": {"power_gpu_soc_mean_watts": 16.679, "power_cpu_cv_mean_watts": 2.302, "power_sys_5v0_mean_watts": 7.002, "gpu_utilization_percent_mean": 86.6}, "timestamp": "2026-01-30T10:58:51.621837"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6091.891, "latencies_ms": [6091.891], "images_per_second": 0.164, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A banana is on top of a phone and a computer is on a desk.", "error": null, "sys_before": {"cpu_percent": 7.8, "ram_used_mb": 15007.8, "ram_available_mb": 47833.1, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 15.5, "ram_used_mb": 15004.1, "ram_available_mb": 47836.8, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 98.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.985, "power_cpu_cv_mean_watts": 2.544, "power_sys_5v0_mean_watts": 6.905, "gpu_utilization_percent_mean": 98.0}, "timestamp": "2026-01-30T10:59:01.940937"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3978.56, "latencies_ms": [3978.56], "images_per_second": 0.251, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image has a white desk with a black phone and a yellow banana on it. The lighting is natural and the banana is ripe.", "error": null, "sys_before": {"cpu_percent": 1.6, "ram_used_mb": 15003.9, "ram_available_mb": 47837.0, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 17.2, "ram_used_mb": 15010.5, "ram_available_mb": 47830.4, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.31, "power_cpu_cv_mean_watts": 3.192, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 75.667}, "timestamp": "2026-01-30T10:59:09.865422"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8895.251, "latencies_ms": [8895.251], "images_per_second": 0.112, "prompt_tokens": 1099, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a bustling scene of a crowd of people gathered in a public space, with individuals of various ages and attires, including a woman in a green jacket and a man in a red shirt, among others, all engaged in different activities, with a prominent presence of a woman holding a teddy bear.", "error": null, "sys_before": {"cpu_percent": 19.3, "ram_used_mb": 15009.7, "ram_available_mb": 47831.2, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 16.4, "ram_used_mb": 15015.4, "ram_available_mb": 47825.4, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.553}, "power_stats": {"power_gpu_soc_mean_watts": 16.047, "power_cpu_cv_mean_watts": 4.016, "power_sys_5v0_mean_watts": 7.282, "gpu_utilization_percent_mean": 84.553}, "timestamp": "2026-01-30T10:59:22.536313"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8676.013, "latencies_ms": [8676.013], "images_per_second": 0.115, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. People: 10\n2. Green bag: 1\n3. Red bag: 1\n4. Blue scarf: 1\n5. Red shirt: 1\n6. Green jacket: 1\n7. Black jacket: 1\n8. Gray jacket: 1", "error": null, "sys_before": {"cpu_percent": 12.2, "ram_used_mb": 15017.2, "ram_available_mb": 47823.7, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 14918.5, "ram_available_mb": 47922.4, "ram_percent": 23.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.365}, "power_stats": {"power_gpu_soc_mean_watts": 15.667, "power_cpu_cv_mean_watts": 2.765, "power_sys_5v0_mean_watts": 7.099, "gpu_utilization_percent_mean": 80.365}, "timestamp": "2026-01-30T10:59:37.127100"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10445.538, "latencies_ms": [10445.538], "images_per_second": 0.096, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The main objects are the crowd of people, the bus stop sign, and the trees in the background. The crowd of people is in the foreground, the bus stop sign is in the middle ground, and the trees are in the background. The crowd of people is in front of the bus stop sign, and the trees are behind the crowd of people.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14918.4, "ram_available_mb": 47922.4, "ram_percent": 23.7}, "sys_after": {"cpu_percent": 13.0, "ram_used_mb": 14962.8, "ram_available_mb": 47878.1, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 90.989}, "power_stats": {"power_gpu_soc_mean_watts": 15.738, "power_cpu_cv_mean_watts": 2.839, "power_sys_5v0_mean_watts": 6.941, "gpu_utilization_percent_mean": 90.989}, "timestamp": "2026-01-30T10:59:51.345861"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8194.725, "latencies_ms": [8194.725], "images_per_second": 0.122, "prompt_tokens": 1111, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A large crowd of people are gathered in a public space, possibly a park or plaza, and they are all engaged in various activities such as talking, laughing, and looking at their phones.", "error": null, "sys_before": {"cpu_percent": 7.6, "ram_used_mb": 14966.2, "ram_available_mb": 47874.7, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 14.1, "ram_used_mb": 14962.4, "ram_available_mb": 47878.5, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.851}, "power_stats": {"power_gpu_soc_mean_watts": 16.216, "power_cpu_cv_mean_watts": 2.564, "power_sys_5v0_mean_watts": 6.861, "gpu_utilization_percent_mean": 97.851}, "timestamp": "2026-01-30T11:00:03.613149"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6337.684, "latencies_ms": [6337.684], "images_per_second": 0.158, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the colors are vibrant and varied.", "error": null, "sys_before": {"cpu_percent": 3.9, "ram_used_mb": 14962.5, "ram_available_mb": 47878.4, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 14.1, "ram_used_mb": 14965.6, "ram_available_mb": 47875.3, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 97.962}, "power_stats": {"power_gpu_soc_mean_watts": 16.88, "power_cpu_cv_mean_watts": 2.644, "power_sys_5v0_mean_watts": 6.772, "gpu_utilization_percent_mean": 97.962}, "timestamp": "2026-01-30T11:00:16.931874"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3399.191, "latencies_ms": [3399.191], "images_per_second": 0.294, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing a red shirt is holding a baby in his arms while a horse nuzzles the baby's hand.", "error": null, "sys_before": {"cpu_percent": 8.6, "ram_used_mb": 14967.4, "ram_available_mb": 47873.5, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 15011.1, "ram_available_mb": 47829.8, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.929}, "power_stats": {"power_gpu_soc_mean_watts": 23.07, "power_cpu_cv_mean_watts": 1.258, "power_sys_5v0_mean_watts": 8.398, "gpu_utilization_percent_mean": 75.929}, "timestamp": "2026-01-30T11:00:24.046485"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6660.013, "latencies_ms": [6660.013], "images_per_second": 0.15, "prompt_tokens": 1114, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. horse: 1\n2. man: 1\n3. baby: 1\n4. man's shirt: 1\n5. man's pants: 1\n6. man's shoes: 1\n7. man's hair: 1\n8. man's face: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15011.1, "ram_available_mb": 47829.8, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 18.9, "ram_used_mb": 15006.0, "ram_available_mb": 47834.9, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.071}, "power_stats": {"power_gpu_soc_mean_watts": 18.629, "power_cpu_cv_mean_watts": 3.325, "power_sys_5v0_mean_watts": 7.899, "gpu_utilization_percent_mean": 75.071}, "timestamp": "2026-01-30T11:00:32.750234"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4820.206, "latencies_ms": [4820.206], "images_per_second": 0.207, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The man is standing to the left of the horse, and the baby is in his arms, which are positioned in the foreground. The horse is in the background, and the man is in front of the horse.", "error": null, "sys_before": {"cpu_percent": 18.5, "ram_used_mb": 15005.6, "ram_available_mb": 47835.3, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 19.2, "ram_used_mb": 14944.3, "ram_available_mb": 47896.6, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.394, "power_cpu_cv_mean_watts": 4.045, "power_sys_5v0_mean_watts": 7.953, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-30T11:00:39.597074"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3671.402, "latencies_ms": [3671.402], "images_per_second": 0.272, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man in a red shirt is holding a baby in his arms while a horse nuzzles the baby's hand.", "error": null, "sys_before": {"cpu_percent": 45.5, "ram_used_mb": 14944.3, "ram_available_mb": 47896.6, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 14955.0, "ram_available_mb": 47885.9, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.733}, "power_stats": {"power_gpu_soc_mean_watts": 22.12, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 78.733}, "timestamp": "2026-01-30T11:00:45.314920"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5777.51, "latencies_ms": [5777.51], "images_per_second": 0.173, "prompt_tokens": 1110, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a man wearing a red shirt and a baby in his arms. The man is holding the baby close to a brown horse, which is standing in front of a brick wall. The lighting in the image is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14955.0, "ram_available_mb": 47885.9, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 13.5, "ram_used_mb": 14975.0, "ram_available_mb": 47865.9, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.188}, "power_stats": {"power_gpu_soc_mean_watts": 19.54, "power_cpu_cv_mean_watts": 2.411, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 74.188}, "timestamp": "2026-01-30T11:00:53.118614"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3359.983, "latencies_ms": [3359.983], "images_per_second": 0.298, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A white plate with a banana and a small amount of peanut butter on it.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 14975.0, "ram_available_mb": 47865.9, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 14977.2, "ram_available_mb": 47863.7, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.655, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 83.714}, "timestamp": "2026-01-30T11:00:58.530355"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3347.537, "latencies_ms": [3347.537], "images_per_second": 0.299, "prompt_tokens": 1114, "response_tokens_est": 15, "n_tiles": 1, "output_text": " banana: 1, plate: 1, peanut butter: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14977.2, "ram_available_mb": 47863.7, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14978.9, "ram_available_mb": 47862.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.692, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 83.185}, "timestamp": "2026-01-30T11:01:03.908418"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4715.366, "latencies_ms": [4715.366], "images_per_second": 0.212, "prompt_tokens": 1118, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The banana is on the left side of the plate, and the peanut butter is in the center. The plate is in the foreground, and the table is in the background.", "error": null, "sys_before": {"cpu_percent": 6.0, "ram_used_mb": 14974.4, "ram_available_mb": 47866.5, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 14977.9, "ram_available_mb": 47863.0, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.868}, "power_stats": {"power_gpu_soc_mean_watts": 20.539, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 8.245, "gpu_utilization_percent_mean": 78.868}, "timestamp": "2026-01-30T11:01:11.936938"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3389.242, "latencies_ms": [3389.242], "images_per_second": 0.295, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A banana and a bowl of peanut butter are on a plate on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14977.9, "ram_available_mb": 47863.0, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 14978.7, "ram_available_mb": 47862.2, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.821}, "power_stats": {"power_gpu_soc_mean_watts": 22.411, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 84.821}, "timestamp": "2026-01-30T11:01:17.342521"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3768.742, "latencies_ms": [3768.742], "images_per_second": 0.265, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image shows a white plate with a banana and peanut butter on it. The plate is placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14978.7, "ram_available_mb": 47862.2, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14976.8, "ram_available_mb": 47864.1, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.742}, "power_stats": {"power_gpu_soc_mean_watts": 22.23, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 79.742}, "timestamp": "2026-01-30T11:01:23.137800"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3860.682, "latencies_ms": [3860.682], "images_per_second": 0.259, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man in a green shirt and glasses is working on a bicycle wheel on the ground next to a motorcycle.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 14976.8, "ram_available_mb": 47864.1, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 14976.3, "ram_available_mb": 47864.6, "ram_percent": 23.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.75}, "power_stats": {"power_gpu_soc_mean_watts": 21.474, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 83.75}, "timestamp": "2026-01-30T11:01:29.069112"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6238.895, "latencies_ms": [6238.895], "images_per_second": 0.16, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. motorcycle: 1\n3. bicycle: 1\n4. wheel: 1\n5. tool: 1\n6. tire: 1\n7. chain: 1\n8. chain link: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14976.3, "ram_available_mb": 47864.6, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 16.5, "ram_used_mb": 15014.8, "ram_available_mb": 47826.1, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.385}, "power_stats": {"power_gpu_soc_mean_watts": 18.969, "power_cpu_cv_mean_watts": 3.103, "power_sys_5v0_mean_watts": 7.907, "gpu_utilization_percent_mean": 80.385}, "timestamp": "2026-01-30T11:01:37.336005"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5539.812, "latencies_ms": [5539.812], "images_per_second": 0.181, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The man is kneeling on the left side of the image, with the motorcycle on the right side. The motorcycle is in the foreground, while the bicycle is in the background. The man is closer to the camera than the bicycle.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 15014.8, "ram_available_mb": 47826.1, "ram_percent": 23.9}, "sys_after": {"cpu_percent": 20.8, "ram_used_mb": 15314.5, "ram_available_mb": 47526.4, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.021}, "power_stats": {"power_gpu_soc_mean_watts": 19.699, "power_cpu_cv_mean_watts": 3.016, "power_sys_5v0_mean_watts": 7.904, "gpu_utilization_percent_mean": 79.021}, "timestamp": "2026-01-30T11:01:44.908309"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3489.571, "latencies_ms": [3489.571], "images_per_second": 0.287, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man is fixing a bicycle wheel on the ground next to a motorcycle.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15313.9, "ram_available_mb": 47527.0, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 17.2, "ram_used_mb": 15329.3, "ram_available_mb": 47511.6, "ram_percent": 24.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.643}, "power_stats": {"power_gpu_soc_mean_watts": 22.297, "power_cpu_cv_mean_watts": 2.016, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 85.643}, "timestamp": "2026-01-30T11:01:50.467540"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5572.668, "latencies_ms": [5572.668], "images_per_second": 0.179, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a man wearing a green shirt and blue pants, kneeling on the ground while working on a bicycle wheel. The lighting is natural, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 15330.3, "ram_available_mb": 47510.6, "ram_percent": 24.4}, "sys_after": {"cpu_percent": 23.4, "ram_used_mb": 15134.5, "ram_available_mb": 47706.4, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.936}, "power_stats": {"power_gpu_soc_mean_watts": 19.052, "power_cpu_cv_mean_watts": 4.499, "power_sys_5v0_mean_watts": 7.901, "gpu_utilization_percent_mean": 80.936}, "timestamp": "2026-01-30T11:01:58.101207"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3461.524, "latencies_ms": [3461.524], "images_per_second": 0.289, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man with long hair is riding a skateboard and jumping in the air.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 15134.5, "ram_available_mb": 47706.4, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 15118.3, "ram_available_mb": 47722.6, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.364, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.929, "gpu_utilization_percent_mean": 82.185}, "timestamp": "2026-01-30T11:02:03.608354"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5810.523, "latencies_ms": [5810.523], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. person: 1\n3. grass: 1\n4. fence: 1\n5. building: 1\n6. tree: 1\n7. sky: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 15118.3, "ram_available_mb": 47722.6, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 15113.7, "ram_available_mb": 47727.2, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.833}, "power_stats": {"power_gpu_soc_mean_watts": 18.908, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 7.882, "gpu_utilization_percent_mean": 71.833}, "timestamp": "2026-01-30T11:02:11.486772"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5838.269, "latencies_ms": [5838.269], "images_per_second": 0.171, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on a ramp. The ramp is located in the middle ground, with the skateboarder's body positioned above it. The background features a fence and trees, providing a natural setting for the skateboarding activity.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15113.7, "ram_available_mb": 47727.2, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 15113.7, "ram_available_mb": 47727.2, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.512}, "power_stats": {"power_gpu_soc_mean_watts": 19.137, "power_cpu_cv_mean_watts": 2.253, "power_sys_5v0_mean_watts": 7.831, "gpu_utilization_percent_mean": 77.512}, "timestamp": "2026-01-30T11:02:19.361881"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3416.292, "latencies_ms": [3416.292], "images_per_second": 0.293, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15113.7, "ram_available_mb": 47727.2, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 13.9, "ram_used_mb": 15072.3, "ram_available_mb": 47768.6, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.304}, "power_stats": {"power_gpu_soc_mean_watts": 22.179, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 79.304}, "timestamp": "2026-01-30T11:02:24.835210"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5868.265, "latencies_ms": [5868.265], "images_per_second": 0.17, "prompt_tokens": 1110, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a concrete ramp, with the skateboarder wearing a black t-shirt and black pants. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 15072.3, "ram_available_mb": 47768.6, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 17.5, "ram_used_mb": 15076.7, "ram_available_mb": 47764.2, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.633}, "power_stats": {"power_gpu_soc_mean_watts": 19.344, "power_cpu_cv_mean_watts": 2.721, "power_sys_5v0_mean_watts": 7.673, "gpu_utilization_percent_mean": 84.633}, "timestamp": "2026-01-30T11:02:32.727795"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4276.922, "latencies_ms": [4276.922], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of five people are posing for a photo on a grassy field at sunset, each holding a frisbee with different colored designs.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 15076.7, "ram_available_mb": 47764.2, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 15078.1, "ram_available_mb": 47762.8, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.829}, "power_stats": {"power_gpu_soc_mean_watts": 20.801, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 7.826, "gpu_utilization_percent_mean": 80.829}, "timestamp": "2026-01-30T11:02:39.030974"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3223.883, "latencies_ms": [3223.883], "images_per_second": 0.31, "prompt_tokens": 1113, "response_tokens_est": 9, "n_tiles": 1, "output_text": " 1. frisbee: 5", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15078.1, "ram_available_mb": 47762.8, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 15077.7, "ram_available_mb": 47763.2, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 91.308}, "power_stats": {"power_gpu_soc_mean_watts": 22.239, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 91.308}, "timestamp": "2026-01-30T11:02:44.296049"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7590.258, "latencies_ms": [7590.258], "images_per_second": 0.132, "prompt_tokens": 1117, "response_tokens_est": 79, "n_tiles": 1, "output_text": " The frisbee is held by the person on the left, the person in the middle is holding a frisbee, and the person on the right is holding a frisbee. The frisbee is in the foreground, and the person on the left is in the foreground. The person in the middle is in the middle, and the person on the right is in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 15077.7, "ram_available_mb": 47763.2, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 15078.1, "ram_available_mb": 47762.8, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.254}, "power_stats": {"power_gpu_soc_mean_watts": 17.054, "power_cpu_cv_mean_watts": 2.04, "power_sys_5v0_mean_watts": 7.63, "gpu_utilization_percent_mean": 71.254}, "timestamp": "2026-01-30T11:02:53.909476"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3898.962, "latencies_ms": [3898.962], "images_per_second": 0.256, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of five people are posing for a picture on a grassy field at sunset.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15078.1, "ram_available_mb": 47762.8, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 15074.2, "ram_available_mb": 47766.7, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.281}, "power_stats": {"power_gpu_soc_mean_watts": 20.56, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 7.533, "gpu_utilization_percent_mean": 88.281}, "timestamp": "2026-01-30T11:02:59.856258"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7142.38, "latencies_ms": [7142.38], "images_per_second": 0.14, "prompt_tokens": 1109, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image features a group of five people posing for a photo on a grassy field at sunset. The sky is painted with hues of orange and blue, and the sun is setting behind the horizon, casting a warm glow over the scene. The people are holding frisbees, which are white with green and red designs, and they are all wearing casual athletic clothing.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15074.2, "ram_available_mb": 47766.7, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 15070.9, "ram_available_mb": 47770.0, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 17.224, "power_cpu_cv_mean_watts": 2.229, "power_sys_5v0_mean_watts": 7.667, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-30T11:03:09.037165"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5103.261, "latencies_ms": [5103.261], "images_per_second": 0.196, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A large white airplane with red and black accents is parked at an airport gate, surrounded by a few vehicles and equipment, with a clear blue sky and a few clouds in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 15070.9, "ram_available_mb": 47770.0, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 15070.6, "ram_available_mb": 47770.3, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.429}, "power_stats": {"power_gpu_soc_mean_watts": 19.647, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 7.641, "gpu_utilization_percent_mean": 83.429}, "timestamp": "2026-01-30T11:03:16.174816"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4429.328, "latencies_ms": [4429.328], "images_per_second": 0.226, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " airplane: 1, clouds: 1, runway: 1, terminal: 1, luggage cart: 1, palm tree: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15070.6, "ram_available_mb": 47770.3, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 15069.4, "ram_available_mb": 47771.5, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.842, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 74.054}, "timestamp": "2026-01-30T11:03:22.642586"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6015.733, "latencies_ms": [6015.733], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The airplane is positioned on the left side of the image, with the terminal building located in the background. The airplane is situated in the foreground, with the terminal building in the background. The airplane is closer to the viewer than the terminal building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15069.4, "ram_available_mb": 47771.5, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 15069.3, "ram_available_mb": 47771.6, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.12}, "power_stats": {"power_gpu_soc_mean_watts": 18.837, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 7.513, "gpu_utilization_percent_mean": 82.12}, "timestamp": "2026-01-30T11:03:30.688323"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6210.545, "latencies_ms": [6210.545], "images_per_second": 0.161, "prompt_tokens": 1111, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a moment at an airport where a large airplane, adorned with a red and white logo, is parked at a gate. The sky above is a clear blue, dotted with fluffy white clouds, and the ground below is marked with yellow arrows and lines, indicating the path for the airplane's movement.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15069.3, "ram_available_mb": 47771.6, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 15068.8, "ram_available_mb": 47772.1, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.385}, "power_stats": {"power_gpu_soc_mean_watts": 18.198, "power_cpu_cv_mean_watts": 2.033, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 73.385}, "timestamp": "2026-01-30T11:03:38.921349"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3927.263, "latencies_ms": [3927.263], "images_per_second": 0.255, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The airplane is white with red and black accents, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15068.8, "ram_available_mb": 47772.1, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 15067.9, "ram_available_mb": 47773.0, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.152}, "power_stats": {"power_gpu_soc_mean_watts": 20.727, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.626, "gpu_utilization_percent_mean": 88.152}, "timestamp": "2026-01-30T11:03:44.891333"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3689.14, "latencies_ms": [3689.14], "images_per_second": 0.271, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is skateboarding on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 15067.9, "ram_available_mb": 47773.0, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 15069.0, "ram_available_mb": 47771.9, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.833}, "power_stats": {"power_gpu_soc_mean_watts": 21.571, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.814, "gpu_utilization_percent_mean": 81.833}, "timestamp": "2026-01-30T11:03:50.618559"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6087.65, "latencies_ms": [6087.65], "images_per_second": 0.164, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. bench: 1\n4. trash can: 1\n5. fence: 1\n6. bench: 1\n7. person: 1\n8. graffiti: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 15069.0, "ram_available_mb": 47771.9, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 15069.0, "ram_available_mb": 47771.9, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.725}, "power_stats": {"power_gpu_soc_mean_watts": 19.417, "power_cpu_cv_mean_watts": 2.065, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 80.725}, "timestamp": "2026-01-30T11:03:58.731566"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5275.178, "latencies_ms": [5275.178], "images_per_second": 0.19, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on a ramp, while the bench is in the background. The skateboarder is closer to the camera than the bench.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15069.0, "ram_available_mb": 47771.9, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 17.0, "ram_used_mb": 15069.4, "ram_available_mb": 47771.5, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.295}, "power_stats": {"power_gpu_soc_mean_watts": 19.393, "power_cpu_cv_mean_watts": 2.375, "power_sys_5v0_mean_watts": 7.699, "gpu_utilization_percent_mean": 82.295}, "timestamp": "2026-01-30T11:04:06.037244"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3505.584, "latencies_ms": [3505.584], "images_per_second": 0.285, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 38.5, "ram_used_mb": 15069.4, "ram_available_mb": 47771.5, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 20.3, "ram_used_mb": 15099.6, "ram_available_mb": 47741.2, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.679}, "power_stats": {"power_gpu_soc_mean_watts": 22.424, "power_cpu_cv_mean_watts": 1.816, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 87.679}, "timestamp": "2026-01-30T11:04:11.554516"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7300.999, "latencies_ms": [7300.999], "images_per_second": 0.137, "prompt_tokens": 1109, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a concrete ramp, with a vibrant green grass field in the background. The lighting is bright and sunny, casting a clear shadow of the skateboarder on the ramp. The skateboarder is wearing a yellow shirt and black pants, and the ramp is covered in graffiti.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 15099.6, "ram_available_mb": 47741.2, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 17.9, "ram_used_mb": 15104.6, "ram_available_mb": 47736.3, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.414, "power_cpu_cv_mean_watts": 3.026, "power_sys_5v0_mean_watts": 7.7, "gpu_utilization_percent_mean": 80.0}, "timestamp": "2026-01-30T11:04:20.882193"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3656.561, "latencies_ms": [3656.561], "images_per_second": 0.273, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A slice of chocolate cake with caramel drizzle sits on a white plate with gold designs.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 15104.6, "ram_available_mb": 47736.3, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 15103.4, "ram_available_mb": 47737.5, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.367}, "power_stats": {"power_gpu_soc_mean_watts": 21.796, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 7.841, "gpu_utilization_percent_mean": 86.367}, "timestamp": "2026-01-30T11:04:26.581555"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6628.575, "latencies_ms": [6628.575], "images_per_second": 0.151, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. plate: 1\n2. cake: 1\n3. syrup: 1\n4. chocolate: 1\n5. chocolate syrup: 1\n6. caramel: 1\n7. caramel sauce: 1\n8. chocolate drizzle: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15103.4, "ram_available_mb": 47737.5, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 15102.0, "ram_available_mb": 47738.9, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.091}, "power_stats": {"power_gpu_soc_mean_watts": 18.653, "power_cpu_cv_mean_watts": 2.075, "power_sys_5v0_mean_watts": 7.602, "gpu_utilization_percent_mean": 81.091}, "timestamp": "2026-01-30T11:04:35.238746"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4660.805, "latencies_ms": [4660.805], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The slice of chocolate cake is positioned in the foreground, with the plate and the caramel sauce in the background. The cake is placed on the plate, which is resting on a wooden surface.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15102.0, "ram_available_mb": 47738.9, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 15101.5, "ram_available_mb": 47739.4, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.769}, "power_stats": {"power_gpu_soc_mean_watts": 20.903, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 7.896, "gpu_utilization_percent_mean": 77.769}, "timestamp": "2026-01-30T11:04:41.915064"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3919.396, "latencies_ms": [3919.396], "images_per_second": 0.255, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A slice of chocolate cake with caramel drizzle is on a white plate with gold designs.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15101.5, "ram_available_mb": 47739.4, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 15102.0, "ram_available_mb": 47738.9, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.375}, "power_stats": {"power_gpu_soc_mean_watts": 20.759, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 7.638, "gpu_utilization_percent_mean": 88.375}, "timestamp": "2026-01-30T11:04:47.860205"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4715.055, "latencies_ms": [4715.055], "images_per_second": 0.212, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The slice of chocolate cake is on a white plate with gold designs, and the plate is on a wooden table. The lighting is bright and natural, and the cake is shiny and moist.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 15102.0, "ram_available_mb": 47738.9, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 13.3, "ram_used_mb": 15097.2, "ram_available_mb": 47743.7, "ram_percent": 24.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.59}, "power_stats": {"power_gpu_soc_mean_watts": 20.082, "power_cpu_cv_mean_watts": 2.033, "power_sys_5v0_mean_watts": 7.89, "gpu_utilization_percent_mean": 76.59}, "timestamp": "2026-01-30T11:04:54.589172"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3904.408, "latencies_ms": [3904.408], "images_per_second": 0.256, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man is sitting at a desk with a laptop and a computer in front of him.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 15097.2, "ram_available_mb": 47743.7, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 24.6, "ram_used_mb": 15265.5, "ram_available_mb": 47575.4, "ram_percent": 24.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.094}, "power_stats": {"power_gpu_soc_mean_watts": 21.432, "power_cpu_cv_mean_watts": 3.328, "power_sys_5v0_mean_watts": 7.942, "gpu_utilization_percent_mean": 89.094}, "timestamp": "2026-01-30T11:05:00.545270"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6684.428, "latencies_ms": [6684.428], "images_per_second": 0.15, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. laptop: 2\n2. chair: 3\n3. person: 2\n4. box: 1\n5. bottle: 1\n6. computer: 2\n7. table: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15265.5, "ram_available_mb": 47575.4, "ram_percent": 24.3}, "sys_after": {"cpu_percent": 21.7, "ram_used_mb": 15295.3, "ram_available_mb": 47545.6, "ram_percent": 24.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.893}, "power_stats": {"power_gpu_soc_mean_watts": 18.742, "power_cpu_cv_mean_watts": 3.69, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 81.893}, "timestamp": "2026-01-30T11:05:09.277921"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4884.7, "latencies_ms": [4884.7], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The man is sitting in the foreground, working on his laptop. The boxes are in the background, and the people are standing around the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15295.3, "ram_available_mb": 47545.6, "ram_percent": 24.3}, "sys_after": {"cpu_percent": 19.5, "ram_used_mb": 15174.7, "ram_available_mb": 47666.2, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.5}, "power_stats": {"power_gpu_soc_mean_watts": 19.934, "power_cpu_cv_mean_watts": 2.453, "power_sys_5v0_mean_watts": 7.812, "gpu_utilization_percent_mean": 86.5}, "timestamp": "2026-01-30T11:05:16.178776"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3868.312, "latencies_ms": [3868.312], "images_per_second": 0.259, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are working in a cluttered office with computers and laptops.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 15174.7, "ram_available_mb": 47666.2, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 19.0, "ram_used_mb": 15178.5, "ram_available_mb": 47662.4, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.062}, "power_stats": {"power_gpu_soc_mean_watts": 21.462, "power_cpu_cv_mean_watts": 2.365, "power_sys_5v0_mean_watts": 7.92, "gpu_utilization_percent_mean": 88.062}, "timestamp": "2026-01-30T11:05:22.073146"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4261.637, "latencies_ms": [4261.637], "images_per_second": 0.235, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is lit with fluorescent lighting, and the walls are painted white. The floor is covered with yellow paint.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15178.5, "ram_available_mb": 47662.4, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 19.7, "ram_used_mb": 15192.6, "ram_available_mb": 47648.3, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.028}, "power_stats": {"power_gpu_soc_mean_watts": 20.992, "power_cpu_cv_mean_watts": 3.27, "power_sys_5v0_mean_watts": 7.915, "gpu_utilization_percent_mean": 88.028}, "timestamp": "2026-01-30T11:05:28.375176"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5055.996, "latencies_ms": [5055.996], "images_per_second": 0.198, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A group of people are playing a video game in a living room, with a woman holding a Wii remote and a man holding a Wii controller.", "error": null, "sys_before": {"cpu_percent": 26.1, "ram_used_mb": 15192.6, "ram_available_mb": 47648.3, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 17.0, "ram_used_mb": 15229.8, "ram_available_mb": 47611.1, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.405}, "power_stats": {"power_gpu_soc_mean_watts": 19.526, "power_cpu_cv_mean_watts": 2.736, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 87.405}, "timestamp": "2026-01-30T11:05:35.481252"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7520.871, "latencies_ms": [7520.871], "images_per_second": 0.133, "prompt_tokens": 1113, "response_tokens_est": 77, "n_tiles": 1, "output_text": " 1. Wii remote: 2\n2. Wii controller: 1\n3. Wii game: 1\n4. Wii console: 1\n5. Wii remote holder: 1\n6. Wii game case: 1\n7. Wii game disc: 1\n8. Wii game disc case: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15229.8, "ram_available_mb": 47611.1, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 15222.9, "ram_available_mb": 47618.0, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.048}, "power_stats": {"power_gpu_soc_mean_watts": 18.606, "power_cpu_cv_mean_watts": 2.218, "power_sys_5v0_mean_watts": 7.696, "gpu_utilization_percent_mean": 80.048}, "timestamp": "2026-01-30T11:05:45.029639"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7952.279, "latencies_ms": [7952.279], "images_per_second": 0.126, "prompt_tokens": 1117, "response_tokens_est": 84, "n_tiles": 1, "output_text": " The woman is standing to the left of the man in the blue shirt, who is standing to the right of the man in the white shirt. The woman is in the foreground, while the man in the blue shirt is in the background. The man in the green shirt is standing in the middle of the room, with the man in the white shirt to his left and the man in the blue shirt to his right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15222.9, "ram_available_mb": 47618.0, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 13.6, "ram_used_mb": 15220.1, "ram_available_mb": 47620.8, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.507}, "power_stats": {"power_gpu_soc_mean_watts": 17.793, "power_cpu_cv_mean_watts": 2.57, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 74.507}, "timestamp": "2026-01-30T11:05:55.029884"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3512.208, "latencies_ms": [3512.208], "images_per_second": 0.285, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A group of people are playing a video game in a living room.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15220.1, "ram_available_mb": 47620.8, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 15221.2, "ram_available_mb": 47619.7, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.586}, "power_stats": {"power_gpu_soc_mean_watts": 21.956, "power_cpu_cv_mean_watts": 1.353, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 89.586}, "timestamp": "2026-01-30T11:06:00.593560"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3956.738, "latencies_ms": [3956.738], "images_per_second": 0.253, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is well lit with natural light coming from the windows, and the carpet is a light gray color.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 15221.2, "ram_available_mb": 47619.7, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 15221.8, "ram_available_mb": 47619.1, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.818}, "power_stats": {"power_gpu_soc_mean_watts": 21.09, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 80.818}, "timestamp": "2026-01-30T11:06:06.591152"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3934.154, "latencies_ms": [3934.154], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person stands on a frozen lake at sunset, with a frisbee in the air above them.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 15221.8, "ram_available_mb": 47619.1, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 15201.1, "ram_available_mb": 47639.8, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.156}, "power_stats": {"power_gpu_soc_mean_watts": 20.858, "power_cpu_cv_mean_watts": 1.451, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 85.156}, "timestamp": "2026-01-30T11:06:12.551755"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6390.132, "latencies_ms": [6390.132], "images_per_second": 0.156, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. sun: 1\n3. sky: 2\n4. water: 1\n5. ice: 1\n6. frisbee: 1\n7. shadow: 1\n8. reflection: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15201.1, "ram_available_mb": 47639.8, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 13.7, "ram_used_mb": 15179.5, "ram_available_mb": 47661.4, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.556}, "power_stats": {"power_gpu_soc_mean_watts": 18.717, "power_cpu_cv_mean_watts": 2.691, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 77.556}, "timestamp": "2026-01-30T11:06:20.977559"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5456.323, "latencies_ms": [5456.323], "images_per_second": 0.183, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The person is standing on the left side of the image, with the sun in the center and the horizon line in the background. The person is in the foreground, with the sun and horizon line in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 15179.5, "ram_available_mb": 47661.4, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 15180.2, "ram_available_mb": 47660.7, "ram_percent": 24.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.71, "power_cpu_cv_mean_watts": 2.064, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 84.244}, "timestamp": "2026-01-30T11:06:28.471434"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4118.997, "latencies_ms": [4118.997], "images_per_second": 0.243, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person stands on a frozen lake at sunset, with a frisbee in the air above them.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 15180.2, "ram_available_mb": 47660.7, "ram_percent": 24.2}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 15156.6, "ram_available_mb": 47684.3, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.765}, "power_stats": {"power_gpu_soc_mean_watts": 20.376, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.621, "gpu_utilization_percent_mean": 85.765}, "timestamp": "2026-01-30T11:06:34.622956"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5339.824, "latencies_ms": [5339.824], "images_per_second": 0.187, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a person standing on a frozen lake at sunset, with the sun casting a warm glow on the ice and the person's shadow. The sky is a gradient of orange and blue, with the sun positioned near the horizon.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 15156.6, "ram_available_mb": 47684.3, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 15172.4, "ram_available_mb": 47668.5, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.356}, "power_stats": {"power_gpu_soc_mean_watts": 19.773, "power_cpu_cv_mean_watts": 1.993, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 76.356}, "timestamp": "2026-01-30T11:06:41.988275"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5257.027, "latencies_ms": [5257.027], "images_per_second": 0.19, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image depicts a well-lit living room with a white sofa, a dining table with chairs, a television on a stand, and a variety of decorative items on the walls and shelves.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 15172.4, "ram_available_mb": 47668.5, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 15133.9, "ram_available_mb": 47707.0, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.953}, "power_stats": {"power_gpu_soc_mean_watts": 19.287, "power_cpu_cv_mean_watts": 1.871, "power_sys_5v0_mean_watts": 7.613, "gpu_utilization_percent_mean": 81.953}, "timestamp": "2026-01-30T11:06:49.286283"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4886.486, "latencies_ms": [4886.486], "images_per_second": 0.205, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " sofa: 1, chair: 2, table: 1, vase: 1, television: 1, rug: 1, wall art: 4", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15133.9, "ram_available_mb": 47707.0, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 11.6, "ram_used_mb": 15136.4, "ram_available_mb": 47704.5, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.275}, "power_stats": {"power_gpu_soc_mean_watts": 20.181, "power_cpu_cv_mean_watts": 2.092, "power_sys_5v0_mean_watts": 7.803, "gpu_utilization_percent_mean": 81.275}, "timestamp": "2026-01-30T11:06:56.201441"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6384.675, "latencies_ms": [6384.675], "images_per_second": 0.157, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The white sofa is positioned to the left of the television, which is situated in the middle of the room. The dining table is located in the foreground, with the red chairs placed around it. The living room extends into the background, with the large window providing natural light.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 15136.4, "ram_available_mb": 47704.5, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 15128.6, "ram_available_mb": 47712.3, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.17}, "power_stats": {"power_gpu_soc_mean_watts": 18.95, "power_cpu_cv_mean_watts": 2.13, "power_sys_5v0_mean_watts": 7.609, "gpu_utilization_percent_mean": 83.17}, "timestamp": "2026-01-30T11:07:04.613923"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3568.947, "latencies_ms": [3568.947], "images_per_second": 0.28, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A living room with a white couch, red chairs, and a dining table with a vase of flowers.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 15128.6, "ram_available_mb": 47712.3, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 15133.0, "ram_available_mb": 47707.9, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.138}, "power_stats": {"power_gpu_soc_mean_watts": 22.839, "power_cpu_cv_mean_watts": 1.753, "power_sys_5v0_mean_watts": 8.14, "gpu_utilization_percent_mean": 81.138}, "timestamp": "2026-01-30T11:07:10.210740"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4561.616, "latencies_ms": [4561.616], "images_per_second": 0.219, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The room is well lit with natural light coming in from the windows. The walls are painted white and the furniture is mostly black and white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15133.0, "ram_available_mb": 47707.9, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 15.9, "ram_used_mb": 15129.4, "ram_available_mb": 47711.5, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.105}, "power_stats": {"power_gpu_soc_mean_watts": 20.274, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.692, "gpu_utilization_percent_mean": 87.105}, "timestamp": "2026-01-30T11:07:16.807578"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3871.842, "latencies_ms": [3871.842], "images_per_second": 0.258, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A cat is standing on top of a blue refrigerator, looking out the window.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 15129.4, "ram_available_mb": 47711.5, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 18.7, "ram_used_mb": 15148.2, "ram_available_mb": 47692.7, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 88.188}, "power_stats": {"power_gpu_soc_mean_watts": 21.249, "power_cpu_cv_mean_watts": 2.652, "power_sys_5v0_mean_watts": 7.863, "gpu_utilization_percent_mean": 88.188}, "timestamp": "2026-01-30T11:07:22.715967"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6735.79, "latencies_ms": [6735.79], "images_per_second": 0.148, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. refrigerator: 1\n3. cabinet: 1\n4. shelf: 1\n5. light: 1\n6. door: 1\n7. wall: 1\n8. ceiling: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 15148.2, "ram_available_mb": 47692.7, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 13.5, "ram_used_mb": 15134.4, "ram_available_mb": 47706.5, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.839}, "power_stats": {"power_gpu_soc_mean_watts": 18.056, "power_cpu_cv_mean_watts": 2.495, "power_sys_5v0_mean_watts": 7.555, "gpu_utilization_percent_mean": 82.839}, "timestamp": "2026-01-30T11:07:31.481284"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5704.994, "latencies_ms": [5704.994], "images_per_second": 0.175, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The cat is positioned on the right side of the refrigerator, which is located in the foreground of the image. The refrigerator is situated in the middle of the image, with the cat's head and body occupying a significant portion of the frame.", "error": null, "sys_before": {"cpu_percent": 40.0, "ram_used_mb": 15134.4, "ram_available_mb": 47706.5, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 12.4, "ram_used_mb": 15136.9, "ram_available_mb": 47704.0, "ram_percent": 24.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.083}, "power_stats": {"power_gpu_soc_mean_watts": 18.939, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 77.083}, "timestamp": "2026-01-30T11:07:39.239119"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3511.317, "latencies_ms": [3511.317], "images_per_second": 0.285, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A cat is standing on top of a refrigerator in a kitchen.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 15136.9, "ram_available_mb": 47704.0, "ram_percent": 24.1}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 14024.3, "ram_available_mb": 48816.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.897}, "power_stats": {"power_gpu_soc_mean_watts": 21.707, "power_cpu_cv_mean_watts": 2.126, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 87.897}, "timestamp": "2026-01-30T11:07:44.785516"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3452.718, "latencies_ms": [3452.718], "images_per_second": 0.29, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The cat is brown and black, the refrigerator is blue, and the room is lit by a fluorescent light.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14024.3, "ram_available_mb": 48816.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14024.9, "ram_available_mb": 48816.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.01, "power_cpu_cv_mean_watts": 1.244, "power_sys_5v0_mean_watts": 8.151, "gpu_utilization_percent_mean": 75.5}, "timestamp": "2026-01-30T11:07:50.253099"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4485.73, "latencies_ms": [4485.73], "images_per_second": 0.223, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image depicts a room with a wooden floor, a white ceiling, and a yellow wall, adorned with various decorations such as balloons, a smiley face balloon, and a chandelier.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 14024.9, "ram_available_mb": 48816.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14036.1, "ram_available_mb": 48804.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.282, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 71.676}, "timestamp": "2026-01-30T11:07:56.770995"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6006.318, "latencies_ms": [6006.318], "images_per_second": 0.166, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Balloons: 4\n2. Balloons: 2\n3. Balloons: 1\n4. Balloons: 1\n5. Balloons: 1\n6. Balloons: 1\n7. Balloons: 1\n8. Balloons: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14036.1, "ram_available_mb": 48804.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14035.3, "ram_available_mb": 48805.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.42}, "power_stats": {"power_gpu_soc_mean_watts": 17.844, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 68.42}, "timestamp": "2026-01-30T11:08:04.799392"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7370.39, "latencies_ms": [7370.39], "images_per_second": 0.136, "prompt_tokens": 1117, "response_tokens_est": 86, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the foreground is dominated by the wooden table and the balloons, while the background features the refrigerator, the wall, and the bookshelf. The balloons are positioned in the foreground, with the refrigerator and the wall in the background. The wooden table is located in the middle of the room, with the balloons and the refrigerator on the left side, and the bookshelf on the right side.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14035.3, "ram_available_mb": 48805.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14034.6, "ram_available_mb": 48806.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.873}, "power_stats": {"power_gpu_soc_mean_watts": 16.457, "power_cpu_cv_mean_watts": 1.83, "power_sys_5v0_mean_watts": 7.838, "gpu_utilization_percent_mean": 67.873}, "timestamp": "2026-01-30T11:08:14.192207"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3069.412, "latencies_ms": [3069.412], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A room with balloons and a smiley face balloon is decorated for a party.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14034.6, "ram_available_mb": 48806.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14034.9, "ram_available_mb": 48806.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.2}, "power_stats": {"power_gpu_soc_mean_watts": 23.514, "power_cpu_cv_mean_watts": 1.041, "power_sys_5v0_mean_watts": 8.192, "gpu_utilization_percent_mean": 79.2}, "timestamp": "2026-01-30T11:08:19.276981"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2884.953, "latencies_ms": [2884.953], "images_per_second": 0.347, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The room is lit by a chandelier and has wooden floors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14034.9, "ram_available_mb": 48806.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14034.6, "ram_available_mb": 48806.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.125}, "power_stats": {"power_gpu_soc_mean_watts": 24.192, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 78.125}, "timestamp": "2026-01-30T11:08:24.201550"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3610.794, "latencies_ms": [3610.794], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man wearing headphones is sitting at a table with a laptop in front of him, and there is a window in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14034.6, "ram_available_mb": 48806.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14034.6, "ram_available_mb": 48806.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.3}, "power_stats": {"power_gpu_soc_mean_watts": 22.329, "power_cpu_cv_mean_watts": 1.241, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 74.3}, "timestamp": "2026-01-30T11:08:29.864060"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5610.361, "latencies_ms": [5610.361], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. laptop: 1\n3. chair: 1\n4. window: 1\n5. train: 1\n6. train tracks: 1\n7. headset: 1\n8. table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14034.6, "ram_available_mb": 48806.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14034.5, "ram_available_mb": 48806.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.851}, "power_stats": {"power_gpu_soc_mean_watts": 18.309, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.931, "gpu_utilization_percent_mean": 69.851}, "timestamp": "2026-01-30T11:08:37.497425"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4460.755, "latencies_ms": [4460.755], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, with the laptop in front of him. The laptop is on the right side of the image, and the window is in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14034.5, "ram_available_mb": 48806.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14034.6, "ram_available_mb": 48806.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.419, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 68.0}, "timestamp": "2026-01-30T11:08:43.972774"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3051.06, "latencies_ms": [3051.06], "images_per_second": 0.328, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing headphones is sitting at a table in a train, using a laptop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14034.6, "ram_available_mb": 48806.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14015.1, "ram_available_mb": 48825.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.68}, "power_stats": {"power_gpu_soc_mean_watts": 23.783, "power_cpu_cv_mean_watts": 1.073, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 75.68}, "timestamp": "2026-01-30T11:08:49.075754"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3518.111, "latencies_ms": [3518.111], "images_per_second": 0.284, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The man is wearing a green shirt and has red hair. The laptop is silver and has an Apple logo on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14015.1, "ram_available_mb": 48825.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14014.8, "ram_available_mb": 48826.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.354, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.143, "gpu_utilization_percent_mean": 71.379}, "timestamp": "2026-01-30T11:08:54.624644"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6183.022, "latencies_ms": [6183.022], "images_per_second": 0.162, "prompt_tokens": 1099, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image captures a striking white cable-stayed bridge with a unique, pointed design, spanning across a bustling train station with multiple tracks and platforms. The sky above is a clear blue, dotted with fluffy white clouds, and the cityscape in the background is a mix of buildings and trees, adding depth and context to the scene.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 14014.8, "ram_available_mb": 48826.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14015.3, "ram_available_mb": 48825.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.808}, "power_stats": {"power_gpu_soc_mean_watts": 17.548, "power_cpu_cv_mean_watts": 1.701, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 68.808}, "timestamp": "2026-01-30T11:09:02.840400"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5658.551, "latencies_ms": [5658.551], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. train tracks: 4\n3. train: 1\n4. train station: 1\n5. platform: 1\n6. platform sign: 1\n7. fence: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14015.3, "ram_available_mb": 48825.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14015.0, "ram_available_mb": 48825.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.211, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 7.952, "gpu_utilization_percent_mean": 68.021}, "timestamp": "2026-01-30T11:09:10.518059"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4894.113, "latencies_ms": [4894.113], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The train station is located in the foreground, with the bridge stretching across the image, and the city skyline is visible in the background. The train tracks are parallel to each other, and the bridge is positioned above them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14015.0, "ram_available_mb": 48825.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14015.0, "ram_available_mb": 48825.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.146}, "power_stats": {"power_gpu_soc_mean_watts": 19.131, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 69.146}, "timestamp": "2026-01-30T11:09:17.462154"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4293.843, "latencies_ms": [4293.843], "images_per_second": 0.233, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image captures a modern white bridge with a unique triangular design, spanning over a bustling train station. The station is filled with multiple tracks and platforms, indicating a busy transportation hub.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14015.0, "ram_available_mb": 48825.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14014.9, "ram_available_mb": 48826.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.917}, "power_stats": {"power_gpu_soc_mean_watts": 20.29, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 72.917}, "timestamp": "2026-01-30T11:09:23.800150"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5037.07, "latencies_ms": [5037.07], "images_per_second": 0.199, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a white bridge with a unique triangular design, set against a backdrop of a clear blue sky with scattered clouds. The bridge is situated over a train station with multiple tracks and platforms, and the train tracks are visible beneath the bridge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14014.9, "ram_available_mb": 48826.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 14002.2, "ram_available_mb": 48838.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.071}, "power_stats": {"power_gpu_soc_mean_watts": 19.248, "power_cpu_cv_mean_watts": 2.021, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 69.071}, "timestamp": "2026-01-30T11:09:30.852386"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3524.462, "latencies_ms": [3524.462], "images_per_second": 0.284, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of people are flying a large kite with a purple and yellow design on a sunny day in a park.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14002.2, "ram_available_mb": 48838.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14003.3, "ram_available_mb": 48837.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.369, "power_cpu_cv_mean_watts": 1.215, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 74.552}, "timestamp": "2026-01-30T11:09:36.424840"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4159.624, "latencies_ms": [4159.624], "images_per_second": 0.24, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " kite: 1, person: 2, ball: 1, chair: 1, backpack: 1, person: 1, tree: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14003.3, "ram_available_mb": 48837.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.229}, "power_stats": {"power_gpu_soc_mean_watts": 20.674, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 71.229}, "timestamp": "2026-01-30T11:09:42.628390"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4980.938, "latencies_ms": [4980.938], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the people are in the background, walking around the park. The kite is positioned to the left of the people, and the park is spread out in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.19}, "power_stats": {"power_gpu_soc_mean_watts": 19.038, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 71.19}, "timestamp": "2026-01-30T11:09:49.623678"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2848.769, "latencies_ms": [2848.769], "images_per_second": 0.351, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A group of people are flying a large kite in a park.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.087}, "power_stats": {"power_gpu_soc_mean_watts": 24.441, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 78.087}, "timestamp": "2026-01-30T11:09:54.490666"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4803.283, "latencies_ms": [4803.283], "images_per_second": 0.208, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The kite is a vibrant mix of blue, purple, and yellow, with a long tail that trails behind it. The sky is clear and blue, and the sun is shining brightly, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.575}, "power_stats": {"power_gpu_soc_mean_watts": 19.651, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 71.575}, "timestamp": "2026-01-30T11:10:01.336420"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4851.776, "latencies_ms": [4851.776], "images_per_second": 0.206, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a miniature model of a train station with a red and black train, a red and white train, and a red and black train on the tracks, with workers in orange uniforms and white helmets walking along the tracks.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.339, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T11:10:08.249278"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4153.667, "latencies_ms": [4153.667], "images_per_second": 0.241, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " train: 1, workers: 4, tracks: 3, wires: 2, fence: 1, grass: 1, hills: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.964, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T11:10:14.416910"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4804.023, "latencies_ms": [4804.023], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The train is positioned on the right side of the image, with the workers on the left. The train is in the foreground, while the workers are in the background. The train is closer to the viewer than the workers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.6}, "power_stats": {"power_gpu_soc_mean_watts": 19.601, "power_cpu_cv_mean_watts": 1.541, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 67.6}, "timestamp": "2026-01-30T11:10:21.259709"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4317.06, "latencies_ms": [4317.06], "images_per_second": 0.232, "prompt_tokens": 1111, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A model train is traveling on a track, passing by a group of people who are working on the track. The train is red and black, and the people are wearing orange uniforms.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.417}, "power_stats": {"power_gpu_soc_mean_watts": 20.611, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 71.417}, "timestamp": "2026-01-30T11:10:27.629648"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3613.068, "latencies_ms": [3613.068], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The train is red and black, and the workers are wearing orange. The lighting is natural, and the weather is clear.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.233}, "power_stats": {"power_gpu_soc_mean_watts": 22.146, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.117, "gpu_utilization_percent_mean": 70.233}, "timestamp": "2026-01-30T11:10:33.291548"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4363.799, "latencies_ms": [4363.799], "images_per_second": 0.229, "prompt_tokens": 1100, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image shows a close-up view of a cat's fur, which is a mix of brown and white colors, and the cat is lying on a textured, light-colored blanket.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.413, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 71.444}, "timestamp": "2026-01-30T11:10:39.704166"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5450.899, "latencies_ms": [5450.899], "images_per_second": 0.183, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. fur: 1\n3. blanket: 1\n4. fabric: 1\n5. pattern: 1\n6. texture: 1\n7. surface: 1\n8. background: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.4}, "power_stats": {"power_gpu_soc_mean_watts": 18.741, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 68.4}, "timestamp": "2026-01-30T11:10:47.177711"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4535.417, "latencies_ms": [4535.417], "images_per_second": 0.22, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The cat's fur is in the foreground, while the patterned fabric is in the background. The cat's fur is on the left side of the image, and the fabric is on the right side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.622}, "power_stats": {"power_gpu_soc_mean_watts": 20.193, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 67.622}, "timestamp": "2026-01-30T11:10:53.731238"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2897.447, "latencies_ms": [2897.447], "images_per_second": 0.345, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cat is laying on a bed with a brown and white fur coat.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.16, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 76.25}, "timestamp": "2026-01-30T11:10:58.672136"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5050.783, "latencies_ms": [5050.783], "images_per_second": 0.198, "prompt_tokens": 1110, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a close-up of a cat's fur, which is a mix of brown and white colors. The lighting appears to be natural, coming from the left side of the image, and the cat's fur is soft and fluffy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.381}, "power_stats": {"power_gpu_soc_mean_watts": 19.125, "power_cpu_cv_mean_watts": 1.554, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 69.381}, "timestamp": "2026-01-30T11:11:05.756929"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4409.044, "latencies_ms": [4409.044], "images_per_second": 0.227, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a close-up view of a cow's udder, which is attached to a black and yellow object, possibly a milking machine, with red caps on the tubes.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13999.7, "ram_available_mb": 48841.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.108}, "power_stats": {"power_gpu_soc_mean_watts": 20.236, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.108}, "timestamp": "2026-01-30T11:11:12.220601"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4845.601, "latencies_ms": [4845.601], "images_per_second": 0.206, "prompt_tokens": 1113, "response_tokens_est": 45, "n_tiles": 1, "output_text": " cow: 1, black: 1, white: 1, red: 1, black and white: 1, black carbon fiber: 1, yellow sticker: 1, metal pipe: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13999.7, "ram_available_mb": 48841.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13999.9, "ram_available_mb": 48841.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.15}, "power_stats": {"power_gpu_soc_mean_watts": 19.484, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 7.984, "gpu_utilization_percent_mean": 70.15}, "timestamp": "2026-01-30T11:11:19.079051"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5211.023, "latencies_ms": [5211.023], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The cow's udder is positioned in the foreground, with the black and white cow's legs and the black object in the background. The cow's udder is near the black object, and the cow's legs are near the black object.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13999.9, "ram_available_mb": 48841.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13999.9, "ram_available_mb": 48841.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.837}, "power_stats": {"power_gpu_soc_mean_watts": 18.847, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 7.963, "gpu_utilization_percent_mean": 66.837}, "timestamp": "2026-01-30T11:11:26.304331"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3401.961, "latencies_ms": [3401.961], "images_per_second": 0.294, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A cow is milking itself in a barn, with a black and white cow standing next to it.", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 13999.9, "ram_available_mb": 48841.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.786}, "power_stats": {"power_gpu_soc_mean_watts": 22.565, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.135, "gpu_utilization_percent_mean": 75.786}, "timestamp": "2026-01-30T11:11:31.729244"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5032.815, "latencies_ms": [5032.815], "images_per_second": 0.199, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a black and white cow with red and white tubes attached to its udder, standing on a dirty floor. The lighting is dim, and the cow is positioned in a stall with a black and yellow label on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14006.6, "ram_available_mb": 48834.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.119}, "power_stats": {"power_gpu_soc_mean_watts": 19.192, "power_cpu_cv_mean_watts": 1.554, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 71.119}, "timestamp": "2026-01-30T11:11:38.818494"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3268.945, "latencies_ms": [3268.945], "images_per_second": 0.306, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A sandwich with a bite taken out of it is on a plate with a knife beside it.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14006.6, "ram_available_mb": 48834.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14038.5, "ram_available_mb": 48802.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.115}, "power_stats": {"power_gpu_soc_mean_watts": 23.01, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.171, "gpu_utilization_percent_mean": 72.115}, "timestamp": "2026-01-30T11:11:44.126080"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3549.957, "latencies_ms": [3549.957], "images_per_second": 0.282, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " plate: 1, knife: 1, sandwich: 1, bread: 2, butter: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14038.5, "ram_available_mb": 48802.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14049.5, "ram_available_mb": 48791.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.69}, "power_stats": {"power_gpu_soc_mean_watts": 22.163, "power_cpu_cv_mean_watts": 1.712, "power_sys_5v0_mean_watts": 8.253, "gpu_utilization_percent_mean": 71.69}, "timestamp": "2026-01-30T11:11:49.699097"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4887.972, "latencies_ms": [4887.972], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The sandwich is located in the foreground of the image, with the knife placed to the right of it. The plate is situated in the middle ground, with the sandwich and knife appearing to be in close proximity to each other.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14049.3, "ram_available_mb": 48791.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 11.8, "ram_used_mb": 14063.1, "ram_available_mb": 48777.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.073}, "power_stats": {"power_gpu_soc_mean_watts": 19.17, "power_cpu_cv_mean_watts": 2.266, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 69.073}, "timestamp": "2026-01-30T11:11:56.645895"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2897.309, "latencies_ms": [2897.309], "images_per_second": 0.345, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate with a sandwich and a knife on a green tablecloth.", "error": null, "sys_before": {"cpu_percent": 7.5, "ram_used_mb": 14063.2, "ram_available_mb": 48777.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 14011.9, "ram_available_mb": 48829.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.208}, "power_stats": {"power_gpu_soc_mean_watts": 24.19, "power_cpu_cv_mean_watts": 3.12, "power_sys_5v0_mean_watts": 8.415, "gpu_utilization_percent_mean": 75.208}, "timestamp": "2026-01-30T11:12:01.612423"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3917.453, "latencies_ms": [3917.453], "images_per_second": 0.255, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The sandwich is on a plate with a knife and the plate is on a green tablecloth. The lighting is dim and the sandwich is in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14011.9, "ram_available_mb": 48829.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14012.0, "ram_available_mb": 48828.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.219}, "power_stats": {"power_gpu_soc_mean_watts": 21.574, "power_cpu_cv_mean_watts": 1.339, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 73.219}, "timestamp": "2026-01-30T11:12:07.568303"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4575.859, "latencies_ms": [4575.859], "images_per_second": 0.219, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image shows a colorful and well-organized meal in a purple divided container, featuring a variety of food items such as a salad, pasta with cheese, and grapes, all neatly arranged in separate compartments.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14012.0, "ram_available_mb": 48828.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14011.6, "ram_available_mb": 48829.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.763}, "power_stats": {"power_gpu_soc_mean_watts": 19.895, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 68.763}, "timestamp": "2026-01-30T11:12:14.189922"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4317.58, "latencies_ms": [4317.58], "images_per_second": 0.232, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " 1. purple tray\n2. orange container\n3. green container\n4. red container\n5. blue container\n6. carrots\n7. grapes\n8. salad", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14011.6, "ram_available_mb": 48829.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14012.4, "ram_available_mb": 48828.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.722}, "power_stats": {"power_gpu_soc_mean_watts": 20.501, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 71.722}, "timestamp": "2026-01-30T11:12:20.527848"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6989.529, "latencies_ms": [6989.529], "images_per_second": 0.143, "prompt_tokens": 1117, "response_tokens_est": 81, "n_tiles": 1, "output_text": " The main objects are arranged in a square pattern with the carrots in the top right corner, the salad in the top left corner, the pasta in the bottom left corner, and the grapes in the bottom right corner. The carrots are positioned in the top right corner, the salad is in the top left corner, the pasta is in the bottom left corner, and the grapes are in the bottom right corner.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14012.4, "ram_available_mb": 48828.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14020.7, "ram_available_mb": 48820.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.729}, "power_stats": {"power_gpu_soc_mean_watts": 17.023, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.221, "gpu_utilization_percent_mean": 68.729}, "timestamp": "2026-01-30T11:12:29.554112"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3698.895, "latencies_ms": [3698.895], "images_per_second": 0.27, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A colorful meal is served in a purple divided container, with a variety of food items including pasta, vegetables, and fruit.", "error": null, "sys_before": {"cpu_percent": 1.5, "ram_used_mb": 14021.0, "ram_available_mb": 48819.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14021.2, "ram_available_mb": 48819.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.12, "power_cpu_cv_mean_watts": 1.134, "power_sys_5v0_mean_watts": 8.295, "gpu_utilization_percent_mean": 71.667}, "timestamp": "2026-01-30T11:12:38.224027"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6408.317, "latencies_ms": [6408.317], "images_per_second": 0.156, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image features a vibrant and colorful meal in a purple divided container, with a variety of food items including pasta, vegetables, and fruits. The lighting is bright and even, illuminating the food items and creating a visually appealing presentation. The container is made of plastic, and the food is fresh and healthy, suggesting a well-balanced and nutritious meal.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14021.2, "ram_available_mb": 48819.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14022.1, "ram_available_mb": 48818.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.679}, "power_stats": {"power_gpu_soc_mean_watts": 17.325, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 7.914, "gpu_utilization_percent_mean": 67.679}, "timestamp": "2026-01-30T11:12:46.656967"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2854.769, "latencies_ms": [2854.769], "images_per_second": 0.35, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A traffic light hangs above a street with cherry blossoms in full bloom.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 14022.1, "ram_available_mb": 48818.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14021.5, "ram_available_mb": 48819.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.304}, "power_stats": {"power_gpu_soc_mean_watts": 24.602, "power_cpu_cv_mean_watts": 0.923, "power_sys_5v0_mean_watts": 8.299, "gpu_utilization_percent_mean": 79.304}, "timestamp": "2026-01-30T11:12:51.563920"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2547.0, "latencies_ms": [2547.0], "images_per_second": 0.393, "prompt_tokens": 1114, "response_tokens_est": 8, "n_tiles": 1, "output_text": " 1. traffic light: 3", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14021.5, "ram_available_mb": 48819.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.9, "ram_used_mb": 14020.9, "ram_available_mb": 48820.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.381}, "power_stats": {"power_gpu_soc_mean_watts": 24.827, "power_cpu_cv_mean_watts": 0.724, "power_sys_5v0_mean_watts": 8.263, "gpu_utilization_percent_mean": 84.381}, "timestamp": "2026-01-30T11:12:56.125475"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4774.828, "latencies_ms": [4774.828], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The traffic light is positioned to the left of the cherry blossoms, and the traffic light is in the foreground of the image. The cherry blossoms are in the background of the image, and they are positioned behind the traffic light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14020.9, "ram_available_mb": 48820.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14019.3, "ram_available_mb": 48821.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.675}, "power_stats": {"power_gpu_soc_mean_watts": 19.802, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 69.675}, "timestamp": "2026-01-30T11:13:02.917145"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5445.108, "latencies_ms": [5445.108], "images_per_second": 0.184, "prompt_tokens": 1112, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image captures a serene scene of a cherry blossom tree in full bloom, with its branches adorned with delicate pink and white flowers. The tree is situated in a park, and a traffic light is visible in the background, adding a touch of urbanity to the otherwise natural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14019.3, "ram_available_mb": 48821.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14019.3, "ram_available_mb": 48821.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.674}, "power_stats": {"power_gpu_soc_mean_watts": 18.44, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 68.674}, "timestamp": "2026-01-30T11:13:10.384623"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4123.27, "latencies_ms": [4123.27], "images_per_second": 0.243, "prompt_tokens": 1110, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image features a cherry blossom tree with pink flowers and a traffic light with red and green lights. The sky is clear and blue, and the light is bright.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14019.3, "ram_available_mb": 48821.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14019.0, "ram_available_mb": 48821.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.912}, "power_stats": {"power_gpu_soc_mean_watts": 20.895, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 71.912}, "timestamp": "2026-01-30T11:13:16.521783"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3675.46, "latencies_ms": [3675.46], "images_per_second": 0.272, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a plate with a serving of broccoli and a piece of salmon, with the broccoli being the main focus of the dish.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14019.0, "ram_available_mb": 48821.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14019.6, "ram_available_mb": 48821.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.032}, "power_stats": {"power_gpu_soc_mean_watts": 21.911, "power_cpu_cv_mean_watts": 1.292, "power_sys_5v0_mean_watts": 8.118, "gpu_utilization_percent_mean": 73.032}, "timestamp": "2026-01-30T11:13:22.242591"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6542.269, "latencies_ms": [6542.269], "images_per_second": 0.153, "prompt_tokens": 1113, "response_tokens_est": 72, "n_tiles": 1, "output_text": " 1. Broccoli florets: 12\n2. Salmon: 1\n3. Plate: 1\n4. Sauce: 1\n5. Dried herbs: 1\n6. Chopped garlic: 1\n7. Chopped red pepper: 1\n8. Broth: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14019.6, "ram_available_mb": 48821.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14018.6, "ram_available_mb": 48822.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.2}, "power_stats": {"power_gpu_soc_mean_watts": 17.17, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 7.875, "gpu_utilization_percent_mean": 67.2}, "timestamp": "2026-01-30T11:13:30.799399"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4213.562, "latencies_ms": [4213.562], "images_per_second": 0.237, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The broccoli is in the foreground, while the salmon is in the background. The broccoli is on the left side of the plate, and the salmon is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14018.6, "ram_available_mb": 48822.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14017.9, "ram_available_mb": 48823.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.441}, "power_stats": {"power_gpu_soc_mean_watts": 21.024, "power_cpu_cv_mean_watts": 1.378, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 69.441}, "timestamp": "2026-01-30T11:13:37.045138"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4655.462, "latencies_ms": [4655.462], "images_per_second": 0.215, "prompt_tokens": 1111, "response_tokens_est": 42, "n_tiles": 1, "output_text": " In the image, there is a plate of food that includes a piece of salmon and broccoli. The salmon is cooked and has a golden-brown color, while the broccoli is green and appears to be steamed.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14017.9, "ram_available_mb": 48823.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14017.1, "ram_available_mb": 48823.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.974}, "power_stats": {"power_gpu_soc_mean_watts": 19.653, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 67.974}, "timestamp": "2026-01-30T11:13:43.737570"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6350.674, "latencies_ms": [6350.674], "images_per_second": 0.157, "prompt_tokens": 1109, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a plate of food with a vibrant green broccoli dish and a piece of grilled salmon. The broccoli is cooked to a tender consistency, and the salmon is seasoned with a light glaze. The plate is white, and the food is placed on a white tablecloth. The lighting is bright and even, highlighting the colors of the food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14017.1, "ram_available_mb": 48823.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 14025.9, "ram_available_mb": 48814.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.057}, "power_stats": {"power_gpu_soc_mean_watts": 17.355, "power_cpu_cv_mean_watts": 2.259, "power_sys_5v0_mean_watts": 7.968, "gpu_utilization_percent_mean": 67.057}, "timestamp": "2026-01-30T11:13:52.105742"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3380.69, "latencies_ms": [3380.69], "images_per_second": 0.296, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man and two women are sitting at a table in a restaurant, with a man wearing a gray shirt.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14027.4, "ram_available_mb": 48813.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 14170.4, "ram_available_mb": 48670.4, "ram_percent": 22.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.81, "power_cpu_cv_mean_watts": 3.075, "power_sys_5v0_mean_watts": 8.295, "gpu_utilization_percent_mean": 74.714}, "timestamp": "2026-01-30T11:13:57.548035"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5476.484, "latencies_ms": [5476.484], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 3\n2. chair: 1\n3. table: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14170.4, "ram_available_mb": 48670.4, "ram_percent": 22.5}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14011.4, "ram_available_mb": 48829.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.174}, "power_stats": {"power_gpu_soc_mean_watts": 18.497, "power_cpu_cv_mean_watts": 1.767, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 68.174}, "timestamp": "2026-01-30T11:14:05.066741"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5693.473, "latencies_ms": [5693.473], "images_per_second": 0.176, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The person on the left is sitting next to the person in the middle, who is sitting next to the person on the right. The person on the left is closer to the camera than the person in the middle. The person on the right is sitting in front of the person in the middle.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14011.4, "ram_available_mb": 48829.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14011.0, "ram_available_mb": 48829.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.745}, "power_stats": {"power_gpu_soc_mean_watts": 18.25, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 67.745}, "timestamp": "2026-01-30T11:14:12.770504"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2844.626, "latencies_ms": [2844.626], "images_per_second": 0.352, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14010.4, "ram_available_mb": 48830.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14010.3, "ram_available_mb": 48830.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.3, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.247, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T11:14:17.655769"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4262.564, "latencies_ms": [4262.564], "images_per_second": 0.235, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken in a dimly lit restaurant with warm lighting. The colors in the image are mostly warm tones, with the brown of the wood and the red of the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14010.3, "ram_available_mb": 48830.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14010.8, "ram_available_mb": 48830.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.857}, "power_stats": {"power_gpu_soc_mean_watts": 20.968, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.104, "gpu_utilization_percent_mean": 70.857}, "timestamp": "2026-01-30T11:14:23.958784"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4659.455, "latencies_ms": [4659.455], "images_per_second": 0.215, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image captures a bustling city street with a yellow bus parked on the side of the road, a white van and a white bus in the background, and a large building with a modern design in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14010.8, "ram_available_mb": 48830.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14010.5, "ram_available_mb": 48830.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.462}, "power_stats": {"power_gpu_soc_mean_watts": 19.711, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 69.462}, "timestamp": "2026-01-30T11:14:30.669231"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5867.11, "latencies_ms": [5867.11], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Bus: 2\n2. Street: 1\n3. Building: 1\n4. Trees: 3\n5. Benches: 1\n6. Streetlamp: 1\n7. Sidewalk: 1\n8. Bike: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14010.5, "ram_available_mb": 48830.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14010.5, "ram_available_mb": 48830.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.469}, "power_stats": {"power_gpu_soc_mean_watts": 18.042, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 68.469}, "timestamp": "2026-01-30T11:14:38.554678"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4416.856, "latencies_ms": [4416.856], "images_per_second": 0.226, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The yellow bus is parked on the side of the road, while the white bus is driving down the road. The building is located in the background, and the trees are in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14010.5, "ram_available_mb": 48830.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14010.5, "ram_available_mb": 48830.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.412, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 68.333}, "timestamp": "2026-01-30T11:14:44.991939"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5628.061, "latencies_ms": [5628.061], "images_per_second": 0.178, "prompt_tokens": 1111, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image captures a bustling city street with a large building in the background. A yellow bus is driving down the road, while a white bus is parked on the side of the street. The scene is set in a modern city, with trees lining the sidewalk and a clear blue sky overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14010.5, "ram_available_mb": 48830.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14010.5, "ram_available_mb": 48830.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.234}, "power_stats": {"power_gpu_soc_mean_watts": 18.259, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 67.234}, "timestamp": "2026-01-30T11:14:52.645782"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4240.464, "latencies_ms": [4240.464], "images_per_second": 0.236, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a vibrant yellow bus parked on the side of the road, with a white building in the background. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14010.5, "ram_available_mb": 48830.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14010.9, "ram_available_mb": 48830.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.371}, "power_stats": {"power_gpu_soc_mean_watts": 20.616, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 73.371}, "timestamp": "2026-01-30T11:14:58.918857"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4317.132, "latencies_ms": [4317.132], "images_per_second": 0.232, "prompt_tokens": 1100, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image captures a stop sign with a sun flare effect, set against a backdrop of a cityscape with buildings and parked cars, all bathed in the warm glow of the sun.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14010.9, "ram_available_mb": 48830.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14011.4, "ram_available_mb": 48829.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.486, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T11:15:05.277644"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5808.69, "latencies_ms": [5808.69], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. stop sign: 1\n2. pole: 1\n3. railing: 1\n4. building: 1\n5. car: 1\n6. street: 1\n7. sidewalk: 1\n8. grass: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14011.4, "ram_available_mb": 48829.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14012.3, "ram_available_mb": 48828.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.229}, "power_stats": {"power_gpu_soc_mean_watts": 17.842, "power_cpu_cv_mean_watts": 1.676, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 69.229}, "timestamp": "2026-01-30T11:15:13.098734"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5243.219, "latencies_ms": [5243.219], "images_per_second": 0.191, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The stop sign is positioned to the left of the pole, with the pole being in the foreground and the background featuring a parking lot and buildings. The stop sign is also near the pole, while the parking lot and buildings are far away from the camera.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14012.3, "ram_available_mb": 48828.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14011.5, "ram_available_mb": 48829.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.886}, "power_stats": {"power_gpu_soc_mean_watts": 18.71, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 69.886}, "timestamp": "2026-01-30T11:15:20.383806"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6382.362, "latencies_ms": [6382.362], "images_per_second": 0.157, "prompt_tokens": 1112, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a serene urban scene during sunset, where a stop sign stands prominently in the foreground, casting a warm glow on the surroundings. In the background, a parking lot is visible, with a few cars parked neatly, and a building with a sign that reads \"\u041c\u0410\u0420\u041a\u0415\u0422\" can be seen.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14011.5, "ram_available_mb": 48829.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14012.2, "ram_available_mb": 48828.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.245}, "power_stats": {"power_gpu_soc_mean_watts": 17.4, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.889, "gpu_utilization_percent_mean": 68.245}, "timestamp": "2026-01-30T11:15:28.790402"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5550.753, "latencies_ms": [5550.753], "images_per_second": 0.18, "prompt_tokens": 1110, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a red stop sign with a white \"STOP\" written on it, standing on a metal pole. The sun is shining brightly, casting a warm glow on the scene. The background includes a parking lot with cars and buildings, and the ground is covered with gravel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14012.2, "ram_available_mb": 48828.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14012.0, "ram_available_mb": 48828.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.826}, "power_stats": {"power_gpu_soc_mean_watts": 18.332, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.931, "gpu_utilization_percent_mean": 71.826}, "timestamp": "2026-01-30T11:15:36.366366"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3335.378, "latencies_ms": [3335.378], "images_per_second": 0.3, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A cat with a white and brown coat is lying on a black surface next to a white computer mouse.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14012.0, "ram_available_mb": 48828.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14011.7, "ram_available_mb": 48829.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.556}, "power_stats": {"power_gpu_soc_mean_watts": 23.12, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 72.556}, "timestamp": "2026-01-30T11:15:41.747770"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4259.285, "latencies_ms": [4259.285], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " cat: 1, mouse: 1, cord: 1, black: 1, white: 1, brown: 1, black and white: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14011.7, "ram_available_mb": 48829.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.88, "power_cpu_cv_mean_watts": 2.323, "power_sys_5v0_mean_watts": 8.315, "gpu_utilization_percent_mean": 69.286}, "timestamp": "2026-01-30T11:15:48.022436"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4629.368, "latencies_ms": [4629.368], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The cat is in the foreground, lying on a black surface. The mouse is in the foreground, to the left of the cat. The cord is in the foreground, to the right of the cat.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.132}, "power_stats": {"power_gpu_soc_mean_watts": 19.851, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 70.132}, "timestamp": "2026-01-30T11:15:54.671976"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3023.805, "latencies_ms": [3023.805], "images_per_second": 0.331, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cat is lying on a bed with a computer mouse next to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13995.6, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.72}, "power_stats": {"power_gpu_soc_mean_watts": 23.334, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 76.72}, "timestamp": "2026-01-30T11:15:59.738693"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2981.23, "latencies_ms": [2981.23], "images_per_second": 0.335, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The cat is white and brown with green eyes, and the mouse is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.167}, "power_stats": {"power_gpu_soc_mean_watts": 24.255, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 77.167}, "timestamp": "2026-01-30T11:16:04.742119"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3821.154, "latencies_ms": [3821.154], "images_per_second": 0.262, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image captures a bustling cityscape with a large parking lot filled with buses, a prominent white building, and a clear blue sky dotted with clouds.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.969}, "power_stats": {"power_gpu_soc_mean_watts": 21.732, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 8.129, "gpu_utilization_percent_mean": 70.969}, "timestamp": "2026-01-30T11:16:10.613712"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5446.498, "latencies_ms": [5446.498], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Bus: 3\n2. Bus: 2\n3. Bus: 1\n4. Bus: 1\n5. Bus: 1\n6. Bus: 1\n7. Bus: 1\n8. Bus: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.978}, "power_stats": {"power_gpu_soc_mean_watts": 18.715, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 66.978}, "timestamp": "2026-01-30T11:16:18.077124"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4062.727, "latencies_ms": [4062.727], "images_per_second": 0.246, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The buses are positioned in the foreground, with the buildings in the background. The trees are located near the buses, while the overpass is situated further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.441}, "power_stats": {"power_gpu_soc_mean_watts": 20.867, "power_cpu_cv_mean_watts": 1.295, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 72.441}, "timestamp": "2026-01-30T11:16:24.178511"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3823.895, "latencies_ms": [3823.895], "images_per_second": 0.262, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image captures a bustling cityscape with a large parking lot filled with buses and cars, surrounded by tall buildings and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.645}, "power_stats": {"power_gpu_soc_mean_watts": 21.659, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 70.645}, "timestamp": "2026-01-30T11:16:30.041586"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4086.073, "latencies_ms": [4086.073], "images_per_second": 0.245, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image features a vibrant cityscape with a mix of green and white buildings, a clear blue sky with white clouds, and a bustling street with several buses and cars.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.324}, "power_stats": {"power_gpu_soc_mean_watts": 21.127, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 8.116, "gpu_utilization_percent_mean": 70.324}, "timestamp": "2026-01-30T11:16:36.163916"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3841.711, "latencies_ms": [3841.711], "images_per_second": 0.26, "prompt_tokens": 1100, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A man wearing a cowboy hat and shorts is riding a skateboard on a ramp in a skate park, with a large tent in the background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.406}, "power_stats": {"power_gpu_soc_mean_watts": 21.761, "power_cpu_cv_mean_watts": 1.314, "power_sys_5v0_mean_watts": 8.113, "gpu_utilization_percent_mean": 73.406}, "timestamp": "2026-01-30T11:16:42.052554"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5603.541, "latencies_ms": [5603.541], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. hat: 1\n3. shorts: 1\n4. skateboard: 1\n5. ramp: 1\n6. shadow: 1\n7. tent: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.638}, "power_stats": {"power_gpu_soc_mean_watts": 18.24, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 7.914, "gpu_utilization_percent_mean": 71.638}, "timestamp": "2026-01-30T11:16:49.680649"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5543.293, "latencies_ms": [5543.293], "images_per_second": 0.18, "prompt_tokens": 1118, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The skateboarder is positioned in the foreground, performing a trick on the ramp, while the tents are located in the background, providing a contrast between the foreground and background elements. The shadow of the skateboarder is cast on the ramp, indicating the direction of the light source.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.652}, "power_stats": {"power_gpu_soc_mean_watts": 18.498, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 70.652}, "timestamp": "2026-01-30T11:16:57.257240"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3476.469, "latencies_ms": [3476.469], "images_per_second": 0.288, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing a hat and shorts is riding a skateboard on a ramp. There are tents in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14002.0, "ram_available_mb": 48838.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.241}, "power_stats": {"power_gpu_soc_mean_watts": 22.228, "power_cpu_cv_mean_watts": 1.947, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 73.241}, "timestamp": "2026-01-30T11:17:02.755195"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4594.615, "latencies_ms": [4594.615], "images_per_second": 0.218, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a ramp, with a clear blue sky in the background. The skateboarder is wearing a hat and shorts, and the ramp is made of wood.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14002.0, "ram_available_mb": 48838.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14002.6, "ram_available_mb": 48838.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.842}, "power_stats": {"power_gpu_soc_mean_watts": 20.071, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 69.842}, "timestamp": "2026-01-30T11:17:09.399768"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3844.991, "latencies_ms": [3844.991], "images_per_second": 0.26, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A person is standing on a surfboard with a windsurfing board attached to it, and there are several kites flying in the sky.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 14002.6, "ram_available_mb": 48838.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14003.0, "ram_available_mb": 48837.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.323}, "power_stats": {"power_gpu_soc_mean_watts": 21.878, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.131, "gpu_utilization_percent_mean": 71.323}, "timestamp": "2026-01-30T11:17:15.286108"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5806.534, "latencies_ms": [5806.534], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. person: 1\n2. windsurf board: 1\n3. kite: 2\n4. ocean: 1\n5. sky: 2\n6. waves: 1\n7. water: 1\n8. kite string: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.0, "ram_available_mb": 48837.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14003.4, "ram_available_mb": 48837.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.229}, "power_stats": {"power_gpu_soc_mean_watts": 17.925, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.896, "gpu_utilization_percent_mean": 70.229}, "timestamp": "2026-01-30T11:17:23.134653"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4461.974, "latencies_ms": [4461.974], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The kiteboarder is positioned in the foreground, with the ocean and sky in the background. The kites are flying in the sky, with the kiteboarder being closer to the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.4, "ram_available_mb": 48837.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14005.4, "ram_available_mb": 48835.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.757}, "power_stats": {"power_gpu_soc_mean_watts": 20.18, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 70.757}, "timestamp": "2026-01-30T11:17:29.629376"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3661.239, "latencies_ms": [3661.239], "images_per_second": 0.273, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man is windsurfing in the ocean with a kite. The sky is blue and there are other people in the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14005.4, "ram_available_mb": 48835.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14005.4, "ram_available_mb": 48835.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.767}, "power_stats": {"power_gpu_soc_mean_watts": 22.008, "power_cpu_cv_mean_watts": 1.268, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 71.767}, "timestamp": "2026-01-30T11:17:35.320579"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5382.546, "latencies_ms": [5382.546], "images_per_second": 0.186, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a vibrant scene with a clear blue sky and a vast ocean. The water is a deep blue, and the sky is a bright blue with a few white clouds. The windsurfer is wearing a red shirt and is holding onto a blue and white sail.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14005.4, "ram_available_mb": 48835.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14003.8, "ram_available_mb": 48837.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.978}, "power_stats": {"power_gpu_soc_mean_watts": 18.845, "power_cpu_cv_mean_watts": 2.26, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 69.978}, "timestamp": "2026-01-30T11:17:42.736358"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3218.467, "latencies_ms": [3218.467], "images_per_second": 0.311, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " An old red fire hydrant is in the grass in front of a house with purple flowers.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 14003.8, "ram_available_mb": 48837.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.577}, "power_stats": {"power_gpu_soc_mean_watts": 23.453, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.206, "gpu_utilization_percent_mean": 73.577}, "timestamp": "2026-01-30T11:17:47.999872"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5691.816, "latencies_ms": [5691.816], "images_per_second": 0.176, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Fire hydrant: 1\n2. Grass: 1\n3. Flowers: 2\n4. Tree: 1\n5. House: 1\n6. Window: 1\n7. Roof: 1\n8. Purple flowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14003.3, "ram_available_mb": 48837.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.298, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.911, "gpu_utilization_percent_mean": 66.043}, "timestamp": "2026-01-30T11:17:55.722079"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4671.585, "latencies_ms": [4671.585], "images_per_second": 0.214, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The fire hydrant is located in the foreground of the image, with the house and trees in the background. The hydrant is positioned to the left of the house, and the grass is in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14003.3, "ram_available_mb": 48837.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14003.3, "ram_available_mb": 48837.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.615}, "power_stats": {"power_gpu_soc_mean_watts": 19.684, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 69.615}, "timestamp": "2026-01-30T11:18:02.418366"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2919.296, "latencies_ms": [2919.296], "images_per_second": 0.343, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A red fire hydrant is in the grass in front of a house.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.3, "ram_available_mb": 48837.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14003.1, "ram_available_mb": 48837.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.083}, "power_stats": {"power_gpu_soc_mean_watts": 23.989, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.281, "gpu_utilization_percent_mean": 76.083}, "timestamp": "2026-01-30T11:18:07.373187"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3248.966, "latencies_ms": [3248.966], "images_per_second": 0.308, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The fire hydrant is red and black, and it is in a grassy area with dandelions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.1, "ram_available_mb": 48837.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14003.3, "ram_available_mb": 48837.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.222}, "power_stats": {"power_gpu_soc_mean_watts": 23.34, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 76.222}, "timestamp": "2026-01-30T11:18:12.665597"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3304.439, "latencies_ms": [3304.439], "images_per_second": 0.303, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A bird is flying over a roof with a blue hue, while other birds are on the ground nearby.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 14003.0, "ram_available_mb": 48837.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.889}, "power_stats": {"power_gpu_soc_mean_watts": 23.252, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.163, "gpu_utilization_percent_mean": 75.889}, "timestamp": "2026-01-30T11:18:18.018754"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4452.861, "latencies_ms": [4452.861], "images_per_second": 0.225, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " bird: 1, roof: 1, bird: 1, roof: 1, bird: 1, roof: 1, bird: 1, roof: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14003.2, "ram_available_mb": 48837.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.139, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 71.324}, "timestamp": "2026-01-30T11:18:24.493391"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4551.43, "latencies_ms": [4551.43], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The main object, a bird, is located in the foreground, flying towards the right side of the image. The bird is near the edge of the roof, which is the background of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14003.2, "ram_available_mb": 48837.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14003.5, "ram_available_mb": 48837.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.263}, "power_stats": {"power_gpu_soc_mean_watts": 19.841, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 71.263}, "timestamp": "2026-01-30T11:18:31.064020"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3061.037, "latencies_ms": [3061.037], "images_per_second": 0.327, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bird is flying over a roof, while other birds are on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.5, "ram_available_mb": 48837.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14003.5, "ram_available_mb": 48837.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.8}, "power_stats": {"power_gpu_soc_mean_watts": 23.415, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 78.8}, "timestamp": "2026-01-30T11:18:36.171496"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4210.399, "latencies_ms": [4210.399], "images_per_second": 0.238, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a bird with a blue and black body, flying over a wooden surface with a blue hue. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.5, "ram_available_mb": 48837.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14003.7, "ram_available_mb": 48837.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.171}, "power_stats": {"power_gpu_soc_mean_watts": 20.673, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 71.171}, "timestamp": "2026-01-30T11:18:42.403675"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3638.492, "latencies_ms": [3638.492], "images_per_second": 0.275, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a person is walking a horse in a barn, with a red door and a ladder visible in the background.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 14003.7, "ram_available_mb": 48837.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14004.1, "ram_available_mb": 48836.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.033}, "power_stats": {"power_gpu_soc_mean_watts": 22.153, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.141, "gpu_utilization_percent_mean": 72.033}, "timestamp": "2026-01-30T11:18:48.095570"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4082.319, "latencies_ms": [4082.319], "images_per_second": 0.245, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " horse: 1, person: 1, door: 1, ladder: 1, bucket: 1, wall: 1, window: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.1, "ram_available_mb": 48836.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14002.7, "ram_available_mb": 48838.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.382}, "power_stats": {"power_gpu_soc_mean_watts": 21.152, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 71.382}, "timestamp": "2026-01-30T11:18:54.196435"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4913.267, "latencies_ms": [4913.267], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The horse is positioned in the foreground, with the person walking beside it. The person is standing in the middle of the image, with the horse to their left. The horse is in the background, with the person in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14002.7, "ram_available_mb": 48838.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14003.0, "ram_available_mb": 48837.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.537}, "power_stats": {"power_gpu_soc_mean_watts": 19.427, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 71.537}, "timestamp": "2026-01-30T11:19:01.157875"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2673.659, "latencies_ms": [2673.659], "images_per_second": 0.374, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A woman is walking a horse in a barn.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14003.0, "ram_available_mb": 48837.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14003.2, "ram_available_mb": 48837.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.227}, "power_stats": {"power_gpu_soc_mean_watts": 24.443, "power_cpu_cv_mean_watts": 0.782, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 79.227}, "timestamp": "2026-01-30T11:19:05.885227"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4636.991, "latencies_ms": [4636.991], "images_per_second": 0.216, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is taken in a stable with a brown horse and a woman walking in it. The horse is wearing a red harness and the woman is wearing blue jeans. The lighting is natural and the colors are warm.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.2, "ram_available_mb": 48837.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.974}, "power_stats": {"power_gpu_soc_mean_watts": 20.062, "power_cpu_cv_mean_watts": 1.499, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 69.974}, "timestamp": "2026-01-30T11:19:12.576760"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3933.487, "latencies_ms": [3933.487], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, a group of animals, including zebras and sheep, are grazing in a grassy field, with trees and a fence in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.061}, "power_stats": {"power_gpu_soc_mean_watts": 21.416, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 69.061}, "timestamp": "2026-01-30T11:19:18.543932"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5511.307, "latencies_ms": [5511.307], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. tree: 1\n2. zebra: 2\n3. sheep: 4\n4. grass: 1\n5. rocks: 1\n6. fence: 1\n7. water: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14003.6, "ram_available_mb": 48837.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.745}, "power_stats": {"power_gpu_soc_mean_watts": 18.291, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.929, "gpu_utilization_percent_mean": 67.745}, "timestamp": "2026-01-30T11:19:26.080452"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5163.522, "latencies_ms": [5163.522], "images_per_second": 0.194, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground, with the sheep grazing in the background. The zebras are closer to the camera than the sheep, which are further away. The zebras are near the pond, while the sheep are grazing on the grass.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14003.6, "ram_available_mb": 48837.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14003.8, "ram_available_mb": 48837.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.558}, "power_stats": {"power_gpu_soc_mean_watts": 19.175, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 70.558}, "timestamp": "2026-01-30T11:19:33.277966"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4215.368, "latencies_ms": [4215.368], "images_per_second": 0.237, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In this image, we can see a herd of animals, including zebras and sheep, grazing in a grassy field. In the background, we can see trees and a pond.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14003.8, "ram_available_mb": 48837.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14004.0, "ram_available_mb": 48836.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.029}, "power_stats": {"power_gpu_soc_mean_watts": 20.891, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 71.029}, "timestamp": "2026-01-30T11:19:39.515996"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4555.46, "latencies_ms": [4555.46], "images_per_second": 0.22, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a grassy field with a variety of animals, including zebras, sheep, and deer. The sky is blue with some clouds, and the trees in the background are tall and green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.0, "ram_available_mb": 48836.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14004.2, "ram_available_mb": 48836.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.526}, "power_stats": {"power_gpu_soc_mean_watts": 19.916, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 71.526}, "timestamp": "2026-01-30T11:19:46.116756"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3606.774, "latencies_ms": [3606.774], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A vintage trolley car with a green and gold body and a red roof is being pulled by two white horses in a park.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14004.2, "ram_available_mb": 48836.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.238, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 8.151, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-30T11:19:51.794649"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4158.332, "latencies_ms": [4158.332], "images_per_second": 0.24, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " trolley: 1, horse: 2, carriage: 1, people: 1, bench: 1, trees: 1, umbrella: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.984, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 68.486}, "timestamp": "2026-01-30T11:19:57.971818"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6128.181, "latencies_ms": [6128.181], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The horse-drawn trolley is positioned in the foreground of the image, with the passengers seated inside. The trolley is moving towards the right side of the image, while the people are standing on the left side. The background features a park with trees and benches, indicating that the trolley is passing through a public area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.038}, "power_stats": {"power_gpu_soc_mean_watts": 17.612, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 7.905, "gpu_utilization_percent_mean": 67.038}, "timestamp": "2026-01-30T11:20:06.157723"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3626.597, "latencies_ms": [3626.597], "images_per_second": 0.276, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A horse-drawn trolley car is driving down a street in a park, with people walking around and sitting on benches.", "error": null, "sys_before": {"cpu_percent": 3.2, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.233}, "power_stats": {"power_gpu_soc_mean_watts": 21.997, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 8.197, "gpu_utilization_percent_mean": 71.233}, "timestamp": "2026-01-30T11:20:11.949448"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5653.759, "latencies_ms": [5653.759], "images_per_second": 0.177, "prompt_tokens": 1109, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image features a vibrant scene with a green and red trolley car, white horses pulling it, and a yellow canopy overhead. The trolley car is adorned with gold accents and has a sign that reads \"DINING CAR\". The sky is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.468}, "power_stats": {"power_gpu_soc_mean_watts": 18.395, "power_cpu_cv_mean_watts": 1.687, "power_sys_5v0_mean_watts": 7.931, "gpu_utilization_percent_mean": 69.468}, "timestamp": "2026-01-30T11:20:19.630459"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4412.516, "latencies_ms": [4412.516], "images_per_second": 0.227, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " An elderly man sits on a green bench reading a newspaper while a group of people sit on benches in front of a building with a sign that says \"S.C.C.C.\"", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.889}, "power_stats": {"power_gpu_soc_mean_watts": 20.2, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 67.889}, "timestamp": "2026-01-30T11:20:26.082592"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5495.964, "latencies_ms": [5495.964], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. bench: 4\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.522}, "power_stats": {"power_gpu_soc_mean_watts": 18.412, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.935, "gpu_utilization_percent_mean": 67.522}, "timestamp": "2026-01-30T11:20:33.614113"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5654.722, "latencies_ms": [5654.722], "images_per_second": 0.177, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The man on the left is sitting on a green bench, while the man on the right is sitting on a red bench. The man on the left is closer to the camera than the man on the right. The man on the left is sitting in front of the man on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 14053.6, "ram_available_mb": 48787.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.511}, "power_stats": {"power_gpu_soc_mean_watts": 18.32, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 69.511}, "timestamp": "2026-01-30T11:20:41.300288"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5964.115, "latencies_ms": [5964.115], "images_per_second": 0.168, "prompt_tokens": 1111, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a serene scene of a group of people enjoying a sunny day on a city sidewalk. The individuals are seated on green metal benches, each engrossed in their own world. The backdrop is a bustling cityscape with a prominent building adorned with a maroon sign that reads \"S.C.C.C.\"", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14053.4, "ram_available_mb": 48787.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 14002.7, "ram_available_mb": 48838.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.46}, "power_stats": {"power_gpu_soc_mean_watts": 17.974, "power_cpu_cv_mean_watts": 2.146, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 68.46}, "timestamp": "2026-01-30T11:20:49.313137"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4466.222, "latencies_ms": [4466.222], "images_per_second": 0.224, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image is taken during the day with natural light, and the ground is paved with concrete. The color of the benches is green, and the man is wearing a gray suit.", "error": null, "sys_before": {"cpu_percent": 0.7, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 14037.2, "ram_available_mb": 48803.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.833}, "power_stats": {"power_gpu_soc_mean_watts": 20.367, "power_cpu_cv_mean_watts": 2.013, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 69.833}, "timestamp": "2026-01-30T11:20:56.583775"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3252.144, "latencies_ms": [3252.144], "images_per_second": 0.307, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black desk with a laptop, a lamp, and a glass of orange juice on it.", "error": null, "sys_before": {"cpu_percent": 20.8, "ram_used_mb": 14037.5, "ram_available_mb": 48803.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 14039.8, "ram_available_mb": 48801.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.231}, "power_stats": {"power_gpu_soc_mean_watts": 23.089, "power_cpu_cv_mean_watts": 1.293, "power_sys_5v0_mean_watts": 8.229, "gpu_utilization_percent_mean": 76.231}, "timestamp": "2026-01-30T11:21:01.887908"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4605.507, "latencies_ms": [4605.507], "images_per_second": 0.217, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " 1. black laptop\n2. white telephone\n3. black lamp\n4. glass of orange juice\n5. book\n6. white paper\n7. black pen\n8. black chair", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14039.5, "ram_available_mb": 48801.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 13.1, "ram_used_mb": 14044.1, "ram_available_mb": 48796.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.892}, "power_stats": {"power_gpu_soc_mean_watts": 20.012, "power_cpu_cv_mean_watts": 1.991, "power_sys_5v0_mean_watts": 8.115, "gpu_utilization_percent_mean": 70.892}, "timestamp": "2026-01-30T11:21:08.518584"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4357.274, "latencies_ms": [4357.274], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The laptop is positioned to the left of the desk, with the lamp and telephone to its right. The desk is situated in the foreground, with the wall and painting in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14044.2, "ram_available_mb": 48796.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 14044.3, "ram_available_mb": 48796.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.75}, "power_stats": {"power_gpu_soc_mean_watts": 20.345, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 68.75}, "timestamp": "2026-01-30T11:21:14.890846"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3718.644, "latencies_ms": [3718.644], "images_per_second": 0.269, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A desk with a laptop computer, a lamp, and a glass of orange juice is in a room with a painting on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14044.3, "ram_available_mb": 48796.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 14045.5, "ram_available_mb": 48795.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.167}, "power_stats": {"power_gpu_soc_mean_watts": 22.067, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 8.379, "gpu_utilization_percent_mean": 74.167}, "timestamp": "2026-01-30T11:21:20.645981"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3443.073, "latencies_ms": [3443.073], "images_per_second": 0.29, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is well-lit with a warm yellow light, and the desk is made of wood.", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 14042.8, "ram_available_mb": 48798.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 14043.2, "ram_available_mb": 48797.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.914, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 8.61, "gpu_utilization_percent_mean": 72.667}, "timestamp": "2026-01-30T11:21:29.334088"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5896.063, "latencies_ms": [5896.063], "images_per_second": 0.17, "prompt_tokens": 1432, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a blue and white striped towel, a pink and white surfboard, and a blue surfboard resting on the sand, with a beach umbrella and chairs nearby, and a person enjoying the ocean waves in the distance.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14039.5, "ram_available_mb": 48801.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 13.0, "ram_used_mb": 14044.4, "ram_available_mb": 48796.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.875}, "power_stats": {"power_gpu_soc_mean_watts": 20.673, "power_cpu_cv_mean_watts": 2.044, "power_sys_5v0_mean_watts": 8.763, "gpu_utilization_percent_mean": 69.875}, "timestamp": "2026-01-30T11:21:39.928429"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4880.324, "latencies_ms": [4880.324], "images_per_second": 0.205, "prompt_tokens": 1446, "response_tokens_est": 33, "n_tiles": 1, "output_text": " beach chair: 2\nsurfboard: 3\nbag: 1\numbrella: 1\nsand: 1\nwater: 1", "error": null, "sys_before": {"cpu_percent": 6.1, "ram_used_mb": 14045.7, "ram_available_mb": 48795.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 11.6, "ram_used_mb": 14049.1, "ram_available_mb": 48791.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.053}, "power_stats": {"power_gpu_soc_mean_watts": 23.616, "power_cpu_cv_mean_watts": 1.538, "power_sys_5v0_mean_watts": 8.957, "gpu_utilization_percent_mean": 77.053}, "timestamp": "2026-01-30T11:21:48.639455"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6905.458, "latencies_ms": [6905.458], "images_per_second": 0.145, "prompt_tokens": 1450, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The blue and white striped towel is positioned to the left of the blue surfboard, which is closer to the camera than the pink and white surfboard. The red cooler is located in the foreground, near the beach chairs and umbrellas, while the person in the water is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14049.3, "ram_available_mb": 48791.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 14052.4, "ram_available_mb": 48788.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.175}, "power_stats": {"power_gpu_soc_mean_watts": 19.306, "power_cpu_cv_mean_watts": 2.171, "power_sys_5v0_mean_watts": 8.218, "gpu_utilization_percent_mean": 72.175}, "timestamp": "2026-01-30T11:21:57.588174"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5096.683, "latencies_ms": [5096.683], "images_per_second": 0.196, "prompt_tokens": 1444, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a clear blue sky and calm ocean waves. People are enjoying the beach, with some relaxing on the sand and others swimming in the water.", "error": null, "sys_before": {"cpu_percent": 4.1, "ram_used_mb": 14049.7, "ram_available_mb": 48791.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 14052.4, "ram_available_mb": 48788.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.102, "power_cpu_cv_mean_watts": 1.64, "power_sys_5v0_mean_watts": 8.341, "gpu_utilization_percent_mean": 72.071}, "timestamp": "2026-01-30T11:22:06.925540"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3945.733, "latencies_ms": [3945.733], "images_per_second": 0.253, "prompt_tokens": 1442, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The beach is covered in sand, the sky is blue, and the ocean is blue.", "error": null, "sys_before": {"cpu_percent": 4.7, "ram_used_mb": 14052.8, "ram_available_mb": 48788.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 14053.5, "ram_available_mb": 48787.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.219}, "power_stats": {"power_gpu_soc_mean_watts": 25.038, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.993, "gpu_utilization_percent_mean": 80.219}, "timestamp": "2026-01-30T11:22:14.709846"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3348.16, "latencies_ms": [3348.16], "images_per_second": 0.299, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A sheep with a black face is standing on a rocky hill under a blue sky with white clouds.", "error": null, "sys_before": {"cpu_percent": 3.4, "ram_used_mb": 14054.7, "ram_available_mb": 48786.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14055.5, "ram_available_mb": 48785.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.821}, "power_stats": {"power_gpu_soc_mean_watts": 22.768, "power_cpu_cv_mean_watts": 1.244, "power_sys_5v0_mean_watts": 8.623, "gpu_utilization_percent_mean": 72.821}, "timestamp": "2026-01-30T11:22:22.634262"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5884.487, "latencies_ms": [5884.487], "images_per_second": 0.17, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. rock: 1\n3. grass: 1\n4. sky: 1\n5. clouds: 1\n6. cloud: 1\n7. sheep's head: 1\n8. sheep's body: 1", "error": null, "sys_before": {"cpu_percent": 1.4, "ram_used_mb": 14055.7, "ram_available_mb": 48785.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14047.8, "ram_available_mb": 48793.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.714}, "power_stats": {"power_gpu_soc_mean_watts": 18.159, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 8.413, "gpu_utilization_percent_mean": 68.714}, "timestamp": "2026-01-30T11:22:32.281309"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4636.458, "latencies_ms": [4636.458], "images_per_second": 0.216, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The sheep is positioned on the left side of the image, with the sky occupying the majority of the background. The sheep is in the foreground, with the grass and rocks in the middle ground.", "error": null, "sys_before": {"cpu_percent": 1.8, "ram_used_mb": 14046.8, "ram_available_mb": 48794.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14051.2, "ram_available_mb": 48789.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.459}, "power_stats": {"power_gpu_soc_mean_watts": 20.247, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.463, "gpu_utilization_percent_mean": 69.459}, "timestamp": "2026-01-30T11:22:40.277335"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3230.277, "latencies_ms": [3230.277], "images_per_second": 0.31, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A sheep with a black face is standing on a rocky hill under a blue sky with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14049.1, "ram_available_mb": 48791.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 14049.0, "ram_available_mb": 48791.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.741}, "power_stats": {"power_gpu_soc_mean_watts": 23.148, "power_cpu_cv_mean_watts": 2.921, "power_sys_5v0_mean_watts": 8.442, "gpu_utilization_percent_mean": 74.741}, "timestamp": "2026-01-30T11:22:45.549011"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3492.023, "latencies_ms": [3492.023], "images_per_second": 0.286, "prompt_tokens": 1110, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The sheep is white with a black face and is standing on a rocky hill under a blue sky with white clouds.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14051.2, "ram_available_mb": 48789.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 14049.6, "ram_available_mb": 48791.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.069}, "power_stats": {"power_gpu_soc_mean_watts": 22.504, "power_cpu_cv_mean_watts": 3.037, "power_sys_5v0_mean_watts": 8.235, "gpu_utilization_percent_mean": 73.069}, "timestamp": "2026-01-30T11:22:51.072300"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2939.592, "latencies_ms": [2939.592], "images_per_second": 0.34, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person with blue hair is taking a selfie in the mirror.", "error": null, "sys_before": {"cpu_percent": 17.2, "ram_used_mb": 14049.3, "ram_available_mb": 48791.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 12.3, "ram_used_mb": 14050.8, "ram_available_mb": 48790.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.667}, "power_stats": {"power_gpu_soc_mean_watts": 24.159, "power_cpu_cv_mean_watts": 2.92, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 80.667}, "timestamp": "2026-01-30T11:22:56.045508"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5603.21, "latencies_ms": [5603.21], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. phone: 1\n3. shirt: 1\n4. tie: 1\n5. wall: 1\n6. ring: 1\n7. mirror: 1\n8. blue: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 14.2, "ram_used_mb": 14048.9, "ram_available_mb": 48792.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.128}, "power_stats": {"power_gpu_soc_mean_watts": 18.293, "power_cpu_cv_mean_watts": 3.357, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 66.128}, "timestamp": "2026-01-30T11:23:03.674481"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5377.507, "latencies_ms": [5377.507], "images_per_second": 0.186, "prompt_tokens": 1118, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The person is in the foreground of the image, taking a selfie with a phone. The phone is held up to the camera, and the person's reflection is visible in the mirror. The mirror is located in the background, reflecting the person and the phone.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14049.0, "ram_available_mb": 48791.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 13.9, "ram_used_mb": 14052.5, "ram_available_mb": 48788.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.133}, "power_stats": {"power_gpu_soc_mean_watts": 18.597, "power_cpu_cv_mean_watts": 3.39, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 69.133}, "timestamp": "2026-01-30T11:23:11.083902"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3060.977, "latencies_ms": [3060.977], "images_per_second": 0.327, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman with blue hair is taking a selfie in the mirror.", "error": null, "sys_before": {"cpu_percent": 2.4, "ram_used_mb": 14051.7, "ram_available_mb": 48789.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 12.4, "ram_used_mb": 14067.1, "ram_available_mb": 48773.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.458}, "power_stats": {"power_gpu_soc_mean_watts": 23.687, "power_cpu_cv_mean_watts": 2.402, "power_sys_5v0_mean_watts": 8.726, "gpu_utilization_percent_mean": 75.458}, "timestamp": "2026-01-30T11:23:17.380112"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3547.106, "latencies_ms": [3547.106], "images_per_second": 0.282, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The woman has blue hair and is wearing a blue shirt. The lighting is bright and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 7.0, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 14074.9, "ram_available_mb": 48766.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.766, "power_cpu_cv_mean_watts": 2.789, "power_sys_5v0_mean_watts": 8.653, "gpu_utilization_percent_mean": 72.207}, "timestamp": "2026-01-30T11:23:26.094221"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4154.414, "latencies_ms": [4154.414], "images_per_second": 0.241, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a room with a fireplace, a wooden cabinet, a table, and chairs, all arranged in a way that suggests a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 5.7, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 14089.7, "ram_available_mb": 48751.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.265}, "power_stats": {"power_gpu_soc_mean_watts": 21.02, "power_cpu_cv_mean_watts": 2.567, "power_sys_5v0_mean_watts": 8.562, "gpu_utilization_percent_mean": 69.265}, "timestamp": "2026-01-30T11:23:35.981570"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4542.919, "latencies_ms": [4542.919], "images_per_second": 0.22, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " fireplace: 1, table: 1, chair: 2, bookshelf: 1, painting: 2, vase: 2, floor: 1", "error": null, "sys_before": {"cpu_percent": 1.9, "ram_used_mb": 14090.4, "ram_available_mb": 48750.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14088.1, "ram_available_mb": 48752.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.811}, "power_stats": {"power_gpu_soc_mean_watts": 19.762, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 8.323, "gpu_utilization_percent_mean": 68.811}, "timestamp": "2026-01-30T11:23:44.557291"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5508.892, "latencies_ms": [5508.892], "images_per_second": 0.182, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The fireplace is located on the left side of the room, with the wooden cabinet positioned against the right wall. The round wooden table is situated in the foreground, with the chairs placed in the background. The bookshelf is positioned in the background, behind the wooden cabinet.", "error": null, "sys_before": {"cpu_percent": 2.3, "ram_used_mb": 14089.3, "ram_available_mb": 48751.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14020.2, "ram_available_mb": 48820.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.699, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 8.44, "gpu_utilization_percent_mean": 70.043}, "timestamp": "2026-01-30T11:23:55.090873"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3373.072, "latencies_ms": [3373.072], "images_per_second": 0.296, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image depicts a room with a fireplace, a wooden cabinet, and a table with chairs.", "error": null, "sys_before": {"cpu_percent": 0.7, "ram_used_mb": 14022.8, "ram_available_mb": 48818.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14021.5, "ram_available_mb": 48819.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.259}, "power_stats": {"power_gpu_soc_mean_watts": 22.988, "power_cpu_cv_mean_watts": 1.008, "power_sys_5v0_mean_watts": 8.568, "gpu_utilization_percent_mean": 73.259}, "timestamp": "2026-01-30T11:24:02.339031"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4282.01, "latencies_ms": [4282.01], "images_per_second": 0.234, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted white. The furniture is made of wood, and the floor is covered with a patterned carpet.", "error": null, "sys_before": {"cpu_percent": 0.6, "ram_used_mb": 14021.5, "ram_available_mb": 48819.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 14281.1, "ram_available_mb": 48559.8, "ram_percent": 22.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.029}, "power_stats": {"power_gpu_soc_mean_watts": 20.846, "power_cpu_cv_mean_watts": 1.418, "power_sys_5v0_mean_watts": 8.433, "gpu_utilization_percent_mean": 70.029}, "timestamp": "2026-01-30T11:24:11.757406"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3749.405, "latencies_ms": [3749.405], "images_per_second": 0.267, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A brown dog is jumping in the air to catch a red frisbee.", "error": null, "sys_before": {"cpu_percent": 2.4, "ram_used_mb": 14023.6, "ram_available_mb": 48817.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14021.0, "ram_available_mb": 48819.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.7}, "power_stats": {"power_gpu_soc_mean_watts": 25.493, "power_cpu_cv_mean_watts": 0.921, "power_sys_5v0_mean_watts": 8.926, "gpu_utilization_percent_mean": 76.7}, "timestamp": "2026-01-30T11:24:19.269065"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4711.7, "latencies_ms": [4711.7], "images_per_second": 0.212, "prompt_tokens": 1446, "response_tokens_est": 31, "n_tiles": 1, "output_text": " dog: 1, frisbee: 1, car: 1, tree: 1, grass: 1, mulch: 1", "error": null, "sys_before": {"cpu_percent": 0.6, "ram_used_mb": 14022.5, "ram_available_mb": 48818.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14020.5, "ram_available_mb": 48820.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.447}, "power_stats": {"power_gpu_soc_mean_watts": 23.486, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.795, "gpu_utilization_percent_mean": 74.447}, "timestamp": "2026-01-30T11:24:29.050417"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5307.023, "latencies_ms": [5307.023], "images_per_second": 0.188, "prompt_tokens": 1450, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The dog is in the foreground, jumping up to catch the frisbee, which is in the middle ground. The frisbee is in the air, and the car is in the background.", "error": null, "sys_before": {"cpu_percent": 0.8, "ram_used_mb": 14020.5, "ram_available_mb": 48820.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14020.2, "ram_available_mb": 48820.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.419}, "power_stats": {"power_gpu_soc_mean_watts": 22.218, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.756, "gpu_utilization_percent_mean": 73.419}, "timestamp": "2026-01-30T11:24:37.840757"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4141.001, "latencies_ms": [4141.001], "images_per_second": 0.241, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A brown dog is playing frisbee in a yard with a tree and a car in the background.", "error": null, "sys_before": {"cpu_percent": 0.8, "ram_used_mb": 14020.2, "ram_available_mb": 48820.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 14226.4, "ram_available_mb": 48614.5, "ram_percent": 22.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.147}, "power_stats": {"power_gpu_soc_mean_watts": 24.285, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.713, "gpu_utilization_percent_mean": 76.147}, "timestamp": "2026-01-30T11:24:46.935672"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5165.264, "latencies_ms": [5165.264], "images_per_second": 0.194, "prompt_tokens": 1442, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a black dog with a red frisbee in its mouth, jumping in the air in a grassy yard. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 9.0, "ram_used_mb": 14294.6, "ram_available_mb": 48546.3, "ram_percent": 22.7}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 14630.3, "ram_available_mb": 48210.6, "ram_percent": 23.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.025}, "power_stats": {"power_gpu_soc_mean_watts": 23.306, "power_cpu_cv_mean_watts": 2.693, "power_sys_5v0_mean_watts": 9.04, "gpu_utilization_percent_mean": 75.025}, "timestamp": "2026-01-30T11:24:55.623520"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3798.996, "latencies_ms": [3798.996], "images_per_second": 0.263, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image captures a giraffe in a natural setting, with its head and neck prominently displayed, and the background filled with lush greenery.", "error": null, "sys_before": {"cpu_percent": 9.3, "ram_used_mb": 14939.8, "ram_available_mb": 47901.1, "ram_percent": 23.8}, "sys_after": {"cpu_percent": 13.1, "ram_used_mb": 15048.1, "ram_available_mb": 47792.8, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.29}, "power_stats": {"power_gpu_soc_mean_watts": 21.84, "power_cpu_cv_mean_watts": 2.971, "power_sys_5v0_mean_watts": 8.756, "gpu_utilization_percent_mean": 72.29}, "timestamp": "2026-01-30T11:25:03.350934"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4371.316, "latencies_ms": [4371.316], "images_per_second": 0.229, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " giraffe: 1, ear: 2, eye: 2, nose: 1, mouth: 1, horn: 1, tail: 1", "error": null, "sys_before": {"cpu_percent": 5.2, "ram_used_mb": 15081.3, "ram_available_mb": 47759.6, "ram_percent": 24.0}, "sys_after": {"cpu_percent": 13.8, "ram_used_mb": 15545.3, "ram_available_mb": 47295.6, "ram_percent": 24.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.559}, "power_stats": {"power_gpu_soc_mean_watts": 20.729, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 8.514, "gpu_utilization_percent_mean": 69.559}, "timestamp": "2026-01-30T11:25:11.373610"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4329.212, "latencies_ms": [4329.212], "images_per_second": 0.231, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The giraffe is in the foreground, with its head and neck prominently displayed. The background is filled with green foliage, suggesting that the giraffe is in a natural habitat.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 15738.0, "ram_available_mb": 47102.9, "ram_percent": 25.0}, "sys_after": {"cpu_percent": 17.8, "ram_used_mb": 16183.3, "ram_available_mb": 46657.6, "ram_percent": 25.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.471}, "power_stats": {"power_gpu_soc_mean_watts": 20.729, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 8.57, "gpu_utilization_percent_mean": 69.471}, "timestamp": "2026-01-30T11:25:20.835663"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5232.921, "latencies_ms": [5232.921], "images_per_second": 0.191, "prompt_tokens": 1111, "response_tokens_est": 50, "n_tiles": 1, "output_text": " In the heart of a verdant forest, a majestic giraffe stands tall and proud, its long neck reaching towards the sky. The giraffe's coat, a beautiful mosaic of brown and white spots, contrasts beautifully with the lush greenery of the trees.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 16182.0, "ram_available_mb": 46658.9, "ram_percent": 25.8}, "sys_after": {"cpu_percent": 14.3, "ram_used_mb": 16587.9, "ram_available_mb": 46253.0, "ram_percent": 26.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.357}, "power_stats": {"power_gpu_soc_mean_watts": 18.85, "power_cpu_cv_mean_watts": 2.183, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 67.357}, "timestamp": "2026-01-30T11:25:28.110638"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4135.958, "latencies_ms": [4135.958], "images_per_second": 0.242, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The giraffe's coat is a rich brown with white spots, and the sunlight filters through the green leaves of the trees, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 15.2, "ram_used_mb": 16589.6, "ram_available_mb": 46251.3, "ram_percent": 26.4}, "sys_after": {"cpu_percent": 16.1, "ram_used_mb": 16867.9, "ram_available_mb": 45973.0, "ram_percent": 26.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.515}, "power_stats": {"power_gpu_soc_mean_watts": 20.749, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.094, "gpu_utilization_percent_mean": 70.515}, "timestamp": "2026-01-30T11:25:34.572918"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3591.758, "latencies_ms": [3591.758], "images_per_second": 0.278, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Two zebras with black and white stripes are standing in a fenced area with a chain link fence in the background.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 16860.4, "ram_available_mb": 45980.5, "ram_percent": 26.8}, "sys_after": {"cpu_percent": 15.5, "ram_used_mb": 17054.0, "ram_available_mb": 45786.9, "ram_percent": 27.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.828}, "power_stats": {"power_gpu_soc_mean_watts": 22.286, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.243, "gpu_utilization_percent_mean": 73.828}, "timestamp": "2026-01-30T11:25:40.232805"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5695.199, "latencies_ms": [5695.199], "images_per_second": 0.176, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. zebra: 2\n2. fence: 1\n3. ground: 1\n4. rocks: 1\n5. trees: 1\n6. leaves: 1\n7. grass: 1\n8. zebra's tail: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 17055.5, "ram_available_mb": 45785.4, "ram_percent": 27.1}, "sys_after": {"cpu_percent": 14.4, "ram_used_mb": 17322.3, "ram_available_mb": 45518.6, "ram_percent": 27.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 64.894}, "power_stats": {"power_gpu_soc_mean_watts": 18.155, "power_cpu_cv_mean_watts": 2.224, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 64.894}, "timestamp": "2026-01-30T11:25:47.983882"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5748.279, "latencies_ms": [5748.279], "images_per_second": 0.174, "prompt_tokens": 1118, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the fence serving as a boundary between them and the background. The zebras are facing away from the camera, with their tails prominently displayed, and the fence is located behind them, separating them from the rest of the environment.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 17322.2, "ram_available_mb": 45518.7, "ram_percent": 27.6}, "sys_after": {"cpu_percent": 16.7, "ram_used_mb": 17707.0, "ram_available_mb": 45133.9, "ram_percent": 28.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.936}, "power_stats": {"power_gpu_soc_mean_watts": 18.138, "power_cpu_cv_mean_watts": 2.624, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 65.936}, "timestamp": "2026-01-30T11:25:55.757455"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3495.939, "latencies_ms": [3495.939], "images_per_second": 0.286, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two zebras are standing in a fenced enclosure, their black and white stripes contrasting against the brown dirt ground.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 17706.6, "ram_available_mb": 45134.3, "ram_percent": 28.2}, "sys_after": {"cpu_percent": 12.6, "ram_used_mb": 18074.3, "ram_available_mb": 44766.6, "ram_percent": 28.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.75}, "power_stats": {"power_gpu_soc_mean_watts": 22.478, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.224, "gpu_utilization_percent_mean": 71.75}, "timestamp": "2026-01-30T11:26:01.296502"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4992.993, "latencies_ms": [4992.993], "images_per_second": 0.2, "prompt_tokens": 1110, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features two zebras with their backs to the camera, standing in a grassy area with a chain link fence in the background. The zebras have black and white stripes, and the lighting appears to be natural daylight.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18073.8, "ram_available_mb": 44767.1, "ram_percent": 28.8}, "sys_after": {"cpu_percent": 18.5, "ram_used_mb": 17946.8, "ram_available_mb": 44894.1, "ram_percent": 28.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.512}, "power_stats": {"power_gpu_soc_mean_watts": 18.994, "power_cpu_cv_mean_watts": 2.48, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.512}, "timestamp": "2026-01-30T11:26:08.334104"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4061.253, "latencies_ms": [4061.253], "images_per_second": 0.246, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, a group of horses is walking down a road, with a car parked on the side, and a pile of poop on the ground.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 17946.9, "ram_available_mb": 44894.0, "ram_percent": 28.6}, "sys_after": {"cpu_percent": 17.7, "ram_used_mb": 17426.6, "ram_available_mb": 45414.3, "ram_percent": 27.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.054, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 8.351, "gpu_utilization_percent_mean": 68.0}, "timestamp": "2026-01-30T11:26:14.441046"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5912.707, "latencies_ms": [5912.707], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 4\n2. car: 1\n3. horse: 2\n4. horse: 1\n5. horse: 1\n6. horse: 1\n7. horse: 1\n8. horse: 1", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 17425.9, "ram_available_mb": 45414.9, "ram_percent": 27.7}, "sys_after": {"cpu_percent": 38.5, "ram_used_mb": 17143.0, "ram_available_mb": 45697.9, "ram_percent": 27.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.542}, "power_stats": {"power_gpu_soc_mean_watts": 17.443, "power_cpu_cv_mean_watts": 4.538, "power_sys_5v0_mean_watts": 8.56, "gpu_utilization_percent_mean": 66.542}, "timestamp": "2026-01-30T11:26:22.376827"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5690.554, "latencies_ms": [5690.554], "images_per_second": 0.176, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The horses are positioned in the middle of the road, with the car parked on the right side of the street. The car is relatively close to the camera, while the horses are farther away. The horses are near the car, but not directly in front of it.", "error": null, "sys_before": {"cpu_percent": 29.4, "ram_used_mb": 17117.8, "ram_available_mb": 45723.1, "ram_percent": 27.2}, "sys_after": {"cpu_percent": 30.9, "ram_used_mb": 17050.1, "ram_available_mb": 45790.8, "ram_percent": 27.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.667}, "power_stats": {"power_gpu_soc_mean_watts": 18.768, "power_cpu_cv_mean_watts": 5.58, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 70.667}, "timestamp": "2026-01-30T11:26:32.461431"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5846.944, "latencies_ms": [5846.944], "images_per_second": 0.171, "prompt_tokens": 1111, "response_tokens_est": 57, "n_tiles": 1, "output_text": " In a serene suburban setting, a group of horses, their coats a mix of brown and black, are peacefully grazing on the lush green grass along a quiet street. A silver car is parked on the side of the road, its presence adding a touch of modernity to the tranquil scene.", "error": null, "sys_before": {"cpu_percent": 34.7, "ram_used_mb": 17381.6, "ram_available_mb": 45459.3, "ram_percent": 27.7}, "sys_after": {"cpu_percent": 23.2, "ram_used_mb": 17788.8, "ram_available_mb": 45052.1, "ram_percent": 28.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.694}, "power_stats": {"power_gpu_soc_mean_watts": 17.807, "power_cpu_cv_mean_watts": 4.846, "power_sys_5v0_mean_watts": 8.541, "gpu_utilization_percent_mean": 67.694}, "timestamp": "2026-01-30T11:26:42.639402"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5047.115, "latencies_ms": [5047.115], "images_per_second": 0.198, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a group of horses walking down a tree-lined street, with a silver car parked on the side of the road. The horses are brown and black, and the trees are green, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.9, "ram_used_mb": 17802.6, "ram_available_mb": 45038.3, "ram_percent": 28.3}, "sys_after": {"cpu_percent": 20.3, "ram_used_mb": 18161.6, "ram_available_mb": 44679.3, "ram_percent": 28.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.659}, "power_stats": {"power_gpu_soc_mean_watts": 18.937, "power_cpu_cv_mean_watts": 2.793, "power_sys_5v0_mean_watts": 8.518, "gpu_utilization_percent_mean": 65.659}, "timestamp": "2026-01-30T11:26:52.448444"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3970.411, "latencies_ms": [3970.411], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " In the image, there is a wooden desk with a blue book and a red apple on it, and a blackboard behind it.", "error": null, "sys_before": {"cpu_percent": 9.3, "ram_used_mb": 18189.4, "ram_available_mb": 44651.5, "ram_percent": 28.9}, "sys_after": {"cpu_percent": 14.6, "ram_used_mb": 18515.2, "ram_available_mb": 44325.7, "ram_percent": 29.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.613}, "power_stats": {"power_gpu_soc_mean_watts": 21.624, "power_cpu_cv_mean_watts": 2.195, "power_sys_5v0_mean_watts": 8.609, "gpu_utilization_percent_mean": 72.613}, "timestamp": "2026-01-30T11:26:59.741646"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4182.523, "latencies_ms": [4182.523], "images_per_second": 0.239, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " desk: 1\nbooks: 1\napple: 1\nblackboard: 1\nchair: 1\ndoor: 1", "error": null, "sys_before": {"cpu_percent": 17.4, "ram_used_mb": 18687.3, "ram_available_mb": 44153.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 18.5, "ram_used_mb": 19005.1, "ram_available_mb": 43835.8, "ram_percent": 30.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.394}, "power_stats": {"power_gpu_soc_mean_watts": 20.918, "power_cpu_cv_mean_watts": 2.427, "power_sys_5v0_mean_watts": 8.645, "gpu_utilization_percent_mean": 66.394}, "timestamp": "2026-01-30T11:27:08.691563"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6033.478, "latencies_ms": [6033.478], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The desk is positioned to the left of the chalkboard, with the chair in front of it. The books are placed on the desk, with the apple on top of the books. The chalkboard is located behind the desk, and the picture is on the wall to the right of the desk.", "error": null, "sys_before": {"cpu_percent": 13.1, "ram_used_mb": 19164.0, "ram_available_mb": 43676.9, "ram_percent": 30.5}, "sys_after": {"cpu_percent": 15.1, "ram_used_mb": 18818.6, "ram_available_mb": 44022.3, "ram_percent": 29.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 64.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.929, "power_cpu_cv_mean_watts": 2.337, "power_sys_5v0_mean_watts": 8.45, "gpu_utilization_percent_mean": 64.0}, "timestamp": "2026-01-30T11:27:19.812543"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3004.172, "latencies_ms": [3004.172], "images_per_second": 0.333, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A classroom with a desk, books, and a chalkboard.", "error": null, "sys_before": {"cpu_percent": 17.5, "ram_used_mb": 18955.6, "ram_available_mb": 43885.3, "ram_percent": 30.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 14989.6, "ram_available_mb": 47851.3, "ram_percent": 23.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9