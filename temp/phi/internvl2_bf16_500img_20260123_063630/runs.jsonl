{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11346.036, "latencies_ms": [11346.036], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a woman standing in a spacious living room with yellow walls. She is positioned near a dining table, which is surrounded by several chairs. The room is well-lit, with a television placed on the left side of the room. A potted plant can be seen on the right side of the room, adding a touch of greenery to the space.\n", "error": null, "sys_before": {"cpu_percent": 7.6, "ram_used_mb": 19684.4, "ram_available_mb": 43156.5, "ram_percent": 31.3}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 19618.4, "ram_available_mb": 43222.5, "ram_percent": 31.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 12926.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 12926.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.037, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 8.725}, "timestamp": "2026-01-23T06:38:38.196020"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8440.566, "latencies_ms": [8440.566], "images_per_second": 0.118, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "- Television: 1\n- Chair: 6\n- Table: 1\n- Sofa: 1\n- Cabinet: 2\n- Window: 3\n- Plant: 2\n- Rug: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 19618.4, "ram_available_mb": 43222.5, "ram_percent": 31.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 19650.1, "ram_available_mb": 43190.8, "ram_percent": 31.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 12926.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 12926.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.687, "power_cpu_cv_mean_watts": 1.809, "power_sys_5v0_mean_watts": 8.581}, "timestamp": "2026-01-23T06:38:48.678530"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11449.969, "latencies_ms": [11449.969], "images_per_second": 0.087, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a wooden floor with a rug and a yellow vase on a pink tray. The main objects in the room, such as the television, the chairs, and the dining table, are positioned in the background, with the television on the left side of the room and the chairs and table on the right side. The person is standing near", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19650.1, "ram_available_mb": 43190.8, "ram_percent": 31.3}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 19701.5, "ram_available_mb": 43139.4, "ram_percent": 31.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 12926.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 12926.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.599, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.612}, "timestamp": "2026-01-23T06:39:02.166567"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7915.65, "latencies_ms": [7915.65], "images_per_second": 0.126, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The image depicts a warm and inviting living room with yellow walls and hardwood flooring. A person is standing near the kitchen area, which is visible in the background with a refrigerator and cabinets.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19621.1, "ram_available_mb": 43219.8, "ram_percent": 31.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 19705.0, "ram_available_mb": 43135.9, "ram_percent": 31.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 12926.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 12926.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.273, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 8.656}, "timestamp": "2026-01-23T06:39:12.100737"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6781.29, "latencies_ms": [6781.29], "images_per_second": 0.147, "prompt_tokens": 36, "response_tokens_est": 39, "n_tiles": 16, "output_text": "The room has a warm and inviting atmosphere with yellow walls and wooden flooring. The lighting is soft and natural, coming from the large windows that let in plenty of sunlight.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 19705.0, "ram_available_mb": 43135.9, "ram_percent": 31.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 19699.1, "ram_available_mb": 43141.8, "ram_percent": 31.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 12926.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 12926.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.981, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 8.77}, "timestamp": "2026-01-23T06:39:20.939400"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 13014.308, "latencies_ms": [13014.308], "images_per_second": 0.077, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of tranquility featuring a brown bear in its natural habitat. The bear, with its fur glistening in the sunlight, is sitting on a bed of lush green grass. Its head is slightly tilted to the left, and it gazes directly into the camera, giving the impression of a curious or attentive demeanor. The bear", "error": null, "sys_before": {"cpu_percent": 15.8, "ram_used_mb": 19610.7, "ram_available_mb": 43230.2, "ram_percent": 31.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 21269.2, "ram_available_mb": 41571.7, "ram_percent": 33.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 14490.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 14490.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.201, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 8.744}, "timestamp": "2026-01-23T06:39:36.001225"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5431.676, "latencies_ms": [5431.676], "images_per_second": 0.184, "prompt_tokens": 39, "response_tokens_est": 11, "n_tiles": 16, "output_text": "grass: numerous\nbear: 1\n", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 21188.9, "ram_available_mb": 41652.0, "ram_percent": 33.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 22771.3, "ram_available_mb": 40069.6, "ram_percent": 36.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 16070.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 16070.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.607, "power_cpu_cv_mean_watts": 0.792, "power_sys_5v0_mean_watts": 8.695}, "timestamp": "2026-01-23T06:39:43.469551"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 13125.897, "latencies_ms": [13125.897], "images_per_second": 0.076, "prompt_tokens": 44, "response_tokens_est": 80, "n_tiles": 16, "output_text": "The bear is positioned in the foreground of the image, appearing large and prominent. The background is a natural setting with grass, which is less detailed and smaller in size, indicating that the bear is closer to the viewer. The bear's head is turned slightly to the left, and its ears are perked up, suggesting it is attentive to its surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 22771.3, "ram_available_mb": 40069.6, "ram_percent": 36.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24406.1, "ram_available_mb": 38434.8, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.224, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 8.77}, "timestamp": "2026-01-23T06:39:58.615158"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9561.275, "latencies_ms": [9561.275], "images_per_second": 0.105, "prompt_tokens": 37, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image shows a close-up of a bear's face, with its fur appearing soft and well-groomed. The bear is sitting in a grassy area, with the background consisting of green grass and some brown patches.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24406.1, "ram_available_mb": 38434.8, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24386.3, "ram_available_mb": 38454.6, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.108, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 8.906}, "timestamp": "2026-01-23T06:40:10.202929"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9788.82, "latencies_ms": [9788.82], "images_per_second": 0.102, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The bear in the image has a rich golden-brown fur, and the lighting is soft and natural, suggesting it might be a sunny day. The bear is sitting in a grassy area, which adds a contrasting green background to its fur.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24386.3, "ram_available_mb": 38454.6, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24404.2, "ram_available_mb": 38436.7, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.796, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 8.973}, "timestamp": "2026-01-23T06:40:22.019156"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12596.031, "latencies_ms": [12596.031], "images_per_second": 0.079, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a cozy bedroom with a large bed taking up most of the space. The bed is covered with a blue comforter, and there is a window above it, allowing natural light to fill the room. A wooden bookshelf is situated next to the bed, filled with numerous books of various sizes. \n\nIn addition to the books, there are two potted", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24404.2, "ram_available_mb": 38436.7, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24411.8, "ram_available_mb": 38429.1, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.752, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 8.94}, "timestamp": "2026-01-23T06:40:36.685658"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9329.662, "latencies_ms": [9329.662], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 48, "n_tiles": 16, "output_text": "Bed: 1\nBookshelf: 1\nPlants: 2\nBooks: numerous\nBasket: 1\nMirror: 1\nDresser: 1\nWindow: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24411.8, "ram_available_mb": 38429.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24427.4, "ram_available_mb": 38413.5, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.276, "power_cpu_cv_mean_watts": 1.506, "power_sys_5v0_mean_watts": 8.94}, "timestamp": "2026-01-23T06:40:48.074559"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10484.971, "latencies_ms": [10484.971], "images_per_second": 0.095, "prompt_tokens": 44, "response_tokens_est": 60, "n_tiles": 16, "output_text": "The bed is in the foreground on the left side of the image, with a wooden dresser and mirror behind it. The bookshelf is in the background on the right side, filled with books and plants. The window is in the middle ground, providing natural light to the room.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24427.4, "ram_available_mb": 38413.5, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24446.9, "ram_available_mb": 38394.0, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.583, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 8.991}, "timestamp": "2026-01-23T06:41:00.609502"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11660.099, "latencies_ms": [11660.099], "images_per_second": 0.086, "prompt_tokens": 37, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The image depicts a cozy bedroom with a large bed covered in a blue comforter, a wooden dresser with a mirror, and a bookshelf filled with books. The room has a window with a view of greenery outside, and there are potted plants adding a touch of nature to the space.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24384.9, "ram_available_mb": 38456.0, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24385.9, "ram_available_mb": 38455.0, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.295, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 8.912}, "timestamp": "2026-01-23T06:41:14.330051"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9541.994, "latencies_ms": [9541.994], "images_per_second": 0.105, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The room is filled with natural light from the large window, which shows a view of lush green trees outside. The bed is covered with a blue comforter, and there is a wooden bookshelf filled with various books and decorative items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24385.9, "ram_available_mb": 38455.0, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24385.8, "ram_available_mb": 38455.1, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.923, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 9.025}, "timestamp": "2026-01-23T06:41:25.917443"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11424.413, "latencies_ms": [11424.413], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene day at a suburban intersection. Dominating the scene is a stop sign, its octagonal shape and bold red color standing out against the backdrop of a clear blue sky dotted with fluffy white clouds. The sign, mounted on a sturdy black pole, is positioned on the right side of the frame, commanding attention.\n", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24385.8, "ram_available_mb": 38455.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24447.3, "ram_available_mb": 38393.6, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.725, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 8.721}, "timestamp": "2026-01-23T06:41:39.410267"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7367.625, "latencies_ms": [7367.625], "images_per_second": 0.136, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "stop sign: 1, tree: 5, car: 1, building: 1, bush: 3, bench: 1, street: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24368.8, "ram_available_mb": 38472.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24357.9, "ram_available_mb": 38483.0, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.899, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.797}, "timestamp": "2026-01-23T06:41:48.840231"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8482.477, "latencies_ms": [8482.477], "images_per_second": 0.118, "prompt_tokens": 44, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The stop sign is in the foreground on the right side of the image, near the center. In the background, there is a road that curves to the left with a vehicle visible on it, and beyond the road, there are trees and a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24357.9, "ram_available_mb": 38483.0, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24424.8, "ram_available_mb": 38416.1, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.995, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 8.804}, "timestamp": "2026-01-23T06:41:59.351333"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9119.811, "latencies_ms": [9119.811], "images_per_second": 0.11, "prompt_tokens": 37, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image shows a red stop sign with the word \"STOP\" in white letters, mounted on a metal pole at an intersection. The sign is partially obscured by a tree, and the background features a clear sky, some greenery, and a building in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24424.8, "ram_available_mb": 38416.1, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 24444.8, "ram_available_mb": 38396.1, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.757, "power_cpu_cv_mean_watts": 1.816, "power_sys_5v0_mean_watts": 8.754}, "timestamp": "2026-01-23T06:42:10.514403"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8420.069, "latencies_ms": [8420.069], "images_per_second": 0.119, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The stop sign in the image is octagonal and red with white lettering, indicating a command to stop. The sign is mounted on a single metal post and is positioned at an intersection with a clear sky in the background and some greenery around.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24374.8, "ram_available_mb": 38466.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 24445.9, "ram_available_mb": 38395.0, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.089, "power_cpu_cv_mean_watts": 2.235, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T06:42:20.958662"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11407.144, "latencies_ms": [11407.144], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there are three teddy bears of different sizes and colors, all sitting together on a couch. The largest teddy bear is positioned in the center, with the other two smaller ones on either side of it. The teddy bears are arranged in a way that they appear to be hugging each other, creating a sense of warmth and togethern", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24373.4, "ram_available_mb": 38467.5, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 24445.1, "ram_available_mb": 38395.8, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.767, "power_cpu_cv_mean_watts": 2.032, "power_sys_5v0_mean_watts": 8.779}, "timestamp": "2026-01-23T06:42:34.408579"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10688.427, "latencies_ms": [10688.427], "images_per_second": 0.094, "prompt_tokens": 39, "response_tokens_est": 71, "n_tiles": 16, "output_text": "- Teddy bear: 3\n- Stuffed animal: 3\n- Stuffed animal: 3\n- Stuffed animal: 3\n- Stuffed animal: 3\n- Stuffed animal: 3\n- Stuffed animal: 3\n- Stuffed animal: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24364.2, "ram_available_mb": 38476.7, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24381.7, "ram_available_mb": 38459.2, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.1, "power_cpu_cv_mean_watts": 1.871, "power_sys_5v0_mean_watts": 8.74}, "timestamp": "2026-01-23T06:42:47.124913"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11462.042, "latencies_ms": [11462.042], "images_per_second": 0.087, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the foreground, there is a large brown teddy bear with a smaller one in front of it, both are positioned close to each other, suggesting a sense of closeness or affection. In the background, there is a blue blanket, which is partially visible and appears to be underneath the teddy bears, indicating that they are placed on top of it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24381.7, "ram_available_mb": 38459.2, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24452.5, "ram_available_mb": 38388.4, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.525, "power_cpu_cv_mean_watts": 1.938, "power_sys_5v0_mean_watts": 8.744}, "timestamp": "2026-01-23T06:43:00.617705"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7816.763, "latencies_ms": [7816.763], "images_per_second": 0.128, "prompt_tokens": 37, "response_tokens_est": 46, "n_tiles": 16, "output_text": "Three teddy bears are huddled together on a couch, creating a cozy and comforting scene. The bears appear to be snuggled up close, possibly for warmth or companionship.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24372.0, "ram_available_mb": 38468.9, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24395.1, "ram_available_mb": 38445.8, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.444, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 8.794}, "timestamp": "2026-01-23T06:43:10.490133"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7533.365, "latencies_ms": [7533.365], "images_per_second": 0.133, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image features three teddy bears with a warm, golden-brown color palette. The lighting appears to be soft and diffused, highlighting the plush texture of the bears' fur.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24395.1, "ram_available_mb": 38445.8, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24448.4, "ram_available_mb": 38392.5, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.421, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T06:43:20.046302"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11473.217, "latencies_ms": [11473.217], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a woman is skiing down a snowy hill on a sunny day. She is wearing a red and black ski jacket, and her skis are visible as she glides through the snow. The woman is holding ski poles, which help her maintain balance and control as she descends the slope. The snowy hill provides a picturesque backdrop for her", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24375.8, "ram_available_mb": 38465.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24381.9, "ram_available_mb": 38459.0, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.471, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 8.747}, "timestamp": "2026-01-23T06:43:33.561094"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8720.309, "latencies_ms": [8720.309], "images_per_second": 0.115, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "hill: 1, red jacket: 1, black pants: 1, ski poles: 2, snow: 1, blue boots: 1, white snow: 1, red and white striped hat: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24381.9, "ram_available_mb": 38459.0, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24387.8, "ram_available_mb": 38453.1, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.797, "power_cpu_cv_mean_watts": 1.738, "power_sys_5v0_mean_watts": 8.778}, "timestamp": "2026-01-23T06:43:44.301251"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10388.389, "latencies_ms": [10388.389], "images_per_second": 0.096, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The skier is positioned in the foreground of the image, actively skiing down the slope. The red poles are held in the skier's hands, aiding in balance and direction. In the background, there are red poles lined up on the snow, possibly indicating a boundary or path for skiers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24387.8, "ram_available_mb": 38453.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24373.7, "ram_available_mb": 38467.2, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.885, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 8.785}, "timestamp": "2026-01-23T06:43:56.720111"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8980.963, "latencies_ms": [8980.963], "images_per_second": 0.111, "prompt_tokens": 37, "response_tokens_est": 56, "n_tiles": 16, "output_text": "A person is skiing on a snowy slope with red poles and wearing a red and black jacket, black pants, and a striped hat. The background shows a snowy mountain with red poles marking the boundaries of the skiing area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24373.7, "ram_available_mb": 38467.2, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24474.6, "ram_available_mb": 38366.3, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.645, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 8.77}, "timestamp": "2026-01-23T06:44:07.761221"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6676.494, "latencies_ms": [6676.494], "images_per_second": 0.15, "prompt_tokens": 36, "response_tokens_est": 38, "n_tiles": 16, "output_text": "The skier is wearing a red and black jacket, black pants, and blue skis. The sky is overcast and the snow appears to be freshly fallen.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24371.0, "ram_available_mb": 38469.9, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24389.9, "ram_available_mb": 38451.0, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.019, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T06:44:16.471251"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11401.585, "latencies_ms": [11401.585], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a cozy kitchen scene. Dominating the space is a white refrigerator, standing tall on the right side of the frame. Adjacent to it, a white oven and a white dishwasher are neatly arranged, their pristine surfaces reflecting the light. A white microwave is tucked away on the left side,", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24389.9, "ram_available_mb": 38451.0, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24371.3, "ram_available_mb": 38469.6, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.526, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.771}, "timestamp": "2026-01-23T06:44:29.907772"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8600.979, "latencies_ms": [8600.979], "images_per_second": 0.116, "prompt_tokens": 39, "response_tokens_est": 53, "n_tiles": 16, "output_text": "refrigerator: 1, oven: 1, stove: 1, dishwasher: 1, microwave: 1, cabinet: 4, drawer: 1, countertop: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24371.3, "ram_available_mb": 38469.6, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24370.6, "ram_available_mb": 38470.2, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.852, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.789}, "timestamp": "2026-01-23T06:44:40.542072"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8789.36, "latencies_ms": [8789.36], "images_per_second": 0.114, "prompt_tokens": 44, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The refrigerator is located in the background, towards the right side of the image, while the oven is in the foreground on the left side. The drawer is situated between the oven and the refrigerator, closer to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24370.6, "ram_available_mb": 38470.2, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24369.8, "ram_available_mb": 38471.1, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.663, "power_cpu_cv_mean_watts": 1.8, "power_sys_5v0_mean_watts": 8.841}, "timestamp": "2026-01-23T06:44:51.374980"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9056.985, "latencies_ms": [9056.985], "images_per_second": 0.11, "prompt_tokens": 37, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image shows a small, well-lit kitchen with wooden cabinets and white appliances. There is a white refrigerator on the right side, a white oven and dishwasher on the left, and a wooden drawer in the center.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24369.8, "ram_available_mb": 38471.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24360.9, "ram_available_mb": 38480.0, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.761, "power_cpu_cv_mean_watts": 1.8, "power_sys_5v0_mean_watts": 8.816}, "timestamp": "2026-01-23T06:45:02.480392"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7527.552, "latencies_ms": [7527.552], "images_per_second": 0.133, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The kitchen has wooden cabinets and white appliances, with a light brownish-beige wall and beige tiled floor. The lighting appears to be artificial, coming from ceiling fixtures.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24360.9, "ram_available_mb": 38480.0, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24388.2, "ram_available_mb": 38452.7, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.529, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T06:45:12.022427"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12611.334, "latencies_ms": [12611.334], "images_per_second": 0.079, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there are two men playing baseball on a field. One man is running towards the base, while the other is throwing the ball. The baseball player running is wearing a blue helmet and a baseball glove, and he is in motion, likely trying to reach the base before the ball is caught. The other player is standing and holding a baseball glove, ready to catch", "error": null, "sys_before": {"cpu_percent": 8.8, "ram_used_mb": 24388.2, "ram_available_mb": 38452.7, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24392.1, "ram_available_mb": 38448.8, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.856, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 9.014}, "timestamp": "2026-01-23T06:45:26.669436"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 12973.703, "latencies_ms": [12973.703], "images_per_second": 0.077, "prompt_tokens": 39, "response_tokens_est": 81, "n_tiles": 16, "output_text": "1. Player: 2\n2. Pitcher: 1\n3. Baseball glove: 1\n4. Baseball: 1\n5. Pitcher's mound: 1\n6. Pitcher's arm: 1\n7. Pitcher's hand: 1\n8. Pitcher's wristband", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24392.1, "ram_available_mb": 38448.8, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24389.1, "ram_available_mb": 38451.8, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.86, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 8.981}, "timestamp": "2026-01-23T06:45:41.665178"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12024.538, "latencies_ms": [12024.538], "images_per_second": 0.083, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "In the foreground, there is a baseball player in a white shirt and gray pants running towards the left side of the image, while another player in a green shirt and gray pants is standing and holding a baseball glove to the right side of the image. The background consists of a grassy field with trees and a wooden fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24389.1, "ram_available_mb": 38451.8, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24414.7, "ram_available_mb": 38426.2, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.032, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 9.043}, "timestamp": "2026-01-23T06:45:55.728579"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7591.218, "latencies_ms": [7591.218], "images_per_second": 0.132, "prompt_tokens": 37, "response_tokens_est": 33, "n_tiles": 16, "output_text": "Two men are playing baseball on a field with trees in the background. One man is running towards the base while the other is preparing to throw the ball.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24414.7, "ram_available_mb": 38426.2, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 24367.6, "ram_available_mb": 38473.3, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.4, "power_cpu_cv_mean_watts": 1.308, "power_sys_5v0_mean_watts": 9.074}, "timestamp": "2026-01-23T06:46:05.370422"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9645.65, "latencies_ms": [9645.65], "images_per_second": 0.104, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image shows two individuals playing baseball on a field with a clear sky above. The person in the foreground is wearing a white shirt and grey pants, while the person in the background is wearing a green cap and a green shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24367.6, "ram_available_mb": 38473.3, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24440.4, "ram_available_mb": 38400.5, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.965, "power_cpu_cv_mean_watts": 1.617, "power_sys_5v0_mean_watts": 9.109}, "timestamp": "2026-01-23T06:46:17.057275"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11483.521, "latencies_ms": [11483.521], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a tennis player in the midst of a powerful swing, holding a tennis racket and preparing to hit the ball. The player is positioned on a tennis court, with a blue wall in the background featuring a J.P. Morgan logo. There are several other people in the scene, likely spectators or fellow players, watching the game. The tennis player is focused on", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24377.0, "ram_available_mb": 38463.9, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 24447.6, "ram_available_mb": 38393.3, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.45, "power_cpu_cv_mean_watts": 2.441, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T06:46:30.570676"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9172.338, "latencies_ms": [9172.338], "images_per_second": 0.109, "prompt_tokens": 39, "response_tokens_est": 58, "n_tiles": 16, "output_text": "- J.P. Morgan: 1\n- Wall: 1\n- Man: 1\n- Tennis racket: 1\n- Tennis ball: 1\n- Tennis court: 1\n- Fan: 1\n- Spectator: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24447.6, "ram_available_mb": 38393.3, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24496.4, "ram_available_mb": 38344.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.662, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T06:46:41.802737"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11431.8, "latencies_ms": [11431.8], "images_per_second": 0.087, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a tennis player is positioned on the court, holding a tennis racket and preparing to hit a ball. The player is near the baseline, which is the line closest to the net. In the background, there is a wall with the J.P. Morgan logo, and a few spectators are seated behind it. To the right of the player,", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24382.7, "ram_available_mb": 38458.2, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24386.9, "ram_available_mb": 38454.0, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.525, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.815}, "timestamp": "2026-01-23T06:46:55.283044"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6863.778, "latencies_ms": [6863.778], "images_per_second": 0.146, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A tennis player is in the midst of a backhand swing on a tennis court. The J.P. Morgan logo is prominently displayed on the back wall of the court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24386.9, "ram_available_mb": 38454.0, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24375.3, "ram_available_mb": 38465.6, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.298, "power_cpu_cv_mean_watts": 1.553, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T06:47:04.169564"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5655.696, "latencies_ms": [5655.696], "images_per_second": 0.177, "prompt_tokens": 36, "response_tokens_est": 29, "n_tiles": 16, "output_text": "The tennis player is wearing a white cap and a white and blue striped shirt. The court is blue with a green surface.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24375.3, "ram_available_mb": 38465.6, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24401.4, "ram_available_mb": 38439.5, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.189, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 8.971}, "timestamp": "2026-01-23T06:47:11.848632"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11425.961, "latencies_ms": [11425.961], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of young children gathered together on a tennis court. They are posing for a picture, with some of them holding tennis rackets. The children are standing in front of a tennis net, which divides the court into two halves. The scene captures a moment of camaraderie and shared interest among the kids as they enjoy their time on the court.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24401.4, "ram_available_mb": 38439.5, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24460.8, "ram_available_mb": 38380.1, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.476, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.775}, "timestamp": "2026-01-23T06:47:25.352863"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8357.06, "latencies_ms": [8357.06], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "children: 11\nbags: 2\nrackets: 2\nsneakers: 5\nhats: 7\nt-shirts: 3\nnets: 2\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24372.3, "ram_available_mb": 38468.6, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24381.2, "ram_available_mb": 38459.7, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.069, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T06:47:35.720744"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11420.87, "latencies_ms": [11420.87], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a group of children is gathered near a tennis court, with some standing closer to the camera and others further away, creating a sense of depth. The children are positioned in front of a green fence that serves as the background, indicating that the tennis court is enclosed. The children are standing on a blue surface, likely the tennis court itself, which is the central", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24381.2, "ram_available_mb": 38459.7, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24478.1, "ram_available_mb": 38362.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.609, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 8.819}, "timestamp": "2026-01-23T06:47:49.205872"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8497.287, "latencies_ms": [8497.287], "images_per_second": 0.118, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "A group of children and one adult are gathered on a tennis court, with the adult holding a trophy, suggesting a tennis-related event or competition. The setting appears to be outdoors, with trees and a fence visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24397.8, "ram_available_mb": 38443.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24391.2, "ram_available_mb": 38449.7, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.833, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 8.795}, "timestamp": "2026-01-23T06:47:59.716533"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8279.531, "latencies_ms": [8279.531], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The image shows a group of children on a tennis court with a bright and sunny day, casting shadows on the ground. They are wearing various sports attire, including white, red, and black, and some are wearing hats.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24391.2, "ram_available_mb": 38449.7, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24476.8, "ram_available_mb": 38364.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.88, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T06:48:10.014693"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11438.064, "latencies_ms": [11438.064], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene scene by a body of water, possibly a river or a lake. A woman is standing on the left side of the frame, holding a camera and taking a picture of a bird on the shore. There are several other people in the scene, with some sitting on the ground and others standing. \n\nIn the background, a boat can be seen on the", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24364.3, "ram_available_mb": 38476.6, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24439.9, "ram_available_mb": 38401.0, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.439, "power_cpu_cv_mean_watts": 1.97, "power_sys_5v0_mean_watts": 8.772}, "timestamp": "2026-01-23T06:48:23.510359"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7250.527, "latencies_ms": [7250.527], "images_per_second": 0.138, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "people: 3, birds: 1, camera: 1, backpack: 1, water: 1, sun: 1, buildings: 1, trees: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24368.0, "ram_available_mb": 38472.9, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24369.3, "ram_available_mb": 38471.6, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.757, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T06:48:32.796804"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11444.927, "latencies_ms": [11444.927], "images_per_second": 0.087, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a paved walkway where a person is taking a photo of a bird on the ground. To the left, two individuals are seated on the edge of the walkway, observing the scene. In the background, there is a body of water with a boat and buildings along the shore. The bird is positioned near the center of the image, closer", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24369.3, "ram_available_mb": 38471.6, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24468.3, "ram_available_mb": 38372.6, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.461, "power_cpu_cv_mean_watts": 1.946, "power_sys_5v0_mean_watts": 8.793}, "timestamp": "2026-01-23T06:48:46.281583"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6864.459, "latencies_ms": [6864.459], "images_per_second": 0.146, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "The image depicts a serene scene by a river with a bridge overhead. People are sitting on the edge of the riverbank, observing a heron in the water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24363.7, "ram_available_mb": 38477.2, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24378.4, "ram_available_mb": 38462.5, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.208, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T06:48:55.206808"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11317.585, "latencies_ms": [11317.585], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 78, "n_tiles": 16, "output_text": "The image features a serene waterfront scene with a curved metal structure overhead, likely a bridge or an awning, casting shadows on the ground. The lighting suggests it's either early morning or late afternoon, with the sun low in the sky, creating a warm glow and highlighting the calm water and the presence of a single white bird on the shore.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24378.4, "ram_available_mb": 38462.5, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24438.1, "ram_available_mb": 38402.8, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.556, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.786}, "timestamp": "2026-01-23T06:49:08.581466"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11434.004, "latencies_ms": [11434.004], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the image, a woman is standing and holding a cell phone in her hands. She is wearing a white shirt and has a bracelet on her wrist. The woman appears to be looking at the phone screen, possibly reading a message or browsing the internet. The cell phone is positioned in her right hand, and she seems to be focused on the device.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24438.1, "ram_available_mb": 38402.8, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24445.4, "ram_available_mb": 38395.5, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.455, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.813}, "timestamp": "2026-01-23T06:49:22.063344"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11627.042, "latencies_ms": [11627.042], "images_per_second": 0.086, "prompt_tokens": 39, "response_tokens_est": 81, "n_tiles": 16, "output_text": "1. Hello Kitty phone case: 1\n2. Woman's face: 1\n3. Woman's hand: 1\n4. Woman's bracelet: 1\n5. Woman's ring: 1\n6. Woman's watch: 1\n7. Woman's ear: 1\n8. Woman's", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24375.0, "ram_available_mb": 38465.9, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24374.4, "ram_available_mb": 38466.5, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.617, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.767}, "timestamp": "2026-01-23T06:49:35.711712"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11161.53, "latencies_ms": [11161.53], "images_per_second": 0.09, "prompt_tokens": 44, "response_tokens_est": 76, "n_tiles": 16, "output_text": "The woman is holding a phone in her right hand, which is positioned in the foreground of the image. The phone screen displays the text \"HELLO KITTY,\" indicating it is the main object of focus. In the background, there are blurred figures of other people, suggesting that the woman is not alone and is possibly in a public space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24374.4, "ram_available_mb": 38466.5, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24366.9, "ram_available_mb": 38474.0, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.541, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.771}, "timestamp": "2026-01-23T06:49:48.898703"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8168.972, "latencies_ms": [8168.972], "images_per_second": 0.122, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A woman is holding a phone case with the text \"HELLO KITTY\" on it, while wearing a bracelet and a ring. She is wearing a sleeveless top with a graphic design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24366.9, "ram_available_mb": 38474.0, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24375.6, "ram_available_mb": 38465.3, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.182, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 8.816}, "timestamp": "2026-01-23T06:49:59.099191"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8461.486, "latencies_ms": [8461.486], "images_per_second": 0.118, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image features a person holding a phone with a case that has a Hello Kitty design on it. The person is wearing a white sleeveless top with a black and white pattern, and a green bracelet on their wrist.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24375.6, "ram_available_mb": 38465.3, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24397.0, "ram_available_mb": 38443.9, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.742, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T06:50:09.586899"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11429.087, "latencies_ms": [11429.087], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a group of children is gathered around a red and white striped carousel horse, which is positioned on a wooden floor. The children are sitting on the horse, with some of them hugging each other, creating a sense of camaraderie and excitement. The carousel horse is the central focus of the scene, and the children are enjoying their time together", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24397.0, "ram_available_mb": 38443.9, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24368.8, "ram_available_mb": 38472.1, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.481, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T06:50:23.060061"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10142.253, "latencies_ms": [10142.253], "images_per_second": 0.099, "prompt_tokens": 39, "response_tokens_est": 66, "n_tiles": 16, "output_text": "- children: 5\n\n- red and white striped barrier: 1\n\n- stage: 1\n\n- microphone stand: 1\n\n- floor: 1\n\n- wall: 1\n\n- ceiling: 1\n\n- light fixture: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24368.8, "ram_available_mb": 38472.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 24433.2, "ram_available_mb": 38407.7, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.135, "power_cpu_cv_mean_watts": 2.163, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T06:50:35.219450"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11497.564, "latencies_ms": [11497.564], "images_per_second": 0.087, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a red and white striped barrel with a group of children sitting inside it, positioned towards the left side of the image. The children are seated closely together, with one child in the front wearing a black jacket and another in the back wearing a white hoodie. In the background, there is a yellow and red striped object", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24371.6, "ram_available_mb": 38469.3, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 24436.3, "ram_available_mb": 38404.6, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.476, "power_cpu_cv_mean_watts": 2.142, "power_sys_5v0_mean_watts": 8.797}, "timestamp": "2026-01-23T06:50:48.750987"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8497.175, "latencies_ms": [8497.175], "images_per_second": 0.118, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "A group of children is seated on a red and white striped carousel ride inside a building with a wooden floor and a brick wall in the background. The children appear to be enjoying the ride, with some looking ahead and others looking around.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24374.2, "ram_available_mb": 38466.7, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24460.7, "ram_available_mb": 38380.2, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.921, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 8.81}, "timestamp": "2026-01-23T06:50:59.281371"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7186.733, "latencies_ms": [7186.733], "images_per_second": 0.139, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image shows a group of children sitting on a red and white striped carousel ride inside a building with wooden flooring and brick walls. The lighting is dim, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24399.1, "ram_available_mb": 38441.8, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24446.8, "ram_available_mb": 38394.1, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.673, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.932}, "timestamp": "2026-01-23T06:51:08.489912"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12548.244, "latencies_ms": [12548.244], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of tranquility, featuring a black and white photograph of a sandwich on a white plate. The sandwich, which is the main subject of the image, is composed of two slices of bread, one of which is slightly larger than the other. The larger slice is filled with a dark substance, possibly a type of meat or vegetable, and the", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24366.7, "ram_available_mb": 38474.2, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24380.7, "ram_available_mb": 38460.2, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.839, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 9.059}, "timestamp": "2026-01-23T06:51:23.080231"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8814.43, "latencies_ms": [8814.43], "images_per_second": 0.113, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "plate: 1\nbread: 1\nfilling: 1\nknife: 1\nperson: 1\nbackground: 1\nlighting: 1\ncolor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24380.7, "ram_available_mb": 38460.2, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24363.8, "ram_available_mb": 38477.1, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.697, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 9.05}, "timestamp": "2026-01-23T06:51:33.924201"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11846.871, "latencies_ms": [11846.871], "images_per_second": 0.084, "prompt_tokens": 44, "response_tokens_est": 72, "n_tiles": 16, "output_text": "The sandwich is positioned in the foreground, occupying the central space of the plate. It is placed near the edge of the plate, with a clear space around it. In the background, there is a blurred object that appears to be a cup or container, suggesting it is further away from the viewer than the sandwich.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24363.8, "ram_available_mb": 38477.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24408.6, "ram_available_mb": 38432.3, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.162, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 9.091}, "timestamp": "2026-01-23T06:51:47.815445"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10351.928, "latencies_ms": [10351.928], "images_per_second": 0.097, "prompt_tokens": 37, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image shows a close-up of a sandwich on a white plate, with a blurred background that suggests a dining setting. The sandwich appears to be a burger with a bun, and there is a small container of sauce on the side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24408.6, "ram_available_mb": 38432.3, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24391.8, "ram_available_mb": 38449.1, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.808, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 9.009}, "timestamp": "2026-01-23T06:52:00.221927"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10890.854, "latencies_ms": [10890.854], "images_per_second": 0.092, "prompt_tokens": 36, "response_tokens_est": 64, "n_tiles": 16, "output_text": "The image is a black and white photograph, focusing on a sandwich with a visible filling that appears to be a creamy substance, possibly cheese or a spread. The lighting is soft and diffused, casting gentle shadows and highlighting the textures of the sandwich and the plate.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 24391.8, "ram_available_mb": 38449.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24475.4, "ram_available_mb": 38365.5, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.522, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 9.101}, "timestamp": "2026-01-23T06:52:13.129557"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12375.737, "latencies_ms": [12375.737], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of tranquility and balance, featuring a person paddleboarding on a vast body of water. The individual, clad in a wetsuit, stands confidently on a paddleboard, holding a paddle in their hands. The water, a deep shade of blue, stretches out to meet a distant shoreline, where a few", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24371.0, "ram_available_mb": 38469.9, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24386.4, "ram_available_mb": 38454.5, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.577, "power_cpu_cv_mean_watts": 1.816, "power_sys_5v0_mean_watts": 9.035}, "timestamp": "2026-01-23T06:52:27.560653"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8487.89, "latencies_ms": [8487.89], "images_per_second": 0.118, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "water: numerous\npaddle: 1\nsurfboard: 1\nperson: 1\nwetsuit: 1\nsand: numerous\ntrees: numerous\nhouses: numerous", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24386.4, "ram_available_mb": 38454.5, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24484.1, "ram_available_mb": 38356.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.286, "power_cpu_cv_mean_watts": 1.466, "power_sys_5v0_mean_watts": 8.992}, "timestamp": "2026-01-23T06:52:38.062923"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10526.146, "latencies_ms": [10526.146], "images_per_second": 0.095, "prompt_tokens": 44, "response_tokens_est": 63, "n_tiles": 16, "output_text": "The person is standing on a paddleboard in the foreground, closer to the viewer, while the waves and the horizon line are in the background, indicating they are further away. The paddleboarder is positioned near the center of the image, creating a sense of balance in the composition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24395.6, "ram_available_mb": 38445.3, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24397.2, "ram_available_mb": 38443.7, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.049, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 9.052}, "timestamp": "2026-01-23T06:52:50.620898"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7502.193, "latencies_ms": [7502.193], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "A person is paddleboarding in the ocean, with a coastline in the background. The image is in black and white, giving it a timeless feel.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24397.2, "ram_available_mb": 38443.7, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 24393.5, "ram_available_mb": 38447.4, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.986, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 9.058}, "timestamp": "2026-01-23T06:53:00.149951"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8035.87, "latencies_ms": [8035.87], "images_per_second": 0.124, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image is in black and white, featuring a person paddleboarding on a calm body of water. The sky is overcast, and the weather appears to be clear with no visible precipitation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24393.5, "ram_available_mb": 38447.4, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24386.4, "ram_available_mb": 38454.5, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.247, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 9.124}, "timestamp": "2026-01-23T06:53:10.235564"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11374.687, "latencies_ms": [11374.687], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene of a workspace, bathed in soft light. Dominating the scene is a white desk, its surface a testament to a busy mind at work. On the left, a laptop sits open, its screen glowing with unseen information. To its right, a desktop computer stands tall, its monitor displaying a window filled with text. A white", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24386.4, "ram_available_mb": 38454.5, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24458.6, "ram_available_mb": 38382.3, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.456, "power_cpu_cv_mean_watts": 1.95, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T06:53:23.653767"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7291.246, "latencies_ms": [7291.246], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "computer: 2, mouse: 1, keyboard: 1, monitor: 1, lamp: 1, figurine: 1, speaker: 2, desk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24386.8, "ram_available_mb": 38454.1, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24471.1, "ram_available_mb": 38369.8, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.817, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.904}, "timestamp": "2026-01-23T06:53:32.977968"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11400.659, "latencies_ms": [11400.659], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a laptop on the left side of the desk, which is positioned near the center of the image. A desktop computer with a monitor is in the background, slightly to the right of the center. A keyboard and a mouse are placed in front of the desktop, with the mouse to the left of the keyboard. Two speakers are located on the right side", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 24417.7, "ram_available_mb": 38423.2, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24412.9, "ram_available_mb": 38428.0, "ram_percent": 38.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.526, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T06:53:46.394504"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7842.817, "latencies_ms": [7842.817], "images_per_second": 0.128, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The image depicts a home office setup with a desktop computer, a laptop, and a pair of speakers on a desk. There is a window with blinds partially open, allowing natural light to enter the room.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24412.9, "ram_available_mb": 38428.0, "ram_percent": 38.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24429.4, "ram_available_mb": 38411.5, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.359, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 8.879}, "timestamp": "2026-01-23T06:53:56.292937"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8000.933, "latencies_ms": [8000.933], "images_per_second": 0.125, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image shows a workspace with a white color scheme, including a white desk, a white computer monitor, and a white keyboard. The lighting appears to be artificial, coming from a lamp on the right side of the desk.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24429.4, "ram_available_mb": 38411.5, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24487.1, "ram_available_mb": 38353.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.15, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 8.944}, "timestamp": "2026-01-23T06:54:06.325752"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11380.732, "latencies_ms": [11380.732], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a bustling scene on a highway. Dominating the frame is a green highway sign, standing tall on a concrete overpass. The sign is a guide for travelers, pointing towards three major destinations: North 101, Hollywood Blvd, and Sunset Blvd. Each destination is clearly marked with white text and arrows, indicating the direction to take", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24487.1, "ram_available_mb": 38353.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24505.3, "ram_available_mb": 38335.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.538, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.813}, "timestamp": "2026-01-23T06:54:19.729835"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9372.514, "latencies_ms": [9372.514], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 60, "n_tiles": 16, "output_text": "- Taxi: 1\n\n- Van: 2\n\n- Suv: 3\n\n- Truck: 1\n\n- Car: 2\n\n- Overpass: 1\n\n- Exit sign: 1\n\n- Tree: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24505.3, "ram_available_mb": 38335.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24483.6, "ram_available_mb": 38357.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.481, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.809}, "timestamp": "2026-01-23T06:54:31.128694"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11383.74, "latencies_ms": [11383.74], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a black SUV with the license plate LC10055, positioned on the right side of the road. In the background, there is a white van and a silver taxi, both on the left side of the road. The main objects, which are the vehicles, are spatially arranged in a way that the black SUV is closest", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24483.6, "ram_available_mb": 38357.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24488.6, "ram_available_mb": 38352.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.584, "power_cpu_cv_mean_watts": 2.255, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T06:54:44.566834"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10454.471, "latencies_ms": [10454.471], "images_per_second": 0.096, "prompt_tokens": 37, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The image shows a busy highway scene with multiple vehicles, including a black SUV and a white van, traveling on a multi-lane road. Above the road, there is an overpass with green directional signs indicating the lanes for North 101 towards Ventura, Hollywood Blvd, and Sunset Blvd.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24488.6, "ram_available_mb": 38352.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 24558.5, "ram_available_mb": 38282.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.159, "power_cpu_cv_mean_watts": 2.109, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T06:54:57.063117"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6648.496, "latencies_ms": [6648.496], "images_per_second": 0.15, "prompt_tokens": 36, "response_tokens_est": 38, "n_tiles": 16, "output_text": "The image shows a clear day with bright sunlight casting shadows under the overpass. The overpass is constructed with concrete and metal, and the signs are green with white text.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24445.8, "ram_available_mb": 38395.1, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24533.6, "ram_available_mb": 38307.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.052, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.96}, "timestamp": "2026-01-23T06:55:05.726049"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12519.373, "latencies_ms": [12519.373], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a vibrant scene on a city street. Dominating the frame is a red double-decker bus, a common sight in many cities around the world. The bus is in motion, driving on the right side of the road, as indicated by the white lines on the road. The license plate of the bus reads \"ALM 898\", a detail that", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 24533.6, "ram_available_mb": 38307.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24487.3, "ram_available_mb": 38353.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.95, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 9.067}, "timestamp": "2026-01-23T06:55:20.268927"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8746.634, "latencies_ms": [8746.634], "images_per_second": 0.114, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "bus: 1, window: many, license plate: 1, advertisement: 1, pedestrian: 1, building: 1, tree: many, sky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24487.3, "ram_available_mb": 38353.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24547.2, "ram_available_mb": 38293.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.63, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 9.051}, "timestamp": "2026-01-23T06:55:31.069938"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10130.867, "latencies_ms": [10130.867], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The red double-decker bus is in the foreground of the image, driving on the road. In the background, there are other vehicles, including a white van on the right side of the image. The bus is closer to the camera than the buildings in the distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24465.3, "ram_available_mb": 38375.6, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24520.3, "ram_available_mb": 38320.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.711, "power_cpu_cv_mean_watts": 1.625, "power_sys_5v0_mean_watts": 9.119}, "timestamp": "2026-01-23T06:55:43.238660"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9543.331, "latencies_ms": [9543.331], "images_per_second": 0.105, "prompt_tokens": 37, "response_tokens_est": 50, "n_tiles": 16, "output_text": "A red double-decker bus is driving on a city street with buildings in the background. The bus has a sign that reads \"St. Paul's Cathedral Aldwych\" and a number \"15\" on the front.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24520.3, "ram_available_mb": 38320.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24460.0, "ram_available_mb": 38380.9, "ram_percent": 38.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.406, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 9.063}, "timestamp": "2026-01-23T06:55:54.799867"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9624.254, "latencies_ms": [9624.254], "images_per_second": 0.104, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image features a vibrant red double-decker bus with a clear sky in the background, suggesting a sunny day. The bus is adorned with advertisements and the number 15 is prominently displayed on the front.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24460.0, "ram_available_mb": 38380.9, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24486.7, "ram_available_mb": 38354.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.083, "power_cpu_cv_mean_watts": 1.587, "power_sys_5v0_mean_watts": 9.121}, "timestamp": "2026-01-23T06:56:06.441959"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11369.808, "latencies_ms": [11369.808], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a black and white cat is the main subject, lying on top of an open laptop. The cat's fur is a mix of black and white, with its eyes looking directly at the camera, giving it a somewhat serious expression. The laptop, which is silver in color, is placed on a white surface. The keyboard of the laptop is visible, and the word \"WOR", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24486.7, "ram_available_mb": 38354.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24491.6, "ram_available_mb": 38349.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.514, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T06:56:19.842587"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7279.505, "latencies_ms": [7279.505], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "cat: 1, keyboard: 1, laptop: 1, paper: 1, pen: 1, screwdriver: 1, cloth: 1, box: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24491.6, "ram_available_mb": 38349.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24557.8, "ram_available_mb": 38283.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.943, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T06:56:29.151069"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9760.727, "latencies_ms": [9760.727], "images_per_second": 0.102, "prompt_tokens": 44, "response_tokens_est": 65, "n_tiles": 16, "output_text": "The cat is positioned in the foreground on the left side of the image, partially obscuring the laptop keyboard which is in the foreground on the right side. The laptop is placed on a surface that appears to be a desk or table, and the background is a plain, light-colored wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24460.8, "ram_available_mb": 38380.1, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24479.3, "ram_available_mb": 38361.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.175, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T06:56:40.945626"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8087.082, "latencies_ms": [8087.082], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A black and white cat with striking yellow eyes is lying down on top of an open laptop, partially covering the keyboard. The cat appears to be resting or sleeping, with its body stretched out across the laptop's surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24479.3, "ram_available_mb": 38361.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24533.9, "ram_available_mb": 38307.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.173, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 8.872}, "timestamp": "2026-01-23T06:56:51.086249"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8247.659, "latencies_ms": [8247.659], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The image features a black cat with striking yellow eyes lying on a white surface, possibly a desk or table. The lighting in the image is bright, illuminating the cat's fur and the keys of the laptop in front of it.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24533.9, "ram_available_mb": 38307.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24549.4, "ram_available_mb": 38291.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.95, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 8.914}, "timestamp": "2026-01-23T06:57:01.346459"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11342.388, "latencies_ms": [11342.388], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a breathtaking view of the Sydney Harbour Bridge in Australia. The bridge, a marvel of engineering, is a large steel arch structure painted in a sleek black color. It spans across the water, connecting the two sides of the harbor. \n\nIn the sky above, two airplanes are captured mid-flight. They are flying", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24478.3, "ram_available_mb": 38362.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24545.8, "ram_available_mb": 38295.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.546, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T06:57:14.743354"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8812.131, "latencies_ms": [8812.131], "images_per_second": 0.113, "prompt_tokens": 39, "response_tokens_est": 55, "n_tiles": 16, "output_text": "- Airplanes: 2\n- Clouds: 1\n- Bridge: 1\n- Cars: 1\n- Bus: 1\n- Water: 1\n- Cityscape: 1\n- Trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24474.1, "ram_available_mb": 38366.8, "ram_percent": 38.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24572.9, "ram_available_mb": 38268.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.901, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T06:57:25.568523"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11417.788, "latencies_ms": [11417.788], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a large, curved bridge spanning across the image, with two airplanes flying in the background. The airplanes are positioned in the sky, with one flying higher and to the right of the bridge, and the other flying lower and to the left of the bridge. The bridge appears to be in the middle ground of the image, with the", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24501.2, "ram_available_mb": 38339.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24511.1, "ram_available_mb": 38329.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.528, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T06:57:39.018643"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6508.882, "latencies_ms": [6508.882], "images_per_second": 0.154, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "Two airplanes are flying in formation over the Sydney Harbour Bridge in Australia. The sky is cloudy and the city skyline can be seen in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24511.1, "ram_available_mb": 38329.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24493.9, "ram_available_mb": 38347.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.608, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 8.917}, "timestamp": "2026-01-23T06:57:47.547721"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9548.604, "latencies_ms": [9548.604], "images_per_second": 0.105, "prompt_tokens": 36, "response_tokens_est": 63, "n_tiles": 16, "output_text": "The sky is overcast with a mix of white and gray clouds, and the lighting is diffused, with no harsh shadows visible. Two airplanes, one with a red and white color scheme and the other with a darker color scheme, are flying in the sky above the bridge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24493.9, "ram_available_mb": 38347.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24582.2, "ram_available_mb": 38258.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.293, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 8.885}, "timestamp": "2026-01-23T06:57:59.132511"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11356.51, "latencies_ms": [11356.51], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment in the wild, featuring two zebras in a grassy field. The zebra on the left, with its distinctive black and white stripes, is facing the camera, its head turned to the right. Its mane is a lighter shade of black, contrasting with the darker stripes on its body. The zebra on", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24582.2, "ram_available_mb": 38258.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24616.3, "ram_available_mb": 38224.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.585, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T06:58:12.545919"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9825.761, "latencies_ms": [9825.761], "images_per_second": 0.102, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "zebra: 2\n\nhair: numerous\n\nstripes: numerous\n\ngrass: sparse\n\nground: visible\n\nzebra's head: 1\n\nzebra's neck: 1\n\nzebra's body: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24520.3, "ram_available_mb": 38320.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24607.1, "ram_available_mb": 38233.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.258, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T06:58:24.394365"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11347.448, "latencies_ms": [11347.448], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a zebra's head and neck prominently displayed, with its head turned towards the left side of the image, suggesting it is looking or facing in that direction. The background is filled with the full body of another zebra, which is positioned to the right of the foreground zebra, creating a sense of depth. The grass", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24607.1, "ram_available_mb": 38233.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.609, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T06:58:37.783562"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6946.374, "latencies_ms": [6946.374], "images_per_second": 0.144, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "In the image, two zebras are standing close to each other in a grassy area. One zebra is nuzzling the other, showing affection or social bonding.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.259, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T06:58:46.759739"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7917.708, "latencies_ms": [7917.708], "images_per_second": 0.126, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image is a black and white photograph capturing a moment between two zebras. The lighting is soft and diffused, highlighting the intricate patterns of the zebras' stripes and the texture of their fur.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 24622.4, "ram_available_mb": 38218.5, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.111, "power_cpu_cv_mean_watts": 2.242, "power_sys_5v0_mean_watts": 8.933}, "timestamp": "2026-01-23T06:58:56.707626"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11377.767, "latencies_ms": [11377.767], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a cozy bedroom scene. Dominating the space is a bed, adorned with a vibrant comforter that boasts a geometric pattern in hues of pink, blue, and green. The bed is positioned against a wall, which is characterized by a window dressed in white blinds, allowing a soft light to filter into the room.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24513.8, "ram_available_mb": 38327.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 24608.4, "ram_available_mb": 38232.5, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.579, "power_cpu_cv_mean_watts": 2.098, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T06:59:10.117864"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8092.909, "latencies_ms": [8092.909], "images_per_second": 0.124, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "- bed: 1\n- chair: 1\n- table: 1\n- window: 2\n- wall: 1\n- floor: 1\n- curtain: 1\n- door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.7, "ram_available_mb": 38304.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24619.2, "ram_available_mb": 38221.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.197, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T06:59:20.236088"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11333.054, "latencies_ms": [11333.054], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground of the image, there is a bed with a colorful patterned cover situated near the right side of the frame. To the left of the bed, there is a small round table with a single black object on top, positioned closer to the viewer than the bed. In the background, there is a window with a view of a building outside, and a chair is", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.1, "ram_available_mb": 38287.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24561.6, "ram_available_mb": 38279.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.642, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T06:59:33.610288"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8536.641, "latencies_ms": [8536.641], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image shows a cozy bedroom with a large window that offers a view of a stone wall outside. The room features a bed with a colorful patterned bedspread, a round wooden table with a black chair, and a purple wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24561.6, "ram_available_mb": 38279.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24592.2, "ram_available_mb": 38248.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.925, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T06:59:44.194943"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5021.359, "latencies_ms": [5021.359], "images_per_second": 0.199, "prompt_tokens": 36, "response_tokens_est": 24, "n_tiles": 16, "output_text": "The room has a purple wall and a stone wall outside. The bed has a colorful pattern on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24592.2, "ram_available_mb": 38248.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24627.1, "ram_available_mb": 38213.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.32, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 9.11}, "timestamp": "2026-01-23T06:59:51.277829"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11349.405, "latencies_ms": [11349.405], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a purple bus driving down a street. The bus is a double-decker bus, and it is traveling on a road with a crosswalk in front of it. There are several people around the bus, with one person walking on the sidewalk and another person standing near the bus. \n\nIn addition to the bus, there are two traffic lights visible in the", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24538.6, "ram_available_mb": 38302.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24526.9, "ram_available_mb": 38314.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.613, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.841}, "timestamp": "2026-01-23T07:00:04.653807"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7976.87, "latencies_ms": [7976.87], "images_per_second": 0.125, "prompt_tokens": 39, "response_tokens_est": 48, "n_tiles": 16, "output_text": "bus: 1, window: 12, wheelchair symbol: 1, traffic light: 1, pedestrian: 1, bus stop: 1, tree: 1, building: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24526.9, "ram_available_mb": 38314.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24547.9, "ram_available_mb": 38293.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.358, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T07:00:14.662603"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10663.084, "latencies_ms": [10663.084], "images_per_second": 0.094, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "The bus is in the foreground of the image, positioned on the left side of the frame, and appears to be moving towards the right. There is a pedestrian walking on the sidewalk in the background, behind the bus. The bus is also closer to the camera than the buildings in the background, which are further away and appear smaller.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24547.9, "ram_available_mb": 38293.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24547.7, "ram_available_mb": 38293.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.832, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T07:00:27.377698"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7885.605, "latencies_ms": [7885.605], "images_per_second": 0.127, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "A purple South Tyne Metrocentre bus is driving on the road, with a pedestrian walking on the sidewalk. The bus is marked with the route number 96 and is headed towards Bens.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24547.7, "ram_available_mb": 38293.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24641.1, "ram_available_mb": 38199.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.404, "power_cpu_cv_mean_watts": 1.674, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T07:00:37.314440"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7565.075, "latencies_ms": [7565.075], "images_per_second": 0.132, "prompt_tokens": 36, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The bus is purple with a colorful design and the words \"Metrocentre via Bens\" on the front. It is a sunny day with clear skies and the bus is driving on a city street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24561.0, "ram_available_mb": 38279.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24563.9, "ram_available_mb": 38277.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.349, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.926}, "timestamp": "2026-01-23T07:00:46.916887"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11344.281, "latencies_ms": [11344.281], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a close-up view of a white plate holding a group of green apples. There are six apples in total, with one prominently displayed in the foreground and the others slightly blurred in the background. The apples are fresh and appear to be of the same variety, with a vibrant green color and a shiny surface. The background is", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 24563.9, "ram_available_mb": 38277.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24616.2, "ram_available_mb": 38224.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.613, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T07:01:00.281936"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3153.707, "latencies_ms": [3153.707], "images_per_second": 0.317, "prompt_tokens": 39, "response_tokens_est": 6, "n_tiles": 16, "output_text": "apple: 5\n", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24616.2, "ram_available_mb": 38224.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 24696.5, "ram_available_mb": 38144.4, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.597, "power_cpu_cv_mean_watts": 0.631, "power_sys_5v0_mean_watts": 9.21}, "timestamp": "2026-01-23T07:01:05.500152"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10616.846, "latencies_ms": [10616.846], "images_per_second": 0.094, "prompt_tokens": 44, "response_tokens_est": 72, "n_tiles": 16, "output_text": "In the foreground, there are several green apples closely packed together, with one prominently in the center. The apples in the background are slightly out of focus, indicating they are further away from the viewer. The lighting suggests that the apples are positioned near a light source, possibly on a table or countertop.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24539.3, "ram_available_mb": 38301.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24609.5, "ram_available_mb": 38231.4, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.771, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 8.834}, "timestamp": "2026-01-23T07:01:18.134683"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7184.436, "latencies_ms": [7184.436], "images_per_second": 0.139, "prompt_tokens": 37, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The image shows a close-up of a group of green apples on a white plate. The apples are fresh and shiny, indicating that they are likely ripe and ready to eat.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24609.5, "ram_available_mb": 38231.4, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24603.8, "ram_available_mb": 38237.1, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.09, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.939}, "timestamp": "2026-01-23T07:01:27.339109"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8809.654, "latencies_ms": [8809.654], "images_per_second": 0.114, "prompt_tokens": 36, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image features a group of green apples with a shiny surface, indicating they might be fresh and possibly wet from washing. The lighting in the image is soft and diffused, with no harsh shadows, suggesting an indoor setting with ambient lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24603.8, "ram_available_mb": 38237.1, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24613.1, "ram_available_mb": 38227.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.576, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T07:01:38.201911"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11380.545, "latencies_ms": [11380.545], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment in a baseball game. The central figures are the batter, the catcher, and the umpire. The batter, dressed in a white uniform with red accents, is in the midst of a powerful swing, his body coiled with the force of the hit. His black bat is caught mid-swing, poised to connect with the incoming ball. ", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 24613.1, "ram_available_mb": 38227.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24583.7, "ram_available_mb": 38257.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.5, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.827}, "timestamp": "2026-01-23T07:01:51.623361"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7638.53, "latencies_ms": [7638.53], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "pitcher: 1, catcher: 1, umpire: 1, batter: 1, runner: 1, base: 1, ball: 1, glove: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24583.7, "ram_available_mb": 38257.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24594.9, "ram_available_mb": 38246.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.705, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 8.879}, "timestamp": "2026-01-23T07:02:01.277102"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11344.379, "latencies_ms": [11344.379], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a baseball player is swinging a bat, positioned near the center of the image, with the catcher and umpire behind him, closer to the background. The pitcher, who is further back in the image, has just thrown the ball towards the batter. The batter is standing in the batter's box, which is located on the left side of the", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24594.9, "ram_available_mb": 38246.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24669.3, "ram_available_mb": 38171.6, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.599, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T07:02:14.647630"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7744.127, "latencies_ms": [7744.127], "images_per_second": 0.129, "prompt_tokens": 37, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image captures a moment from a baseball game, with a batter in the midst of a swing at the pitch. The catcher and umpire are in position behind the batter, ready to react to the play.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24669.3, "ram_available_mb": 38171.6, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24670.5, "ram_available_mb": 38170.4, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.396, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T07:02:24.454985"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7913.365, "latencies_ms": [7913.365], "images_per_second": 0.126, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image captures a baseball game in progress with a clear view of the field and players. The lighting appears to be natural daylight, and the weather seems fair, as there are no signs of rain or overcast skies.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24560.3, "ram_available_mb": 38280.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24668.6, "ram_available_mb": 38172.3, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.153, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 8.911}, "timestamp": "2026-01-23T07:02:34.415348"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11338.305, "latencies_ms": [11338.305], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a dining table covered with a red tablecloth, set for a meal. On the table, there is a large white cake topped with red and blue berries, accompanied by a plate of cheese and crackers. A bowl of grapes is also present on the table. \n\nIn addition to the main dishes, there are several", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24578.5, "ram_available_mb": 38262.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24595.0, "ram_available_mb": 38245.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.554, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.822}, "timestamp": "2026-01-23T07:02:47.811064"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10173.066, "latencies_ms": [10173.066], "images_per_second": 0.098, "prompt_tokens": 39, "response_tokens_est": 66, "n_tiles": 16, "output_text": "cheese: 10\ngrapes: 1 bunch\nblueberries: 1 cup\nstrawberries: 1 cup\nwine glasses: 6\nplates: 10\ncakes: 1\nknife: 2\ngrapes: 1 bunch", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24595.0, "ram_available_mb": 38245.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 24668.9, "ram_available_mb": 38172.0, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.168, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 8.813}, "timestamp": "2026-01-23T07:03:00.029126"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11373.684, "latencies_ms": [11373.684], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a large white cake with red and blue berries on top, placed on the left side of the table. To the right of the cake, there is a plate with an assortment of cheeses and crackers, and further to the right, there are stacks of white plates. In the background, there are several wine glasses and", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24582.8, "ram_available_mb": 38258.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 24582.9, "ram_available_mb": 38258.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.627, "power_cpu_cv_mean_watts": 2.332, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T07:03:13.442220"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9602.518, "latencies_ms": [9602.518], "images_per_second": 0.104, "prompt_tokens": 37, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The image depicts a table set for a meal with a variety of foods and drinks. There is a large white cake with red and blue berries on top, a plate of cheese and crackers, a bowl of grapes, and several wine glasses.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24582.9, "ram_available_mb": 38258.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24610.7, "ram_available_mb": 38230.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.294, "power_cpu_cv_mean_watts": 1.824, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T07:03:25.082981"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8921.116, "latencies_ms": [8921.116], "images_per_second": 0.112, "prompt_tokens": 36, "response_tokens_est": 58, "n_tiles": 16, "output_text": "The image features a vibrant red tablecloth that contrasts with the white cheesecake topped with red and blue berries. The table is set with clear glassware and plates, and the lighting appears to be natural, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24610.7, "ram_available_mb": 38230.2, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24581.1, "ram_available_mb": 38259.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.589, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.86}, "timestamp": "2026-01-23T07:03:36.052968"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11328.273, "latencies_ms": [11328.273], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is seen surfing on a wave in the ocean. He is wearing a black wetsuit and is riding a blue surfboard. The wave he is on is a beautiful shade of green, and it's curling over to the right side of the image. The man is in the process of paddling, his arms extended above", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24581.1, "ram_available_mb": 38259.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24703.4, "ram_available_mb": 38137.5, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.657, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T07:03:49.432597"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7596.01, "latencies_ms": [7596.01], "images_per_second": 0.132, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "wave: 1\nsurfboard: 1\nman: 1\nwater: 1\nsurf: 1\nsand: 1\nsun: 1\nsea: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24566.3, "ram_available_mb": 38274.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24672.5, "ram_available_mb": 38168.4, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.829, "power_cpu_cv_mean_watts": 1.67, "power_sys_5v0_mean_watts": 8.929}, "timestamp": "2026-01-23T07:03:59.064922"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10875.159, "latencies_ms": [10875.159], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "The surfer is positioned in the foreground, riding a wave that is breaking to the right side of the image. The wave originates in the background and extends towards the left, creating a dynamic spatial relationship between the surfer and the wave. The surfer is closer to the viewer than the wave, emphasizing the action of surfing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24602.2, "ram_available_mb": 38238.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24593.8, "ram_available_mb": 38247.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.825, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.88}, "timestamp": "2026-01-23T07:04:11.974212"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5930.22, "latencies_ms": [5930.22], "images_per_second": 0.169, "prompt_tokens": 37, "response_tokens_est": 30, "n_tiles": 16, "output_text": "A person is surfing a wave in the ocean. The wave is green and the surfer is wearing a black wetsuit.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24593.8, "ram_available_mb": 38247.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24596.8, "ram_available_mb": 38244.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.169, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 8.935}, "timestamp": "2026-01-23T07:04:19.927098"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7227.572, "latencies_ms": [7227.572], "images_per_second": 0.138, "prompt_tokens": 36, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The surfer is wearing a black wetsuit and is riding a wave in the ocean. The wave is a vibrant green color and the water is splashing around the surfer.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24596.8, "ram_available_mb": 38244.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24649.2, "ram_available_mb": 38191.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.6, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.946}, "timestamp": "2026-01-23T07:04:29.209571"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 10782.641, "latencies_ms": [10782.641], "images_per_second": 0.093, "prompt_tokens": 24, "response_tokens_est": 74, "n_tiles": 16, "output_text": "The image is a black and white photograph of a group of children, likely from a school, posing for a group picture. They are all dressed in formal attire, with some wearing ties. The children are arranged in rows, with some sitting on the ground and others standing. The photograph appears to be from the early 20th century.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 24649.2, "ram_available_mb": 38191.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24675.8, "ram_available_mb": 38165.1, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.739, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T07:04:42.025367"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7640.493, "latencies_ms": [7640.493], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "children: 30, boys: 12, girls: 18, adults: 2, benches: 2, trees: 1, building: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24562.3, "ram_available_mb": 38278.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24668.7, "ram_available_mb": 38172.2, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.517, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T07:04:51.725454"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11328.136, "latencies_ms": [11328.136], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a group of children is seated on the ground, with some sitting closer to the front and others further back, creating a sense of depth. The children in the background are standing, with a few positioned in the middle ground and others towards the back, adding to the layered effect of the group. The children in the front appear to be the main focus, with", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.1, "ram_available_mb": 38285.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24675.3, "ram_available_mb": 38165.6, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.643, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T07:05:05.080541"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7156.813, "latencies_ms": [7156.813], "images_per_second": 0.14, "prompt_tokens": 37, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The image depicts a large group of children gathered together, likely for a group photo. They are dressed in a mix of formal and casual attire, suggesting a special occasion or event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24675.3, "ram_available_mb": 38165.6, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24676.4, "ram_available_mb": 38164.5, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.876, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T07:05:14.275542"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8154.579, "latencies_ms": [8154.579], "images_per_second": 0.123, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image is a black and white photograph, indicating it was taken in an era before color photography was common. The lighting is even, with no harsh shadows, suggesting it was taken in a controlled environment, possibly indoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24566.3, "ram_available_mb": 38274.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24597.3, "ram_available_mb": 38243.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.941, "power_cpu_cv_mean_watts": 1.77, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T07:05:24.452733"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11302.621, "latencies_ms": [11302.621], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a dining table with a plate of food, including a sandwich and a bowl of soup. The sandwich is placed on the left side of the plate, while the soup is in a bowl on the right side. A wine glass is also present on the table, positioned towards the top right corner. \n\nA knife can be seen resting on", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24597.3, "ram_available_mb": 38243.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24659.0, "ram_available_mb": 38181.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.609, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T07:05:37.791040"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7725.948, "latencies_ms": [7725.948], "images_per_second": 0.129, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "plate: 1\nbread: 2\nknife: 1\nbowl: 1\nplate: 1\nwine glass: 1\nplate: 1\nknife: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24597.2, "ram_available_mb": 38243.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24640.3, "ram_available_mb": 38200.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.75, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 8.907}, "timestamp": "2026-01-23T07:05:47.562230"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10241.247, "latencies_ms": [10241.247], "images_per_second": 0.098, "prompt_tokens": 44, "response_tokens_est": 69, "n_tiles": 16, "output_text": "In the foreground, there is a white plate with a piece of bread on it, positioned to the left of a mortar and pestle. The mortar and pestle are placed on the right side of the plate. In the background, there is a glass of red wine and a person sitting at the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24561.8, "ram_available_mb": 38279.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24665.6, "ram_available_mb": 38175.3, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.124, "power_cpu_cv_mean_watts": 1.878, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T07:05:59.818744"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6546.408, "latencies_ms": [6546.408], "images_per_second": 0.153, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "The image shows a wooden table with a plate of grilled bread and a glass of red wine. There is also a knife and a napkin on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24586.9, "ram_available_mb": 38254.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24679.4, "ram_available_mb": 38161.5, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.601, "power_cpu_cv_mean_watts": 1.514, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T07:06:08.405827"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8488.685, "latencies_ms": [8488.685], "images_per_second": 0.118, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image features a wooden table with a warm, natural lighting that highlights the textures of the food and tableware. A glass of red wine and a piece of crusty bread are visible, suggesting a cozy, indoor dining setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24679.4, "ram_available_mb": 38161.5, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24681.9, "ram_available_mb": 38159.0, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.05, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 8.917}, "timestamp": "2026-01-23T07:06:18.932225"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11376.52, "latencies_ms": [11376.52], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a skier is performing a jump in the air, showcasing their skills and athleticism. The skier is wearing a colorful outfit and is in the middle of a jump, with their skis and poles visible. \n\nThere are several other people in the scene, including a man standing on the left side of the image, a woman", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24561.0, "ram_available_mb": 38279.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24571.8, "ram_available_mb": 38269.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.533, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.825}, "timestamp": "2026-01-23T07:06:32.333396"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7500.001, "latencies_ms": [7500.001], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "person: 3, snowboarder: 1, snowboard: 1, trees: 10, snow: 1, mountain: 1, sky: 1, flags: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24571.8, "ram_available_mb": 38269.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24598.9, "ram_available_mb": 38242.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.709, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 8.905}, "timestamp": "2026-01-23T07:06:41.891507"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11205.016, "latencies_ms": [11205.016], "images_per_second": 0.089, "prompt_tokens": 44, "response_tokens_est": 78, "n_tiles": 16, "output_text": "In the foreground, there is a snowboarder performing a trick in the air, with their snowboard parallel to the ground. In the background, there are two spectators watching the performance, one standing to the left and the other to the right of the snowboarder. The sky is clear and blue, indicating that the event is taking place on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24598.9, "ram_available_mb": 38242.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24674.1, "ram_available_mb": 38166.8, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.676, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T07:06:55.153599"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8205.153, "latencies_ms": [8205.153], "images_per_second": 0.122, "prompt_tokens": 37, "response_tokens_est": 50, "n_tiles": 16, "output_text": "A skier is performing a mid-air trick on a snowy mountain slope, with a clear blue sky in the background. Spectators, including a child, are watching the skier's impressive jump from the sidelines.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24594.0, "ram_available_mb": 38246.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 24672.4, "ram_available_mb": 38168.5, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.156, "power_cpu_cv_mean_watts": 1.701, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T07:07:05.415207"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7680.845, "latencies_ms": [7680.845], "images_per_second": 0.13, "prompt_tokens": 36, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The skier is wearing a colorful outfit with a mix of green, red, and white, and is performing a trick in the air. The sky is clear and blue, indicating good weather conditions for skiing.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24672.4, "ram_available_mb": 38168.5, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 24681.9, "ram_available_mb": 38159.0, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.305, "power_cpu_cv_mean_watts": 2.231, "power_sys_5v0_mean_watts": 8.96}, "timestamp": "2026-01-23T07:07:15.114225"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11333.544, "latencies_ms": [11333.544], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a person is seen cross-country skiing on a snowy mountain. The skier, dressed in a vibrant green jacket and black pants, is in motion, gliding over the snow-covered terrain. The skier is equipped with ski poles, aiding in their navigation through the snow. The mountain is blanketed in a thick", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 24603.2, "ram_available_mb": 38237.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 24594.4, "ram_available_mb": 38246.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.572, "power_cpu_cv_mean_watts": 2.099, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T07:07:28.496388"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9239.202, "latencies_ms": [9239.202], "images_per_second": 0.108, "prompt_tokens": 39, "response_tokens_est": 59, "n_tiles": 16, "output_text": "sky: 1\nclouds: 3\nperson: 1\nski poles: 2\ngreen shirt: 1\nblack pants: 1\nsnow: 1\nmountain: 1\ntree: 1\nrock: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24594.4, "ram_available_mb": 38246.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24665.3, "ram_available_mb": 38175.6, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.595, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 8.835}, "timestamp": "2026-01-23T07:07:39.784252"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11377.88, "latencies_ms": [11377.88], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a person is standing on skis, facing away from the camera, with a clear view of the snowy landscape behind them. The person is positioned on the right side of the image, with a vast expanse of snow-covered ground extending to the left. The background features a mountain range under a blue sky with scattered clouds, suggesting the person is at a", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24595.2, "ram_available_mb": 38245.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24592.9, "ram_available_mb": 38248.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.708, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T07:07:53.187255"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8518.719, "latencies_ms": [8518.719], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "A person is cross-country skiing on a snowy mountain trail with a clear blue sky above and a few clouds scattered across it. The skier is wearing a green top and black pants, and is holding ski poles in their hands.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24592.9, "ram_available_mb": 38248.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24590.8, "ram_available_mb": 38250.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.076, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 8.881}, "timestamp": "2026-01-23T07:08:03.731381"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8143.869, "latencies_ms": [8143.869], "images_per_second": 0.123, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image features a clear blue sky with scattered white clouds, indicating fair weather. The snow-covered landscape is bathed in sunlight, casting shadows and highlighting the white of the snow against the blue of the sky and the earth.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24590.8, "ram_available_mb": 38250.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24636.7, "ram_available_mb": 38204.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.139, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 8.907}, "timestamp": "2026-01-23T07:08:13.887931"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11320.98, "latencies_ms": [11320.98], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image presents a close-up view of a banana and a chocolate-covered donut, both of which are encased in a plastic bag. The banana, with its characteristic yellow color, is positioned to the left of the donut. The donut, with its brown color, is on the right side of the image. The background is dark, which", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24572.4, "ram_available_mb": 38268.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24685.5, "ram_available_mb": 38155.4, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.599, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T07:08:27.271690"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3848.576, "latencies_ms": [3848.576], "images_per_second": 0.26, "prompt_tokens": 39, "response_tokens_est": 12, "n_tiles": 16, "output_text": "banana: 1, donut: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24685.5, "ram_available_mb": 38155.4, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 24647.9, "ram_available_mb": 38193.0, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.811, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 9.101}, "timestamp": "2026-01-23T07:08:33.173743"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9830.305, "latencies_ms": [9830.305], "images_per_second": 0.102, "prompt_tokens": 44, "response_tokens_est": 66, "n_tiles": 16, "output_text": "The banana is positioned in the foreground on the left side of the image, appearing larger and more detailed. The donut is in the background, partially obscured by the banana, and appears smaller due to the perspective. The donut is to the right of the banana when viewing the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24575.8, "ram_available_mb": 38265.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24679.6, "ram_available_mb": 38161.3, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.222, "power_cpu_cv_mean_watts": 1.859, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T07:08:45.048339"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8305.655, "latencies_ms": [8305.655], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows a chocolate glazed donut and a banana, both placed inside a plastic bag, likely for storage or transport. The setting appears to be a kitchen or a place where food items are being prepared or packaged.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24589.4, "ram_available_mb": 38251.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24662.8, "ram_available_mb": 38178.1, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.13, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T07:08:55.366772"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8348.096, "latencies_ms": [8348.096], "images_per_second": 0.12, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image shows a banana and a chocolate-covered donut placed closely together. The banana is yellow, and the donut is brown with a glossy finish, indicating it might be coated with a sugary glaze.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24662.8, "ram_available_mb": 38178.1, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24676.6, "ram_available_mb": 38164.3, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.87, "power_cpu_cv_mean_watts": 1.759, "power_sys_5v0_mean_watts": 8.906}, "timestamp": "2026-01-23T07:09:05.751151"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11054.085, "latencies_ms": [11054.085], "images_per_second": 0.09, "prompt_tokens": 24, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The image presents a scene featuring a white mug with a skull and crossbones design, accompanied by a knife with a black handle. The mug is placed on a surface with a striped pattern, and the knife is positioned next to it. The overall setting appears to be a table or countertop.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24571.3, "ram_available_mb": 38269.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24688.4, "ram_available_mb": 38152.5, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.007, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 9.057}, "timestamp": "2026-01-23T07:09:18.878397"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4901.685, "latencies_ms": [4901.685], "images_per_second": 0.204, "prompt_tokens": 39, "response_tokens_est": 12, "n_tiles": 16, "output_text": "mug: 1, knife: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24573.2, "ram_available_mb": 38267.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 24681.5, "ram_available_mb": 38159.4, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.951, "power_cpu_cv_mean_watts": 0.81, "power_sys_5v0_mean_watts": 9.15}, "timestamp": "2026-01-23T07:09:25.837809"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8957.347, "latencies_ms": [8957.347], "images_per_second": 0.112, "prompt_tokens": 44, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The skull and crossbones mug is positioned to the left of the knife, which is lying flat on the surface in the foreground. The background is a textured surface that appears to be a table or countertop.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 24681.5, "ram_available_mb": 38159.4, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24632.8, "ram_available_mb": 38208.1, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.846, "power_cpu_cv_mean_watts": 1.586, "power_sys_5v0_mean_watts": 9.092}, "timestamp": "2026-01-23T07:09:36.811440"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8882.966, "latencies_ms": [8882.966], "images_per_second": 0.113, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "A white mug with a skull and crossbones design is placed on a textured surface, accompanied by a knife with a black handle lying next to it. The setting appears to be a table or countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24632.8, "ram_available_mb": 38208.1, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24649.1, "ram_available_mb": 38191.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.136, "power_cpu_cv_mean_watts": 1.528, "power_sys_5v0_mean_watts": 9.036}, "timestamp": "2026-01-23T07:09:47.727625"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 12245.403, "latencies_ms": [12245.403], "images_per_second": 0.082, "prompt_tokens": 36, "response_tokens_est": 80, "n_tiles": 16, "output_text": "The image features a white ceramic mug with a black skull and crossbones symbol, accompanied by a black-handled knife with a silver blade, all placed on a surface with a textured grey and white pattern. The lighting in the image is soft and diffused, casting gentle shadows and highlighting the details of the mug and knife.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24649.1, "ram_available_mb": 38191.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24687.1, "ram_available_mb": 38153.8, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.667, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 9.044}, "timestamp": "2026-01-23T07:10:02.003321"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12529.354, "latencies_ms": [12529.354], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of people gathered around a counter in a room. A man is standing at the counter, possibly a bartender, while several other people are standing or sitting nearby. There are at least five people in the scene, with some of them closer to the counter and others standing further back.\n\nThe room has a dining table in the background, and there are multiple", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24600.1, "ram_available_mb": 38240.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24614.9, "ram_available_mb": 38226.0, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.978, "power_cpu_cv_mean_watts": 1.798, "power_sys_5v0_mean_watts": 9.067}, "timestamp": "2026-01-23T07:10:16.592252"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11236.07, "latencies_ms": [11236.07], "images_per_second": 0.089, "prompt_tokens": 39, "response_tokens_est": 65, "n_tiles": 16, "output_text": "1. People: 5\n2. Bottles: 10\n3. Glasses: 4\n4. Barrel: 1\n5. Counter: 1\n6. Window: 1\n7. Chair: 1\n8. Shoe: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24614.9, "ram_available_mb": 38226.0, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24631.1, "ram_available_mb": 38209.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.722, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 9.056}, "timestamp": "2026-01-23T07:10:29.846252"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12593.483, "latencies_ms": [12593.483], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a person in a blue shirt is standing close to a counter with a person in a white shirt behind it. In the background, there are three other individuals standing near a window. The person in the white shirt is positioned between the person in the blue shirt and the person in the black shirt, who is standing to the right of the person in", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24631.1, "ram_available_mb": 38209.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24642.5, "ram_available_mb": 38198.4, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.227, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 9.111}, "timestamp": "2026-01-23T07:10:44.458026"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8343.204, "latencies_ms": [8343.204], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "A group of people are gathered around a counter in a restaurant or cafe, with one person standing at the counter and others standing nearby. It appears to be a casual and social atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24642.5, "ram_available_mb": 38198.4, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 24643.6, "ram_available_mb": 38197.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.028, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 9.098}, "timestamp": "2026-01-23T07:10:54.818589"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8207.914, "latencies_ms": [8207.914], "images_per_second": 0.122, "prompt_tokens": 36, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The image shows a group of people in an indoor setting with warm lighting. The walls are painted in a teal color, and there is a wooden bar counter with a person behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24643.6, "ram_available_mb": 38197.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24584.6, "ram_available_mb": 38256.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.036, "power_cpu_cv_mean_watts": 1.451, "power_sys_5v0_mean_watts": 9.178}, "timestamp": "2026-01-23T07:11:05.069880"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11326.259, "latencies_ms": [11326.259], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene scene of a marshy area with a large body of water in the foreground. Two white birds, possibly egrets, are standing in the water, adding a touch of life to the scene. In the background, there is a harbor filled with various boats and ships, showcasing a bustling maritime environment. The sky above is", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24584.6, "ram_available_mb": 38256.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 24652.0, "ram_available_mb": 38188.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.665, "power_cpu_cv_mean_watts": 2.018, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T07:11:18.426917"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7207.778, "latencies_ms": [7207.778], "images_per_second": 0.139, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "sky: 1, clouds: 1, airplane: 1, boats: 5, buildings: 2, poles: 4, grass: 1, birds: 2", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24652.0, "ram_available_mb": 38188.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 24668.0, "ram_available_mb": 38172.9, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.111, "power_cpu_cv_mean_watts": 2.225, "power_sys_5v0_mean_watts": 8.995}, "timestamp": "2026-01-23T07:11:27.691655"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8137.443, "latencies_ms": [8137.443], "images_per_second": 0.123, "prompt_tokens": 44, "response_tokens_est": 51, "n_tiles": 16, "output_text": "In the foreground, there is a grassy area with two birds standing near the center. The background features a marina with several boats and docks extending into the water. The sky above is filled with clouds, suggesting an overcast day.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24589.6, "ram_available_mb": 38251.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 24584.5, "ram_available_mb": 38256.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.063, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 8.937}, "timestamp": "2026-01-23T07:11:37.847382"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7965.773, "latencies_ms": [7965.773], "images_per_second": 0.126, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image depicts a marshy area with two birds standing in the foreground, and a large industrial area with multiple cranes and buildings in the background. The sky is cloudy, suggesting an overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24584.5, "ram_available_mb": 38256.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24585.3, "ram_available_mb": 38255.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.25, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T07:11:47.865625"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7669.656, "latencies_ms": [7669.656], "images_per_second": 0.13, "prompt_tokens": 36, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The sky is overcast with a mix of blue and gray clouds, suggesting a gloomy or cloudy day. The grass in the foreground is a vibrant green, contrasting with the industrial structures in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24585.3, "ram_available_mb": 38255.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24677.4, "ram_available_mb": 38163.5, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.312, "power_cpu_cv_mean_watts": 1.676, "power_sys_5v0_mean_watts": 8.969}, "timestamp": "2026-01-23T07:11:57.566457"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11322.085, "latencies_ms": [11322.085], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In this black and white photo, a man is kneeling on the floor in a bathroom, working on a toilet. He is wearing a black shirt and jeans, and has a tool belt around his waist. The bathroom is equipped with a white toilet, a sink, and a mirror. The walls of the bathroom are adorned", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24614.1, "ram_available_mb": 38226.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24663.7, "ram_available_mb": 38177.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.571, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.86}, "timestamp": "2026-01-23T07:12:10.926733"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10970.906, "latencies_ms": [10970.906], "images_per_second": 0.091, "prompt_tokens": 39, "response_tokens_est": 74, "n_tiles": 16, "output_text": "1. Toilet: 1\n2. Glove: 1\n3. Tool belt: 1\n4. Tiles: 1\n5. Tile adhesive: 1\n6. Tile cutter: 1\n7. Hammer: 1\n8. Screwdriver: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24663.7, "ram_available_mb": 38177.2, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24584.6, "ram_available_mb": 38256.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.868, "power_cpu_cv_mean_watts": 1.905, "power_sys_5v0_mean_watts": 8.822}, "timestamp": "2026-01-23T07:12:23.909198"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11366.269, "latencies_ms": [11366.269], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The person is seated on a toilet in the foreground, with their body oriented towards the right side of the image. The background features a wall with a checkered pattern, and there is a shelf with various items on it to the right of the person. The person's left hand is placed on the toilet, suggesting they are in the process of using it", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24584.6, "ram_available_mb": 38256.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24638.6, "ram_available_mb": 38202.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.602, "power_cpu_cv_mean_watts": 1.96, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T07:12:37.313543"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7990.526, "latencies_ms": [7990.526], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "A man is sitting on a toilet in a bathroom, wearing a black shirt and jeans, with a tool belt around his waist. He appears to be fixing or maintaining the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24560.3, "ram_available_mb": 38280.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24606.7, "ram_available_mb": 38234.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.391, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 8.873}, "timestamp": "2026-01-23T07:12:47.352293"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8512.969, "latencies_ms": [8512.969], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image is in black and white, featuring a person in a dark shirt and jeans working on a toilet. The lighting is bright and even, illuminating the person and the toilet, which is made of porcelain.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24606.7, "ram_available_mb": 38234.2, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24641.7, "ram_available_mb": 38199.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.81, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T07:12:57.904852"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12276.203, "latencies_ms": [12276.203], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a group of people standing on a snow-covered mountain. There are six people in the scene, with some of them wearing skis. They are positioned near the top of the mountain, possibly preparing for a skiing adventure or taking a break. The group is spread out, with some individuals closer to the foreground and others further back.\n\n", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 24563.1, "ram_available_mb": 38277.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24619.1, "ram_available_mb": 38221.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.709, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 9.079}, "timestamp": "2026-01-23T07:13:12.211079"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8882.199, "latencies_ms": [8882.199], "images_per_second": 0.113, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "people: 5\nskis: 2\nsnowboards: 0\nmountains: 1\ntracks: 1\nsnow: 1\ntrees: 0\nclouds: 0", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24619.1, "ram_available_mb": 38221.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24565.5, "ram_available_mb": 38275.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.114, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 9.04}, "timestamp": "2026-01-23T07:13:23.155257"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11237.781, "latencies_ms": [11237.781], "images_per_second": 0.089, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "In the foreground, there is a group of people standing on skis, positioned near the base of a large snow-covered mountain. The mountain is in the background, with its peak reaching high into the clear blue sky. The people are closer to the viewer than the mountain, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24565.5, "ram_available_mb": 38275.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24608.1, "ram_available_mb": 38232.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.891, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 9.06}, "timestamp": "2026-01-23T07:13:36.424570"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8077.729, "latencies_ms": [8077.729], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "A group of people are standing on a snowy mountain, with a large snow-covered mountain in the background. They appear to be preparing to ski or snowboard down the mountain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24608.1, "ram_available_mb": 38232.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24681.4, "ram_available_mb": 38159.5, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.612, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 9.039}, "timestamp": "2026-01-23T07:13:46.532248"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8372.851, "latencies_ms": [8372.851], "images_per_second": 0.119, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image features a group of people standing on a snowy mountain with a clear blue sky in the background. The snow on the mountain appears to be fresh and untouched, with some tracks visible in the snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24681.4, "ram_available_mb": 38159.5, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24665.1, "ram_available_mb": 38175.8, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.162, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 9.153}, "timestamp": "2026-01-23T07:13:56.950427"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12510.952, "latencies_ms": [12510.952], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image presents a well-balanced meal served on a white plate. The plate is divided into three sections. On the left side, there's a serving of white rice, which is the base of the meal. The middle section of the plate is filled with a vibrant red and yellow chili, adding a pop of color and likely a spicy kick to the me", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24561.5, "ram_available_mb": 38279.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24664.0, "ram_available_mb": 38176.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.072, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 9.115}, "timestamp": "2026-01-23T07:14:11.514352"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6297.353, "latencies_ms": [6297.353], "images_per_second": 0.159, "prompt_tokens": 39, "response_tokens_est": 22, "n_tiles": 16, "output_text": "rice: 1 portion, broccoli: 2 portions, chili: 1 portion", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24558.7, "ram_available_mb": 38282.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 24582.4, "ram_available_mb": 38258.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.798, "power_cpu_cv_mean_watts": 1.065, "power_sys_5v0_mean_watts": 9.131}, "timestamp": "2026-01-23T07:14:19.863650"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12644.211, "latencies_ms": [12644.211], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 80, "n_tiles": 16, "output_text": "In the foreground of the image, there is a white bowl containing a meal. To the left of the bowl, there is a piece of broccoli, and to the right, there is a serving of rice. The bowl is placed on a wooden surface, and the broccoli is positioned to the left of the rice, creating a balanced composition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24582.4, "ram_available_mb": 38258.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24684.8, "ram_available_mb": 38156.1, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.983, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 9.105}, "timestamp": "2026-01-23T07:14:34.529268"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8964.331, "latencies_ms": [8964.331], "images_per_second": 0.112, "prompt_tokens": 37, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image shows a white bowl filled with a meal consisting of white rice, a serving of stewed vegetables, and a piece of broccoli. The bowl is placed on a dark wooden table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24621.6, "ram_available_mb": 38219.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24670.9, "ram_available_mb": 38170.0, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.465, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 9.058}, "timestamp": "2026-01-23T07:14:45.524913"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11878.06, "latencies_ms": [11878.06], "images_per_second": 0.084, "prompt_tokens": 36, "response_tokens_est": 73, "n_tiles": 16, "output_text": "The image shows a meal consisting of white rice, a piece of broccoli, and a red bean stew, all served on a white plate. The lighting in the image is warm and appears to be coming from the top left, casting a soft glow on the food and highlighting the textures of the rice and the stew.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24590.2, "ram_available_mb": 38250.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24664.7, "ram_available_mb": 38176.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.363, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 9.125}, "timestamp": "2026-01-23T07:14:59.453579"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11315.377, "latencies_ms": [11315.377], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a person is skillfully skateboarding on a wooden platform. The skateboarder is wearing a pair of black and white sneakers, which are visible as they perform a trick on the skateboard. The skateboard itself is black and white, with a checkered pattern on the bottom. The wooden platform on which the skateboarder is", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24559.6, "ram_available_mb": 38281.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24668.2, "ram_available_mb": 38172.7, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.634, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T07:15:12.844227"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8409.641, "latencies_ms": [8409.641], "images_per_second": 0.119, "prompt_tokens": 39, "response_tokens_est": 52, "n_tiles": 16, "output_text": "skateboard: 1, wooden platform: 1, grass: multiple patches, person's legs: 2, shoes: 2, wheels: 4, checkered pattern: 1, sunlight: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24585.4, "ram_available_mb": 38255.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24687.7, "ram_available_mb": 38153.2, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.119, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 8.883}, "timestamp": "2026-01-23T07:15:23.286775"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9067.452, "latencies_ms": [9067.452], "images_per_second": 0.11, "prompt_tokens": 44, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The skateboarder is in the foreground, performing a trick on a wooden platform. The platform is elevated above the grassy ground, which is in the background. There is another wooden structure visible in the far background, slightly to the right of the skateboarder.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24687.7, "ram_available_mb": 38153.2, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 24677.9, "ram_available_mb": 38163.0, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.54, "power_cpu_cv_mean_watts": 2.299, "power_sys_5v0_mean_watts": 8.916}, "timestamp": "2026-01-23T07:15:34.413073"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5696.667, "latencies_ms": [5696.667], "images_per_second": 0.176, "prompt_tokens": 37, "response_tokens_est": 28, "n_tiles": 16, "output_text": "A person is skateboarding on a wooden platform outdoors, with a blurred background featuring grass and wooden structures.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24566.1, "ram_available_mb": 38274.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 24669.2, "ram_available_mb": 38171.7, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.642, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 9.021}, "timestamp": "2026-01-23T07:15:42.150397"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8226.962, "latencies_ms": [8226.962], "images_per_second": 0.122, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The image captures a moment of a skateboarder in mid-air, with the skateboard positioned on a wooden platform. The lighting is natural and bright, suggesting the photo was taken outdoors on a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24669.2, "ram_available_mb": 38171.7, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24619.2, "ram_available_mb": 38221.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.944, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 8.924}, "timestamp": "2026-01-23T07:15:52.430938"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12214.745, "latencies_ms": [12214.745], "images_per_second": 0.082, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 16, "output_text": "The image features a bunch of bananas sitting on a wooden table. There are three bananas in the bunch, with one banana placed on top of the other two. The bananas are yellow and appear ripe, indicating that they are ready to be eaten. The table provides a contrasting background for the bananas, making them the focal point of the scene.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24619.2, "ram_available_mb": 38221.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24620.8, "ram_available_mb": 38220.1, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.691, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 9.044}, "timestamp": "2026-01-23T07:16:06.697518"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4353.29, "latencies_ms": [4353.29], "images_per_second": 0.23, "prompt_tokens": 39, "response_tokens_est": 7, "n_tiles": 16, "output_text": "banana: 5\n", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24620.8, "ram_available_mb": 38220.1, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 24703.9, "ram_available_mb": 38137.0, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.821, "power_cpu_cv_mean_watts": 0.6, "power_sys_5v0_mean_watts": 9.159}, "timestamp": "2026-01-23T07:16:13.105189"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9409.955, "latencies_ms": [9409.955], "images_per_second": 0.106, "prompt_tokens": 44, "response_tokens_est": 54, "n_tiles": 16, "output_text": "In the foreground, there is a bunch of bananas with one banana lying on its side, closer to the viewer. The background features a blurred computer monitor and keyboard, indicating that the main objects are placed on a desk or table.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 24565.0, "ram_available_mb": 38275.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24680.5, "ram_available_mb": 38160.4, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.616, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 9.127}, "timestamp": "2026-01-23T07:16:24.564036"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7631.312, "latencies_ms": [7631.312], "images_per_second": 0.131, "prompt_tokens": 37, "response_tokens_est": 36, "n_tiles": 16, "output_text": "A bunch of bananas is precariously balanced on top of another banana on a wooden table. In the background, there is a computer monitor and a keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24680.5, "ram_available_mb": 38160.4, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 24576.4, "ram_available_mb": 38264.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.953, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 9.055}, "timestamp": "2026-01-23T07:16:34.225988"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8039.366, "latencies_ms": [8039.366], "images_per_second": 0.124, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The bananas are yellow with some brown spots, indicating ripeness. They are placed on a wooden surface, likely a table, with a blurred background that includes a computer monitor and keyboard.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24576.4, "ram_available_mb": 38264.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24682.5, "ram_available_mb": 38158.4, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.358, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 9.126}, "timestamp": "2026-01-23T07:16:44.325175"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11339.698, "latencies_ms": [11339.698], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a large plate of food placed on a dining table. The plate contains a variety of food items, including a generous portion of rice, several pieces of broccoli, and a mix of carrots and other vegetables. The dish appears to be a delicious and well-balanced meal, with a combination of vegetables and rice.\n\nIn", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24561.8, "ram_available_mb": 38279.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24565.7, "ram_available_mb": 38275.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.557, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T07:16:57.710305"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8343.917, "latencies_ms": [8343.917], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "plate: 1\nglass: 1\nwater: 1\nfork: 1\nknife: 1\nchicken: 1\nbroccoli: 1\ncarrot: 1\nrice: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24565.7, "ram_available_mb": 38275.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24607.9, "ram_available_mb": 38233.0, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.098, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T07:17:08.069120"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7476.529, "latencies_ms": [7476.529], "images_per_second": 0.134, "prompt_tokens": 44, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The plate of food is in the foreground of the image, placed on a wooden table. In the background, there is a glass of water and a fork and knife placed to the left side of the plate.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24607.9, "ram_available_mb": 38233.0, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24562.6, "ram_available_mb": 38278.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.458, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.917}, "timestamp": "2026-01-23T07:17:17.578588"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7622.851, "latencies_ms": [7622.851], "images_per_second": 0.131, "prompt_tokens": 37, "response_tokens_est": 45, "n_tiles": 16, "output_text": "A plate of food is on a wooden table, with a glass of water and a fork and knife placed beside it. The plate contains a serving of white rice, stir-fried vegetables, and chicken.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24562.6, "ram_available_mb": 38278.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24571.7, "ram_available_mb": 38269.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.51, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 8.901}, "timestamp": "2026-01-23T07:17:27.255862"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7532.189, "latencies_ms": [7532.189], "images_per_second": 0.133, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The plate is colorful with a mix of orange, green, and white hues, and it's placed on a wooden table. There's a glass of water in the background, suggesting a dining setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24571.7, "ram_available_mb": 38269.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24632.1, "ram_available_mb": 38208.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.469, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 8.951}, "timestamp": "2026-01-23T07:17:36.816781"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11315.777, "latencies_ms": [11315.777], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a young girl in a colorful dress playing with a Wii remote in a living room. She is standing in front of a couch, holding the remote in her hand. There are several other people in the room, including a man and a woman standing near the couch, and another person standing further back. \n\nThe living room is furnished with a couch", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24632.1, "ram_available_mb": 38208.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24647.3, "ram_available_mb": 38193.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.567, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 8.865}, "timestamp": "2026-01-23T07:17:50.183892"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9605.233, "latencies_ms": [9605.233], "images_per_second": 0.104, "prompt_tokens": 39, "response_tokens_est": 62, "n_tiles": 16, "output_text": "- people: 5\n\n- couch: 1\n\n- sofa: 1\n\n- rug: 1\n\n- wheelbarrow: 1\n\n- remote control: 1\n\n- wine glass: 1\n\n- bottle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24574.3, "ram_available_mb": 38266.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24591.7, "ram_available_mb": 38249.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.252, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 8.82}, "timestamp": "2026-01-23T07:18:01.805373"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11347.839, "latencies_ms": [11347.839], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a young girl is standing on a gray shaggy rug, holding a remote control and appears to be in motion, possibly playing a video game. Behind her, on the right side of the image, there is a couch with red and white patterned pillows. In the background, there are several people standing and interacting with each other, with one person", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24591.7, "ram_available_mb": 38249.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24581.6, "ram_available_mb": 38259.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.719, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.86}, "timestamp": "2026-01-23T07:18:15.181638"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8545.838, "latencies_ms": [8545.838], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "A young girl is energetically playing with a red ball in a living room, while a group of people watch her. The room is furnished with a couch, a coffee table, and a rug, creating a cozy and lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24581.6, "ram_available_mb": 38259.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24580.5, "ram_available_mb": 38260.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.187, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 8.883}, "timestamp": "2026-01-23T07:18:25.742126"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8285.053, "latencies_ms": [8285.053], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The room is well-lit with natural light coming from the windows, and the carpet is a soft, plush grey. The couch is adorned with red and white patterned pillows, adding a pop of color to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24580.5, "ram_available_mb": 38260.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24577.1, "ram_available_mb": 38263.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.064, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T07:18:36.074723"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11326.57, "latencies_ms": [11326.57], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features two men shaking hands in a room filled with people. The man on the left is wearing a tie, and the man on the right is wearing a suit. They are both smiling, indicating a positive interaction. The room is filled with numerous people, some of whom are also wearing ties.\n\nThere are several dining tables in the room, with", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24577.1, "ram_available_mb": 38263.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24624.3, "ram_available_mb": 38216.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.597, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.832}, "timestamp": "2026-01-23T07:18:49.460277"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10251.872, "latencies_ms": [10251.872], "images_per_second": 0.098, "prompt_tokens": 39, "response_tokens_est": 68, "n_tiles": 16, "output_text": "1. People: 12\n2. Tables: 4\n3. Wine glasses: 3\n4. Plates: 2\n5. Napkins: 2\n6. Menus: 1\n7. Glasses: 1\n8. Suits: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24624.3, "ram_available_mb": 38216.6, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24626.0, "ram_available_mb": 38214.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.147, "power_cpu_cv_mean_watts": 1.855, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T07:19:01.772867"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11322.893, "latencies_ms": [11322.893], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, two men are shaking hands, one wearing a patterned shirt and the other in a suit with a yellow tie. They are standing close to each other, indicating a personal interaction. In the background, there are multiple tables set up with white tablecloths, and several other people are scattered around, suggesting this is a social event or gathering. The", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24626.0, "ram_available_mb": 38214.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24627.7, "ram_available_mb": 38213.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.632, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T07:19:15.108199"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4963.926, "latencies_ms": [4963.926], "images_per_second": 0.201, "prompt_tokens": 37, "response_tokens_est": 22, "n_tiles": 16, "output_text": "Two men are shaking hands in a formal event setting, with a group of people in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24627.7, "ram_available_mb": 38213.2, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 24591.5, "ram_available_mb": 38249.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.625, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 9.04}, "timestamp": "2026-01-23T07:19:22.125780"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8582.967, "latencies_ms": [8582.967], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image shows two men shaking hands in an indoor setting with warm lighting. The man on the left is wearing a patterned shirt with a blue collar, while the man on the right is dressed in a dark suit with a yellow tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24591.5, "ram_available_mb": 38249.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24579.7, "ram_available_mb": 38261.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.735, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 8.899}, "timestamp": "2026-01-23T07:19:32.743080"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11342.729, "latencies_ms": [11342.729], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young man is captured in a moment of quiet contemplation. He is dressed in a crisp white shirt, which contrasts with his dark tie. His gaze is directed off to the side, suggesting he is lost in thought. The background is blurred, drawing focus to the man and his introspective state. The lighting is soft, casting a", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 24579.7, "ram_available_mb": 38261.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 24644.2, "ram_available_mb": 38196.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.596, "power_cpu_cv_mean_watts": 2.353, "power_sys_5v0_mean_watts": 8.865}, "timestamp": "2026-01-23T07:19:46.111753"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7409.697, "latencies_ms": [7409.697], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "person: 1, shirt: 1, tie: 1, collar: 1, button: 1, cuff: 1, pocket: 1, hand: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24644.2, "ram_available_mb": 38196.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 24597.0, "ram_available_mb": 38243.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.9, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 8.919}, "timestamp": "2026-01-23T07:19:55.550052"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11340.746, "latencies_ms": [11340.746], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The person in the image is wearing a white shirt and a striped tie. The shirt is buttoned up, and the tie is tied in a neat knot. The person's left hand is slightly raised, as if they are gesturing or making a point. The background is blurred, but it appears to be an indoor setting with some objects in the distance", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24597.0, "ram_available_mb": 38243.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24596.4, "ram_available_mb": 38244.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.76, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T07:20:08.904229"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8308.168, "latencies_ms": [8308.168], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "A person is standing in a dimly lit environment, wearing a white shirt and a striped tie. The background is blurred, but it appears to be an indoor setting with some objects that could be furniture or equipment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24596.4, "ram_available_mb": 38244.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24638.1, "ram_available_mb": 38202.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.225, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T07:20:19.246789"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7026.337, "latencies_ms": [7026.337], "images_per_second": 0.142, "prompt_tokens": 36, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The image features a person wearing a white shirt and a dark striped tie. The lighting in the image is dim, with a focus on the person's face and upper body.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24638.1, "ram_available_mb": 38202.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24602.6, "ram_available_mb": 38238.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.966, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.952}, "timestamp": "2026-01-23T07:20:28.312622"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11351.546, "latencies_ms": [11351.546], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a cozy living room scene. Dominating the space is a blue and red plaid sofa, inviting and comfortable. To the left of the sofa, a wooden chair with a red and white checkered pattern adds a touch of homeliness. The chair and sofa are positioned in front of a wooden entertainment center, which houses a television set.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24602.6, "ram_available_mb": 38238.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24592.4, "ram_available_mb": 38248.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.537, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.816}, "timestamp": "2026-01-23T07:20:41.689655"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7494.969, "latencies_ms": [7494.969], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "Chair: 1, Sofa: 1, Entertainment center: 1, Television: 1, Picture: 1, List: 1, Speaker: 1, Rug: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24592.4, "ram_available_mb": 38248.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24589.4, "ram_available_mb": 38251.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.812, "power_cpu_cv_mean_watts": 1.64, "power_sys_5v0_mean_watts": 8.926}, "timestamp": "2026-01-23T07:20:51.222428"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11331.002, "latencies_ms": [11331.002], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground of the image, there is a red plaid chair positioned to the left and a blue plaid sofa to the right, both facing forward. The chair and sofa are in the middle ground and are the main objects in the image. In the background, there is a television set on a wooden stand and a whiteboard with writing on it, both situated above the", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24589.4, "ram_available_mb": 38251.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24592.1, "ram_available_mb": 38248.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.623, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T07:21:04.604839"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9124.734, "latencies_ms": [9124.734], "images_per_second": 0.11, "prompt_tokens": 37, "response_tokens_est": 58, "n_tiles": 16, "output_text": "The image depicts a cozy living room setting with a red and blue plaid sofa, a red armchair, and a television on a wooden stand. A whiteboard with writing on it is mounted on the wall, and a framed picture is also visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24592.1, "ram_available_mb": 38248.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24587.3, "ram_available_mb": 38253.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.597, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 8.865}, "timestamp": "2026-01-23T07:21:15.778229"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8230.796, "latencies_ms": [8230.796], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The room has a plaid patterned chair and ottoman, with a whiteboard and a black and white photo on the wall. The lighting in the room is dim, and the materials used for the furniture appear to be wood and fabric.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24587.3, "ram_available_mb": 38253.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24630.2, "ram_available_mb": 38210.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.921, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 8.941}, "timestamp": "2026-01-23T07:21:26.021079"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12505.189, "latencies_ms": [12505.189], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a dynamic scene of a surfer riding a wave. The surfer, clad in a vibrant yellow shirt and black shorts, is skillfully maneuvering a white surfboard. The wave, a powerful force of nature, is breaking to the right, creating a spray of white foam that contrasts with the deep blue-green", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24630.2, "ram_available_mb": 38210.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24628.5, "ram_available_mb": 38212.4, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.978, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 9.098}, "timestamp": "2026-01-23T07:21:40.589086"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9751.495, "latencies_ms": [9751.495], "images_per_second": 0.103, "prompt_tokens": 39, "response_tokens_est": 52, "n_tiles": 16, "output_text": "water: 1\nsurfboard: 1\nyellow shirt: 1\nred shorts: 1\nblack gloves: 1\nwhite surfboard: 1\nsurfer: 1\nwave: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24628.5, "ram_available_mb": 38212.4, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24612.1, "ram_available_mb": 38228.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.254, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 9.025}, "timestamp": "2026-01-23T07:21:52.383161"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12067.538, "latencies_ms": [12067.538], "images_per_second": 0.083, "prompt_tokens": 44, "response_tokens_est": 74, "n_tiles": 16, "output_text": "The surfer is positioned in the foreground, riding a wave that is breaking to the right of the frame. The water in the background appears calmer and is a darker shade of blue, indicating depth and distance from the surfer. The surfboard is angled towards the left side of the image, suggesting movement in that direction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24612.1, "ram_available_mb": 38228.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24629.9, "ram_available_mb": 38211.0, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.282, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 9.141}, "timestamp": "2026-01-23T07:22:06.489419"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7100.728, "latencies_ms": [7100.728], "images_per_second": 0.141, "prompt_tokens": 37, "response_tokens_est": 29, "n_tiles": 16, "output_text": "A person is surfing on a wave in the ocean. The surfer is wearing a yellow shirt and red shorts.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24629.9, "ram_available_mb": 38211.0, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 24636.3, "ram_available_mb": 38204.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.064, "power_cpu_cv_mean_watts": 1.208, "power_sys_5v0_mean_watts": 9.095}, "timestamp": "2026-01-23T07:22:15.641046"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9252.573, "latencies_ms": [9252.573], "images_per_second": 0.108, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The surfer is wearing a bright yellow shirt and red shorts, which stand out against the white foam of the wave. The lighting in the image is natural, suggesting it was taken during the day under clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24636.3, "ram_available_mb": 38204.6, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24635.6, "ram_available_mb": 38205.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.401, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 9.162}, "timestamp": "2026-01-23T07:22:26.936233"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11323.957, "latencies_ms": [11323.957], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the center of the image, a black cat is sitting on a desk, its head tilted to the side as it gazes intently at a computer screen. The screen is displaying a webpage with a white background and black text. The cat's position and the direction of its gaze suggest it is trying to understand or interact with the content on the screen.\n\nTo", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24635.6, "ram_available_mb": 38205.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24593.1, "ram_available_mb": 38247.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.595, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T07:22:40.292163"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7166.327, "latencies_ms": [7166.327], "images_per_second": 0.14, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "computer: 2, monitor: 1, keyboard: 1, mouse: 1, cat: 1, calculator: 1, phone: 1, book: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24593.1, "ram_available_mb": 38247.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24591.6, "ram_available_mb": 38249.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.967, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T07:22:49.477286"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11356.494, "latencies_ms": [11356.494], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a black cat sitting in front of a computer monitor, which is positioned slightly to the left of the center of the image. The cat is facing the monitor, and its body is angled towards it, suggesting it is looking at the screen. In the background, there is a keyboard to the left of the monitor and a telephone to the right, both", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24591.6, "ram_available_mb": 38249.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24599.3, "ram_available_mb": 38241.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.663, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T07:23:02.855932"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6298.856, "latencies_ms": [6298.856], "images_per_second": 0.159, "prompt_tokens": 37, "response_tokens_est": 33, "n_tiles": 16, "output_text": "A cat is sitting in front of a computer monitor, looking at the screen. The computer is placed on a desk with a keyboard and a mouse nearby.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24599.3, "ram_available_mb": 38241.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24591.9, "ram_available_mb": 38249.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.562, "power_cpu_cv_mean_watts": 1.473, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T07:23:11.197616"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7089.968, "latencies_ms": [7089.968], "images_per_second": 0.141, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image shows a cat with a predominantly grey coat, sitting in front of a computer screen. The lighting in the room is bright, illuminating the cat and the computer screen clearly.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24591.9, "ram_available_mb": 38249.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24585.5, "ram_available_mb": 38255.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.845, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.991}, "timestamp": "2026-01-23T07:23:20.301555"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11326.431, "latencies_ms": [11326.431], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of people gathered around a little girl who is cutting a red ribbon. The girl is wearing a helmet and is the center of attention as she holds the scissors, ready to cut the ribbon. Several people are standing around her, watching the event unfold.\n\nIn the scene, there are a few bicycles visible, one on the left", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24585.5, "ram_available_mb": 38255.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24596.8, "ram_available_mb": 38244.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.698, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T07:23:33.684654"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10123.29, "latencies_ms": [10123.29], "images_per_second": 0.099, "prompt_tokens": 39, "response_tokens_est": 67, "n_tiles": 16, "output_text": "1. People: 15\n2. Balloons: 1\n3. Ribbon: 1\n4. Camera: 1\n5. Helmet: 1\n6. Tie: 1\n7. Suitcase: 1\n8. Bicycle: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24596.8, "ram_available_mb": 38244.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 24595.3, "ram_available_mb": 38245.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.237, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T07:23:45.851460"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11290.493, "latencies_ms": [11290.493], "images_per_second": 0.089, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a child wearing a blue helmet is being assisted by an adult to walk through a red ribbon, indicating a ceremonial event. Behind them, a group of people are gathered, with some standing closer to the camera and others further back, creating a sense of depth. The balloons are held by an adult in the center, slightly behind the", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24595.3, "ram_available_mb": 38245.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 24597.7, "ram_available_mb": 38243.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.788, "power_cpu_cv_mean_watts": 2.34, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T07:23:59.160654"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9449.574, "latencies_ms": [9449.574], "images_per_second": 0.106, "prompt_tokens": 37, "response_tokens_est": 61, "n_tiles": 16, "output_text": "A group of people, including children, are gathered on a sidewalk in front of a building with a sign that reads \"Johnny's.\" They are participating in a ribbon-cutting ceremony, with some individuals holding a pair of scissors and a blue balloon.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24597.7, "ram_available_mb": 38243.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24603.3, "ram_available_mb": 38237.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.547, "power_cpu_cv_mean_watts": 1.855, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T07:24:10.631302"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7859.203, "latencies_ms": [7859.203], "images_per_second": 0.127, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image features a group of people gathered outdoors on a sunny day, as indicated by the bright lighting and shadows cast on the ground. The weather appears to be clear and pleasant, suitable for an outdoor event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24603.3, "ram_available_mb": 38237.6, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24604.9, "ram_available_mb": 38236.0, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.195, "power_cpu_cv_mean_watts": 1.757, "power_sys_5v0_mean_watts": 8.938}, "timestamp": "2026-01-23T07:24:20.521206"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11333.594, "latencies_ms": [11333.594], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a large, modern bus parked on the side of a street. The bus is predominantly white and blue, with a pink stripe running along its side. It is a Scania bus, as indicated by the text on the side of the vehicle. The bus is parked in a designated bus stop area, which is marked by yellow lines on the road.\n", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24604.9, "ram_available_mb": 38236.0, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24606.3, "ram_available_mb": 38234.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.637, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T07:24:33.924373"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7063.47, "latencies_ms": [7063.47], "images_per_second": 0.142, "prompt_tokens": 39, "response_tokens_est": 40, "n_tiles": 16, "output_text": "bus: 1, window: multiple, license plate: 1, building: multiple, pedestrian: 1, car: 1, street: multiple, sign: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24606.3, "ram_available_mb": 38234.6, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24599.8, "ram_available_mb": 38241.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.03, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T07:24:43.018633"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11078.373, "latencies_ms": [11078.373], "images_per_second": 0.09, "prompt_tokens": 44, "response_tokens_est": 77, "n_tiles": 16, "output_text": "The bus is in the foreground of the image, positioned on the left side of the frame, and appears to be moving towards the right. It is parked in a designated bus stop area marked with yellow lines on the road. In the background, there are buildings and a pedestrian walking on the sidewalk, indicating that the bus is in an urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24599.8, "ram_available_mb": 38241.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24607.4, "ram_available_mb": 38233.5, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.754, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T07:24:56.117167"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6123.505, "latencies_ms": [6123.505], "images_per_second": 0.163, "prompt_tokens": 37, "response_tokens_est": 32, "n_tiles": 16, "output_text": "A Scania bus with the sign \"First Group\" is parked on the side of a street. The bus offers free Wi-Fi on board.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24607.4, "ram_available_mb": 38233.5, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24604.4, "ram_available_mb": 38236.5, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.164, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 8.97}, "timestamp": "2026-01-23T07:25:04.277764"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8922.148, "latencies_ms": [8922.148], "images_per_second": 0.112, "prompt_tokens": 36, "response_tokens_est": 58, "n_tiles": 16, "output_text": "The bus is predominantly white with pink and blue accents, and it is equipped with free Wi-Fi as indicated by the sign on the front. The bus is parked on a street with a yellow \"BUS STOP\" marking on the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24604.4, "ram_available_mb": 38236.5, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24606.1, "ram_available_mb": 38234.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.544, "power_cpu_cv_mean_watts": 1.789, "power_sys_5v0_mean_watts": 8.909}, "timestamp": "2026-01-23T07:25:15.229662"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11351.027, "latencies_ms": [11351.027], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the image, a man is sitting on the floor in front of a large, ornate mirror. He is wearing a green shirt and is holding a cell phone in his hands. The mirror reflects the room, showing a living room with a couch and a lamp. The man appears to be focused on his phone, possibly taking a photo or browsing the internet.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24606.1, "ram_available_mb": 38234.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24604.2, "ram_available_mb": 38236.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.573, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T07:25:28.617749"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8688.335, "latencies_ms": [8688.335], "images_per_second": 0.115, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "- Mirror: 1\n- Sofa: 1\n- Table: 1\n- Lamp: 1\n- Cell phone: 1\n- Chair: 1\n- Rug: 1\n- Floor: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24604.2, "ram_available_mb": 38236.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24613.9, "ram_available_mb": 38227.0, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.957, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T07:25:39.320509"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10688.864, "latencies_ms": [10688.864], "images_per_second": 0.094, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "In the foreground, a person is seated on the floor in front of a large, ornate mirror. The mirror reflects the interior of a room, showing a person sitting on a couch in the background. The person in the foreground is closer to the camera than the person in the reflection, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24613.9, "ram_available_mb": 38227.0, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24666.7, "ram_available_mb": 38174.2, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.873, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T07:25:52.035285"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7679.752, "latencies_ms": [7679.752], "images_per_second": 0.13, "prompt_tokens": 37, "response_tokens_est": 45, "n_tiles": 16, "output_text": "A man is sitting on the floor in front of a large, ornate mirror, holding a smartphone in his hands. The room has a wooden floor, a green wall, and a red wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24666.7, "ram_available_mb": 38174.2, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24607.1, "ram_available_mb": 38233.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.425, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T07:26:01.770902"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7593.286, "latencies_ms": [7593.286], "images_per_second": 0.132, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image shows a person sitting on the floor in front of a large, ornate mirror. The room has wooden flooring and walls painted in a light green color, with a red accent wall visible in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24607.1, "ram_available_mb": 38233.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24613.0, "ram_available_mb": 38227.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.532, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.939}, "timestamp": "2026-01-23T07:26:11.422404"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11360.418, "latencies_ms": [11360.418], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of five men standing together, each holding a surfboard. They are posing for a picture, with one of the men taking a photo of the group using a cell phone. The surfboards are of various sizes and colors, adding a vibrant touch to the scene.\n\nIn the background, there is a refrigerator, which suggests that", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 24613.0, "ram_available_mb": 38227.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24595.1, "ram_available_mb": 38245.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.539, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T07:26:24.843820"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10222.424, "latencies_ms": [10222.424], "images_per_second": 0.098, "prompt_tokens": 39, "response_tokens_est": 68, "n_tiles": 16, "output_text": "1. Surfboard: 4\n2. Camera: 1\n3. Cell phone: 1\n4. Flag: 2\n5. Surfboard: 1\n6. Surfboard: 1\n7. Surfboard: 1\n8. Surfboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24595.1, "ram_available_mb": 38245.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24606.2, "ram_available_mb": 38234.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.163, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T07:26:37.113655"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10314.546, "latencies_ms": [10314.546], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "In the foreground, there is a person taking a photo of a group of individuals who are standing close together. The group is positioned in the center of the image, with some of them holding surfboards. In the background, there is a wall with various items hanging on it, including a surfboard and a flag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24606.2, "ram_available_mb": 38234.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24604.3, "ram_available_mb": 38236.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.999, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 8.872}, "timestamp": "2026-01-23T07:26:49.439704"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7515.247, "latencies_ms": [7515.247], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A group of young men are gathered in a room, holding surfboards and taking a photo with a camera. The room appears to be a casual setting, possibly a hangout or a surf shop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24604.3, "ram_available_mb": 38236.6, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24598.1, "ram_available_mb": 38242.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.577, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T07:26:58.997744"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8665.056, "latencies_ms": [8665.056], "images_per_second": 0.115, "prompt_tokens": 36, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image shows a group of individuals indoors, with one person taking a photo of the others who are holding surfboards. The lighting appears to be artificial, and the surfboards are of various colors and designs, including yellow, red, and blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24598.1, "ram_available_mb": 38242.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24596.8, "ram_available_mb": 38244.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.818, "power_cpu_cv_mean_watts": 1.799, "power_sys_5v0_mean_watts": 8.924}, "timestamp": "2026-01-23T07:27:09.673072"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12331.884, "latencies_ms": [12331.884], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a large yellow passenger airplane parked on the tarmac at an airport. The airplane is a LOT (Polish Airlines) plane, as indicated by the logo on the side of the aircraft. The plane is positioned in the center of the image, occupying a significant portion of the frame.\n\nIn the background, there are several other airplan", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 24596.8, "ram_available_mb": 38244.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24602.1, "ram_available_mb": 38238.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.609, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 9.041}, "timestamp": "2026-01-23T07:27:24.027335"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8431.42, "latencies_ms": [8431.42], "images_per_second": 0.119, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "airplane: 1, cloud: numerous, runway: 1, engine: 1, wing: 1, tail: 1, door: numerous, runway marking: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24602.1, "ram_available_mb": 38238.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24606.6, "ram_available_mb": 38234.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.436, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 9.037}, "timestamp": "2026-01-23T07:27:34.491495"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11952.857, "latencies_ms": [11952.857], "images_per_second": 0.084, "prompt_tokens": 44, "response_tokens_est": 76, "n_tiles": 16, "output_text": "The airplane is positioned in the foreground of the image, appearing large and prominent. It is situated on the tarmac, with a clear view of its side profile. In the background, there are other airplanes and a landscape that appears to be a hilly area with some buildings, indicating that the airport is located in a relatively open space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24606.6, "ram_available_mb": 38234.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24604.0, "ram_available_mb": 38236.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.736, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 9.043}, "timestamp": "2026-01-23T07:27:48.479874"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7537.981, "latencies_ms": [7537.981], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "A LOT Polish Airlines airplane is on the tarmac, likely preparing for departure. The sky is partly cloudy, suggesting fair weather conditions for flying.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24604.0, "ram_available_mb": 38236.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 24601.8, "ram_available_mb": 38239.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.979, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 9.051}, "timestamp": "2026-01-23T07:27:58.054200"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9323.586, "latencies_ms": [9323.586], "images_per_second": 0.107, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image features a large, yellow passenger airplane with the logo \"LOT\" on its side, indicating it is operated by Lot Polish Airlines. The aircraft is on a runway with a partly cloudy sky above, suggesting fair weather conditions for flying.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24601.8, "ram_available_mb": 38239.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24604.5, "ram_available_mb": 38236.4, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.597, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 9.131}, "timestamp": "2026-01-23T07:28:09.402571"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11405.543, "latencies_ms": [11405.543], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment in a bathroom, bathed in the stark contrast of black and white. Dominating the scene is a toilet, its lid raised in an invitation to use. The seat of the toilet is adorned with a white towel, a common sight in many bathrooms, providing a soft barrier between the user and the porcelain", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24604.5, "ram_available_mb": 38236.4, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 24616.0, "ram_available_mb": 38224.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.513, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 8.816}, "timestamp": "2026-01-23T07:28:22.844519"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7623.539, "latencies_ms": [7623.539], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "toilet: 1, flush handle: 1, towel: 1, wall: 1, floor: 1, person: 1, shoes: 1, door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24616.0, "ram_available_mb": 38224.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24607.3, "ram_available_mb": 38233.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.621, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T07:28:32.501477"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10471.656, "latencies_ms": [10471.656], "images_per_second": 0.095, "prompt_tokens": 44, "response_tokens_est": 71, "n_tiles": 16, "output_text": "The toilet is located in the foreground of the image, with its lid open and seat up. In the background, there is a wall-mounted toilet paper holder with a roll of paper attached to it. The person's legs are visible in the foreground, suggesting they are standing next to the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24607.3, "ram_available_mb": 38233.6, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24603.2, "ram_available_mb": 38237.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.001, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T07:28:45.021324"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7989.382, "latencies_ms": [7989.382], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image shows a close-up of a toilet with the seat cover up, revealing the toilet bowl. A person's legs are visible, suggesting that they are standing next to the toilet.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24603.2, "ram_available_mb": 38237.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24598.7, "ram_available_mb": 38242.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.361, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T07:28:55.047307"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7260.05, "latencies_ms": [7260.05], "images_per_second": 0.138, "prompt_tokens": 36, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image is in black and white, featuring a toilet with a closed lid and a partially open lid. The lighting appears to be artificial, coming from above, casting shadows on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24598.7, "ram_available_mb": 38242.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24600.0, "ram_available_mb": 38240.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.772, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.906}, "timestamp": "2026-01-23T07:29:04.337287"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11324.429, "latencies_ms": [11324.429], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a skier is captured in the midst of a thrilling descent down a snowy mountain slope. The skier, clad in a blue jacket and black pants, is holding two ski poles, aiding in their navigation through the snow. The skier's helmet, a crucial piece of safety gear, is white and matches the color of", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24600.0, "ram_available_mb": 38240.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24601.4, "ram_available_mb": 38239.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.55, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T07:29:17.735703"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8300.481, "latencies_ms": [8300.481], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "tree: multiple, ski: 2, skier: 1, snow: multiple, ski tracks: multiple, snowflakes: multiple, helmet: 1, goggles: 1, gloves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24601.4, "ram_available_mb": 38239.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24602.9, "ram_available_mb": 38238.0, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.353, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T07:29:28.054986"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9901.087, "latencies_ms": [9901.087], "images_per_second": 0.101, "prompt_tokens": 44, "response_tokens_est": 66, "n_tiles": 16, "output_text": "The skier is positioned in the foreground on the left side of the image, moving towards the right. The snow-covered trees form the background, appearing denser and more uniform in the distance. The skier is closer to the viewer than the trees, creating a sense of depth in the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24602.9, "ram_available_mb": 38238.0, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24602.7, "ram_available_mb": 38238.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.306, "power_cpu_cv_mean_watts": 1.852, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T07:29:39.974874"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8111.417, "latencies_ms": [8111.417], "images_per_second": 0.123, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A person is skiing down a snowy slope with trees covered in snow in the background. The skier is wearing a blue jacket, black pants, and a white helmet, and is holding two ski poles.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24602.7, "ram_available_mb": 38238.2, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24606.0, "ram_available_mb": 38234.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.212, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T07:29:50.136328"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7035.218, "latencies_ms": [7035.218], "images_per_second": 0.142, "prompt_tokens": 36, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The skier is wearing a blue jacket and black pants, and the snow is a bright white color. The trees in the background are covered in snow and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24606.0, "ram_available_mb": 38234.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24608.3, "ram_available_mb": 38232.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.047, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.952}, "timestamp": "2026-01-23T07:29:59.202738"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.081, "latencies_ms": [11335.081], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment from a tennis match. A player in a yellow shirt and black shorts is in the midst of a backhand swing, holding a tennis racket. The court is a vibrant blue, and the player is positioned near the baseline. In the background, there are spectators seated on the stands, and the court is adorned with", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24608.3, "ram_available_mb": 38232.6, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24607.0, "ram_available_mb": 38233.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.562, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.821}, "timestamp": "2026-01-23T07:30:12.595088"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7368.393, "latencies_ms": [7368.393], "images_per_second": 0.136, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "player: 1, racket: 1, ball: 0, chair: 2, audience: 1, advertisement: 4, court: 1, logo: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24607.0, "ram_available_mb": 38233.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24605.6, "ram_available_mb": 38235.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.024, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T07:30:21.987761"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11330.085, "latencies_ms": [11330.085], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a tennis player is positioned near the baseline on the left side of the court, preparing to hit a ball. In the background, there are spectators seated on the right side of the court, watching the game. The court itself is surrounded by a blue wall with advertisements, and the floor markings are visible, indicating the boundaries of the playing", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24605.6, "ram_available_mb": 38235.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24599.4, "ram_available_mb": 38241.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.645, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T07:30:35.370433"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9564.241, "latencies_ms": [9564.241], "images_per_second": 0.105, "prompt_tokens": 37, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The image captures a moment from a tennis match, with a player in a yellow shirt and black shorts in the midst of a backhand swing. The court is surrounded by a crowd of spectators, and there are advertisements for Kia and Garnier visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24599.4, "ram_available_mb": 38241.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24604.7, "ram_available_mb": 38236.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.39, "power_cpu_cv_mean_watts": 1.809, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T07:30:46.993162"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7899.856, "latencies_ms": [7899.856], "images_per_second": 0.127, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image shows an indoor tennis court with a blue surface and white boundary lines. The lighting appears to be artificial, as it is evenly distributed across the court, and there are no visible shadows that would indicate natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24604.7, "ram_available_mb": 38236.2, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24591.4, "ram_available_mb": 38249.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.166, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.941}, "timestamp": "2026-01-23T07:30:56.913467"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12335.384, "latencies_ms": [12335.384], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of culinary delight, featuring a black plate with a scalloped edge, resting on a white tablecloth. The plate holds a small metal bowl filled with a vibrant red sauce, its rich color suggesting a tomato base. Adjacent to the sauce, a smaller metal bowl cradles a collection of peach slices", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24591.4, "ram_available_mb": 38249.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24598.1, "ram_available_mb": 38242.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.653, "power_cpu_cv_mean_watts": 1.798, "power_sys_5v0_mean_watts": 9.043}, "timestamp": "2026-01-23T07:31:11.272198"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9015.372, "latencies_ms": [9015.372], "images_per_second": 0.111, "prompt_tokens": 39, "response_tokens_est": 48, "n_tiles": 16, "output_text": "bowl of food: 1, bowl of fruit: 1, fork: 1, knife: 1, glass: 1, napkin: 1, plate: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 30.8, "ram_used_mb": 24598.1, "ram_available_mb": 38242.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24597.9, "ram_available_mb": 38243.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.032, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 9.029}, "timestamp": "2026-01-23T07:31:22.325262"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11019.725, "latencies_ms": [11019.725], "images_per_second": 0.091, "prompt_tokens": 44, "response_tokens_est": 68, "n_tiles": 16, "output_text": "In the foreground, there is a bowl of sliced peaches placed near the edge of a black plate. Behind it, slightly to the left, is a smaller bowl containing what appears to be a meat-based dish. The larger bowl is closer to the viewer than the smaller bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24597.9, "ram_available_mb": 38243.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24594.8, "ram_available_mb": 38246.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.011, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 9.058}, "timestamp": "2026-01-23T07:31:35.406530"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11192.808, "latencies_ms": [11192.808], "images_per_second": 0.089, "prompt_tokens": 37, "response_tokens_est": 67, "n_tiles": 16, "output_text": "The image shows a meal setting with a bowl of sliced peaches and a bowl of what appears to be a meat-based dish, possibly stew, placed on a table. The table has a black surface, and there is a glass of water and a folded napkin on the side.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24594.8, "ram_available_mb": 38246.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24620.0, "ram_available_mb": 38220.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.137, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 9.013}, "timestamp": "2026-01-23T07:31:48.660728"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11128.616, "latencies_ms": [11128.616], "images_per_second": 0.09, "prompt_tokens": 36, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The image shows a meal with a dark, richly colored meat dish in a metal bowl and a lighter, pale yellow dessert in a smaller metal bowl. The lighting is warm and artificial, coming from a source not visible in the image, casting a soft glow on the food and the table surface.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24620.0, "ram_available_mb": 38220.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24708.1, "ram_available_mb": 38132.8, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.923, "power_cpu_cv_mean_watts": 1.733, "power_sys_5v0_mean_watts": 9.052}, "timestamp": "2026-01-23T07:32:01.837553"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11360.276, "latencies_ms": [11360.276], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of sheep standing together in a grassy area near a brick building. There are at least five sheep visible in the scene, with some of them standing close to each other, while others are a bit more spread out. The sheep appear to be of various sizes, and they are all looking in different directions, possibly observing their surroundings or interacting with one another", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24708.1, "ram_available_mb": 38132.8, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 24714.8, "ram_available_mb": 38126.1, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.558, "power_cpu_cv_mean_watts": 2.256, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T07:32:15.269393"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9908.752, "latencies_ms": [9908.752], "images_per_second": 0.101, "prompt_tokens": 39, "response_tokens_est": 65, "n_tiles": 16, "output_text": "1. Sheep: 5\n2. Grass: 1\n3. Brick wall: 1\n4. Tree: 1\n5. Fence: 1\n6. Barn: 1\n7. Shed: 1\n8. Ground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24714.8, "ram_available_mb": 38126.1, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 24612.6, "ram_available_mb": 38228.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.316, "power_cpu_cv_mean_watts": 2.059, "power_sys_5v0_mean_watts": 8.876}, "timestamp": "2026-01-23T07:32:27.206534"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10522.491, "latencies_ms": [10522.491], "images_per_second": 0.095, "prompt_tokens": 44, "response_tokens_est": 72, "n_tiles": 16, "output_text": "In the foreground of the image, there are three sheep standing close together, with one on the left, one in the middle, and one on the right. They are positioned near the grassy area in front of a brick building. In the background, there is another sheep standing further away, and a fence can be seen behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24612.6, "ram_available_mb": 38228.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24608.0, "ram_available_mb": 38232.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.904, "power_cpu_cv_mean_watts": 1.895, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T07:32:39.754903"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6121.986, "latencies_ms": [6121.986], "images_per_second": 0.163, "prompt_tokens": 37, "response_tokens_est": 32, "n_tiles": 16, "output_text": "A group of sheep are standing in a grassy area near a brick building. The sheep appear to be grazing or resting in the shade.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24608.0, "ram_available_mb": 38232.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24606.6, "ram_available_mb": 38234.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.991, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.973}, "timestamp": "2026-01-23T07:32:47.910016"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7312.108, "latencies_ms": [7312.108], "images_per_second": 0.137, "prompt_tokens": 36, "response_tokens_est": 44, "n_tiles": 16, "output_text": "The image features a group of sheep with thick, curly wool in various shades of brown and beige. The lighting is bright and natural, suggesting the photo was taken on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24606.6, "ram_available_mb": 38234.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24601.5, "ram_available_mb": 38239.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.539, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 8.944}, "timestamp": "2026-01-23T07:32:57.241039"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 10709.166, "latencies_ms": [10709.166], "images_per_second": 0.093, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 16, "output_text": "The image features a red apple sitting in the center, surrounded by a bunch of green bananas. The bananas are arranged in a circular pattern around the apple, creating a visually appealing composition. The background consists of a blue and white pattern, which adds a contrasting color to the overall scene.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 24601.5, "ram_available_mb": 38239.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24651.7, "ram_available_mb": 38189.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.486, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 9.083}, "timestamp": "2026-01-23T07:33:09.988005"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5013.716, "latencies_ms": [5013.716], "images_per_second": 0.199, "prompt_tokens": 39, "response_tokens_est": 11, "n_tiles": 16, "output_text": "banana: 5, apple: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24651.7, "ram_available_mb": 38189.2, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 24646.2, "ram_available_mb": 38194.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.535, "power_cpu_cv_mean_watts": 0.753, "power_sys_5v0_mean_watts": 9.208}, "timestamp": "2026-01-23T07:33:17.044288"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12598.303, "latencies_ms": [12598.303], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground of the image, there is a red apple centrally positioned with a cluster of green bananas surrounding it, one on the left and two on the right, all appearing to be in the near vicinity of the apple. The background features a textured pattern that resembles a close-up of a leaf or a frosted glass surface, which is further away", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24646.2, "ram_available_mb": 38194.7, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24605.1, "ram_available_mb": 38235.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.095, "power_cpu_cv_mean_watts": 1.803, "power_sys_5v0_mean_watts": 9.074}, "timestamp": "2026-01-23T07:33:31.657112"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10872.466, "latencies_ms": [10872.466], "images_per_second": 0.092, "prompt_tokens": 37, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The image shows a group of bananas arranged in a circle around a red apple, all set against a blue textured background. The arrangement creates a visually appealing pattern, with the bananas' yellow color contrasting with the apple's red hue and the background's cool tone.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24605.1, "ram_available_mb": 38235.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24631.5, "ram_available_mb": 38209.4, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.827, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 9.068}, "timestamp": "2026-01-23T07:33:44.560396"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11570.085, "latencies_ms": [11570.085], "images_per_second": 0.086, "prompt_tokens": 36, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The image features a vibrant red apple centrally placed among four green bananas, all set against a textured background with a cool blue tone. The lighting in the image highlights the glossy surface of the apple and the smooth skin of the bananas, creating a contrast with the intricate patterns of the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24631.5, "ram_available_mb": 38209.4, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24632.6, "ram_available_mb": 38208.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.381, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 9.113}, "timestamp": "2026-01-23T07:33:58.181643"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12326.093, "latencies_ms": [12326.093], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a blue and white train traveling down the tracks, with several people visible inside the train. The train is moving through a city, and there are multiple cars parked along the side of the road. \n\nIn addition to the train, there are a few other vehicles in the scene, including a truck and a car. A person can be seen standing near the train", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24632.6, "ram_available_mb": 38208.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24593.5, "ram_available_mb": 38247.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.641, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 9.055}, "timestamp": "2026-01-23T07:34:12.529367"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8651.253, "latencies_ms": [8651.253], "images_per_second": 0.116, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "train: 1\ntruck: 1\nwindow: 12\nseat: 10\npassenger: 9\ndoor: 4\ntrack: 2\nplatform: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24593.5, "ram_available_mb": 38247.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24617.5, "ram_available_mb": 38223.4, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.326, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 9.038}, "timestamp": "2026-01-23T07:34:23.211798"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9167.78, "latencies_ms": [9167.78], "images_per_second": 0.109, "prompt_tokens": 44, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The train is in the foreground of the image, positioned on the left side, and appears to be moving towards the right. There is a clear sky in the background, and a building can be seen in the far right corner of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24617.5, "ram_available_mb": 38223.4, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24594.6, "ram_available_mb": 38246.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.712, "power_cpu_cv_mean_watts": 1.612, "power_sys_5v0_mean_watts": 9.119}, "timestamp": "2026-01-23T07:34:34.394513"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7509.935, "latencies_ms": [7509.935], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "A blue and white train with the number 2 on the front is on a track with trees in the background. There are people visible through the windows of the train.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24594.6, "ram_available_mb": 38246.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 24589.8, "ram_available_mb": 38251.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.004, "power_cpu_cv_mean_watts": 1.389, "power_sys_5v0_mean_watts": 9.056}, "timestamp": "2026-01-23T07:34:43.926570"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6770.348, "latencies_ms": [6770.348], "images_per_second": 0.148, "prompt_tokens": 36, "response_tokens_est": 31, "n_tiles": 16, "output_text": "The train is predominantly blue and white with a red interior. It is a clear day with shadows cast on the ground indicating sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24589.8, "ram_available_mb": 38251.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 24583.5, "ram_available_mb": 38257.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.208, "power_cpu_cv_mean_watts": 1.346, "power_sys_5v0_mean_watts": 9.197}, "timestamp": "2026-01-23T07:34:52.724756"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11321.162, "latencies_ms": [11321.162], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene and well-organized bathroom. Dominating the scene is a white bathtub, its interior glowing with a beige hue. A red shower curtain, adorned with a floral pattern, hangs gracefully from the bathtub, adding a pop of color to the otherwise neutral palette. \n\nAd", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 24583.5, "ram_available_mb": 38257.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24594.5, "ram_available_mb": 38246.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.649, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T07:35:06.099444"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7724.116, "latencies_ms": [7724.116], "images_per_second": 0.129, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "mirror: 1\nsink: 1\ntub: 1\ncurtain: 1\ntowel: 1\nmat: 1\ndoor: 1\nmirror frame: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24594.5, "ram_available_mb": 38246.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24590.2, "ram_available_mb": 38250.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.588, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T07:35:15.856826"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8331.156, "latencies_ms": [8331.156], "images_per_second": 0.12, "prompt_tokens": 44, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The shower area is located on the left side of the image, adjacent to the bathroom sink which is on the right. The red bath mat is placed in the foreground on the floor, leading the eye towards the shower area in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24590.2, "ram_available_mb": 38250.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24587.2, "ram_available_mb": 38253.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.053, "power_cpu_cv_mean_watts": 1.779, "power_sys_5v0_mean_watts": 8.943}, "timestamp": "2026-01-23T07:35:26.225200"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8534.203, "latencies_ms": [8534.203], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image depicts a well-lit, clean bathroom with a large mirror above a double sink vanity. A red shower curtain is partially drawn, and a red bath mat is placed on the floor in front of the bathtub.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24587.2, "ram_available_mb": 38253.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24599.5, "ram_available_mb": 38241.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.96, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.879}, "timestamp": "2026-01-23T07:35:36.784288"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9266.621, "latencies_ms": [9266.621], "images_per_second": 0.108, "prompt_tokens": 36, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The bathroom features a beige color scheme with a red patterned shower curtain. The lighting is provided by two wall-mounted sconces with a vintage design, casting a warm glow on the cream-colored walls and the dark wood vanity.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24599.5, "ram_available_mb": 38241.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24591.9, "ram_available_mb": 38248.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.319, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T07:35:48.090854"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11303.079, "latencies_ms": [11303.079], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a dynamic scene of a surfer in action. The surfer, clad in a black wetsuit, is skillfully riding a wave. The wave, a powerful force of nature, is white and frothy, indicating its strength and the speed at which it's moving. The surfer is crouched on the surfboard, arms outstretch", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 24591.9, "ram_available_mb": 38248.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24590.3, "ram_available_mb": 38250.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.629, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T07:36:01.416069"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7625.034, "latencies_ms": [7625.034], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "water: numerous\nsurfboard: 1\nsurfer: 1\nwave: 1\nspray: numerous\nsea: entire background\nblack and white: entire image\ntext: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24590.3, "ram_available_mb": 38250.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24594.8, "ram_available_mb": 38246.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.603, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.899}, "timestamp": "2026-01-23T07:36:11.054815"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11383.221, "latencies_ms": [11383.221], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The surfer is positioned in the foreground, riding a wave that is breaking to the right of the frame. The wave originates from the background and extends towards the left side of the image, creating a dynamic contrast between the surfer's movement and the stationary water. The text 'STB' is placed in the upper right corner, far from the action, suggesting it", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24594.8, "ram_available_mb": 38246.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 24600.5, "ram_available_mb": 38240.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.582, "power_cpu_cv_mean_watts": 2.225, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T07:36:24.457830"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8069.501, "latencies_ms": [8069.501], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A surfer is captured in mid-air, performing a jump above a wave in the ocean. The image is in black and white, with the surfer's silhouette standing out against the white foam of the wave.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24600.5, "ram_available_mb": 38240.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 24648.8, "ram_available_mb": 38192.1, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.249, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 8.918}, "timestamp": "2026-01-23T07:36:34.560622"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6766.05, "latencies_ms": [6766.05], "images_per_second": 0.148, "prompt_tokens": 36, "response_tokens_est": 39, "n_tiles": 16, "output_text": "The image is in black and white, featuring a surfer riding a wave. The wave is large and powerful, with water splashing around the surfer as they navigate it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24648.8, "ram_available_mb": 38192.1, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24603.9, "ram_available_mb": 38237.0, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.047, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.979}, "timestamp": "2026-01-23T07:36:43.356494"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11356.533, "latencies_ms": [11356.533], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a baseball game in progress, with a batter standing at home plate, holding a baseball bat and waiting for the pitch. The catcher is crouched behind the batter, wearing a baseball glove, and the umpire is positioned behind the catcher, observing the game. \n\nThere are several other people in the scene, including players and spect", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24603.9, "ram_available_mb": 38237.0, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24606.7, "ram_available_mb": 38234.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.595, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T07:36:56.743714"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7861.264, "latencies_ms": [7861.264], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "player: 1, catcher: 1, umpire: 1, baseball glove: 1, bat: 1, jersey: 1, number: 10, audience: multiple", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24606.7, "ram_available_mb": 38234.2, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24610.4, "ram_available_mb": 38230.5, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.444, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 8.896}, "timestamp": "2026-01-23T07:37:06.635065"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11393.127, "latencies_ms": [11393.127], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a baseball player in a white uniform with the number 10 is standing at home plate, ready to swing. Behind him, the catcher and umpire are in position, with the catcher crouched behind home plate and the umpire standing to the left of the catcher. In the background, there are spectators seated in the stands", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24610.4, "ram_available_mb": 38230.5, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 24662.1, "ram_available_mb": 38178.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.59, "power_cpu_cv_mean_watts": 2.453, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T07:37:20.054129"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8675.126, "latencies_ms": [8675.126], "images_per_second": 0.115, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image captures a moment during a baseball game where a batter is at the plate, ready to swing. The catcher and umpire are in position behind the batter, with the catcher crouched and the umpire standing upright.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 24662.1, "ram_available_mb": 38178.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 24759.6, "ram_available_mb": 38081.3, "ram_percent": 39.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.931, "power_cpu_cv_mean_watts": 1.969, "power_sys_5v0_mean_watts": 8.885}, "timestamp": "2026-01-23T07:37:30.751695"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9688.032, "latencies_ms": [9688.032], "images_per_second": 0.103, "prompt_tokens": 36, "response_tokens_est": 60, "n_tiles": 16, "output_text": "The image shows a baseball game in progress with a player in a white uniform at bat, a catcher in a black and red uniform, and an umpire in a blue uniform. The lighting appears to be artificial, likely from stadium lights, and the weather is overcast.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24759.6, "ram_available_mb": 38081.3, "ram_percent": 39.4}, "sys_after": {"cpu_percent": 25.2, "ram_used_mb": 25260.6, "ram_available_mb": 37580.3, "ram_percent": 40.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.932, "power_cpu_cv_mean_watts": 4.614, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T07:37:42.474030"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12590.677, "latencies_ms": [12590.677], "images_per_second": 0.079, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image is a black and white drawing of a variety of fruits and nuts. There are two apples, one on the left and one on the right, with the left apple being larger and the right one smaller. A bunch of grapes is placed between the two apples, and a single orange is situated in the center of the composition. Additionally, there are several pean", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 25260.6, "ram_available_mb": 37580.3, "ram_percent": 40.2}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 25442.7, "ram_available_mb": 37398.2, "ram_percent": 40.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.819, "power_cpu_cv_mean_watts": 2.325, "power_sys_5v0_mean_watts": 9.092}, "timestamp": "2026-01-23T07:37:57.088812"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7316.945, "latencies_ms": [7316.945], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 31, "n_tiles": 16, "output_text": "peanuts: 12, grapes: 5, orange: 1, apple: 1, pear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25442.7, "ram_available_mb": 37398.2, "ram_percent": 40.5}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 25452.3, "ram_available_mb": 37388.6, "ram_percent": 40.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.938, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 9.132}, "timestamp": "2026-01-23T07:38:06.425602"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12291.199, "latencies_ms": [12291.199], "images_per_second": 0.081, "prompt_tokens": 44, "response_tokens_est": 76, "n_tiles": 16, "output_text": "In the foreground, there is a pile of peanuts, which are the closest to the viewer. Behind the peanuts, there is a large orange, and further back, there are clusters of grapes. The grapes are positioned on the left side, while the orange is more centrally located among the fruits.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25452.3, "ram_available_mb": 37388.6, "ram_percent": 40.5}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 25410.9, "ram_available_mb": 37430.0, "ram_percent": 40.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.156, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 9.098}, "timestamp": "2026-01-23T07:38:20.745888"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10015.317, "latencies_ms": [10015.317], "images_per_second": 0.1, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image depicts a still life arrangement of various fruits and nuts on a white background. There is a large orange, a bunch of grapes, a few peanuts, and a few other fruits that are not clearly identifiable.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25410.9, "ram_available_mb": 37430.0, "ram_percent": 40.4}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 25199.2, "ram_available_mb": 37641.7, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.086, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 9.075}, "timestamp": "2026-01-23T07:38:32.784330"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8692.498, "latencies_ms": [8692.498], "images_per_second": 0.115, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image is a black and white drawing featuring a variety of fruits. The lighting appears to be coming from the upper left, casting subtle shadows on the right sides of the fruits and nuts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25199.2, "ram_available_mb": 37641.7, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 25238.6, "ram_available_mb": 37602.3, "ram_percent": 40.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.559, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 9.173}, "timestamp": "2026-01-23T07:38:43.491254"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12362.924, "latencies_ms": [12362.924], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image depicts a city street with a mix of modern and older buildings. There are several cars parked along the street, and a few cars are driving down the road. A sidewalk runs alongside the street, providing a pedestrian path. A bike lane is also present, running parallel to the sidewalk.\n\nIn the distance, there is a bus stop with", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 25238.6, "ram_available_mb": 37602.3, "ram_percent": 40.2}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 25190.9, "ram_available_mb": 37650.0, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.62, "power_cpu_cv_mean_watts": 1.8, "power_sys_5v0_mean_watts": 9.047}, "timestamp": "2026-01-23T07:38:57.917308"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9163.324, "latencies_ms": [9163.324], "images_per_second": 0.109, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "buildings: 10, cars: 5, street lights: 4, trees: 2, sidewalks: 1, buses: 1, pedestrians: 0, buildings: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25190.9, "ram_available_mb": 37650.0, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 25183.5, "ram_available_mb": 37657.4, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.913, "power_cpu_cv_mean_watts": 1.54, "power_sys_5v0_mean_watts": 9.038}, "timestamp": "2026-01-23T07:39:09.103252"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11949.77, "latencies_ms": [11949.77], "images_per_second": 0.084, "prompt_tokens": 44, "response_tokens_est": 76, "n_tiles": 16, "output_text": "The image shows a street view with buildings in the background, a road in the foreground, and a clear sky above. The road has multiple lanes with cars parked on the side, and there is a sidewalk parallel to the road. The buildings appear to be residential or commercial structures, and there is a tree line on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 25183.5, "ram_available_mb": 37657.4, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 25193.0, "ram_available_mb": 37647.9, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.671, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 9.045}, "timestamp": "2026-01-23T07:39:23.085673"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8449.213, "latencies_ms": [8449.213], "images_per_second": 0.118, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image depicts a street scene with a clear sky and a few clouds. There are multiple buildings on the left side of the street, and a few cars are parked and driving on the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25193.0, "ram_available_mb": 37647.9, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 25193.0, "ram_available_mb": 37647.9, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.449, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 9.061}, "timestamp": "2026-01-23T07:39:33.562257"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6907.617, "latencies_ms": [6907.617], "images_per_second": 0.145, "prompt_tokens": 36, "response_tokens_est": 32, "n_tiles": 16, "output_text": "The image shows a clear day with a blue sky and some clouds. The buildings are multi-story with a mix of brick and painted exteriors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25193.0, "ram_available_mb": 37647.9, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 25197.5, "ram_available_mb": 37643.4, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.175, "power_cpu_cv_mean_watts": 1.346, "power_sys_5v0_mean_watts": 9.156}, "timestamp": "2026-01-23T07:39:42.511842"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11317.089, "latencies_ms": [11317.089], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there is a man and a woman sitting at a table in a restaurant. The man is wearing a blue striped shirt and a black tie with a gold emblem, and he is holding a phone in his hand. The woman is wearing a white tank top and has her arm around the man's shoulder. They are both smiling and appear to be happy", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 25197.5, "ram_available_mb": 37643.4, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 25197.8, "ram_available_mb": 37643.1, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.626, "power_cpu_cv_mean_watts": 1.952, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T07:39:55.893281"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7203.822, "latencies_ms": [7203.822], "images_per_second": 0.139, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "person: 2, table: 1, menu: 1, drink: 1, cell phone: 1, wall: 1, window: 1, television: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25197.8, "ram_available_mb": 37643.1, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 25193.8, "ram_available_mb": 37647.1, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.914, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.919}, "timestamp": "2026-01-23T07:40:05.142839"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11425.115, "latencies_ms": [11425.115], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The man is standing in the foreground on the left side of the image, while the woman is seated in the foreground on the right side. They are positioned close to each other, suggesting a sense of intimacy or companionship. In the background, there is a wall with framed pictures and a television screen, indicating that they are inside a room, possibly a living room", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 25193.8, "ram_available_mb": 37647.1, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 25200.1, "ram_available_mb": 37640.8, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.57, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T07:40:18.581678"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9056.424, "latencies_ms": [9056.424], "images_per_second": 0.11, "prompt_tokens": 37, "response_tokens_est": 57, "n_tiles": 16, "output_text": "A man and a woman are sitting closely together at a table in a dimly lit restaurant, with the man holding a phone in his hand. The woman is wearing a white tank top and the man is wearing a blue striped shirt with a patterned tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25200.1, "ram_available_mb": 37640.8, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 25202.2, "ram_available_mb": 37638.7, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.786, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 8.836}, "timestamp": "2026-01-23T07:40:29.675493"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7671.24, "latencies_ms": [7671.24], "images_per_second": 0.13, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image shows two individuals in an indoor setting with warm lighting. The man is wearing a blue striped shirt with a patterned tie, and the woman is in a white sleeveless top.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 25202.2, "ram_available_mb": 37638.7, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 25206.1, "ram_available_mb": 37634.8, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.422, "power_cpu_cv_mean_watts": 2.197, "power_sys_5v0_mean_watts": 8.946}, "timestamp": "2026-01-23T07:40:39.399426"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 10977.24, "latencies_ms": [10977.24], "images_per_second": 0.091, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 16, "output_text": "The image features a woman dressed in a costume, possibly as a warrior or a character from a movie, talking on a cell phone. She is surrounded by a group of people, with some of them standing close to her and others further away. The woman is the main focus of the scene, and the people around her seem to be engaged in their own activities.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 25206.1, "ram_available_mb": 37634.8, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 25214.6, "ram_available_mb": 37626.3, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.768, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T07:40:52.438265"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9696.338, "latencies_ms": [9696.338], "images_per_second": 0.103, "prompt_tokens": 39, "response_tokens_est": 63, "n_tiles": 16, "output_text": "1. Woman: 1\n2. Phone: 1\n3. Man: 1\n4. Building: 1\n5. Hat: 1\n6. Necklace: 1\n7. Eye shadow: 1\n8. Lipstick: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 25214.6, "ram_available_mb": 37626.3, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 25197.7, "ram_available_mb": 37643.2, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.306, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 8.873}, "timestamp": "2026-01-23T07:41:04.173406"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11332.766, "latencies_ms": [11332.766], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a person is holding a phone to their ear, seemingly in the middle of a conversation. Behind them, there are several other individuals, some of whom are partially visible and appear to be engaged in their own activities. The person with the phone is positioned slightly to the left of the center of the image, while the others are scattered around, with some in the", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 25197.7, "ram_available_mb": 37643.2, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 25212.2, "ram_available_mb": 37628.7, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.676, "power_cpu_cv_mean_watts": 1.965, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T07:41:17.561591"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7968.304, "latencies_ms": [7968.304], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "A woman dressed in a costume resembling a character from a movie is talking on a phone while standing in a crowd of people. The setting appears to be an outdoor event or gathering, possibly a convention or festival.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 25212.2, "ram_available_mb": 37628.7, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 25211.6, "ram_available_mb": 37629.3, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.269, "power_cpu_cv_mean_watts": 1.814, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T07:41:27.572195"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9270.963, "latencies_ms": [9270.963], "images_per_second": 0.108, "prompt_tokens": 36, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The image features a person wearing a costume with gold and black colors, and the lighting appears to be natural daylight. The costume seems to be made of a shiny, possibly metallic material, and the person is wearing a headpiece with a gold design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25211.6, "ram_available_mb": 37629.3, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 25206.3, "ram_available_mb": 37634.6, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.391, "power_cpu_cv_mean_watts": 1.852, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T07:41:38.891821"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11298.785, "latencies_ms": [11298.785], "images_per_second": 0.089, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene in a bathroom, dominated by a white toilet with a white tank and a white shower head. The toilet is positioned on the left side of the image, while the shower head is on the right. The floor beneath these fixtures is tiled in white, matching the color of the toilet and shower head", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 25206.3, "ram_available_mb": 37634.6, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 25206.1, "ram_available_mb": 37634.8, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.644, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T07:41:52.241529"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7418.555, "latencies_ms": [7418.555], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "shower head: 1, pipe: 3, tiles: many, bucket: 2, drain: 1, toilet: 1, wall: many, floor: many", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25206.1, "ram_available_mb": 37634.8, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 25208.9, "ram_available_mb": 37632.0, "ram_percent": 40.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.869, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.889}, "timestamp": "2026-01-23T07:42:01.674417"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11371.909, "latencies_ms": [11371.909], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground of the image, there is a white toilet with a blue pipe connected to it, situated near a white pillar that appears to be part of a shower system. To the right of the toilet, there is a green bucket placed on the floor, and further back, there is a red bucket. The shower system with a white showerhead is", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 25208.9, "ram_available_mb": 37632.0, "ram_percent": 40.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24564.3, "ram_available_mb": 38276.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.717, "power_cpu_cv_mean_watts": 1.962, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T07:42:15.088342"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9243.892, "latencies_ms": [9243.892], "images_per_second": 0.108, "prompt_tokens": 37, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image depicts a small, cramped bathroom with white tiled walls and floor. There is a white toilet with a blue pipe connected to it, a green bucket, and a red bucket on the floor, and a showerhead mounted on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24564.3, "ram_available_mb": 38276.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24573.3, "ram_available_mb": 38267.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.629, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T07:42:26.384294"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8149.423, "latencies_ms": [8149.423], "images_per_second": 0.123, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows a bathroom with white tiled walls and a white toilet with a blue pipe. There is a green bucket and a red bucket on the floor, and a showerhead is visible on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 24573.3, "ram_available_mb": 38267.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24567.7, "ram_available_mb": 38273.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.173, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 8.899}, "timestamp": "2026-01-23T07:42:36.586134"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11365.901, "latencies_ms": [11365.901], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is standing next to an elephant, with the elephant's trunk wrapped around the man's neck. The man is wearing glasses and appears to be smiling, possibly enjoying the interaction with the elephant. The elephant is also smiling, creating a heartwarming scene.\n\nThere are a few", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24567.7, "ram_available_mb": 38273.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24560.2, "ram_available_mb": 38280.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.54, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T07:42:49.985295"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7164.452, "latencies_ms": [7164.452], "images_per_second": 0.14, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "man: 1, elephant: 2, trees: many, sky: 1, mountains: 1, sun: 1, grass: 1, clouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24560.2, "ram_available_mb": 38280.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24555.7, "ram_available_mb": 38285.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.204, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.919}, "timestamp": "2026-01-23T07:42:59.164976"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11340.597, "latencies_ms": [11340.597], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a man wearing glasses and a light-colored shirt, who is standing close to an elephant. The elephant is positioned to the left of the man, with its trunk extended towards him. In the background, there is a lush green forest, indicating that the man and the elephant are in a natural,", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.7, "ram_available_mb": 38285.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.626, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T07:43:12.544568"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7160.581, "latencies_ms": [7160.581], "images_per_second": 0.14, "prompt_tokens": 37, "response_tokens_est": 41, "n_tiles": 16, "output_text": "A man is standing in front of an elephant, with the elephant's trunk wrapped around his neck. The background shows a lush green forest and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24562.9, "ram_available_mb": 38278.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.002, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T07:43:21.739635"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7332.465, "latencies_ms": [7332.465], "images_per_second": 0.136, "prompt_tokens": 36, "response_tokens_est": 44, "n_tiles": 16, "output_text": "The image features a man wearing glasses and a light-colored t-shirt, standing in front of an elephant. The background shows a lush green forest and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24562.9, "ram_available_mb": 38278.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24557.6, "ram_available_mb": 38283.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.536, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.952}, "timestamp": "2026-01-23T07:43:31.095172"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 10696.199, "latencies_ms": [10696.199], "images_per_second": 0.093, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 16, "output_text": "The image depicts a group of five children sitting on the grass, each holding a white frisbee. They are all wearing different colored shirts, and the scene appears to be set in a park or a grassy area. The children seem to be enjoying their time together, possibly playing a game or just hanging out.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24557.6, "ram_available_mb": 38283.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.763, "power_cpu_cv_mean_watts": 1.886, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T07:43:43.820667"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8435.973, "latencies_ms": [8435.973], "images_per_second": 0.119, "prompt_tokens": 39, "response_tokens_est": 52, "n_tiles": 16, "output_text": "children: 5\nfrisbees: 2\ngrass: numerous\ntrees: 3\nsweatshirts: 2\nsocks: 2\nshirts: 3\npants: 3", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24552.7, "ram_available_mb": 38288.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.076, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T07:43:54.295801"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11347.883, "latencies_ms": [11347.883], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there are five children sitting on the grass, with one child on the far left and the others spread out towards the right. The child on the far right is holding a white frisbee with the word \"Ultimate\" on it, which is the main object in the image. The background consists of trees and shrubs, indicating that the setting is outdo", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24552.7, "ram_available_mb": 38288.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.618, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T07:44:07.692780"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6713.884, "latencies_ms": [6713.884], "images_per_second": 0.149, "prompt_tokens": 37, "response_tokens_est": 37, "n_tiles": 16, "output_text": "A group of children is sitting on the grass, each holding a frisbee. They appear to be in a park or a grassy area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.304, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 8.921}, "timestamp": "2026-01-23T07:44:16.440111"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7665.362, "latencies_ms": [7665.362], "images_per_second": 0.13, "prompt_tokens": 36, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The image shows a group of children sitting on grass with a clear sky in the background. They are holding frisbees, one of which is white with a black logo, and another is white with red and blue text.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.326, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 8.935}, "timestamp": "2026-01-23T07:44:26.122671"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11339.883, "latencies_ms": [11339.883], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young girl is standing on a sidewalk, holding a black umbrella to protect herself from the rain. She is wearing a red coat and white shoes, and she appears to be smiling. The sidewalk is wet, indicating that it has been raining.\n\nThe scene is set in a residential area, with a house visible in the background", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.525, "power_cpu_cv_mean_watts": 1.982, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T07:44:39.494376"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9318.791, "latencies_ms": [9318.791], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 60, "n_tiles": 16, "output_text": "- umbrella: 1\n- child: 1\n- red coat: 1\n- blue jeans: 1\n- white sneakers: 1\n- green bush: 2\n- puddle: 1\n- houses: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.825, "power_cpu_cv_mean_watts": 2.327, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T07:44:50.865172"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9788.917, "latencies_ms": [9788.917], "images_per_second": 0.102, "prompt_tokens": 44, "response_tokens_est": 65, "n_tiles": 16, "output_text": "In the foreground, a child is standing on a wet sidewalk, holding an umbrella to protect from the rain. The child is positioned near a large, well-manicured bush. In the background, there are houses and vehicles, indicating that the scene takes place in a residential area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 24552.6, "ram_available_mb": 38288.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.288, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T07:45:02.687291"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6658.954, "latencies_ms": [6658.954], "images_per_second": 0.15, "prompt_tokens": 37, "response_tokens_est": 36, "n_tiles": 16, "output_text": "A young child is standing on a wet sidewalk, holding an umbrella to shield themselves from the rain. The background shows a residential area with houses and trees.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24552.6, "ram_available_mb": 38288.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.544, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 8.885}, "timestamp": "2026-01-23T07:45:11.405457"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8059.846, "latencies_ms": [8059.846], "images_per_second": 0.124, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "A child in a red coat is holding a patterned umbrella, standing on a wet sidewalk with a hedge and a red truck in the background. The sky is overcast, indicating it is likely a rainy day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.014, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 8.918}, "timestamp": "2026-01-23T07:45:21.509046"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11315.963, "latencies_ms": [11315.963], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a group of elephants is walking along a dirt road. The main elephant in the foreground is walking towards the camera, while the other elephants are following behind. The elephants are of various sizes, with some being larger and others smaller. The scene appears to be in a natural environment, possibly a savannah or a wildlife reserve", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.701, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T07:45:34.889926"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7409.442, "latencies_ms": [7409.442], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "elephant: 3, water: 1, trees: 1, dirt: 1, sky: 1, clouds: 1, grass: 1, ground: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.676, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T07:45:44.338905"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11328.577, "latencies_ms": [11328.577], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a prominent elephant with its trunk extended towards the camera, giving a sense of being close to the viewer. Behind this elephant, there are two more elephants, one partially visible on the left and another more obscured on the right, creating a sense of depth. The background features a body of water and some vegetation,", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24541.6, "ram_available_mb": 38299.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.721, "power_cpu_cv_mean_watts": 1.952, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T07:45:57.704471"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8127.452, "latencies_ms": [8127.452], "images_per_second": 0.123, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A group of elephants, including a young one, are walking along a dirt path near a body of water. The elephants appear to be in a natural habitat, possibly a savannah or a wildlife reserve.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24541.6, "ram_available_mb": 38299.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24538.0, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.074, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T07:46:07.864517"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9959.074, "latencies_ms": [9959.074], "images_per_second": 0.1, "prompt_tokens": 36, "response_tokens_est": 67, "n_tiles": 16, "output_text": "The elephant in the foreground has a rough, sandy-colored skin with patches of lighter and darker shades, indicating a dry and dusty environment. The lighting is soft and diffused, suggesting an overcast sky or a time of day when the sun is not at its peak.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.0, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24532.4, "ram_available_mb": 38308.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.052, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T07:46:19.860876"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12498.873, "latencies_ms": [12498.873], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a thrilling moment of a surfer riding a wave. The surfer, clad in a vibrant red and green wetsuit, is skillfully maneuvering a white surfboard. The wave, a deep green color, is breaking to the right, creating a dynamic and powerful scene. The surfer is positioned on the left side of", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 24532.4, "ram_available_mb": 38308.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24578.7, "ram_available_mb": 38262.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.054, "power_cpu_cv_mean_watts": 1.789, "power_sys_5v0_mean_watts": 9.098}, "timestamp": "2026-01-23T07:46:34.396008"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8809.35, "latencies_ms": [8809.35], "images_per_second": 0.114, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "surfer: 1, wave: multiple, water droplets: numerous, surfboard: 1, air: 1, foam: multiple, ocean: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24578.7, "ram_available_mb": 38262.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24574.4, "ram_available_mb": 38266.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.882, "power_cpu_cv_mean_watts": 1.445, "power_sys_5v0_mean_watts": 9.11}, "timestamp": "2026-01-23T07:46:45.215762"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12658.852, "latencies_ms": [12658.852], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 80, "n_tiles": 16, "output_text": "The surfer is positioned in the foreground, riding a wave that is breaking to the right of the frame. The wave itself is the main object in the background, with its crest curling over to the left side of the image. The spray from the wave is captured in the midground, creating a dynamic contrast between the surfer and the wave's motion.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 24574.4, "ram_available_mb": 38266.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24550.4, "ram_available_mb": 38290.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.017, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 9.084}, "timestamp": "2026-01-23T07:46:59.898785"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8677.863, "latencies_ms": [8677.863], "images_per_second": 0.115, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "A surfer is captured in mid-air, performing a trick above a large wave. The photo is taken from a distance, showcasing the surfer's skill and the power of the ocean.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24550.4, "ram_available_mb": 38290.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 24560.6, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.922, "power_cpu_cv_mean_watts": 1.456, "power_sys_5v0_mean_watts": 9.106}, "timestamp": "2026-01-23T07:47:10.631400"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9250.257, "latencies_ms": [9250.257], "images_per_second": 0.108, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The surfer is wearing a bright red and green wetsuit, which stands out against the darker tones of the ocean. The lighting in the image is natural, suggesting it was taken during the day under clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24560.6, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24529.8, "ram_available_mb": 38311.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.324, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 9.134}, "timestamp": "2026-01-23T07:47:21.905413"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12348.042, "latencies_ms": [12348.042], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a man and a woman riding horses on a sandy beach. The man is riding a white horse, while the woman is on a brown horse. They are both wearing white clothes, and the man is holding a stick in his hand. The beach is bustling with activity, as there are several other people visible in the background. Some of them are standing near", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24529.8, "ram_available_mb": 38311.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24565.2, "ram_available_mb": 38275.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.599, "power_cpu_cv_mean_watts": 1.804, "power_sys_5v0_mean_watts": 9.04}, "timestamp": "2026-01-23T07:47:36.291506"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8103.344, "latencies_ms": [8103.344], "images_per_second": 0.123, "prompt_tokens": 39, "response_tokens_est": 40, "n_tiles": 16, "output_text": "people: 2, horses: 2, beach: 1, ocean: 1, sky: 1, clouds: 1, sand: 1, camera: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24565.2, "ram_available_mb": 38275.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24549.0, "ram_available_mb": 38291.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.601, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 9.031}, "timestamp": "2026-01-23T07:47:46.419246"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12272.342, "latencies_ms": [12272.342], "images_per_second": 0.081, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the foreground, there are two individuals riding horses, with one horse positioned to the left and the other to the right of the frame. The background features a sandy beach with people in the water and a clear blue sky above. The horses and riders are closer to the camera than the people in the water, making them appear larger and more prominent in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.0, "ram_available_mb": 38291.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24532.3, "ram_available_mb": 38308.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.656, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 9.044}, "timestamp": "2026-01-23T07:48:00.734560"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6929.077, "latencies_ms": [6929.077], "images_per_second": 0.144, "prompt_tokens": 37, "response_tokens_est": 30, "n_tiles": 16, "output_text": "Two people are riding horses on a sandy beach near the ocean. The sky is blue and there are a few clouds in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24532.3, "ram_available_mb": 38308.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 24564.1, "ram_available_mb": 38276.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.599, "power_cpu_cv_mean_watts": 1.25, "power_sys_5v0_mean_watts": 9.109}, "timestamp": "2026-01-23T07:48:09.679770"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8255.12, "latencies_ms": [8255.12], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 44, "n_tiles": 16, "output_text": "The sky is a clear blue with a few scattered clouds, indicating a sunny day. The sand is a light beige color, and the water appears a deep blue-green, suggesting a tropical beach setting.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 24564.1, "ram_available_mb": 38276.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24527.9, "ram_available_mb": 38312.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.082, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 9.122}, "timestamp": "2026-01-23T07:48:19.976145"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11357.794, "latencies_ms": [11357.794], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there is a motorcycle parked in front of a garage. The motorcycle is leaning against a wall, and it appears to be a vintage model. A small dog is standing nearby, looking at the motorcycle. The garage is filled with various items, including bicycles and other objects.\n\nIn the background, there is a car park", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 24527.9, "ram_available_mb": 38312.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24526.4, "ram_available_mb": 38314.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.59, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T07:48:33.384712"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9007.267, "latencies_ms": [9007.267], "images_per_second": 0.111, "prompt_tokens": 39, "response_tokens_est": 57, "n_tiles": 16, "output_text": "- Motorcycle: 1\n- Dog: 1\n- Tire: 2\n- Car: 1\n- Bike: 1\n- Grill: 1\n- Motorcycle seat: 1\n- Motorcycle handlebar: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24526.4, "ram_available_mb": 38314.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24520.7, "ram_available_mb": 38320.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.827, "power_cpu_cv_mean_watts": 1.789, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T07:48:44.430354"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10307.527, "latencies_ms": [10307.527], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "In the foreground, there is a motorcycle with a sidecar parked on the grass. The sidecar is attached to a red vehicle, which is positioned in front of a garage. The garage is located in the background, with a car covered in a blue tarp parked to the right of the garage.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24520.7, "ram_available_mb": 38320.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 24535.2, "ram_available_mb": 38305.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.037, "power_cpu_cv_mean_watts": 2.187, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T07:48:56.774544"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6822.507, "latencies_ms": [6822.507], "images_per_second": 0.147, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A motorcycle is parked in front of a garage with a dog standing nearby. The garage is filled with various items, including bicycles hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.2, "ram_available_mb": 38305.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 24539.9, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.288, "power_cpu_cv_mean_watts": 1.967, "power_sys_5v0_mean_watts": 8.951}, "timestamp": "2026-01-23T07:49:05.621299"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5392.999, "latencies_ms": [5392.999], "images_per_second": 0.185, "prompt_tokens": 36, "response_tokens_est": 27, "n_tiles": 16, "output_text": "The motorcycle is primarily silver with a black seat and handlebars. The weather appears to be sunny with clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.9, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24539.4, "ram_available_mb": 38301.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.539, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 9.034}, "timestamp": "2026-01-23T07:49:13.074797"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11329.662, "latencies_ms": [11329.662], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a man flying a kite on a sandy beach. He is standing in the sand, holding onto the kite string, and appears to be enjoying the activity. There are several other people scattered around the beach, some closer to the water and others further away. \n\nIn the background, a few boats can be seen on the water, adding to the beach atmosphere", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 24539.4, "ram_available_mb": 38301.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.608, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T07:49:26.450988"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7518.915, "latencies_ms": [7518.915], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "kite: 1, person: 1, sand: many, water: 1, buildings: 2, trees: many, beach chairs: 0, umbrellas: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24536.6, "ram_available_mb": 38304.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.713, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 8.917}, "timestamp": "2026-01-23T07:49:35.997953"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9277.94, "latencies_ms": [9277.94], "images_per_second": 0.108, "prompt_tokens": 44, "response_tokens_est": 61, "n_tiles": 16, "output_text": "In the foreground, a person is flying a kite on a sandy beach. The beach is adjacent to a body of water, with several people scattered along the shoreline. In the background, there are trees and buildings, indicating that the beach is likely located near a populated area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.6, "ram_available_mb": 38304.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24529.4, "ram_available_mb": 38311.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.443, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T07:49:47.313236"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6588.496, "latencies_ms": [6588.496], "images_per_second": 0.152, "prompt_tokens": 37, "response_tokens_est": 36, "n_tiles": 16, "output_text": "A man is flying a kite on a sandy beach with the ocean in the background. There are several people scattered around the beach, enjoying the sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24529.4, "ram_available_mb": 38311.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.361, "power_cpu_cv_mean_watts": 1.559, "power_sys_5v0_mean_watts": 8.915}, "timestamp": "2026-01-23T07:49:55.930507"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7770.575, "latencies_ms": [7770.575], "images_per_second": 0.129, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image shows a sunny day at the beach with clear blue skies and a few scattered clouds. The sand is a light beige color, and the water appears to be a deep blue, reflecting the bright sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24538.5, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.237, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.927}, "timestamp": "2026-01-23T07:50:05.755148"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11340.513, "latencies_ms": [11340.513], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a kitchen with wooden cabinets and a black countertop. The countertop is cluttered with various items, including a green bottle, a white plate, and several bottles. There is a sink in the kitchen, and a refrigerator is visible on the left side of the scene. \n\nIn addition to the kitchen items, there are a few decor", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24538.5, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24540.1, "ram_available_mb": 38300.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.632, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T07:50:19.165582"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8405.129, "latencies_ms": [8405.129], "images_per_second": 0.119, "prompt_tokens": 39, "response_tokens_est": 52, "n_tiles": 16, "output_text": "refrigerator: 1, sink: 2, dishwasher: 1, microwave: 1, oven: 1, candle: 1, plate: 1, bottle: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.1, "ram_available_mb": 38300.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24541.6, "ram_available_mb": 38299.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.151, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T07:50:29.587618"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10880.38, "latencies_ms": [10880.38], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "In the foreground of the image, there is a kitchen counter with various items scattered on it, including a green bottle, a white plate with a red object on it, and several bottles. The refrigerator is in the background, to the left of the counter. The sink is located in the foreground, to the left of the counter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.6, "ram_available_mb": 38299.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24552.4, "ram_available_mb": 38288.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.714, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T07:50:42.512567"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8324.741, "latencies_ms": [8324.741], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image depicts a kitchen with wooden cabinets and a stainless steel refrigerator. The countertop is cluttered with various items such as bottles, a plate with a red bow, and a green bottle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.4, "ram_available_mb": 38288.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.201, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T07:50:52.861121"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7791.784, "latencies_ms": [7791.784], "images_per_second": 0.128, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The kitchen is well-lit with natural light coming from the window, and the cabinets are made of wood with a light brown color. The countertop is black, and there are various cleaning supplies and food items scattered around.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24532.0, "ram_available_mb": 38308.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.236, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 8.927}, "timestamp": "2026-01-23T07:51:02.677788"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11316.004, "latencies_ms": [11316.004], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the vast expanse of the clear blue sky, a vibrant kite soars high. The kite, a striking combination of white and red, is adorned with black and white designs that add a touch of whimsy to its appearance. The kite is shaped like a diamond, with a pointed nose and a tail that extends behind it, creating a sense", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 24532.0, "ram_available_mb": 38308.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24533.0, "ram_available_mb": 38307.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.678, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.821}, "timestamp": "2026-01-23T07:51:16.031738"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8324.609, "latencies_ms": [8324.609], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "kite: 1, sky: 1, string: 2, kite shape: 1, kite color: 1, kite design: 1, kite brand: 1, kite material: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24533.0, "ram_available_mb": 38307.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24538.8, "ram_available_mb": 38302.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.023, "power_cpu_cv_mean_watts": 1.709, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T07:51:26.372892"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8002.688, "latencies_ms": [8002.688], "images_per_second": 0.125, "prompt_tokens": 44, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The kite is in the foreground and appears to be flying high in the sky. The background is a clear blue sky with no clouds. The kite is positioned in the center of the image, with its tail trailing behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.8, "ram_available_mb": 38302.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24529.1, "ram_available_mb": 38311.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.124, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 8.917}, "timestamp": "2026-01-23T07:51:36.428685"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8420.767, "latencies_ms": [8420.767], "images_per_second": 0.119, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The image captures a vibrant scene of a kite soaring high in the clear blue sky. The kite, with its striking design of black and white patterns on a red and white background, is the focal point of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24529.1, "ram_available_mb": 38311.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24535.7, "ram_available_mb": 38305.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.027, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T07:51:46.861096"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5256.71, "latencies_ms": [5256.71], "images_per_second": 0.19, "prompt_tokens": 36, "response_tokens_est": 26, "n_tiles": 16, "output_text": "The kite is predominantly white with red and black accents. It is flying high in the clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.7, "ram_available_mb": 38305.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24532.4, "ram_available_mb": 38308.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.84, "power_cpu_cv_mean_watts": 1.374, "power_sys_5v0_mean_watts": 9.049}, "timestamp": "2026-01-23T07:51:54.140822"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11339.331, "latencies_ms": [11339.331], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a large, well-lit bedroom with two neatly made beds. The beds are positioned side by side, and the room has a cozy and inviting atmosphere. The beds are adorned with pillows and blankets, and there are two lamps on either side of the beds, providing ample lighting.\n\nIn addition to", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24532.4, "ram_available_mb": 38308.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24534.9, "ram_available_mb": 38306.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.61, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T07:52:07.525632"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7853.617, "latencies_ms": [7853.617], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "bed: 2\nlamps: 2\npillows: 6\nblankets: 2\nrugs: 2\nartwork: 1\nwindows: 2\ndoors: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24534.9, "ram_available_mb": 38306.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24531.0, "ram_available_mb": 38309.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.357, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 8.877}, "timestamp": "2026-01-23T07:52:17.402815"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11318.488, "latencies_ms": [11318.488], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image shows a room with two beds positioned parallel to each other, one in the foreground and the other in the background. The beds are separated by a small space, and there is a door on the right side of the image that is slightly farther away from the viewer than the beds. The room has a wooden floor and walls, and there are two windows, one", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24531.0, "ram_available_mb": 38309.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24539.5, "ram_available_mb": 38301.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.648, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T07:52:30.741214"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8191.63, "latencies_ms": [8191.63], "images_per_second": 0.122, "prompt_tokens": 37, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image shows a well-lit bedroom with two neatly made beds, each adorned with pillows and blankets. The room features a large window with a view of trees outside, and a door leading to another room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.5, "ram_available_mb": 38301.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24535.2, "ram_available_mb": 38305.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.229, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.876}, "timestamp": "2026-01-23T07:52:40.962960"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7988.533, "latencies_ms": [7988.533], "images_per_second": 0.125, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The room is well-lit with warm lighting from lamps on either side of the bed, creating a cozy atmosphere. The walls are painted in a light color, and the wooden floor adds a touch of warmth to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.2, "ram_available_mb": 38305.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24536.2, "ram_available_mb": 38304.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.159, "power_cpu_cv_mean_watts": 1.761, "power_sys_5v0_mean_watts": 8.937}, "timestamp": "2026-01-23T07:52:51.004120"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11357.526, "latencies_ms": [11357.526], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is riding a motorcycle on a road, with a group of people watching him. The man is wearing a white helmet and a white jacket, and he is riding a white motorcycle with a green stripe. The people watching him are standing on the side of the road, and they are all looking at the man as he rides by", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24536.2, "ram_available_mb": 38304.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 24542.7, "ram_available_mb": 38298.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.576, "power_cpu_cv_mean_watts": 2.073, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T07:53:04.422997"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7765.029, "latencies_ms": [7765.029], "images_per_second": 0.129, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "motorcycle: 1, rider: 1, helmet: 1, fence: 4, grass: 1, people: 4, road: 1, motorcycle brand: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24542.7, "ram_available_mb": 38298.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.502, "power_cpu_cv_mean_watts": 2.114, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T07:53:14.217410"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7107.883, "latencies_ms": [7107.883], "images_per_second": 0.141, "prompt_tokens": 44, "response_tokens_est": 42, "n_tiles": 16, "output_text": "A motorcyclist is in the foreground, riding on the left side of the road. Spectators are gathered on the right side of the road, watching the rider from a distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24534.4, "ram_available_mb": 38306.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.824, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.945}, "timestamp": "2026-01-23T07:53:23.365721"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8210.647, "latencies_ms": [8210.647], "images_per_second": 0.122, "prompt_tokens": 37, "response_tokens_est": 50, "n_tiles": 16, "output_text": "A motorcyclist is seen riding a white motorcycle with green accents on a road, wearing a white helmet and racing suit. Spectators are gathered on the side of the road, watching the rider in action.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24534.4, "ram_available_mb": 38306.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.191, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T07:53:33.619348"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7104.647, "latencies_ms": [7104.647], "images_per_second": 0.141, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The motorcycle rider is wearing a white helmet and a white and green racing suit. The motorcycle is white with green accents and has the word \"PAJ\" written on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24528.4, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.711, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.949}, "timestamp": "2026-01-23T07:53:42.738846"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11351.988, "latencies_ms": [11351.988], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene dining scene set in a dimly lit restaurant. The main focus is a table, draped in a pristine white tablecloth, which is adorned with a single white flower in a clear vase. The table is set meticulously with a white plate, silverware, and a glass of water, all arranged with an air", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24528.4, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.587, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.825}, "timestamp": "2026-01-23T07:53:56.140363"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7610.569, "latencies_ms": [7610.569], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "table: 1\nglass: 3\nplate: 2\nknife: 2\nfork: 2\nspoon: 1\nvase: 1\nflower: 5", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24534.5, "ram_available_mb": 38306.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.602, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T07:54:05.761481"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11329.516, "latencies_ms": [11329.516], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a table set for a meal with a white tablecloth. On the table, there are three wine glasses, two of which are placed closer to the viewer and one further away, creating a sense of depth. The main object, a vase with white flowers, is centrally located on the table, with the wine glasses arranged symmet", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24534.5, "ram_available_mb": 38306.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24539.5, "ram_available_mb": 38301.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.634, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T07:54:19.120513"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8983.582, "latencies_ms": [8983.582], "images_per_second": 0.111, "prompt_tokens": 37, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image depicts a serene dining setting with a table elegantly set for a meal. The table is adorned with a white tablecloth, and there are three glass vases with white flowers in them, placed centrally on the table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24539.5, "ram_available_mb": 38301.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24531.2, "ram_available_mb": 38309.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.741, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T07:54:30.156569"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10357.372, "latencies_ms": [10357.372], "images_per_second": 0.097, "prompt_tokens": 36, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The image features a table setting with a central vase holding white flowers, illuminated by soft, warm lighting that creates a cozy atmosphere. The table is adorned with elegant glassware, including wine glasses and a decanter, and is set with white plates and silverware, suggesting a formal dining experience.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24531.2, "ram_available_mb": 38309.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24535.1, "ram_available_mb": 38305.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.794, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 8.826}, "timestamp": "2026-01-23T07:54:42.545931"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12546.767, "latencies_ms": [12546.767], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment frozen in time, featuring a black and white photograph of a street clock. The clock, standing tall on a pole, is the central focus of the image. It's a hexagonal structure, with each of its six sides adorned with a clock face. Each face is marked with numbers from 1 to 12, indicating the hours.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24535.1, "ram_available_mb": 38305.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24573.1, "ram_available_mb": 38267.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.872, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 9.087}, "timestamp": "2026-01-23T07:54:57.114945"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9364.821, "latencies_ms": [9364.821], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "Clock: 2\nGrass: 1\nPole: 1\nPerson: 1\nWheat: 1\nSky: 1\nGround: 1\nClock face: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24573.1, "ram_available_mb": 38267.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24527.7, "ram_available_mb": 38313.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.443, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 9.077}, "timestamp": "2026-01-23T07:55:08.513475"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12399.016, "latencies_ms": [12399.016], "images_per_second": 0.081, "prompt_tokens": 44, "response_tokens_est": 77, "n_tiles": 16, "output_text": "The clock is positioned in the foreground of the image, appearing larger and more detailed compared to the background. The background features a field of crops, which is less distinct due to its distance from the viewer. The clock is closer to the viewer, making it the main object of focus, while the field extends into the distance, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24527.7, "ram_available_mb": 38313.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24573.3, "ram_available_mb": 38267.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.139, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 9.103}, "timestamp": "2026-01-23T07:55:22.946953"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9073.227, "latencies_ms": [9073.227], "images_per_second": 0.11, "prompt_tokens": 37, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image features a unique, octagonal-shaped clock mounted on a pole, with a grassy field in the background. The clock is black and white, adding a classic and timeless feel to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24573.3, "ram_available_mb": 38267.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24553.8, "ram_available_mb": 38287.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.549, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 9.052}, "timestamp": "2026-01-23T07:55:34.057802"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8556.24, "latencies_ms": [8556.24], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 44, "n_tiles": 16, "output_text": "The image is a black and white photograph featuring a street clock with three faces, each displaying the time. The clock is mounted on a pole and the background shows a field of crops under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24553.8, "ram_available_mb": 38287.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24564.1, "ram_available_mb": 38276.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.681, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 9.174}, "timestamp": "2026-01-23T07:55:44.649156"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11383.473, "latencies_ms": [11383.473], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young man is skillfully riding a skateboard on a sidewalk. He is wearing a black shirt and a baseball cap, and his feet are firmly planted on the skateboard. The skateboard is positioned in the center of the image, with the young man's body leaning slightly to the left. The sidewalk on", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 24564.1, "ram_available_mb": 38276.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24538.7, "ram_available_mb": 38302.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.541, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.834}, "timestamp": "2026-01-23T07:55:58.083731"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10408.417, "latencies_ms": [10408.417], "images_per_second": 0.096, "prompt_tokens": 39, "response_tokens_est": 69, "n_tiles": 16, "output_text": "- Skateboard: 1\n\n- Skate park: 1\n\n- Skateboarder: 1\n\n- Pants: 1\n\n- Cap: 1\n\n- T-shirt: 1\n\n- Graffiti: 1\n\n- Trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.7, "ram_available_mb": 38302.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24533.9, "ram_available_mb": 38307.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.142, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.832}, "timestamp": "2026-01-23T07:56:10.506372"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10950.169, "latencies_ms": [10950.169], "images_per_second": 0.091, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "The skateboarder is in the foreground, performing a trick on a skateboard. The background features a concrete surface with graffiti and trees, indicating an outdoor skate park setting. The skateboarder is positioned near the center of the image, with ample space around him, suggesting he is the main focus of the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24533.9, "ram_available_mb": 38307.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.744, "power_cpu_cv_mean_watts": 1.908, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T07:56:23.474040"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7764.132, "latencies_ms": [7764.132], "images_per_second": 0.129, "prompt_tokens": 37, "response_tokens_est": 46, "n_tiles": 16, "output_text": "A person is skateboarding in an outdoor skate park, performing a trick on a red brick surface. The skate park is surrounded by trees and there are a few tents and people in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24534.5, "ram_available_mb": 38306.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.595, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T07:56:33.258382"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7500.456, "latencies_ms": [7500.456], "images_per_second": 0.133, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image shows a person skateboarding on a concrete surface with a graffiti-covered wall in the background. The lighting is natural and appears to be overcast, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24534.5, "ram_available_mb": 38306.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24540.1, "ram_available_mb": 38300.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.569, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 8.928}, "timestamp": "2026-01-23T07:56:42.792469"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12334.115, "latencies_ms": [12334.115], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a white plate filled with a variety of vegetables, including carrots and peas. The carrots are spread out across the plate, with some of them overlapping each other. The peas are placed in the center of the plate, surrounded by the carrots. The plate is placed on a countertop, and there is a knife nearby, suggesting", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24540.1, "ram_available_mb": 38300.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24580.8, "ram_available_mb": 38260.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.614, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 9.061}, "timestamp": "2026-01-23T07:56:57.169807"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9591.774, "latencies_ms": [9591.774], "images_per_second": 0.104, "prompt_tokens": 39, "response_tokens_est": 53, "n_tiles": 16, "output_text": "carrots: 20, peas: 10, beets: 3, carrot peeler: 1, white bowl: 1, black container: 1, sink: 1, spoon: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24580.8, "ram_available_mb": 38260.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24533.9, "ram_available_mb": 38307.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.611, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 9.012}, "timestamp": "2026-01-23T07:57:08.805398"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12268.39, "latencies_ms": [12268.39], "images_per_second": 0.082, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground of the image, there is a white plate filled with orange carrots, which are the main focus of the image. To the right of the plate, there is a blue vegetable peeler, and further to the right, there are some green peas and a bunch of red beets. In the background, there is a white plastic container and a white cup", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.9, "ram_available_mb": 38307.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 24582.8, "ram_available_mb": 38258.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.717, "power_cpu_cv_mean_watts": 2.296, "power_sys_5v0_mean_watts": 9.083}, "timestamp": "2026-01-23T07:57:23.089306"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7532.72, "latencies_ms": [7532.72], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "A white plate filled with orange carrots is placed on a kitchen countertop. There is a blue peeler and some green peas on the plate as well.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24582.8, "ram_available_mb": 38258.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 24603.3, "ram_available_mb": 38237.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.014, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 9.067}, "timestamp": "2026-01-23T07:57:32.662406"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8271.973, "latencies_ms": [8271.973], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 44, "n_tiles": 16, "output_text": "The image shows a bowl of orange carrots on a kitchen counter. The lighting in the image is bright and natural, coming from the left side, casting a shadow to the right of the objects.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24603.3, "ram_available_mb": 38237.6, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24671.2, "ram_available_mb": 38169.7, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.132, "power_cpu_cv_mean_watts": 1.528, "power_sys_5v0_mean_watts": 9.122}, "timestamp": "2026-01-23T07:57:42.989944"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 10189.189, "latencies_ms": [10189.189], "images_per_second": 0.098, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 16, "output_text": "In the image, a man is standing on a stage, dressed in a suit and tie, and appears to be giving a speech or presentation. He is holding a microphone in his hand, and there are people in the audience watching him. The stage is well-lit, and the audience is attentively listening to the speaker.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24539.1, "ram_available_mb": 38301.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.066, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 8.88}, "timestamp": "2026-01-23T07:57:55.208199"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9471.669, "latencies_ms": [9471.669], "images_per_second": 0.106, "prompt_tokens": 39, "response_tokens_est": 61, "n_tiles": 16, "output_text": "1. Screen: 1\n2. Man: 1\n3. Microphone: 1\n4. Stage: 1\n5. Audience: 2\n6. Projector: 1\n7. Camera: 1\n8. Screen: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.1, "ram_available_mb": 38301.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24536.0, "ram_available_mb": 38304.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.583, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T07:58:06.735043"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10067.605, "latencies_ms": [10067.605], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 68, "n_tiles": 16, "output_text": "In the foreground, there is a person with red hair sitting in front of a large screen displaying a man in a suit. The man in the suit is positioned in the center of the screen, appearing to be giving a presentation. The audience is seated in front of the screen, with their attention directed towards the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.0, "ram_available_mb": 38304.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.097, "power_cpu_cv_mean_watts": 1.87, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T07:58:18.817191"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5725.313, "latencies_ms": [5725.313], "images_per_second": 0.175, "prompt_tokens": 37, "response_tokens_est": 28, "n_tiles": 16, "output_text": "A man is giving a presentation on a large screen in front of an audience, with a woman in the foreground watching intently.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24555.4, "ram_available_mb": 38285.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.342, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 8.944}, "timestamp": "2026-01-23T07:58:26.557144"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7582.483, "latencies_ms": [7582.483], "images_per_second": 0.132, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image shows a person on a stage with a blue background and a colorful geometric design on the right side. The stage lighting casts a warm glow on the speaker, highlighting their suit and gestures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.4, "ram_available_mb": 38285.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24542.9, "ram_available_mb": 38298.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.217, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T07:58:36.198731"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11364.874, "latencies_ms": [11364.874], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features two men sitting on a bench in a parking lot, with a motorcycle parked nearby. One man is wearing a blue shirt and the other is wearing a white shirt. They appear to be having a conversation while sitting on the bench. \n\nIn the background, there are several other motorcycles parked around the area, with one", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 24542.9, "ram_available_mb": 38298.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.635, "power_cpu_cv_mean_watts": 1.961, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T07:58:49.627761"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10034.132, "latencies_ms": [10034.132], "images_per_second": 0.1, "prompt_tokens": 39, "response_tokens_est": 66, "n_tiles": 16, "output_text": "1. Motorcycles: 2\n2. Scooters: 2\n3. Bicycles: 0\n4. People: 2\n5. Chair: 1\n6. Pole: 1\n7. Sign: 1\n8. Broom: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.127, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T07:59:01.687153"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11305.699, "latencies_ms": [11305.699], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a man sitting on a chair, facing another man who is standing and holding a shovel. The shovel is positioned near the man standing. In the background, there are two scooters parked on the side of the street, with one closer to the left side and the other slightly further to the right. There is also a building with", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24537.4, "ram_available_mb": 38303.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.645, "power_cpu_cv_mean_watts": 1.953, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T07:59:15.020219"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10584.061, "latencies_ms": [10584.061], "images_per_second": 0.094, "prompt_tokens": 37, "response_tokens_est": 71, "n_tiles": 16, "output_text": "Two men are sitting on a bench in front of a building with a blue and white sign that reads \"X \u5373\u515a\" and a large blue character on the left side of the building. There are two motorcycles parked on the sidewalk next to them, and a man is holding a shovel.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24537.4, "ram_available_mb": 38303.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.086, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T07:59:27.630004"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7623.202, "latencies_ms": [7623.202], "images_per_second": 0.131, "prompt_tokens": 36, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The image shows a street scene with a blue and white sign with a large letter \"L\" on it. There are two men sitting on a bench, one wearing a blue uniform and the other in casual clothes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24537.1, "ram_available_mb": 38303.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.484, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 8.992}, "timestamp": "2026-01-23T07:59:37.273514"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 10891.252, "latencies_ms": [10891.252], "images_per_second": 0.092, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 16, "output_text": "The image shows a black plastic container filled with a green, chunky vegetable dish, likely a curry, placed on a white paper plate. Beside it, there's a pile of shredded chicken. The plate is on a kitchen counter with a granite-like surface.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 24537.1, "ram_available_mb": 38303.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24572.6, "ram_available_mb": 38268.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.478, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 9.113}, "timestamp": "2026-01-23T07:59:50.208892"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9410.345, "latencies_ms": [9410.345], "images_per_second": 0.106, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "plate: 1, bowl: 1, fork: 1, chicken: 1, shredded chicken: 1, broccoli: 1, sauce: 1, container: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24572.6, "ram_available_mb": 38268.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24555.7, "ram_available_mb": 38285.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.482, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 9.07}, "timestamp": "2026-01-23T08:00:01.652855"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12266.89, "latencies_ms": [12266.89], "images_per_second": 0.082, "prompt_tokens": 44, "response_tokens_est": 76, "n_tiles": 16, "output_text": "In the foreground of the image, there is a pile of shredded chicken on the left side, which is closer to the viewer. Behind it, on the right side, there is a black container filled with a green sauce and chunks of vegetables. The container is placed on top of the plate, which is on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.7, "ram_available_mb": 38285.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24579.9, "ram_available_mb": 38261.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.191, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 9.125}, "timestamp": "2026-01-23T08:00:15.958073"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9617.274, "latencies_ms": [9617.274], "images_per_second": 0.104, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows a meal consisting of shredded chicken and a green vegetable dish, possibly a curry, served on a white paper plate with a fork on the side. The meal is presented on a kitchen countertop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24579.9, "ram_available_mb": 38261.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24621.6, "ram_available_mb": 38219.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.385, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 9.059}, "timestamp": "2026-01-23T08:00:27.634821"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10316.691, "latencies_ms": [10316.691], "images_per_second": 0.097, "prompt_tokens": 36, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image shows a meal consisting of shredded chicken and a green sauce in a black container, placed on a white paper plate with a fork on the side. The lighting appears to be artificial, and the surface under the plate seems to be a kitchen countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24621.6, "ram_available_mb": 38219.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24622.4, "ram_available_mb": 38218.5, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.611, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 9.129}, "timestamp": "2026-01-23T08:00:39.996669"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11452.442, "latencies_ms": [11452.442], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is the central figure, exuding an air of professionalism and confidence. He is dressed in a blue shirt and a red tie, a combination that suggests a formal or business setting. His head is adorned with a gray and white plaid hat, adding a touch of personal style to his otherwise formal attire. The hat is slightly tilted", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24622.4, "ram_available_mb": 38218.5, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24568.7, "ram_available_mb": 38272.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.277, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.785}, "timestamp": "2026-01-23T08:00:53.500309"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11510.991, "latencies_ms": [11510.991], "images_per_second": 0.087, "prompt_tokens": 39, "response_tokens_est": 80, "n_tiles": 16, "output_text": "1. Building: 1 visible in the background\n\n2. Chair: 1 visible in the background\n\n3. Man: 1\n\n4. Cap: 1\n\n5. Glasses: 1\n\n6. Shirt: 1\n\n7. Tie: 1\n\n8. Pool: 1 visible in the background", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24568.7, "ram_available_mb": 38272.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24531.7, "ram_available_mb": 38309.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.677, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 8.802}, "timestamp": "2026-01-23T08:01:07.048370"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9635.43, "latencies_ms": [9635.43], "images_per_second": 0.104, "prompt_tokens": 44, "response_tokens_est": 64, "n_tiles": 16, "output_text": "The man is positioned in the foreground of the image, appearing to be the main subject. He is standing in front of a building with windows, which serves as the background. The man is wearing a hat and glasses, and he is smiling, indicating a positive and friendly demeanor.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24531.7, "ram_available_mb": 38309.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.277, "power_cpu_cv_mean_watts": 1.834, "power_sys_5v0_mean_watts": 8.881}, "timestamp": "2026-01-23T08:01:18.712241"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6026.748, "latencies_ms": [6026.748], "images_per_second": 0.166, "prompt_tokens": 37, "response_tokens_est": 31, "n_tiles": 16, "output_text": "A man is standing outdoors, wearing a blue shirt and a red tie. He is smiling and looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.208, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 8.986}, "timestamp": "2026-01-23T08:01:26.777212"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7568.056, "latencies_ms": [7568.056], "images_per_second": 0.132, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image features a person wearing a blue shirt and a red tie, with a plaid hat on their head. The lighting appears to be natural, suggesting the photo was taken outdoors during the day.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 24555.5, "ram_available_mb": 38285.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.339, "power_cpu_cv_mean_watts": 2.14, "power_sys_5v0_mean_watts": 8.958}, "timestamp": "2026-01-23T08:01:36.365413"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12545.574, "latencies_ms": [12545.574], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image is a collage of six photographs showcasing a pizza with various toppings. The pizza appears to be a deep-dish style with a golden-brown crust. The toppings include melted cheese, tomato sauce, and possibly some herbs and spices. The pizza is cut into slices, and some slices are", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 24555.5, "ram_available_mb": 38285.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24572.1, "ram_available_mb": 38268.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.927, "power_cpu_cv_mean_watts": 1.847, "power_sys_5v0_mean_watts": 9.082}, "timestamp": "2026-01-23T08:01:50.945588"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8944.506, "latencies_ms": [8944.506], "images_per_second": 0.112, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "cheese: 5, tomato: 3, crust: 4, plate: 5, fork: 2, bite: 1, slice: 4, crust: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24572.1, "ram_available_mb": 38268.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24593.6, "ram_available_mb": 38247.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.646, "power_cpu_cv_mean_watts": 1.47, "power_sys_5v0_mean_watts": 9.09}, "timestamp": "2026-01-23T08:02:01.931605"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12611.498, "latencies_ms": [12611.498], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The main object, which appears to be a slice of pizza, is positioned in the foreground of the image, occupying the central and lower parts of the frame. It is placed on a white plate, which is in the background. The pizza slice is the closest to the viewer, with other similar slices appearing progressively smaller and further away, creating a sense of depth", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24593.6, "ram_available_mb": 38247.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24561.2, "ram_available_mb": 38279.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.117, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 9.133}, "timestamp": "2026-01-23T08:02:16.569839"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 12846.321, "latencies_ms": [12846.321], "images_per_second": 0.078, "prompt_tokens": 37, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image is a collage of six photographs showing a pizza with various toppings being eaten. The pizza appears to be freshly baked with a golden-brown crust, and the toppings include cheese, tomato sauce, and possibly some herbs and vegetables. The photographs are arranged in a 2x3 grid, with each photo showing", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24561.2, "ram_available_mb": 38279.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24573.5, "ram_available_mb": 38267.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.225, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 9.047}, "timestamp": "2026-01-23T08:02:31.431971"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 12637.053, "latencies_ms": [12637.053], "images_per_second": 0.079, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image is a collage of six photos showing different views of a pizza. The pizza appears to have a golden-brown crust, melted cheese, and various toppings that could include vegetables and possibly meats. The lighting in the photos highlights the textures and colors of the pizza, with the cheese looking particularly gooey and the", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24573.5, "ram_available_mb": 38267.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24535.6, "ram_available_mb": 38305.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.108, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 9.107}, "timestamp": "2026-01-23T08:02:46.078916"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11360.256, "latencies_ms": [11360.256], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, two young girls are standing next to a black goat and a white goat in a fenced area. The girls are petting the goats, and one of them is holding a stick. The goats seem to be enjoying the attention from the children. The scene takes place in a grassy area, with the goats and the girls being the main focus of", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 24535.6, "ram_available_mb": 38305.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24539.3, "ram_available_mb": 38301.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.609, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T08:02:59.477966"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9947.952, "latencies_ms": [9947.952], "images_per_second": 0.101, "prompt_tokens": 39, "response_tokens_est": 65, "n_tiles": 16, "output_text": "1. Girl: 2\n2. Goat: 2\n3. Fence: 1\n4. Grass: 1\n5. Dress: 2\n6. Pole: 1\n7. Strawberry: 1\n8. Trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.3, "ram_available_mb": 38301.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24542.4, "ram_available_mb": 38298.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.186, "power_cpu_cv_mean_watts": 1.847, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T08:03:11.464241"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11333.345, "latencies_ms": [11333.345], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a black goat with white patches on its head and neck, being petted by a child. The goat is positioned near the center of the image, close to the viewer. In the background, there are two children, one wearing a floral dress and the other in a blue dress with a pink bow, both standing behind", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24540.4, "ram_available_mb": 38300.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.666, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T08:03:24.814885"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5439.976, "latencies_ms": [5439.976], "images_per_second": 0.184, "prompt_tokens": 37, "response_tokens_est": 26, "n_tiles": 16, "output_text": "Two young girls are petting a black goat in a fenced area, likely at a petting zoo or farm.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24542.8, "ram_available_mb": 38298.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.093, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 9.005}, "timestamp": "2026-01-23T08:03:32.281633"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11335.363, "latencies_ms": [11335.363], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features two young girls in colorful dresses, one in pink with a floral pattern and the other in blue with a strawberry pattern, standing in front of a black goat with white patches. The goat is being petted by one of the girls, and there is a white goat with black patches in the background. The setting appears to be", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24542.8, "ram_available_mb": 38298.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24538.6, "ram_available_mb": 38302.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.586, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.841}, "timestamp": "2026-01-23T08:03:45.672216"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11359.321, "latencies_ms": [11359.321], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene evening scene at a traffic intersection. The sky, painted in a deep shade of blue, serves as a backdrop to the silhouette of a mountain range. The mountains, bathed in the soft glow of the setting sun, add a sense of tranquility to the scene.\n\nIn the foreground, a traffic light hangs from", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 24538.6, "ram_available_mb": 38302.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.545, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T08:03:59.082287"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11512.347, "latencies_ms": [11512.347], "images_per_second": 0.087, "prompt_tokens": 39, "response_tokens_est": 81, "n_tiles": 16, "output_text": "traffic light: 2, street sign: 1, traffic light: 1, street sign: 1, traffic light: 1, traffic light: 1, traffic light: 1, traffic light: 1, traffic light: 1, traffic light: 1, traffic light: 1, traffic light: 1, traffic light: 1, traffic light", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24544.9, "ram_available_mb": 38296.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.592, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 8.811}, "timestamp": "2026-01-23T08:04:12.625225"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8142.957, "latencies_ms": [8142.957], "images_per_second": 0.123, "prompt_tokens": 44, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The traffic lights are positioned in the foreground on the right side of the image, while the sun is setting in the background on the left side. The street sign is located near the traffic lights, slightly above and to the right of them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.9, "ram_available_mb": 38296.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.044, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.925}, "timestamp": "2026-01-23T08:04:22.802176"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11494.417, "latencies_ms": [11494.417], "images_per_second": 0.087, "prompt_tokens": 37, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene evening at a traffic intersection, bathed in the soft glow of a setting sun. The sky, painted in hues of deep blue, serves as a stunning backdrop to the silhouette of distant mountains. The traffic lights, glowing in a vibrant green, guide the flow of vehicles, while a street sign reading \"BEL", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24550.8, "ram_available_mb": 38290.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.712, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 8.826}, "timestamp": "2026-01-23T08:04:36.315877"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8573.7, "latencies_ms": [8573.7], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image captures a night scene with a clear sky, as evidenced by the visible stars. The traffic lights are illuminated, casting a green glow, and the street is bathed in a soft light from the traffic signal and street lamps.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.8, "ram_available_mb": 38290.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.722, "power_cpu_cv_mean_watts": 1.799, "power_sys_5v0_mean_watts": 8.904}, "timestamp": "2026-01-23T08:04:46.942541"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 9069.41, "latencies_ms": [9069.41], "images_per_second": 0.11, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image shows a smiling woman standing behind a table laden with bunches of bananas. She is wearing a patterned dress and is in a building with a yellow wall and a sign that reads 'BANANAS'. The bananas are yellow and appear ripe.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.4, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T08:04:58.069533"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9094.43, "latencies_ms": [9094.43], "images_per_second": 0.11, "prompt_tokens": 39, "response_tokens_est": 58, "n_tiles": 16, "output_text": "bananas: 2 bunches, approximately 20-30 bananas each\nwoman: 1\nbuilding: 1\nred sign: 1\nblue sign: 1\nwindow: 1\ndoor: 1\nother people: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.859, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T08:05:09.199279"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9056.881, "latencies_ms": [9056.881], "images_per_second": 0.11, "prompt_tokens": 44, "response_tokens_est": 59, "n_tiles": 16, "output_text": "In the foreground, there is a large bunch of bananas placed on a wooden surface. To the left of the bananas, there is a building with a red circular sign above the entrance. In the background, there is another individual standing near the doorway of the same building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.562, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.888}, "timestamp": "2026-01-23T08:05:20.278690"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9209.642, "latencies_ms": [9209.642], "images_per_second": 0.109, "prompt_tokens": 37, "response_tokens_est": 59, "n_tiles": 16, "output_text": "A woman is standing behind a table laden with bunches of bananas, likely at a market or a stall. The background shows a building with a sign that reads \"BANANAS\", suggesting that this is a place where bananas are sold or a themed establishment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.546, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T08:05:31.528052"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10833.714, "latencies_ms": [10833.714], "images_per_second": 0.092, "prompt_tokens": 36, "response_tokens_est": 75, "n_tiles": 16, "output_text": "The image features a vibrant yellow banana bunch in sharp focus against a blurred background, with natural lighting highlighting the texture of the bananas and the patterned fabric of the person's clothing. The background shows a building with a rough texture and a mix of warm and cool tones, suggesting an outdoor setting with natural light.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.916, "power_cpu_cv_mean_watts": 2.381, "power_sys_5v0_mean_watts": 8.914}, "timestamp": "2026-01-23T08:05:44.406981"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12525.943, "latencies_ms": [12525.943], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene on a city street. Dominating the view is a three-story brick building, its facade a vibrant green. The building is adorned with a fire escape on the second floor, a common sight in urban architecture. The ground floor features a green door, above which hang two closed garage doors, their surfaces a canvas for graffiti.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.96, "power_cpu_cv_mean_watts": 1.991, "power_sys_5v0_mean_watts": 9.096}, "timestamp": "2026-01-23T08:05:58.961038"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11150.205, "latencies_ms": [11150.205], "images_per_second": 0.09, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "- Fire hydrant: 1\n\n- Door: 2\n\n- Graffiti: 10\n\n- Windows: 4\n\n- Bike: 1\n\n- Tree: 1\n\n- Trash can: 1\n\n- Sign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24544.0, "ram_available_mb": 38296.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.685, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 9.043}, "timestamp": "2026-01-23T08:06:12.171106"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11909.992, "latencies_ms": [11909.992], "images_per_second": 0.084, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "The fire hydrant is located in the foreground on the left side of the image, near the sidewalk. The building with graffiti is in the background, behind the fire hydrant. The green door is on the right side of the building, and the graffiti is spread across the garage doors on both sides of the green door.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24544.0, "ram_available_mb": 38296.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24583.5, "ram_available_mb": 38257.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.298, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 9.115}, "timestamp": "2026-01-23T08:06:26.138978"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8812.093, "latencies_ms": [8812.093], "images_per_second": 0.113, "prompt_tokens": 37, "response_tokens_est": 44, "n_tiles": 16, "output_text": "The image depicts a red brick building with a green awning and a fire hydrant on the sidewalk in front of it. The building has multiple windows and a green fire escape on the second floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24583.5, "ram_available_mb": 38257.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24544.3, "ram_available_mb": 38296.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.856, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 9.098}, "timestamp": "2026-01-23T08:06:36.987341"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8796.256, "latencies_ms": [8796.256], "images_per_second": 0.114, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image shows a red brick building with a green awning and a fire escape on the second floor. The garage doors on the ground floor are covered in various graffiti tags in blue, red, and black.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24544.3, "ram_available_mb": 38296.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.611, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 9.168}, "timestamp": "2026-01-23T08:06:47.825675"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11364.123, "latencies_ms": [11364.123], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man with long, curly hair is the main focus. He is wearing a black shirt and a blue and white striped beanie. The man is holding a bright yellow frisbee in his right hand, preparing to throw it. The background is a simple, unadorned wall. The man's expression is serious, suggesting concentration or", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.516, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T08:07:01.223278"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7832.895, "latencies_ms": [7832.895], "images_per_second": 0.128, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "person: 1, camera: 1, yellow frisbee: 1, wall: 1, room: 1, ceiling: 1, light fixture: 1, audience: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.499, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T08:07:11.102408"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11350.183, "latencies_ms": [11350.183], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The person in the foreground is holding a yellow frisbee with their right hand, extending it towards the camera, while the background shows a group of people sitting and standing, with some facing the camera and others turned away. The person with the frisbee is positioned in the center of the image, making them the main focus, with the audience members behind them appearing smaller and", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.549, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T08:07:24.487383"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7837.96, "latencies_ms": [7837.96], "images_per_second": 0.128, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "A person with long curly hair is holding a neon green frisbee in a dimly lit indoor setting, possibly a room or a hallway. The person's face is not visible in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.463, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T08:07:34.345603"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8671.031, "latencies_ms": [8671.031], "images_per_second": 0.115, "prompt_tokens": 36, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image features a person with long, curly hair wearing a black shirt and a blue and white striped headband. The person is holding a bright yellow frisbee in a dimly lit indoor setting with a crowd of people in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24533.7, "ram_available_mb": 38307.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.768, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.929}, "timestamp": "2026-01-23T08:07:45.051456"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11352.679, "latencies_ms": [11352.679], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of people sitting around a dining table, each with their own laptop open in front of them. There are at least five people visible, with some sitting closer to the left side of the table and others on the right side. The laptops are placed on the table, and the people seem to be engaged in their work or activities.\n\nIn addition to the", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24533.7, "ram_available_mb": 38307.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.616, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T08:07:58.434921"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9462.225, "latencies_ms": [9462.225], "images_per_second": 0.106, "prompt_tokens": 39, "response_tokens_est": 61, "n_tiles": 16, "output_text": "- Laptop: 3\n\n- Computer mouse: 2\n\n- Keyboard: 2\n\n- Computer monitor: 2\n\n- Laptop screen: 2\n\n- Chair: 2\n\n- Table: 2\n\n- Person: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24530.0, "ram_available_mb": 38310.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.416, "power_cpu_cv_mean_watts": 1.814, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T08:08:09.937821"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10658.395, "latencies_ms": [10658.395], "images_per_second": 0.094, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "In the foreground, there is a laptop with a blurred screen on the left side, and a clear laptop screen in the center. In the background, there are multiple people seated around tables, with some facing the camera and others turned away. The tables are arranged in a way that suggests a communal workspace or a caf\u00e9 setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24530.0, "ram_available_mb": 38310.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24539.1, "ram_available_mb": 38301.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.811, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.883}, "timestamp": "2026-01-23T08:08:22.655820"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8529.099, "latencies_ms": [8529.099], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image depicts a group of people sitting around a table in a casual setting, possibly a cafe or a restaurant, working on their laptops. The atmosphere appears to be relaxed and collaborative, with people engaged in their tasks.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24539.1, "ram_available_mb": 38301.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24541.1, "ram_available_mb": 38299.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.046, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.865}, "timestamp": "2026-01-23T08:08:33.205703"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7567.744, "latencies_ms": [7567.744], "images_per_second": 0.132, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image is taken indoors with warm lighting, likely from overhead fixtures. Various objects are scattered on the table, including a laptop, a mug, and a bottle of ketchup.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.1, "ram_available_mb": 38299.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24536.7, "ram_available_mb": 38304.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.384, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 8.917}, "timestamp": "2026-01-23T08:08:42.834110"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12515.319, "latencies_ms": [12515.319], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young girl is the main subject. She is standing on a sidewalk, which is made of concrete. The girl is holding a blue umbrella with a wooden handle. The umbrella is open, providing a canopy over her. She is dressed in a pink jacket and blue jeans, adding a pop of color to the scene. The background is", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 24536.7, "ram_available_mb": 38304.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24538.5, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.95, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 9.08}, "timestamp": "2026-01-23T08:08:57.416744"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9523.705, "latencies_ms": [9523.705], "images_per_second": 0.105, "prompt_tokens": 39, "response_tokens_est": 50, "n_tiles": 16, "output_text": "umbrella: 1, girl: 1, pink jacket: 1, blue jeans: 1, brown purse: 1, sandals: 1, ground: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.5, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.383, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 9.049}, "timestamp": "2026-01-23T08:09:08.968709"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12603.72, "latencies_ms": [12603.72], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The girl is standing in the foreground holding a blue umbrella with her right hand, which is positioned near the top of the umbrella. The umbrella is open and covers a significant portion of the background, which appears to be a paved area. The girl is facing towards the camera, and her body is slightly angled to the left, creating a sense of depth", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24534.6, "ram_available_mb": 38306.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.167, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 9.106}, "timestamp": "2026-01-23T08:09:23.604273"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9408.718, "latencies_ms": [9408.718], "images_per_second": 0.106, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A young girl is standing under a blue umbrella, likely to protect herself from rain or sun. She is wearing a pink jacket and blue jeans, and appears to be outdoors on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.6, "ram_available_mb": 38306.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24587.3, "ram_available_mb": 38253.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.425, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 9.079}, "timestamp": "2026-01-23T08:09:35.055606"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7072.556, "latencies_ms": [7072.556], "images_per_second": 0.141, "prompt_tokens": 36, "response_tokens_est": 31, "n_tiles": 16, "output_text": "A young child is holding a blue umbrella with a wooden handle. The child is wearing a pink jacket and blue jeans.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24587.3, "ram_available_mb": 38253.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 24583.0, "ram_available_mb": 38257.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.646, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 9.202}, "timestamp": "2026-01-23T08:09:44.144273"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11280.457, "latencies_ms": [11280.457], "images_per_second": 0.089, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man in a suit is standing in front of a desk with a computer. The man is wearing a tie and appears to be a businessman or a professional. The desk has a computer monitor, keyboard, and mouse, indicating that it is a workspace. There is a window in the background, providing natural light to the room.\n\nIn addition to", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 24583.0, "ram_available_mb": 38257.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 24553.1, "ram_available_mb": 38287.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.763, "power_cpu_cv_mean_watts": 2.457, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T08:09:57.453912"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11521.131, "latencies_ms": [11521.131], "images_per_second": 0.087, "prompt_tokens": 39, "response_tokens_est": 79, "n_tiles": 16, "output_text": "man: 1, suit: 1, tie: 1, shirt: 1, jacket: 1, tie: 1, chair: 2, window: 1, computer: 1, monitor: 1, keyboard: 1, mouse: 1, desk: 2, outlet: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.1, "ram_available_mb": 38287.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 24547.2, "ram_available_mb": 38293.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.701, "power_cpu_cv_mean_watts": 2.076, "power_sys_5v0_mean_watts": 8.825}, "timestamp": "2026-01-23T08:10:11.031385"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11322.814, "latencies_ms": [11322.814], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the foreground, there is a man standing in front of a desk with a computer and a monitor. The desk is located near a window in the background, which has a reflection of a person and a chair visible on it. The man is standing to the left of the desk, and the computer and monitor are positioned on the right side of the desk.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24547.2, "ram_available_mb": 38293.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.591, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T08:10:24.390463"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8312.996, "latencies_ms": [8312.996], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "A man in a suit stands in front of a desk with a computer and a monitor displaying an image of a room with a couch and a chair. The room appears to be an office or a conference room with a window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24552.1, "ram_available_mb": 38288.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.098, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T08:10:34.735016"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8479.388, "latencies_ms": [8479.388], "images_per_second": 0.118, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The room has a neutral color scheme with white walls and a light-colored carpet. The lighting appears to be artificial, coming from ceiling fixtures, and the room contains a wooden desk with a computer and a monitor displaying an image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.1, "ram_available_mb": 38288.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24543.5, "ram_available_mb": 38297.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.81, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T08:10:45.227018"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11345.52, "latencies_ms": [11345.52], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of four men sitting around a wooden dining table, enjoying a meal together. They are all dressed in casual clothing, and the atmosphere appears to be relaxed and friendly. The table is filled with various dishes, including bowls, cups, and bottles, as well as utensils like forks and knives.\n\nThere", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 24543.5, "ram_available_mb": 38297.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24550.3, "ram_available_mb": 38290.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.601, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T08:10:58.629732"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8325.267, "latencies_ms": [8325.267], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "table: 1\ncups: 4\nbowls: 3\nplates: 5\nsugar packets: 2\nsalt packets: 2\nmugs: 2\ncandies: 1\n", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.3, "ram_available_mb": 38290.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24553.4, "ram_available_mb": 38287.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.269, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 8.872}, "timestamp": "2026-01-23T08:11:08.985118"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11328.457, "latencies_ms": [11328.457], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a wooden table with various items on it, including bowls, cups, and a bottle, indicating a meal is being shared. In the background, there are four individuals seated around the table, with one person on the left side, two in the center, and one on the right side. The table is positioned in the middle of the", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.4, "ram_available_mb": 38287.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24539.7, "ram_available_mb": 38301.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.584, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T08:11:22.345043"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7849.72, "latencies_ms": [7849.72], "images_per_second": 0.127, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "A group of people are gathered around a wooden table, enjoying a meal together. The table is set with various dishes, cups, and utensils, and there is a clock on the wall behind them.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24539.7, "ram_available_mb": 38301.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24552.4, "ram_available_mb": 38288.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.537, "power_cpu_cv_mean_watts": 1.698, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T08:11:32.247264"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6862.759, "latencies_ms": [6862.759], "images_per_second": 0.146, "prompt_tokens": 36, "response_tokens_est": 40, "n_tiles": 16, "output_text": "The room has a warm and cozy atmosphere with wooden walls and a wooden ceiling. The lighting is soft and natural, coming from the large window on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24552.4, "ram_available_mb": 38288.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.972, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.965}, "timestamp": "2026-01-23T08:11:41.166590"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11375.429, "latencies_ms": [11375.429], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a red pickup truck is parked on a snowy street, with a person standing next to it. The truck is equipped with a snow plow, which is attached to the front of the vehicle. The person appears to be either preparing to or has just finished using the plow to clear the snow from the street.\n\nThere are several houses", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24541.9, "ram_available_mb": 38299.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.582, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.834}, "timestamp": "2026-01-23T08:11:54.579214"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7527.362, "latencies_ms": [7527.362], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "house: 3, truck: 1, snow plow: 1, person: 1, tree: 4, house: 2, snow: 1, truck: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.9, "ram_available_mb": 38299.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24543.7, "ram_available_mb": 38297.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.568, "power_cpu_cv_mean_watts": 1.658, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T08:12:04.168572"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9490.558, "latencies_ms": [9490.558], "images_per_second": 0.105, "prompt_tokens": 44, "response_tokens_est": 63, "n_tiles": 16, "output_text": "A red pickup truck is in the foreground, positioned on the right side of the image, moving towards the left. The truck is closer to the viewer than the houses in the background. A person is standing behind the truck, partially obscured by the snow plow attachment.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24543.7, "ram_available_mb": 38297.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24534.3, "ram_available_mb": 38306.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.375, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 8.911}, "timestamp": "2026-01-23T08:12:15.676014"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6720.728, "latencies_ms": [6720.728], "images_per_second": 0.149, "prompt_tokens": 37, "response_tokens_est": 37, "n_tiles": 16, "output_text": "A red pickup truck is being used to clear snow from a residential street. A person is standing next to the truck, assisting in the snow removal process.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24534.3, "ram_available_mb": 38306.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24535.6, "ram_available_mb": 38305.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.258, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 8.917}, "timestamp": "2026-01-23T08:12:24.434432"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7317.314, "latencies_ms": [7317.314], "images_per_second": 0.137, "prompt_tokens": 36, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A red pickup truck is being used to clear snow from a residential street. The truck has a snowplow attached to the front and is being operated by a person in a yellow jacket.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24535.6, "ram_available_mb": 38305.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.627, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.965}, "timestamp": "2026-01-23T08:12:33.801462"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12540.749, "latencies_ms": [12540.749], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment in a luxurious bathroom. The room is bathed in soft light, casting a warm glow on the beige walls and marble countertop. A large mirror dominates the wall, reflecting the room's opulence. Above the mirror, a television is mounted, adding a modern touch to the space.\n\nThe countertop", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24539.2, "ram_available_mb": 38301.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.877, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 9.055}, "timestamp": "2026-01-23T08:12:48.399453"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9052.714, "latencies_ms": [9052.714], "images_per_second": 0.11, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "mirror: 1\ncamera: 1\nlight fixture: 4\ntowel: 3\nfaucet: 2\nbucket: 1\ntile: 1\nmat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.2, "ram_available_mb": 38301.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.678, "power_cpu_cv_mean_watts": 1.47, "power_sys_5v0_mean_watts": 9.081}, "timestamp": "2026-01-23T08:12:59.463734"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10076.754, "latencies_ms": [10076.754], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The main objects in the image are the bathroom counter, sink, mirror, and the person taking a photo. The counter and sink are in the foreground, while the mirror and person are in the background. The person is standing near the mirror, capturing their reflection.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24580.0, "ram_available_mb": 38260.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.982, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 9.11}, "timestamp": "2026-01-23T08:13:11.553549"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9264.695, "latencies_ms": [9264.695], "images_per_second": 0.108, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "A person is taking a photo of a luxurious bathroom with a large mirror, double sinks, and a bathtub. The bathroom is well-lit with multiple light fixtures and has a modern design.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24580.0, "ram_available_mb": 38260.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24584.3, "ram_available_mb": 38256.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.593, "power_cpu_cv_mean_watts": 1.52, "power_sys_5v0_mean_watts": 9.084}, "timestamp": "2026-01-23T08:13:22.834225"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9509.675, "latencies_ms": [9509.675], "images_per_second": 0.105, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The bathroom features a large mirror with a dark frame, and the countertop is made of marble with gold faucets. The lighting is warm and ambient, with multiple sconces on the walls and a television mounted above the mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24584.3, "ram_available_mb": 38256.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24581.6, "ram_available_mb": 38259.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.114, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 9.132}, "timestamp": "2026-01-23T08:13:34.397055"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.849, "latencies_ms": [11335.849], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image depicts a busy airport scene with several people standing around, some of them loading luggage into a white car. There are at least three people in the scene, with one man standing near a cart filled with luggage, another man standing close to the car, and a third person standing further back. \n\nThere are multiple suitcases scattered around the area,", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 24581.6, "ram_available_mb": 38259.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24537.6, "ram_available_mb": 38303.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.652, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T08:13:47.794907"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7881.181, "latencies_ms": [7881.181], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "cart: 1\nman: 2\nsuitcase: 3\ncar: 1\nlicense plate: 1\ndenim: 1\nshoes: 1\nbags: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.6, "ram_available_mb": 38303.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 24531.2, "ram_available_mb": 38309.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.365, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T08:13:57.731345"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11304.871, "latencies_ms": [11304.871], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the foreground, a man is standing and appears to be in the process of loading luggage into a white SUV parked in the background. Another man is standing nearby, also with luggage, and a luggage cart is positioned to the left of the scene. The background features a sign indicating the direction to the Short Bus to McCorman Airport.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24531.2, "ram_available_mb": 38309.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.732, "power_cpu_cv_mean_watts": 2.428, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T08:14:11.056802"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9449.249, "latencies_ms": [9449.249], "images_per_second": 0.106, "prompt_tokens": 37, "response_tokens_est": 61, "n_tiles": 16, "output_text": "In the image, two men are unloading luggage from a white car in a parking garage. The car is parked in a designated parking spot, and the men are standing on the concrete floor, with one man holding a suitcase and the other holding a handbag.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.445, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.873}, "timestamp": "2026-01-23T08:14:22.549432"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8573.46, "latencies_ms": [8573.46], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image shows an indoor setting with artificial lighting, predominantly white walls, and a concrete floor. There is a white car parked on the right side of the image, and the environment appears to be a covered parking area or a garage.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24535.9, "ram_available_mb": 38305.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.758, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.904}, "timestamp": "2026-01-23T08:14:33.152862"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11351.407, "latencies_ms": [11351.407], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a delicious meal consisting of a sandwich, fries, and a side of ketchup. The sandwich is placed in the center of the plate, with the fries surrounding it. The ketchup is positioned to the left of the sandwich. The meal is served on a white plate, which is placed on a dining table. The sand", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24535.9, "ram_available_mb": 38305.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.599, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T08:14:46.560595"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8637.174, "latencies_ms": [8637.174], "images_per_second": 0.116, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "Hamburger: 2\nFries: many\nKetchup: 1\nOnion: 1\nBun: 1\nBread: 1\nBun: 1\nBread: 1\nBun: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.939, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 8.896}, "timestamp": "2026-01-23T08:14:57.235639"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11361.083, "latencies_ms": [11361.083], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground of the image, there is a plate with two burgers, one of which is cut in half, revealing the inside. Behind the burgers, there is a generous portion of golden fries. To the left of the plate, there is a small bowl of ketchup and a small bowl of mayonnaise, both within easy reach for di", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.572, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T08:15:10.636594"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7752.251, "latencies_ms": [7752.251], "images_per_second": 0.129, "prompt_tokens": 37, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image shows a plate of food consisting of a burger, fries, and a small bowl of ketchup. The burger is topped with sesame seeds and the fries are golden brown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24532.9, "ram_available_mb": 38308.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.551, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T08:15:20.426160"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7775.449, "latencies_ms": [7775.449], "images_per_second": 0.129, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image features a meal with a sesame seed bun, a side of fries, and a small bowl of ketchup. The bun is golden brown and the fries are golden and crispy.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24532.9, "ram_available_mb": 38308.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24538.1, "ram_available_mb": 38302.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.215, "power_cpu_cv_mean_watts": 1.733, "power_sys_5v0_mean_watts": 8.927}, "timestamp": "2026-01-23T08:15:30.249270"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11348.036, "latencies_ms": [11348.036], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene and inviting bedroom. Dominating the center of the room is a bed, adorned with a green mosquito net that cascades over the headboard, providing a sense of tranquility. The bed is dressed in a white comforter, and a white pillow rests at its foot, inviting rest and relaxation.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24538.1, "ram_available_mb": 38302.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24536.1, "ram_available_mb": 38304.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.615, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.833}, "timestamp": "2026-01-23T08:15:43.626371"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7407.621, "latencies_ms": [7407.621], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "bed: 1, canopy: 1, window: 4, curtain: 4, painting: 2, table: 1, chair: 1, candle: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24536.1, "ram_available_mb": 38304.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.821, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 8.873}, "timestamp": "2026-01-23T08:15:53.079471"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11342.364, "latencies_ms": [11342.364], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 80, "n_tiles": 16, "output_text": "The bed with the mosquito net is positioned in the foreground of the image, occupying a central space in the room. In the background, there is a wooden table and a small bedside table with a lamp, both of which are to the right of the bed. The room has large windows on the left side, allowing natural light to enter and creating a bright atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.662, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T08:16:06.443858"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9547.599, "latencies_ms": [9547.599], "images_per_second": 0.105, "prompt_tokens": 37, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The image depicts a cozy bedroom with a large bed covered in a green mosquito net, a wooden nightstand with a candle on it, and a table with chairs. The room has a thatched roof and is decorated with framed pictures on the walls.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24536.2, "ram_available_mb": 38304.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.365, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.808}, "timestamp": "2026-01-23T08:16:18.016486"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7433.808, "latencies_ms": [7433.808], "images_per_second": 0.135, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The room has a warm and inviting atmosphere with orange walls and a thatched roof. The bed is covered with a green mosquito net, and there is a small wooden table and chairs in the corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.2, "ram_available_mb": 38304.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.497, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 8.946}, "timestamp": "2026-01-23T08:16:27.506451"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12337.276, "latencies_ms": [12337.276], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a gray and white cat is standing on top of a black car in a garage. The cat appears to be looking around, possibly observing its surroundings. The garage is filled with various items, including a bicycle, a bottle, a box, and a few other objects. The cat is positioned near the center of the car, with its", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24538.6, "ram_available_mb": 38302.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.627, "power_cpu_cv_mean_watts": 1.808, "power_sys_5v0_mean_watts": 9.043}, "timestamp": "2026-01-23T08:16:41.887410"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8771.167, "latencies_ms": [8771.167], "images_per_second": 0.114, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "car: 1, cat: 1, lamps: 2, boxes: 1, tires: 2, bicycles: 2, bottles: 2, drawers: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.6, "ram_available_mb": 38302.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24526.2, "ram_available_mb": 38314.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.222, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 9.042}, "timestamp": "2026-01-23T08:16:52.712699"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12282.95, "latencies_ms": [12282.95], "images_per_second": 0.081, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a cat is standing on the hood of a black car, which is positioned in the center of the image. The car is in the foreground and appears to be the main subject of the photo. In the background, there are various items such as a bicycle, a lamp, and a box, which are less prominent and appear to be further away from", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24526.2, "ram_available_mb": 38314.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24531.6, "ram_available_mb": 38309.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.633, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 9.05}, "timestamp": "2026-01-23T08:17:07.017446"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8566.423, "latencies_ms": [8566.423], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A cat is standing on the hood of a black car in a garage. The garage is cluttered with various items, including a bicycle, a lamp, and a cardboard box.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24531.6, "ram_available_mb": 38309.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24518.5, "ram_available_mb": 38322.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.308, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 9.026}, "timestamp": "2026-01-23T08:17:17.609278"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7705.598, "latencies_ms": [7705.598], "images_per_second": 0.13, "prompt_tokens": 36, "response_tokens_est": 39, "n_tiles": 16, "output_text": "The image shows a gray and white striped cat standing on a black car in an indoor setting. The lighting is artificial, with a lamp and overhead lights visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24518.5, "ram_available_mb": 38322.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24519.4, "ram_available_mb": 38321.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.512, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 9.132}, "timestamp": "2026-01-23T08:17:27.356484"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12531.07, "latencies_ms": [12531.07], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image presents a white plate holding a delicious-looking sandwich. The sandwich is made with a toasted bun, filled with a generous amount of meat, and topped with a slice of tomato and a dollop of sauce. The plate is placed on a table, and there's a fork visible on the right side of the plate. The background is bl", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 24519.4, "ram_available_mb": 38321.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24522.0, "ram_available_mb": 38318.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.95, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 9.09}, "timestamp": "2026-01-23T08:17:41.916875"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9468.66, "latencies_ms": [9468.66], "images_per_second": 0.106, "prompt_tokens": 39, "response_tokens_est": 50, "n_tiles": 16, "output_text": "plate: 1\nmushroom: 1\ngravy: 1\nbread: 1\nmeat: 1\ntomato: 1\nparsley: 1\ngravy: 1\n", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24522.0, "ram_available_mb": 38318.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24526.6, "ram_available_mb": 38314.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.592, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 9.098}, "timestamp": "2026-01-23T08:17:53.399235"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11723.067, "latencies_ms": [11723.067], "images_per_second": 0.085, "prompt_tokens": 44, "response_tokens_est": 71, "n_tiles": 16, "output_text": "In the foreground, there is a plate with a sandwich that has a large piece of meat and a slice of tomato on top. The plate is placed on a table with a black and white checkered pattern. In the background, there is another plate with a different type of food, and a fork is also visible on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24526.6, "ram_available_mb": 38314.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24574.8, "ram_available_mb": 38266.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.424, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 9.123}, "timestamp": "2026-01-23T08:18:07.165607"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11716.832, "latencies_ms": [11716.832], "images_per_second": 0.085, "prompt_tokens": 37, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The image shows a plate of food with a sandwich topped with a slice of tomato and a generous amount of gravy, garnished with chopped herbs. The plate is placed on a table with a black and white checkered tablecloth, and there is a fork on the right side of the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24574.8, "ram_available_mb": 38266.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 24567.4, "ram_available_mb": 38273.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.53, "power_cpu_cv_mean_watts": 2.175, "power_sys_5v0_mean_watts": 9.09}, "timestamp": "2026-01-23T08:18:20.925463"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11656.972, "latencies_ms": [11656.972], "images_per_second": 0.086, "prompt_tokens": 36, "response_tokens_est": 71, "n_tiles": 16, "output_text": "The image shows a plate of food with a rich, dark brown gravy and a slice of tomato on top, garnished with green herbs, possibly parsley. The plate is white, and the food is presented on a table with a black and white checkered tablecloth, suggesting an outdoor setting with natural light.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24567.4, "ram_available_mb": 38273.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 24573.7, "ram_available_mb": 38267.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.413, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 9.149}, "timestamp": "2026-01-23T08:18:34.594979"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11355.139, "latencies_ms": [11355.139], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image depicts a group of three men sitting on a couch in a living room, enjoying a beer and playing a video game together. They are all focused on the game, with one man holding a remote controller in his hand. The room is furnished with a couch, a dining table, and a chair.\n\nVarious items can be seen in the", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24573.7, "ram_available_mb": 38267.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.583, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T08:18:48.019998"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10711.738, "latencies_ms": [10711.738], "images_per_second": 0.093, "prompt_tokens": 39, "response_tokens_est": 72, "n_tiles": 16, "output_text": "- Beer cans: 5\n\n- Beer bottles: 2\n\n- Glasses: 1\n\n- Laptop: 1\n\n- Couch: 1\n\n- Chair: 1\n\n- Beer keg: 1\n\n- Beer keg cap: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24549.9, "ram_available_mb": 38291.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.059, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T08:19:00.747700"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11091.352, "latencies_ms": [11091.352], "images_per_second": 0.09, "prompt_tokens": 44, "response_tokens_est": 77, "n_tiles": 16, "output_text": "In the foreground, there is a red couch with a person sitting on it, and a red table with various items on it. In the background, there is a window with blinds partially open, allowing natural light to enter the room. The person standing on the right side of the image is holding a remote control, and there is a laptop on the couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.9, "ram_available_mb": 38291.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24620.1, "ram_available_mb": 38220.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.74, "power_cpu_cv_mean_watts": 1.917, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T08:19:13.864614"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9984.766, "latencies_ms": [9984.766], "images_per_second": 0.1, "prompt_tokens": 37, "response_tokens_est": 65, "n_tiles": 16, "output_text": "A group of people are gathered in a living room, with one person standing and holding a Wii remote, while the others are seated on a couch and a red couch. There are various items scattered around the room, including a red table, a laptop, a backpack, and a bottle.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24626.6, "ram_available_mb": 38214.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.131, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 8.798}, "timestamp": "2026-01-23T08:19:25.875676"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8118.68, "latencies_ms": [8118.68], "images_per_second": 0.123, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The room is dimly lit with a warm yellow light emanating from a lamp on the right side of the image. There is a red couch and a red table in the room, along with a white couch and a white table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24573.1, "ram_available_mb": 38267.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24626.8, "ram_available_mb": 38214.1, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.109, "power_cpu_cv_mean_watts": 1.761, "power_sys_5v0_mean_watts": 8.943}, "timestamp": "2026-01-23T08:19:36.029323"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11322.126, "latencies_ms": [11322.126], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the heart of a vibrant baseball field, a catcher crouches in anticipation. Dressed in a uniform of black and white, the catcher's helmet gleams under the sunlight, reflecting the intensity of the game. The catcher's mitt, a symbol of readiness, is held firmly in both hands, ready to catch any incoming", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24626.8, "ram_available_mb": 38214.1, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24627.0, "ram_available_mb": 38213.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.664, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 8.86}, "timestamp": "2026-01-23T08:19:49.416747"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10034.304, "latencies_ms": [10034.304], "images_per_second": 0.1, "prompt_tokens": 39, "response_tokens_est": 66, "n_tiles": 16, "output_text": "1. Catcher: 1\n2. Home plate: 1\n3. Mound: 1\n4. Baseball field: 1\n5. Baseball glove: 1\n6. Helmet: 1\n7. Uniform: 1\n8. Net: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24617.1, "ram_available_mb": 38223.8, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.189, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T08:20:01.483221"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11089.415, "latencies_ms": [11089.415], "images_per_second": 0.09, "prompt_tokens": 44, "response_tokens_est": 77, "n_tiles": 16, "output_text": "The catcher is positioned in the foreground on the baseball field, crouched behind home plate, which is the focal point of the image. The background features a well-maintained grassy area, likely the outfield, which is part of the baseball diamond. The catcher is near the home plate, indicating readiness to catch a pitch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24617.1, "ram_available_mb": 38223.8, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24626.3, "ram_available_mb": 38214.6, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.641, "power_cpu_cv_mean_watts": 1.939, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T08:20:14.602674"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7383.014, "latencies_ms": [7383.014], "images_per_second": 0.135, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "A baseball catcher is crouched down on the field, ready to catch the ball. The catcher is wearing a black and white uniform with a helmet and a catcher's mitt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24626.3, "ram_available_mb": 38214.6, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24627.6, "ram_available_mb": 38213.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.893, "power_cpu_cv_mean_watts": 1.608, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T08:20:24.010732"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7775.407, "latencies_ms": [7775.407], "images_per_second": 0.129, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The baseball catcher is wearing a black and white uniform with a black helmet and mask. The field is covered in green grass and the dirt around the catcher's area is brown with white chalk markings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.1, "ram_available_mb": 38291.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24549.9, "ram_available_mb": 38291.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.252, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T08:20:33.822922"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11336.262, "latencies_ms": [11336.262], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image presents a bathroom scene. The dominant color scheme is pink and blue, with the walls painted in these hues. A white toilet is situated in the center of the room, with a white bathtub positioned to its left. Above the bathtub, a window is visible, allowing natural light to enter the space. The floor is covered with a green", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 24549.9, "ram_available_mb": 38291.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.597, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T08:20:47.226069"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7898.005, "latencies_ms": [7898.005], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "door: 2, bathtub: 1, toilet: 1, window: 1, shower curtain: 1, sink: 1, cabinet: 1, mirror: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24546.6, "ram_available_mb": 38294.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.33, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.907}, "timestamp": "2026-01-23T08:20:57.155817"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9839.035, "latencies_ms": [9839.035], "images_per_second": 0.102, "prompt_tokens": 44, "response_tokens_est": 66, "n_tiles": 16, "output_text": "The toilet is located in the foreground of the image, near the left side. The bathtub is in the background, to the left of the toilet. The shower curtain is hanging vertically in the center of the image, between the bathtub and the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.6, "ram_available_mb": 38294.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24541.4, "ram_available_mb": 38299.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.271, "power_cpu_cv_mean_watts": 1.852, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T08:21:09.044797"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9801.7, "latencies_ms": [9801.7], "images_per_second": 0.102, "prompt_tokens": 37, "response_tokens_est": 64, "n_tiles": 16, "output_text": "The image shows a small, well-lit bathroom with a white toilet, a bathtub with a shower curtain, and a wooden vanity with a sink. The walls are painted in a light blue and pink color scheme, and there is a window above the bathtub.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24541.4, "ram_available_mb": 38299.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.317, "power_cpu_cv_mean_watts": 1.824, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T08:21:20.868591"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6613.239, "latencies_ms": [6613.239], "images_per_second": 0.151, "prompt_tokens": 36, "response_tokens_est": 38, "n_tiles": 16, "output_text": "The image shows a bathroom with a pink tiled wall and a white toilet. There is a window with white curtains on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24543.5, "ram_available_mb": 38297.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.215, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 8.997}, "timestamp": "2026-01-23T08:21:29.539033"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11348.48, "latencies_ms": [11348.48], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene and cozy bedroom scene. Dominating the right side of the frame is a bed, dressed in a bedspread of a warm, inviting yellow and white plaid pattern. The bed, with its dark wooden headboard, stands as the centerpiece of the room.\n\nTo the left, a window draped with red curtain", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24543.5, "ram_available_mb": 38297.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.64, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T08:21:42.922734"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9807.766, "latencies_ms": [9807.766], "images_per_second": 0.102, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "1. Bed: 1\n2. Pillow: 2\n3. Nightstand: 1\n4. Lamp: 1\n5. Window: 1\n6. Curtains: 2\n7. Drape: 1\n8. Wall: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24533.3, "ram_available_mb": 38307.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.462, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 8.817}, "timestamp": "2026-01-23T08:21:54.767814"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9607.484, "latencies_ms": [9607.484], "images_per_second": 0.104, "prompt_tokens": 44, "response_tokens_est": 64, "n_tiles": 16, "output_text": "The bed is located in the foreground of the image, occupying the lower right portion. The window with curtains is in the background, positioned on the left side of the image. The lamp is placed on a small bedside table, situated to the right of the bed and slightly behind it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24533.3, "ram_available_mb": 38307.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.276, "power_cpu_cv_mean_watts": 1.87, "power_sys_5v0_mean_watts": 8.896}, "timestamp": "2026-01-23T08:22:06.396621"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7393.998, "latencies_ms": [7393.998], "images_per_second": 0.135, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image depicts a cozy bedroom with a bed placed against a wall, next to a window with curtains. The room is dimly lit, creating a calm and relaxing atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.668, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T08:22:15.827847"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8230.686, "latencies_ms": [8230.686], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The room is dimly lit with natural light coming in through the window, casting a soft glow on the plaid bedspread. The curtains are drawn back, allowing the light to filter into the room and create a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.999, "power_cpu_cv_mean_watts": 2.031, "power_sys_5v0_mean_watts": 8.971}, "timestamp": "2026-01-23T08:22:26.087162"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12526.134, "latencies_ms": [12526.134], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young man and woman are standing close to each other, with the woman placing a white flower on the man's lapel. The man is wearing a black suit and tie, while the woman is dressed in a black dress. They are both smiling, indicating a joyful and celebratory atmosphere. The woman is holding the flower with her right hand, and the", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 24595.7, "ram_available_mb": 38245.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.022, "power_cpu_cv_mean_watts": 2.274, "power_sys_5v0_mean_watts": 9.12}, "timestamp": "2026-01-23T08:22:40.682569"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8839.959, "latencies_ms": [8839.959], "images_per_second": 0.113, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "person: 2, flower: 1, tie: 1, suit: 1, dress: 1, bracelet: 1, earring: 1, necklace: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24595.7, "ram_available_mb": 38245.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24546.4, "ram_available_mb": 38294.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.779, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 9.083}, "timestamp": "2026-01-23T08:22:51.546624"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8466.383, "latencies_ms": [8466.383], "images_per_second": 0.118, "prompt_tokens": 44, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The person on the left is standing in the foreground, while the person on the right is slightly behind and to the right of the person on the left. The background is a plain wall with a door.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.4, "ram_available_mb": 38294.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.612, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 9.163}, "timestamp": "2026-01-23T08:23:02.054849"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9965.257, "latencies_ms": [9965.257], "images_per_second": 0.1, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "In the image, a young man and woman are standing close to each other, with the woman placing a white flower on the man's lapel. They are both dressed in formal attire, suggesting that they are attending a special event or celebration.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24586.4, "ram_available_mb": 38254.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.196, "power_cpu_cv_mean_watts": 1.559, "power_sys_5v0_mean_watts": 9.092}, "timestamp": "2026-01-23T08:23:14.043283"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10182.456, "latencies_ms": [10182.456], "images_per_second": 0.098, "prompt_tokens": 36, "response_tokens_est": 58, "n_tiles": 16, "output_text": "The image features a man in a black suit with a beige tie and a woman in a black and silver sequined dress. The lighting appears to be artificial, likely from indoor lighting, and the overall color scheme is dark with some shimmering silver accents.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24586.4, "ram_available_mb": 38254.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.865, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 9.154}, "timestamp": "2026-01-23T08:23:26.276349"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11382.403, "latencies_ms": [11382.403], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene of urban tranquility. Dominating the foreground is a chain-link fence, its metallic gray color contrasting with the lush green of the grass and the vibrant green of the palm trees in the background. The fence, standing tall and sturdy, serves as a boundary between the viewer and the scene beyond.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.481, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.836}, "timestamp": "2026-01-23T08:23:39.699531"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7651.077, "latencies_ms": [7651.077], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "fence: 1, stop sign: 1, palm trees: 5, trash: 2, bush: 1, building: 1, car: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24539.0, "ram_available_mb": 38301.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.783, "power_cpu_cv_mean_watts": 1.658, "power_sys_5v0_mean_watts": 8.912}, "timestamp": "2026-01-23T08:23:49.396396"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9289.006, "latencies_ms": [9289.006], "images_per_second": 0.108, "prompt_tokens": 44, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The stop sign is positioned in the foreground on the left side of the image, behind the chain-link fence which occupies the middle ground. In the background, there are palm trees and a building, indicating that the fence is likely in an urban or residential area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.0, "ram_available_mb": 38301.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24539.6, "ram_available_mb": 38301.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.474, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T08:24:00.700889"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8936.489, "latencies_ms": [8936.489], "images_per_second": 0.112, "prompt_tokens": 37, "response_tokens_est": 56, "n_tiles": 16, "output_text": "A stop sign is mounted on a chain-link fence, indicating that vehicles must come to a complete stop before proceeding. The fence is located in a grassy area with palm trees and a building in the background, suggesting an urban or residential setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.6, "ram_available_mb": 38301.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24528.9, "ram_available_mb": 38312.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.637, "power_cpu_cv_mean_watts": 1.761, "power_sys_5v0_mean_watts": 8.831}, "timestamp": "2026-01-23T08:24:11.655007"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9054.55, "latencies_ms": [9054.55], "images_per_second": 0.11, "prompt_tokens": 36, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image features a red and white stop sign mounted on a metal pole, which is partially obscured by a chain-link fence. The fence is green and appears to be in a state of disrepair, with some debris and trash scattered around the area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24528.9, "ram_available_mb": 38312.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24542.4, "ram_available_mb": 38298.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.518, "power_cpu_cv_mean_watts": 1.799, "power_sys_5v0_mean_watts": 8.905}, "timestamp": "2026-01-23T08:24:22.770542"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11355.548, "latencies_ms": [11355.548], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there is a man standing next to a motorcycle and a bicycle. The man is wearing a white helmet and is positioned on the left side of the scene. The motorcycle is parked on the left side of the image, while the bicycle is on the right side. The bicycle has a basket attached to it, and it is", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24542.4, "ram_available_mb": 38298.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24536.6, "ram_available_mb": 38304.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.614, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T08:24:36.149731"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7685.663, "latencies_ms": [7685.663], "images_per_second": 0.13, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "motorcycle: 1, bicycle: 3, tree: 2, fence: 1, basket: 1, tire: 4, leaf: 1, person: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24536.6, "ram_available_mb": 38304.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24540.8, "ram_available_mb": 38300.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.399, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T08:24:45.880848"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11323.925, "latencies_ms": [11323.925], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the foreground, there is a motorcycle on the left side of the image, and a bicycle on the right side. The bicycle is positioned closer to the viewer than the motorcycle. In the background, there is a person standing to the right of the bicycle, and another bicycle is partially visible behind the first bicycle.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24540.8, "ram_available_mb": 38300.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24545.5, "ram_available_mb": 38295.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.636, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T08:24:59.242396"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7867.492, "latencies_ms": [7867.492], "images_per_second": 0.127, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "In a residential area, a man is standing next to a motorcycle while two bicycles are parked nearby. The scene suggests a casual outdoor setting where people are engaging in different modes of transportation.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24545.5, "ram_available_mb": 38295.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24537.2, "ram_available_mb": 38303.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.315, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T08:25:09.164073"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7781.039, "latencies_ms": [7781.039], "images_per_second": 0.129, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image shows a sunny day with clear skies, casting shadows on the ground. There are three bicycles, one yellow, one black, and one with a red seat, all parked on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24537.2, "ram_available_mb": 38303.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.269, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.936}, "timestamp": "2026-01-23T08:25:18.994062"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11361.795, "latencies_ms": [11361.795], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a busy city street scene with a man standing on the sidewalk, looking at a street sign. He is wearing a blue shirt and jeans. There are several other people in the scene, including a woman carrying a handbag and a man with a backpack. \n\nThe street is filled with various vehicles, including cars and a truck. There are", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24543.0, "ram_available_mb": 38297.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.517, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T08:25:32.387855"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9553.872, "latencies_ms": [9553.872], "images_per_second": 0.105, "prompt_tokens": 39, "response_tokens_est": 62, "n_tiles": 16, "output_text": "- pedestrian: 1\n\n- traffic light: 3\n\n- car: 1\n\n- bicycle: 1\n\n- building: 1\n\n- sign: 2\n\n- trash can: 1\n\n- road: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24543.0, "ram_available_mb": 38297.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24533.7, "ram_available_mb": 38307.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.535, "power_cpu_cv_mean_watts": 1.809, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T08:25:44.001724"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11337.19, "latencies_ms": [11337.19], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a pedestrian standing on the sidewalk, looking towards the street where a red car is parked on the right side. The car is near the curb, and there is a traffic light above it. In the background, there is a building with a sign that reads \"PROCTER 2\" and a street sign with a \"No Parking", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24533.7, "ram_available_mb": 38307.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24534.6, "ram_available_mb": 38306.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.66, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T08:25:57.352165"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9106.731, "latencies_ms": [9106.731], "images_per_second": 0.11, "prompt_tokens": 37, "response_tokens_est": 58, "n_tiles": 16, "output_text": "The image depicts a city street scene with a pedestrian standing on the sidewalk, a car parked on the side of the road, and a cyclist riding a bicycle. There are traffic lights and street signs visible, indicating a busy urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.6, "ram_available_mb": 38306.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24542.3, "ram_available_mb": 38298.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.557, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T08:26:08.485761"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9737.318, "latencies_ms": [9737.318], "images_per_second": 0.103, "prompt_tokens": 36, "response_tokens_est": 65, "n_tiles": 16, "output_text": "The image shows a street scene with a pedestrian standing on the sidewalk, a red car in the background, and a building with a brick facade. The weather appears to be overcast, and the lighting is natural but subdued, suggesting it might be an early morning or late afternoon time.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24542.3, "ram_available_mb": 38298.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24528.3, "ram_available_mb": 38312.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.214, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T08:26:20.239722"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.683, "latencies_ms": [11335.683], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a bronze statue of two people sitting on a bench, with one person holding a suitcase. The statue is located on a sidewalk, and there are several people standing nearby, observing the artwork. Some of the people are wearing backpacks, and one of them is holding a handbag.\n\nIn the background, there is a car parked further", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24528.3, "ram_available_mb": 38312.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.649, "power_cpu_cv_mean_watts": 1.939, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T08:26:33.605379"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7160.78, "latencies_ms": [7160.78], "images_per_second": 0.14, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "people: 3, statue: 1, bench: 1, bag: 1, building: 1, pole: 2, shadow: 1, sun: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 24565.6, "ram_available_mb": 38275.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.014, "power_cpu_cv_mean_watts": 2.162, "power_sys_5v0_mean_watts": 8.948}, "timestamp": "2026-01-23T08:26:42.785509"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11365.533, "latencies_ms": [11365.533], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a bronze statue of two people sitting closely together on a bench, with a suitcase placed in front of them. In the background, there are people standing near a closed garage door, and a stroller is visible to the right side of the image. The statue is positioned on a stone bench, and the people in the background are at a", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24565.6, "ram_available_mb": 38275.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 24549.1, "ram_available_mb": 38291.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.566, "power_cpu_cv_mean_watts": 2.175, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T08:26:56.174342"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6481.827, "latencies_ms": [6481.827], "images_per_second": 0.154, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "A bronze statue of two people sitting on a bench is located on a brick sidewalk. In the background, there are people standing and a closed garage door.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24549.1, "ram_available_mb": 38291.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24553.8, "ram_available_mb": 38287.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.568, "power_cpu_cv_mean_watts": 1.528, "power_sys_5v0_mean_watts": 8.941}, "timestamp": "2026-01-23T08:27:04.672939"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11071.382, "latencies_ms": [11071.382], "images_per_second": 0.09, "prompt_tokens": 36, "response_tokens_est": 77, "n_tiles": 16, "output_text": "The sculpture depicts two figures seated closely together, with one figure holding a suitcase. The figures are made of a dark material, possibly bronze, and the sculpture is situated on a stone pedestal. The lighting in the image is natural, with shadows cast on the ground, indicating that the photo was taken outdoors during the day.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 24553.8, "ram_available_mb": 38287.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24628.4, "ram_available_mb": 38212.5, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.726, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T08:27:17.770865"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11315.661, "latencies_ms": [11315.661], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene of a street sign post, standing tall against the backdrop of a clear blue sky. The post is adorned with a series of signs, each with its own unique color and symbol, guiding the way for different types of vehicles.\n\nAt the top, a blue sign with a white airplane symbol indicates the direction to an airport. Just below", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 24558.2, "ram_available_mb": 38282.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24629.7, "ram_available_mb": 38211.2, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.689, "power_cpu_cv_mean_watts": 1.952, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T08:27:31.126938"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10482.076, "latencies_ms": [10482.076], "images_per_second": 0.095, "prompt_tokens": 39, "response_tokens_est": 70, "n_tiles": 16, "output_text": "- Sign: 5\n\n- Parking symbol: 1\n\n- Truck symbol: 1\n\n- Bus symbol: 1\n\n- Traffic light: 1\n\n- Parking sign: 1\n\n- No parking sign: 1\n\n- No truck sign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.4, "ram_available_mb": 38292.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.148, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 8.834}, "timestamp": "2026-01-23T08:27:43.657794"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11162.622, "latencies_ms": [11162.622], "images_per_second": 0.09, "prompt_tokens": 44, "response_tokens_est": 77, "n_tiles": 16, "output_text": "The signs are arranged vertically with the 'Severinsbr\u00fccke' sign at the top, followed by 'Koelnmesse' in the middle, and 'Im Sionstal' at the bottom. The 'no truck' sign is in the foreground on the left, while the 'no parking' sign is in the background on the right.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24558.2, "ram_available_mb": 38282.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.71, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T08:27:56.858431"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11563.706, "latencies_ms": [11563.706], "images_per_second": 0.086, "prompt_tokens": 37, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image shows a collection of traffic signs mounted on a pole, likely at a roadside or intersection. The signs indicate directions to various destinations such as Severinsbr\u00fccke, Koelnmesse, and Im Sionstal, with arrows pointing to the right for each. Additionally, there is a no parking sign and a no left turn sign, indicating traffic regulations at this location", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24558.2, "ram_available_mb": 38282.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24538.7, "ram_available_mb": 38302.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.655, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 8.793}, "timestamp": "2026-01-23T08:28:10.456013"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10679.123, "latencies_ms": [10679.123], "images_per_second": 0.094, "prompt_tokens": 36, "response_tokens_est": 73, "n_tiles": 16, "output_text": "The image shows a series of traffic signs mounted on a pole, with the top sign featuring an airplane and a bridge, indicating directions to an airport and a bridge. The signs are in various colors such as blue, white, green, and red, and there is a no parking sign at the bottom with a red circle and a blue background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24538.7, "ram_available_mb": 38302.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24547.6, "ram_available_mb": 38293.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.917, "power_cpu_cv_mean_watts": 1.905, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T08:28:23.195335"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11334.243, "latencies_ms": [11334.243], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a woman and a young girl are standing next to each other on a train platform. They are both smiling and posing for the camera. The woman is wearing a red shirt, and the girl is wearing a blue shirt. They are standing close to a black suitcase, which is placed on the platform.\n\nThere are other people in the background", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24547.6, "ram_available_mb": 38293.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.562, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T08:28:36.565896"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9015.816, "latencies_ms": [9015.816], "images_per_second": 0.111, "prompt_tokens": 39, "response_tokens_est": 57, "n_tiles": 16, "output_text": "- Suitcase: 1\n- Tag: 1\n- Woman: 2\n- Train: 1\n- Flower patterned bag: 1\n- Train platform: 1\n- Train door: 1\n- Train window: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.798, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T08:28:47.616843"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11394.365, "latencies_ms": [11394.365], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a black suitcase with a tag on it, placed on the ground. Behind the suitcase, there are two individuals standing close to each other, with one person wearing a red shirt and the other wearing a blue shirt. In the background, there is a red pillar and a train or bus with a window showing a view of trees", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24543.9, "ram_available_mb": 38297.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.656, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T08:29:01.039541"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7298.415, "latencies_ms": [7298.415], "images_per_second": 0.137, "prompt_tokens": 37, "response_tokens_est": 42, "n_tiles": 16, "output_text": "Two women are standing next to a suitcase on a train platform, possibly waiting for their train or just arrived at their destination. They are both smiling and appear to be in a good mood.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24543.9, "ram_available_mb": 38297.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24533.3, "ram_available_mb": 38307.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.864, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T08:29:10.365901"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10090.117, "latencies_ms": [10090.117], "images_per_second": 0.099, "prompt_tokens": 36, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The image shows two individuals standing next to a black suitcase with a tag visible on it, in a well-lit indoor setting with a red and white color scheme. The person on the left is wearing a red hoodie and the person on the right is wearing a blue shirt with a floral pattern.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24533.3, "ram_available_mb": 38307.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24535.6, "ram_available_mb": 38305.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.174, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T08:29:22.494405"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 10983.534, "latencies_ms": [10983.534], "images_per_second": 0.091, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 16, "output_text": "In the image, there are three zebras standing in a line, facing the camera. They are positioned in front of a tree with purple flowers, possibly a wisteria tree. The zebras are standing on a dirt ground, and their black and white stripes are clearly visible. The scene appears to be a natural habitat for these animals.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 24535.6, "ram_available_mb": 38305.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.767, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T08:29:35.535375"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7294.164, "latencies_ms": [7294.164], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "zebra: 3, trees: numerous, flowers: numerous, branches: numerous, ground: dirt, rocks: few, grass: dirt, sun: visible, shadows: visible", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.829, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.898}, "timestamp": "2026-01-23T08:29:44.859295"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10287.369, "latencies_ms": [10287.369], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The three zebras are positioned in a line, with the one on the left being the farthest from the camera, the middle zebra being slightly closer, and the zebra on the right being the closest to the camera. They are standing on a dirt ground with trees and purple flowers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.949, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T08:29:57.160933"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7751.426, "latencies_ms": [7751.426], "images_per_second": 0.129, "prompt_tokens": 37, "response_tokens_est": 46, "n_tiles": 16, "output_text": "Three zebras are standing in a natural setting with trees and purple flowers in the background. The zebras appear to be in a peaceful and serene environment, possibly a wildlife reserve or a zoo.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24535.9, "ram_available_mb": 38305.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.435, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 8.885}, "timestamp": "2026-01-23T08:30:06.954055"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6971.533, "latencies_ms": [6971.533], "images_per_second": 0.143, "prompt_tokens": 36, "response_tokens_est": 41, "n_tiles": 16, "output_text": "Three zebras are standing in a natural habitat with trees and purple flowers in the background. The ground is covered in dirt and the zebras have distinct black and white stripes.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24535.9, "ram_available_mb": 38305.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.857, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.957}, "timestamp": "2026-01-23T08:30:15.988324"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11286.635, "latencies_ms": [11286.635], "images_per_second": 0.089, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a tripod with a camera mounted on top of it, positioned in the foreground. The camera is focused on a laptop that is placed on a chair in the background. The chair is located near a dining table, which is also visible in the scene. \n\nIn addition to the laptop and the camera, there are two refrigerators in the background,", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24542.8, "ram_available_mb": 38298.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.578, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T08:30:29.340185"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9570.437, "latencies_ms": [9570.437], "images_per_second": 0.104, "prompt_tokens": 39, "response_tokens_est": 62, "n_tiles": 16, "output_text": "- tripod: 1\n\n- camera: 1\n\n- laptop: 1\n\n- chair: 1\n\n- cooler: 1\n\n- refrigerator: 1\n\n- water dispenser: 1\n\n- table: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24542.8, "ram_available_mb": 38298.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24531.7, "ram_available_mb": 38309.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.499, "power_cpu_cv_mean_watts": 1.799, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T08:30:40.952979"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11404.586, "latencies_ms": [11404.586], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a tripod with a camera mounted on top, positioned near a laptop that is placed on a chair. The laptop is in the foreground and appears to be the main focus of the image. In the background, there is a vending machine and a table with various items on it, both of which are further away from the camera's viewpoint.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24531.7, "ram_available_mb": 38309.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.608, "power_cpu_cv_mean_watts": 2.234, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T08:30:54.397813"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7984.861, "latencies_ms": [7984.861], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "In the image, a tripod is set up in a room with a laptop on it, and a vending machine is visible in the background. It appears to be a workspace or a temporary setup for a project or presentation.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 24559.0, "ram_available_mb": 38281.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.413, "power_cpu_cv_mean_watts": 2.08, "power_sys_5v0_mean_watts": 8.906}, "timestamp": "2026-01-23T08:31:04.433621"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8626.894, "latencies_ms": [8626.894], "images_per_second": 0.116, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image features a tripod with a camera mounted on top, positioned in an indoor setting with a vending machine in the background. The tripod is light brown, and the camera is black, while the vending machine is metallic and blue.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24559.0, "ram_available_mb": 38281.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24558.1, "ram_available_mb": 38282.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.836, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 8.892}, "timestamp": "2026-01-23T08:31:15.085933"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11331.504, "latencies_ms": [11331.504], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the image, a sheep is standing in a pen, surrounded by a large amount of wool. The sheep is positioned in the center of the pen, with its body facing the camera. The wool is scattered all around the sheep, covering the ground and the sheep itself. The pen appears to be a fenced area, providing a safe and contained space for the sheep.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 24558.1, "ram_available_mb": 38282.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24548.0, "ram_available_mb": 38292.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.692, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T08:31:28.457119"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8203.198, "latencies_ms": [8203.198], "images_per_second": 0.122, "prompt_tokens": 39, "response_tokens_est": 50, "n_tiles": 16, "output_text": "sheep: 1, wool pile: 1, metal fence: 1, concrete ground: 1, white object: 1, black object: 1, gray object: 1, metal grid: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.0, "ram_available_mb": 38292.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24551.3, "ram_available_mb": 38289.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.192, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T08:31:38.719393"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9970.785, "latencies_ms": [9970.785], "images_per_second": 0.1, "prompt_tokens": 44, "response_tokens_est": 67, "n_tiles": 16, "output_text": "In the foreground, there is a pile of wool that is being sorted by a sheep. The sheep is standing behind the pile of wool, with its head resting on the pile. The background shows a metal fence that is enclosing the area where the sheep and wool are located.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24551.3, "ram_available_mb": 38289.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.12, "power_cpu_cv_mean_watts": 1.855, "power_sys_5v0_mean_watts": 8.879}, "timestamp": "2026-01-23T08:31:50.700253"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6594.689, "latencies_ms": [6594.689], "images_per_second": 0.152, "prompt_tokens": 37, "response_tokens_est": 36, "n_tiles": 16, "output_text": "A sheep is standing in a pen with a pile of wool in front of it. The sheep appears to be eating or nibbling on the wool.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.446, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 8.924}, "timestamp": "2026-01-23T08:31:59.313048"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7787.353, "latencies_ms": [7787.353], "images_per_second": 0.128, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image shows a sheep standing in a pen with a wire fence, surrounded by a large amount of wool. The wool is in various shades of grey and white, indicating different breeds or stages of shearing.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.204, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 8.937}, "timestamp": "2026-01-23T08:32:09.153511"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11332.268, "latencies_ms": [11332.268], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a tennis match in progress on a blue court. There are two players, one on each side of the net, actively engaged in the game. Both players are holding tennis rackets and are focused on the ball, which is located near the center of the court. \n\nIn addition to the players, there are several other people present in the scene. Some of them", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24576.9, "ram_available_mb": 38264.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.637, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T08:32:22.513474"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8766.056, "latencies_ms": [8766.056], "images_per_second": 0.114, "prompt_tokens": 39, "response_tokens_est": 55, "n_tiles": 16, "output_text": "- Players: 2\n- Ball: 1\n- Net: 1\n- Chair: 1\n- Spectators: 20\n- Banners: 4\n- Signs: 3\n- Towel: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24576.9, "ram_available_mb": 38264.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24577.8, "ram_available_mb": 38263.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.058, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 8.88}, "timestamp": "2026-01-23T08:32:33.302727"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10620.212, "latencies_ms": [10620.212], "images_per_second": 0.094, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "In the foreground, there is a tennis court with two players in the middle of a match, one near the baseline and the other closer to the net. The audience is seated in the background, surrounding the court on all sides. The scoreboard is positioned above the court, near the center, and is at a distance from the players.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24577.8, "ram_available_mb": 38263.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 24579.6, "ram_available_mb": 38261.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.959, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T08:32:45.962372"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9684.278, "latencies_ms": [9684.278], "images_per_second": 0.103, "prompt_tokens": 37, "response_tokens_est": 63, "n_tiles": 16, "output_text": "The image captures a tennis match in progress on a blue court with a crowd of spectators watching. Two players are actively engaged in the game, with one player in a pink outfit and the other in a red outfit, both holding tennis rackets and preparing to hit the ball.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24579.6, "ram_available_mb": 38261.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24551.5, "ram_available_mb": 38289.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.369, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.835}, "timestamp": "2026-01-23T08:32:57.707095"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7994.018, "latencies_ms": [7994.018], "images_per_second": 0.125, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The tennis court is a vibrant blue color, likely due to the blue paint used on the surface. The lighting in the image appears to be artificial, as it is evenly distributed across the court, suggesting an indoor setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24551.5, "ram_available_mb": 38289.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24581.2, "ram_available_mb": 38259.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.075, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 8.922}, "timestamp": "2026-01-23T08:33:07.740938"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11309.702, "latencies_ms": [11309.702], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a woman is walking through a large glass door in a building. She is wearing a black coat and carrying a suitcase, suggesting she might be traveling or commuting. The woman is walking towards the right side of the image, and the glass door is open, allowing her to pass through.\n\nThere are several other people in the scene, some of whom are", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24581.2, "ram_available_mb": 38259.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.635, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T08:33:21.086661"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9834.377, "latencies_ms": [9834.377], "images_per_second": 0.102, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "- Glass doors: 1\n\n- Suitcase: 1\n\n- Person: 1\n\n- Stairs: 1\n\n- Signage: 1\n\n- Tiles: 1\n\n- Floor: 1\n\n- Pipes: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.407, "power_cpu_cv_mean_watts": 1.814, "power_sys_5v0_mean_watts": 8.831}, "timestamp": "2026-01-23T08:33:32.933693"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9322.844, "latencies_ms": [9322.844], "images_per_second": 0.107, "prompt_tokens": 44, "response_tokens_est": 61, "n_tiles": 16, "output_text": "A person is walking in the foreground, carrying a suitcase, towards the left side of the image, while the background features a staircase and various signs overhead. The person is near the left edge of the image, and the staircase is further back, towards the right side.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24532.1, "ram_available_mb": 38308.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.478, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 8.877}, "timestamp": "2026-01-23T08:33:44.317273"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6969.335, "latencies_ms": [6969.335], "images_per_second": 0.143, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "A person is seen walking through a glass door in a modern building, carrying a suitcase. The interior appears to be a public transportation station with escalators and directional signs.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24532.1, "ram_available_mb": 38308.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24533.6, "ram_available_mb": 38307.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.383, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T08:33:53.303786"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9322.381, "latencies_ms": [9322.381], "images_per_second": 0.107, "prompt_tokens": 36, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The image shows a person in a black outfit with a hat, carrying a large black suitcase, walking through a glass door. The environment appears to be an indoor setting with a modern design, featuring a tiled floor, metal pillars, and a staircase in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.6, "ram_available_mb": 38307.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.468, "power_cpu_cv_mean_watts": 1.83, "power_sys_5v0_mean_watts": 8.901}, "timestamp": "2026-01-23T08:34:04.641256"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11333.619, "latencies_ms": [11333.619], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a dining table with two pizzas placed on it. One pizza is located towards the left side of the table, while the other is positioned more towards the center. There are also two cups on the table, one near the left pizza and the other near the right pizza. \n\nIn the background, there is a person sitting at the table", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.605, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T08:34:18.021961"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7896.955, "latencies_ms": [7896.955], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "pizza: 2\nglass: 3\nbox: 2\nfork: 2\nknife: 2\npizza box: 2\npizza: 2\npizza: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24540.5, "ram_available_mb": 38300.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.508, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T08:34:27.958005"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11363.672, "latencies_ms": [11363.672], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a large pizza on a white box with the word 'PIZZA' printed on it, positioned on the left side of the image. In the background, there is a smaller pizza on a similar white box, also with 'PIZZA' printed on it, placed towards the right side of the image. A person is seated", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.5, "ram_available_mb": 38300.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24540.5, "ram_available_mb": 38300.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.762, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T08:34:41.359323"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8272.63, "latencies_ms": [8272.63], "images_per_second": 0.121, "prompt_tokens": 37, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image shows a dining table with two pizza boxes, one of which is open, and a glass of a dark-colored beverage. There is a person sitting at the table, and a television is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.5, "ram_available_mb": 38300.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24538.0, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.221, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 8.825}, "timestamp": "2026-01-23T08:34:51.668996"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8887.369, "latencies_ms": [8887.369], "images_per_second": 0.113, "prompt_tokens": 36, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image shows a cozy indoor setting with a focus on a pizza in a box, suggesting a casual dining atmosphere. The lighting is warm and artificial, likely from an indoor source, and the table is covered with a plaid tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.0, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 24543.0, "ram_available_mb": 38297.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.753, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T08:35:02.615657"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11436.488, "latencies_ms": [11436.488], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a young boy in a baseball uniform, holding a baseball bat and standing at home plate, ready to swing. He is wearing a helmet and is surrounded by a group of people, including other children and adults, who are watching the game. The boy is in the center of attention, and the onlookers are spread out around him, some closer to the field and", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24543.0, "ram_available_mb": 38297.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 24556.7, "ram_available_mb": 38284.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.394, "power_cpu_cv_mean_watts": 2.378, "power_sys_5v0_mean_watts": 8.814}, "timestamp": "2026-01-23T08:35:16.111808"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9260.477, "latencies_ms": [9260.477], "images_per_second": 0.108, "prompt_tokens": 39, "response_tokens_est": 59, "n_tiles": 16, "output_text": "- children: 10\n- adults: 5\n- baseball bats: 2\n- baseball gloves: 2\n- helmets: 2\n- baseball uniforms: 2\n- benches: 1\n- trees: 4", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24556.7, "ram_available_mb": 38284.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24558.7, "ram_available_mb": 38282.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.676, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T08:35:27.399356"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11386.679, "latencies_ms": [11386.679], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a young baseball player is standing on a dirt path, holding a baseball bat and wearing a helmet, ready to swing. Behind him, another player is crouched down, wearing a catcher's mitt, positioned to catch the ball. In the background, a group of spectators is seated on the grass, watching the game unfold", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24558.7, "ram_available_mb": 38282.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.683, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T08:35:40.810294"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10504.649, "latencies_ms": [10504.649], "images_per_second": 0.095, "prompt_tokens": 37, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The image depicts a baseball game in progress with a young boy in a white shirt and gray pants at bat, wearing a black helmet, and a catcher in a red shirt and black pants crouched behind him. Spectators are seated on the grassy field, watching the game intently.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24556.7, "ram_available_mb": 38284.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.083, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T08:35:53.328940"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8524.085, "latencies_ms": [8524.085], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image shows a sunny day with clear skies, as evidenced by the bright lighting and shadows cast on the ground. The players are wearing helmets and catcher's gear, indicating a baseball game is in progress.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.7, "ram_available_mb": 38284.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.732, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 8.905}, "timestamp": "2026-01-23T08:36:03.863354"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11379.463, "latencies_ms": [11379.463], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the center of the image, a yellow banana is resting on a black corded telephone, which is placed on a white desk. The banana is positioned in such a way that it appears to be leaning against the telephone. The desk is also home to a white computer monitor and a white printer, both of which are situated in the background. The tele", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24548.1, "ram_available_mb": 38292.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.55, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.808}, "timestamp": "2026-01-23T08:36:17.284490"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7493.291, "latencies_ms": [7493.291], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "phone: 1\nbanana: 1\ncord: 1\nnumbers: 1\ncalculator: 1\npen: 1\nnotepad: 1\npencil: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.1, "ram_available_mb": 38292.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24554.2, "ram_available_mb": 38286.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.83, "power_cpu_cv_mean_watts": 1.633, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T08:36:26.800553"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11347.363, "latencies_ms": [11347.363], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a banana with a black cord wrapped around it, positioned near a Philips telephone. The banana is closer to the viewer than the telephone. In the background, there is a white telephone and a white electrical outlet on a wall. The banana is in the foreground, while the telephone and outlet are further", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24554.2, "ram_available_mb": 38286.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24545.5, "ram_available_mb": 38295.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.602, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T08:36:40.182408"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8310.078, "latencies_ms": [8310.078], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "A banana is placed on top of a Philips telephone, which is on a desk with a white surface. The telephone has a corded handset and a small screen, and there is a white computer tower in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.5, "ram_available_mb": 38295.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24547.1, "ram_available_mb": 38293.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.088, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T08:36:50.515334"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8277.225, "latencies_ms": [8277.225], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "A ripe banana is placed on top of a black corded phone, which is situated on a white desk. The desk also holds a white telephone and a small white object that appears to be a piece of paper or a label.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24547.1, "ram_available_mb": 38293.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.994, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 8.881}, "timestamp": "2026-01-23T08:37:00.818332"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11410.258, "latencies_ms": [11410.258], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a lively scene of a crowd of people gathered in what appears to be a public space, possibly a park or a street. The focus is on a woman in the center holding a large teddy bear, which stands out due to its size and the contrasting color of her outfit. The crowd is diverse, with individuals of various ages and styles, some wearing back", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.443, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T08:37:14.272081"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4535.317, "latencies_ms": [4535.317], "images_per_second": 0.22, "prompt_tokens": 39, "response_tokens_est": 18, "n_tiles": 16, "output_text": "people: numerous\nbear: 1\nbackpacks: 2\n", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 24538.4, "ram_available_mb": 38302.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.335, "power_cpu_cv_mean_watts": 1.138, "power_sys_5v0_mean_watts": 9.062}, "timestamp": "2026-01-23T08:37:20.833676"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11302.702, "latencies_ms": [11302.702], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a person holding a large teddy bear, positioned near the center of the image. To the left of this person, there is a group of individuals standing close together, possibly engaged in conversation. In the background, there is a bus stop with a sign that reads \"Tomato station,\" and beyond that, there are more people scattered around, some standing and", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.4, "ram_available_mb": 38302.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24542.7, "ram_available_mb": 38298.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.703, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.881}, "timestamp": "2026-01-23T08:37:34.153080"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10815.487, "latencies_ms": [10815.487], "images_per_second": 0.092, "prompt_tokens": 37, "response_tokens_est": 73, "n_tiles": 16, "output_text": "The image depicts a bustling outdoor scene with a large crowd of people, some of whom are carrying backpacks and one person is holding a teddy bear. The setting appears to be a public event or gathering, possibly in a park or open space, as suggested by the presence of trees and a bus stop in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24542.7, "ram_available_mb": 38298.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.85, "power_cpu_cv_mean_watts": 1.884, "power_sys_5v0_mean_watts": 8.823}, "timestamp": "2026-01-23T08:37:47.003381"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8824.993, "latencies_ms": [8824.993], "images_per_second": 0.113, "prompt_tokens": 36, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image is taken on a bright and sunny day, with natural light illuminating the scene. The crowd is diverse, with people wearing a variety of colors, and the environment appears to be an outdoor public space with trees and a clear sky in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.641, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 8.898}, "timestamp": "2026-01-23T08:37:57.854280"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11353.556, "latencies_ms": [11353.556], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is holding a baby in his arms while standing next to a brown horse. The man is wearing a red shirt and is smiling as he interacts with the horse. The baby is also smiling, enjoying the experience. The scene takes place in a stable or barn, with a stone wall visible in the background. The man and the baby are", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24551.2, "ram_available_mb": 38289.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.427, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T08:38:11.238415"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9679.256, "latencies_ms": [9679.256], "images_per_second": 0.103, "prompt_tokens": 39, "response_tokens_est": 63, "n_tiles": 16, "output_text": "1. Man: 1\n2. Child: 1\n3. Horse: 1\n4. Fence: 1\n5. Door: 1\n6. Straw: 1\n7. Grass: 1\n8. Trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.2, "ram_available_mb": 38289.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.473, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T08:38:22.979418"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11394.99, "latencies_ms": [11394.99], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a man in a red shirt is holding a baby in his arms, positioned near the center of the image. The baby is facing the horse, which is in the background, and appears to be sniffing the baby's hand. The man and baby are standing on a porch with a tiled floor, and there is a stone wall to the left", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24533.4, "ram_available_mb": 38307.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.681, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T08:38:36.409328"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7993.075, "latencies_ms": [7993.075], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "A man is holding a baby while standing next to a brown horse, which is sniffing the baby's hand. They appear to be in a stable or barn with a stone wall and a wooden door in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24533.4, "ram_available_mb": 38307.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24539.6, "ram_available_mb": 38301.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.436, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T08:38:46.435921"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7494.205, "latencies_ms": [7494.205], "images_per_second": 0.133, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image features a man in a red shirt holding a child, with a brown horse standing close to them. The setting appears to be outdoors, with natural lighting and a stone wall in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24539.6, "ram_available_mb": 38301.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.602, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 8.951}, "timestamp": "2026-01-23T08:38:55.951085"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11319.071, "latencies_ms": [11319.071], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of tranquility, featuring a single banana resting on a white plate with a gold rim. The banana, curved in a gentle arc, is positioned on the right side of the plate. On the left side of the plate, there's a small amount of pinkish-brown sauce, adding a touch of color to the", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24529.2, "ram_available_mb": 38311.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.589, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T08:39:09.327795"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4218.914, "latencies_ms": [4218.914], "images_per_second": 0.237, "prompt_tokens": 39, "response_tokens_est": 15, "n_tiles": 16, "output_text": "banana: 1, peanut butter: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24529.2, "ram_available_mb": 38311.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.32, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 9.085}, "timestamp": "2026-01-23T08:39:15.583144"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9827.487, "latencies_ms": [9827.487], "images_per_second": 0.102, "prompt_tokens": 44, "response_tokens_est": 65, "n_tiles": 16, "output_text": "The banana is positioned in the foreground on the left side of the plate, which is placed on a wooden surface. The peanut butter is in the center of the plate, creating a contrast between the smooth texture of the banana and the creamy texture of the peanut butter.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 24555.9, "ram_available_mb": 38285.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.254, "power_cpu_cv_mean_watts": 2.301, "power_sys_5v0_mean_watts": 8.892}, "timestamp": "2026-01-23T08:39:27.421890"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10482.615, "latencies_ms": [10482.615], "images_per_second": 0.095, "prompt_tokens": 37, "response_tokens_est": 69, "n_tiles": 16, "output_text": "A single banana is placed on a white plate with a brown rim, and there is a small amount of pink substance, possibly a spread or jam, in the center of the plate. The plate is on a wooden surface, and the setting appears to be casual, possibly for a snack or a light meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.9, "ram_available_mb": 38285.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 24546.2, "ram_available_mb": 38294.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.079, "power_cpu_cv_mean_watts": 1.916, "power_sys_5v0_mean_watts": 8.815}, "timestamp": "2026-01-23T08:39:39.931555"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11357.812, "latencies_ms": [11357.812], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image shows a banana placed on a plate with a pink substance in the center. The plate has a white base with a brown rim, and the banana is positioned in such a way that it appears to be peeling or sliced. The lighting in the image is warm, suggesting it may have been taken indoors with artificial light. The material of the", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.2, "ram_available_mb": 38294.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24552.3, "ram_available_mb": 38288.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.754, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T08:39:53.309727"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11313.587, "latencies_ms": [11313.587], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is kneeling down and working on a motorcycle tire. He is using a wrench to loosen the lug nuts on the tire, which is a crucial step in changing a tire. The man appears to be focused on his task, ensuring that the lug nuts are properly removed.\n\nThe motorcycle is parked on a", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24552.3, "ram_available_mb": 38288.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24551.3, "ram_available_mb": 38289.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.663, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T08:40:06.670673"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9574.591, "latencies_ms": [9574.591], "images_per_second": 0.104, "prompt_tokens": 39, "response_tokens_est": 62, "n_tiles": 16, "output_text": "- Man: 1\n\n- Bike: 2\n\n- Wheel: 2\n\n- Tool: 1\n\n- Ground: 1\n\n- Basket: 1\n\n- Bicycle: 1\n\n- Basket: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.3, "ram_available_mb": 38289.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24549.6, "ram_available_mb": 38291.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.587, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 8.834}, "timestamp": "2026-01-23T08:40:18.262436"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11330.46, "latencies_ms": [11330.46], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a man is kneeling on the ground, working on a motorcycle wheel. The motorcycle is positioned to the left of the image, with its front wheel visible and the rear wheel partially obscured by another motorcycle in the background. The man is focused on the wheel, which is in the center of the image, and there is a tire iron in his", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.6, "ram_available_mb": 38291.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.628, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T08:40:31.628588"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7399.395, "latencies_ms": [7399.395], "images_per_second": 0.135, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "A man is repairing a motorcycle tire in an outdoor setting, possibly a garage or workshop. He is kneeling on the ground and using a tool to work on the tire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24552.7, "ram_available_mb": 38288.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.657, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T08:40:41.054777"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11292.504, "latencies_ms": [11292.504], "images_per_second": 0.089, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "A man in a green shirt and blue pants is working on a motorcycle wheel. The motorcycle is blue with colorful decals on the side. The man is using a tool to work on the wheel, which is resting on a metal stand. The background shows a tiled floor and a bicycle. The weather appears to be overcast, as the lighting", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.7, "ram_available_mb": 38288.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.615, "power_cpu_cv_mean_watts": 1.957, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T08:40:54.386654"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11314.298, "latencies_ms": [11314.298], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a skateboarder is captured in the midst of performing a trick on a ramp. The skateboarder, dressed in a black t-shirt and black pants, is balancing on one foot on the skateboard while the other foot is lifted off the board. The skateboard, which is brown with a white logo on it, is position", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24542.3, "ram_available_mb": 38298.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.603, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T08:41:07.736017"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10478.132, "latencies_ms": [10478.132], "images_per_second": 0.095, "prompt_tokens": 39, "response_tokens_est": 70, "n_tiles": 16, "output_text": "- Skateboard: 1\n\n- Skate park ramp: 1\n\n- Fence: 1\n\n- Tree: 1\n\n- Grass: 1\n\n- Skateboarder: 1\n\n- Wristband: 1\n\n- Wristband: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.3, "ram_available_mb": 38298.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24542.4, "ram_available_mb": 38298.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.098, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T08:41:20.257077"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10840.223, "latencies_ms": [10840.223], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 74, "n_tiles": 16, "output_text": "The skateboarder is in the foreground, performing a trick on a ramp. In the background, there is a fence and some greenery, indicating the skate park is likely outdoors. The skateboarder is near the edge of the ramp, suggesting they are in the process of grinding or sliding down it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24542.4, "ram_available_mb": 38298.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24539.6, "ram_available_mb": 38301.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.822, "power_cpu_cv_mean_watts": 1.907, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T08:41:33.156596"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6627.74, "latencies_ms": [6627.74], "images_per_second": 0.151, "prompt_tokens": 37, "response_tokens_est": 36, "n_tiles": 16, "output_text": "A skateboarder with long hair is performing a trick on a ramp in a park. The background shows a fence and trees, indicating an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.6, "ram_available_mb": 38301.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.589, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T08:41:41.826788"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9294.367, "latencies_ms": [9294.367], "images_per_second": 0.108, "prompt_tokens": 36, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The skateboarder is wearing a black t-shirt and black pants, and the skateboard is a mix of colors with a prominent red and white design. The lighting is natural, suggesting it is daytime, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.411, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T08:41:53.137640"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11311.3, "latencies_ms": [11311.3], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of four men standing in a grassy field, each holding a frisbee. They are posing for a picture, with the frisbees in their hands, showcasing their shared interest in the sport. The men are standing close to each other, creating a sense of camaraderie and enjoyment. The field appears to be a perfect setting", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24533.6, "ram_available_mb": 38307.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.707, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T08:42:06.496970"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10596.979, "latencies_ms": [10596.979], "images_per_second": 0.094, "prompt_tokens": 39, "response_tokens_est": 71, "n_tiles": 16, "output_text": "1. Frisbee: 4\n2. People: 4\n3. Grass: 1 (field)\n4. Sky: 1\n5. Trees: 1 (in background)\n6. Clouds: 0\n7. Sun: 0\n8. Clouds: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.6, "ram_available_mb": 38307.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24545.3, "ram_available_mb": 38295.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.109, "power_cpu_cv_mean_watts": 1.861, "power_sys_5v0_mean_watts": 8.813}, "timestamp": "2026-01-23T08:42:19.118595"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10869.382, "latencies_ms": [10869.382], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "In the foreground, there are four individuals standing on a grassy field, each holding a frisbee. The person on the far left is standing with their back to the camera, while the others are facing the camera. In the background, there are two tall poles, one on the right side and one on the far right side of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24545.3, "ram_available_mb": 38295.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24534.2, "ram_available_mb": 38306.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.88, "power_cpu_cv_mean_watts": 1.907, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T08:42:32.004306"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7392.396, "latencies_ms": [7392.396], "images_per_second": 0.135, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "Four people are standing in a grassy field holding frisbees, likely preparing to play a game of frisbee. The sky is clear and it appears to be a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.2, "ram_available_mb": 38306.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24533.4, "ram_available_mb": 38307.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.906, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.907}, "timestamp": "2026-01-23T08:42:41.422981"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9180.424, "latencies_ms": [9180.424], "images_per_second": 0.109, "prompt_tokens": 36, "response_tokens_est": 60, "n_tiles": 16, "output_text": "The image shows a group of people in a field during what appears to be either sunrise or sunset, given the warm lighting and long shadows. They are wearing casual clothing and are holding frisbees, suggesting they are enjoying a recreational activity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.4, "ram_available_mb": 38307.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.4, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T08:42:52.624983"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11366.796, "latencies_ms": [11366.796], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a large white airplane with a red tail parked on the tarmac at an airport. The airplane is surrounded by several people, who are likely airport staff or passengers. There are also a few trucks and a car visible in the scene, possibly providing support services for the airplane.\n\nIn addition to the airplane and the people, there", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.5, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T08:43:06.020908"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9028.575, "latencies_ms": [9028.575], "images_per_second": 0.111, "prompt_tokens": 39, "response_tokens_est": 57, "n_tiles": 16, "output_text": "- Airplane: 1\n- Windows: 100+\n- People: 5\n- Carts: 2\n- Trees: 1\n- Building: 1\n- Clouds: 10+\n- Sign: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24524.6, "ram_available_mb": 38316.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.799, "power_cpu_cv_mean_watts": 1.763, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T08:43:17.075496"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11241.237, "latencies_ms": [11241.237], "images_per_second": 0.089, "prompt_tokens": 44, "response_tokens_est": 78, "n_tiles": 16, "output_text": "The airplane is parked on the tarmac in the foreground of the image, with the ground crew working around it. In the background, there is a clear blue sky with some clouds, and a building can be seen on the right side of the image. The airplane is positioned near the center of the image, with the ground crew and equipment surrounding it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24524.6, "ram_available_mb": 38316.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 24541.1, "ram_available_mb": 38299.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.67, "power_cpu_cv_mean_watts": 2.157, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T08:43:30.345433"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8164.049, "latencies_ms": [8164.049], "images_per_second": 0.122, "prompt_tokens": 37, "response_tokens_est": 50, "n_tiles": 16, "output_text": "A JAL airplane is parked on the tarmac at an airport, with ground crew members attending to it. The sky is blue with some clouds, and there are other airplanes and buildings visible in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.1, "ram_available_mb": 38299.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 24551.0, "ram_available_mb": 38289.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.364, "power_cpu_cv_mean_watts": 2.165, "power_sys_5v0_mean_watts": 8.909}, "timestamp": "2026-01-23T08:43:40.538517"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6863.138, "latencies_ms": [6863.138], "images_per_second": 0.146, "prompt_tokens": 36, "response_tokens_est": 40, "n_tiles": 16, "output_text": "The image features a large commercial airplane with a white body and a red tail, parked on the tarmac. The sky is blue with scattered white clouds, indicating fair weather conditions.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 24551.0, "ram_available_mb": 38289.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24548.7, "ram_available_mb": 38292.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.84, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 8.974}, "timestamp": "2026-01-23T08:43:49.450797"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11353.349, "latencies_ms": [11353.349], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young man is skillfully riding a skateboard on a cement ledge in a park. He is performing a trick, possibly a grind, as he balances on the edge of the ledge. The skateboarder is wearing a yellow shirt and is the main focus of the scene.\n\nThe park is filled with various benches", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24548.7, "ram_available_mb": 38292.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.599, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T08:44:02.831458"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9349.745, "latencies_ms": [9349.745], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 60, "n_tiles": 16, "output_text": "- Bench: 2\n- Trash can: 1\n- Skateboard: 1\n- Skateboarder: 1\n- Graffiti: 1\n- Park: 1\n- Trees: 1\n- Fence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24548.3, "ram_available_mb": 38292.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.466, "power_cpu_cv_mean_watts": 1.805, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T08:44:14.235865"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11352.439, "latencies_ms": [11352.439], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the foreground, a skateboarder is performing a trick on a concrete ledge. The ledge is located near the center of the image and is surrounded by a grassy area with a trash can and a bench in the background. There is a fence and a tree further back, and a person walking on the sidewalk can be seen in the distance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24548.3, "ram_available_mb": 38292.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.582, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T08:44:27.628622"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6805.614, "latencies_ms": [6805.614], "images_per_second": 0.147, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A person is skateboarding on a concrete ledge in a park. The ledge has graffiti on it and there are benches and a trash can nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.314, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 8.937}, "timestamp": "2026-01-23T08:44:36.447363"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6486.141, "latencies_ms": [6486.141], "images_per_second": 0.154, "prompt_tokens": 36, "response_tokens_est": 37, "n_tiles": 16, "output_text": "The image shows a person skateboarding on a concrete ledge with graffiti on it. The weather appears to be sunny with shadows cast on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.36, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.995}, "timestamp": "2026-01-23T08:44:44.954309"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11337.123, "latencies_ms": [11337.123], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of indulgence, featuring a single slice of chocolate tart resting on a white plate adorned with gold floral patterns. The tart, with its rich, dark chocolate filling, is topped with a glossy chocolate glaze that is artistically drizzled in a zigzag pattern. The glaze's", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24542.9, "ram_available_mb": 38298.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.555, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T08:44:58.352539"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10776.915, "latencies_ms": [10776.915], "images_per_second": 0.093, "prompt_tokens": 39, "response_tokens_est": 73, "n_tiles": 16, "output_text": "plate: 1, slice of cake: 1, caramel sauce: 1, drizzle of caramel sauce: 1, chocolate drizzle: 1, chocolate shavings: 1, chocolate cake: 1, decorative pattern on plate: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24542.9, "ram_available_mb": 38298.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.118, "power_cpu_cv_mean_watts": 1.886, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T08:45:11.147842"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11346.813, "latencies_ms": [11346.813], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The slice of chocolate pie is positioned in the foreground, appearing large and in focus. It is placed on the left side of the plate, which is adorned with a floral pattern. The caramel sauce is drizzled around the pie, with some of it pooling near the base of the slice, indicating it is on the right side of the pie", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24542.8, "ram_available_mb": 38298.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.656, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T08:45:24.509065"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6368.265, "latencies_ms": [6368.265], "images_per_second": 0.157, "prompt_tokens": 37, "response_tokens_est": 34, "n_tiles": 16, "output_text": "A slice of chocolate tart with a caramel drizzle is placed on a white plate with gold floral patterns, set on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.8, "ram_available_mb": 38298.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24529.6, "ram_available_mb": 38311.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.633, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 8.925}, "timestamp": "2026-01-23T08:45:32.919640"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9504.86, "latencies_ms": [9504.86], "images_per_second": 0.105, "prompt_tokens": 36, "response_tokens_est": 63, "n_tiles": 16, "output_text": "The image features a slice of chocolate tart on a white plate with a gold floral pattern around the edge. The tart has a glossy chocolate glaze on top with a pattern of white lines, and there is a drizzle of caramel sauce on the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24529.6, "ram_available_mb": 38311.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24533.8, "ram_available_mb": 38307.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.248, "power_cpu_cv_mean_watts": 1.854, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T08:45:44.456668"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11316.182, "latencies_ms": [11316.182], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image depicts a busy office environment with several people working on their laptops. There are at least four people visible in the scene, with one man sitting at a desk in the foreground, and three others working in the background. The office is filled with desks and chairs, and there are multiple laptops on the tables.\n\nIn addition to the la", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 24533.8, "ram_available_mb": 38307.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24582.0, "ram_available_mb": 38258.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.62, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T08:45:57.809321"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10831.015, "latencies_ms": [10831.015], "images_per_second": 0.092, "prompt_tokens": 39, "response_tokens_est": 73, "n_tiles": 16, "output_text": "- Laptops: 3\n\n- Chairs: 5\n\n- Desks: 3\n\n- Papers: numerous, exact count unspecified\n\n- Boxes: 1\n\n- Cables: numerous, exact count unspecified\n\n- Computers: 2\n\n- People: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24582.0, "ram_available_mb": 38258.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.952, "power_cpu_cv_mean_watts": 1.871, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T08:46:10.699399"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11318.124, "latencies_ms": [11318.124], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a man sitting at a desk with a laptop in front of him, and another laptop is on the desk to his left. In the background, there are several other people working at desks with computers, some of which are in the middle ground, while others are further back. The room appears to be a busy workspace with multiple workstations.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24586.9, "ram_available_mb": 38254.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.681, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T08:46:24.031180"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8028.15, "latencies_ms": [8028.15], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image depicts a busy office environment with multiple individuals working on laptops and other electronic devices. There are several desks and chairs arranged in the room, with people sitting and standing around, engaged in their tasks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24586.9, "ram_available_mb": 38254.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24541.4, "ram_available_mb": 38299.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.103, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T08:46:34.094232"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8016.274, "latencies_ms": [8016.274], "images_per_second": 0.125, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image shows an indoor setting with a yellowish light, possibly from fluorescent lights, illuminating the room. Various materials such as cardboard boxes, electronic devices, and papers are scattered across the tables and desks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.4, "ram_available_mb": 38299.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24547.0, "ram_available_mb": 38293.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.036, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 8.924}, "timestamp": "2026-01-23T08:46:44.152795"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11341.161, "latencies_ms": [11341.161], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of people gathered in a living room, playing a video game using Wii controllers. There are three men and a woman standing in the room, all holding Wii remotes and actively participating in the game. The room is furnished with a couch, a dining table, and a chair.\n\nOn the dining table, there are two bott", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24547.0, "ram_available_mb": 38293.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.653, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T08:46:57.538104"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7739.503, "latencies_ms": [7739.503], "images_per_second": 0.129, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "person: 4\nwii controller: 2\ncouch: 1\nbottles: 2\nframes: 2\nbasket: 1\ntable: 1\ndoor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24535.4, "ram_available_mb": 38305.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.659, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T08:47:07.304412"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11342.571, "latencies_ms": [11342.571], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a woman in a white dress is standing and facing a man in a striped shirt who is also standing. In the background, two more men are standing near a couch and a window with blinds. The room appears to be a living space with a wooden table, a bottle, and a picture frame on the table, and a basket on the floor.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24535.4, "ram_available_mb": 38305.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24530.9, "ram_available_mb": 38310.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.621, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T08:47:20.682162"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9949.609, "latencies_ms": [9949.609], "images_per_second": 0.101, "prompt_tokens": 37, "response_tokens_est": 65, "n_tiles": 16, "output_text": "In a cozy living room, a group of people are gathered to play a video game using Wii controllers. The room is furnished with a couch, a wooden table, and a few bottles on the table, creating a casual and relaxed atmosphere for the group to enjoy their gaming session.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24530.9, "ram_available_mb": 38310.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24535.6, "ram_available_mb": 38305.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.154, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 8.812}, "timestamp": "2026-01-23T08:47:32.649995"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6548.719, "latencies_ms": [6548.719], "images_per_second": 0.153, "prompt_tokens": 36, "response_tokens_est": 37, "n_tiles": 16, "output_text": "The room is dimly lit with natural light coming from the window with blinds. The walls are painted in a light color, and the carpet is a neutral shade.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24535.6, "ram_available_mb": 38305.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 24540.9, "ram_available_mb": 38300.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.203, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 8.977}, "timestamp": "2026-01-23T08:47:41.241877"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11369.37, "latencies_ms": [11369.37], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene beach scene at sunset. A person is standing on the wet sand, facing the ocean. The sun is setting in the background, casting a warm glow over the scene. The sky is a gradient of blue and orange hues, indicating the time of day. The ocean is calm with gentle waves lapping at the shore. The person appears to be looking", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 24540.9, "ram_available_mb": 38300.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 24540.8, "ram_available_mb": 38300.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.533, "power_cpu_cv_mean_watts": 2.391, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T08:47:54.651903"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7184.027, "latencies_ms": [7184.027], "images_per_second": 0.139, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "person: 1, sun: 1, frisbee: 1, waves: numerous, sand: extensive, horizon: 1, sky: 1, reflection: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24540.8, "ram_available_mb": 38300.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.892, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.904}, "timestamp": "2026-01-23T08:48:03.857184"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11332.931, "latencies_ms": [11332.931], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a person standing on a wet surface, likely the beach, with the sun low on the horizon directly behind them, creating a silhouette effect. The person is positioned near the center of the image, with the sun appearing in the background slightly to the right. The waves on the beach are in the middle ground, extending from the left to the right side", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24542.4, "ram_available_mb": 38298.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.62, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T08:48:17.226838"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6147.954, "latencies_ms": [6147.954], "images_per_second": 0.163, "prompt_tokens": 37, "response_tokens_est": 32, "n_tiles": 16, "output_text": "A person is standing on a beach, looking at the sunset. The sun is setting over the horizon, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24542.4, "ram_available_mb": 38298.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24540.7, "ram_available_mb": 38300.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.165, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.949}, "timestamp": "2026-01-23T08:48:25.398588"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9813.433, "latencies_ms": [9813.433], "images_per_second": 0.102, "prompt_tokens": 36, "response_tokens_est": 66, "n_tiles": 16, "output_text": "The image captures a serene beach scene at sunset with the sun casting a warm orange glow across the sky and reflecting off the wet sand. A person is silhouetted against the bright horizon, standing on the beach with a frisbee in hand, suggesting a leisurely activity.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24540.7, "ram_available_mb": 38300.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24538.8, "ram_available_mb": 38302.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.149, "power_cpu_cv_mean_watts": 1.878, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T08:48:37.272113"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11311.922, "latencies_ms": [11311.922], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a spacious living room with a variety of furniture and decorations. There is a white couch positioned against the wall, accompanied by a dining table with four chairs around it. The chairs are arranged in a semi-circle, creating a cozy and inviting atmosphere. \n\nIn the room, there are two potted plants, one placed", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24538.8, "ram_available_mb": 38302.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.695, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T08:48:50.657579"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8521.65, "latencies_ms": [8521.65], "images_per_second": 0.117, "prompt_tokens": 39, "response_tokens_est": 53, "n_tiles": 16, "output_text": "- Chair: 2\n- Table: 1\n- Sofa: 1\n- Rug: 1\n- Plant: 2\n- Television: 1\n- Screen: 1\n- Coffee table: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.06, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T08:49:01.214851"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11327.687, "latencies_ms": [11327.687], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a white table with a vase of flowers on it, positioned near the center of the image. To the left of the table, there is a red chair, and to the right, there is a white couch. In the background, there is a black and white patterned rug on the floor, and behind the couch, there is a window", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.656, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T08:49:14.579484"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8645.689, "latencies_ms": [8645.689], "images_per_second": 0.116, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image depicts a cozy living room with a white sofa, a red chair, and a white coffee table. There is a flat-screen TV mounted on the wall, and the room is decorated with various artworks and decorative items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.915, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T08:49:25.270149"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6658.885, "latencies_ms": [6658.885], "images_per_second": 0.15, "prompt_tokens": 36, "response_tokens_est": 38, "n_tiles": 16, "output_text": "The living room is bright and airy with natural light coming in from the large windows. The furniture is modern and colorful, with red chairs and a white coffee table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24538.2, "ram_available_mb": 38302.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.092, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.954}, "timestamp": "2026-01-23T08:49:33.982675"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11345.45, "latencies_ms": [11345.45], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the heart of a cozy kitchen, a curious feline companion has found an elevated perch on top of a blue refrigerator. The cat, adorned with a vibrant blue collar, gazes intently towards the left side of the image, its eyes reflecting a sense of curiosity and alertness. The refrigerator, a pristine", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 24538.2, "ram_available_mb": 38302.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24536.5, "ram_available_mb": 38304.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.614, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.826}, "timestamp": "2026-01-23T08:49:47.363578"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8065.263, "latencies_ms": [8065.263], "images_per_second": 0.124, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "refrigerator: 2, cat: 1, light fixture: 1, cabinet: 1, drawer: 1, bracelet: 1, keychain: 1, key: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.5, "ram_available_mb": 38304.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24548.6, "ram_available_mb": 38292.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.49, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T08:49:57.489466"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11333.202, "latencies_ms": [11333.202], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a white refrigerator on the left side of the image, and a blue refrigerator on the right side. The cat is positioned on top of the blue refrigerator, near the top right corner of the image. The light source is coming from the top right corner, casting a shadow on the left side of the white refr", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24548.6, "ram_available_mb": 38292.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24543.9, "ram_available_mb": 38297.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.619, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.841}, "timestamp": "2026-01-23T08:50:10.838493"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7739.729, "latencies_ms": [7739.729], "images_per_second": 0.129, "prompt_tokens": 37, "response_tokens_est": 46, "n_tiles": 16, "output_text": "A cat is sitting on top of a blue refrigerator, looking curiously to the side. The refrigerator is in a kitchen, with a white cabinet and a light fixture visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.9, "ram_available_mb": 38297.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.435, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 8.877}, "timestamp": "2026-01-23T08:50:20.624919"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7322.672, "latencies_ms": [7322.672], "images_per_second": 0.137, "prompt_tokens": 36, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A cat with a striped pattern is perched on top of a blue refrigerator. The refrigerator is in a room with beige walls and a ceiling with a light fixture.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24537.9, "ram_available_mb": 38303.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.56, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 8.948}, "timestamp": "2026-01-23T08:50:29.965568"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11323.008, "latencies_ms": [11323.008], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image depicts a small, cluttered living room with a wooden floor. The room is filled with various items, including a refrigerator on the left side, a TV in the center, and a bookshelf on the right side. There are multiple balloons scattered throughout the room, with some hanging from the ceiling and others placed on the floor. ", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24537.9, "ram_available_mb": 38303.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24542.2, "ram_available_mb": 38298.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.599, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T08:50:43.346780"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8846.669, "latencies_ms": [8846.669], "images_per_second": 0.113, "prompt_tokens": 39, "response_tokens_est": 56, "n_tiles": 16, "output_text": "- Balloons: 4\n- Furniture: 3\n- Electronics: 2\n- Books: 1\n- Plant: 1\n- Lamp: 1\n- Curtains: 1\n- Bed: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24542.2, "ram_available_mb": 38298.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.942, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.889}, "timestamp": "2026-01-23T08:50:54.207544"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11321.95, "latencies_ms": [11321.95], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a wooden entertainment center with a TV and various electronic devices, positioned near the center of the room. The refrigerator is on the left side of the room, and there is a bed in the background towards the right side. The room is decorated with balloons, including a smiley face balloon hanging from the ceiling", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24531.6, "ram_available_mb": 38309.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.653, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T08:51:07.582643"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7833.927, "latencies_ms": [7833.927], "images_per_second": 0.128, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The image shows a cozy and cluttered living room with a variety of objects scattered throughout the space. There are balloons, books, and other items on the shelves, and a bed in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24531.6, "ram_available_mb": 38309.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24548.3, "ram_available_mb": 38292.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.443, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T08:51:17.445569"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7678.4, "latencies_ms": [7678.4], "images_per_second": 0.13, "prompt_tokens": 36, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The room is decorated with yellow and blue balloons, and has a chandelier hanging from the ceiling. The walls are painted white, and there is a bookshelf with various items on it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24548.3, "ram_available_mb": 38292.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24546.4, "ram_available_mb": 38294.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.285, "power_cpu_cv_mean_watts": 1.7, "power_sys_5v0_mean_watts": 8.961}, "timestamp": "2026-01-23T08:51:27.143640"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11337.695, "latencies_ms": [11337.695], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is sitting on a train, engrossed in his laptop. He is wearing a green jacket and has a headset on, suggesting he might be working or studying. The laptop, which is silver in color, is placed on a gray table in front of him. The train's interior is visible in the background, with a window that offers a view", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24546.4, "ram_available_mb": 38294.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.61, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.841}, "timestamp": "2026-01-23T08:51:40.523059"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8670.037, "latencies_ms": [8670.037], "images_per_second": 0.115, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "- Man: 1\n- Computer: 1\n- Train window: 1\n- Seat: 1\n- Headphones: 1\n- Train tracks: 2\n- Train: 1\n- Train seat: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.999, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T08:51:51.224198"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11311.022, "latencies_ms": [11311.022], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The laptop is in the foreground, placed on a table that extends from the left side of the image to the right. The person is seated in the background, with their body oriented towards the laptop, indicating that the laptop is the main object of focus. The window in the background provides a sense of depth, showing a view of the outside world that is nearer than the person and", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.661, "power_cpu_cv_mean_watts": 2.369, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T08:52:04.570410"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7501.958, "latencies_ms": [7501.958], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A person is sitting on a train seat, using a laptop placed on a table in front of them. The train appears to be in motion, as the window shows a blurred view of the tracks outside.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.825, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 8.918}, "timestamp": "2026-01-23T08:52:14.111662"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4823.482, "latencies_ms": [4823.482], "images_per_second": 0.207, "prompt_tokens": 36, "response_tokens_est": 22, "n_tiles": 16, "output_text": "The laptop is silver and has a reflective surface. The man is wearing a green shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.538, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 9.077}, "timestamp": "2026-01-23T08:52:20.953811"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11332.481, "latencies_ms": [11332.481], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene day at a train station. A silver train, gleaming under the clear blue sky, is stationed on the tracks. The train is facing towards the right side of the image, ready to embark on its journey. The tracks, a symbol of connectivity and movement, are nestled amidst lush green trees, adding a touch of nature to the", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24552.8, "ram_available_mb": 38288.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.614, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T08:52:34.345122"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9335.633, "latencies_ms": [9335.633], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 60, "n_tiles": 16, "output_text": "- Train: 1\n\n- Train tracks: 2\n\n- Cars: 1\n\n- Bridge: 1\n\n- Houses: 1\n\n- Trees: 1\n\n- Clouds: 1\n\n- Sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.8, "ram_available_mb": 38288.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24549.3, "ram_available_mb": 38291.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.673, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T08:52:45.712317"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10038.046, "latencies_ms": [10038.046], "images_per_second": 0.1, "prompt_tokens": 44, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The train is in the foreground, moving along the tracks, while the bridge is in the background, spanning across the image. The road is in the foreground on the left side of the image, with the bridge connecting the two sides of the road. The town is in the far background, nestled among the hills.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24549.3, "ram_available_mb": 38291.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.113, "power_cpu_cv_mean_watts": 1.895, "power_sys_5v0_mean_watts": 8.899}, "timestamp": "2026-01-23T08:52:57.770462"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6465.473, "latencies_ms": [6465.473], "images_per_second": 0.155, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "A modern white bridge spans over a railway track, with a train passing underneath. The sky is partly cloudy, and there are buildings in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.783, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 8.942}, "timestamp": "2026-01-23T08:53:06.253129"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6875.895, "latencies_ms": [6875.895], "images_per_second": 0.145, "prompt_tokens": 36, "response_tokens_est": 40, "n_tiles": 16, "output_text": "The bridge in the image is a white suspension bridge with a clear blue sky and fluffy white clouds in the background. The train on the tracks appears to be a silver bullet train.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24555.8, "ram_available_mb": 38285.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.929, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.937}, "timestamp": "2026-01-23T08:53:15.170128"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11312.868, "latencies_ms": [11312.868], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of people gathered in a park, enjoying a day of flying kites. There are several kites of various sizes and colors, with one large kite flying in the air and others on the ground. The people are spread out across the field, with some standing closer to the kites and others further away.\n\nIn the background, there are a few cars", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24555.8, "ram_available_mb": 38285.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.675, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T08:53:28.537161"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10365.132, "latencies_ms": [10365.132], "images_per_second": 0.096, "prompt_tokens": 39, "response_tokens_est": 69, "n_tiles": 16, "output_text": "1. Kite: 1\n2. People: 10\n3. Grass: 1\n4. Chair: 1\n5. Frisbee: 0\n6. Trees: 1\n7. Soccer ball: 0\n8. Sweatshirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24540.5, "ram_available_mb": 38300.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.11, "power_cpu_cv_mean_watts": 1.861, "power_sys_5v0_mean_watts": 8.816}, "timestamp": "2026-01-23T08:53:40.956490"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10449.144, "latencies_ms": [10449.144], "images_per_second": 0.096, "prompt_tokens": 44, "response_tokens_est": 71, "n_tiles": 16, "output_text": "In the foreground, there is a vibrant kite with a butterfly design flying in the air. In the background, there are people on a grassy field, some of whom are flying kites as well. The kite in the foreground is closer to the camera, while the people in the background are further away.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24540.5, "ram_available_mb": 38300.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.931, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T08:53:53.464047"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7840.074, "latencies_ms": [7840.074], "images_per_second": 0.128, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "A group of people are gathered in a park, flying kites on a sunny day. The kites are colorful and soaring high in the sky, while some people are sitting on the grass, watching the fun.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.407, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T08:54:03.335110"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9605.621, "latencies_ms": [9605.621], "images_per_second": 0.104, "prompt_tokens": 36, "response_tokens_est": 64, "n_tiles": 16, "output_text": "The image features a vibrant kite with a combination of blue, purple, yellow, and red colors flying in the sky. The kite appears to be made of a lightweight fabric, and the weather seems to be sunny and windy, making it an ideal day for kite flying.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24543.1, "ram_available_mb": 38297.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.281, "power_cpu_cv_mean_watts": 1.839, "power_sys_5v0_mean_watts": 8.881}, "timestamp": "2026-01-23T08:54:14.955192"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11341.232, "latencies_ms": [11341.232], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a miniature model train set, meticulously crafted to resemble a real-life scenario. Dominating the scene is a vibrant red Virgin brand train, its sleek design accentuated by a white stripe running along its side. The train is in motion, traveling from the left to the right of the frame, as indicated by the bl", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24543.1, "ram_available_mb": 38297.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.621, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T08:54:28.347138"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9599.143, "latencies_ms": [9599.143], "images_per_second": 0.104, "prompt_tokens": 39, "response_tokens_est": 62, "n_tiles": 16, "output_text": "1. Virgin: 1\n2. Train: 1\n3. Workers: 5\n4. Train tracks: 4\n5. Fence: 1\n6. Bushes: 1\n7. Hill: 1\n8. Cable: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.496, "power_cpu_cv_mean_watts": 1.814, "power_sys_5v0_mean_watts": 8.831}, "timestamp": "2026-01-23T08:54:39.990618"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10185.036, "latencies_ms": [10185.036], "images_per_second": 0.098, "prompt_tokens": 44, "response_tokens_est": 69, "n_tiles": 16, "output_text": "In the foreground, there is a model train on a track with miniature figures of workers in orange uniforms standing on the tracks beside it. The train is positioned in the middle ground of the image, moving from left to right. In the background, there is a miniature landscape with a fence and some greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.112, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 8.881}, "timestamp": "2026-01-23T08:54:52.216250"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8411.631, "latencies_ms": [8411.631], "images_per_second": 0.119, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "A model train set depicts a Virgin brand train traveling on tracks with miniature workers in orange uniforms standing on the tracks beside it. The scene is set in a miniature landscape with grassy hills and a fence in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24533.0, "ram_available_mb": 38307.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.19, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T08:55:02.663467"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7224.135, "latencies_ms": [7224.135], "images_per_second": 0.138, "prompt_tokens": 36, "response_tokens_est": 43, "n_tiles": 16, "output_text": "A model train set is displayed on a track with miniature figures of workers in orange uniforms. The train is predominantly red and black with a yellow front and the Virgin branding on the side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.0, "ram_available_mb": 38307.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24541.2, "ram_available_mb": 38299.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.645, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 8.956}, "timestamp": "2026-01-23T08:55:11.923478"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11354.219, "latencies_ms": [11354.219], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a close-up view of a cat's fur, which is predominantly white with a distinct brown patch on its back. The fur appears soft and well-groomed, with a natural sheen that suggests it is healthy and well-cared for. The background is blurred, but it seems to be a textured surface, possibly a piece", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24541.2, "ram_available_mb": 38299.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24544.9, "ram_available_mb": 38296.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.577, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T08:55:25.309779"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7077.895, "latencies_ms": [7077.895], "images_per_second": 0.141, "prompt_tokens": 39, "response_tokens_est": 40, "n_tiles": 16, "output_text": "animal: 1, fur: numerous, stripes: 2, pattern: 1, background: 1, texture: 1, color: 2, direction: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.9, "ram_available_mb": 38296.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24536.4, "ram_available_mb": 38304.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.045, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T08:55:34.402670"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11410.178, "latencies_ms": [11410.178], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a close-up of an animal's fur in the foreground, with a soft, textured background that appears to be a patterned fabric, possibly a blanket or a piece of clothing. The fur is in sharp focus, while the background is out of focus, creating a sense of depth. The fur's texture and color contrast with the background, making the", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24536.4, "ram_available_mb": 38304.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24535.2, "ram_available_mb": 38305.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.597, "power_cpu_cv_mean_watts": 1.911, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T08:55:47.827429"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10952.451, "latencies_ms": [10952.451], "images_per_second": 0.091, "prompt_tokens": 37, "response_tokens_est": 74, "n_tiles": 16, "output_text": "The image shows a close-up of a cat's fur, with a blurred background that appears to be a textured fabric, possibly a blanket or a piece of clothing. The focus is on the fur, which is predominantly brown with some white patches, suggesting that the cat may have a tabby or similar coat pattern.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.2, "ram_available_mb": 38305.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24535.9, "ram_available_mb": 38305.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.911, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 8.817}, "timestamp": "2026-01-23T08:56:00.810686"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8516.869, "latencies_ms": [8516.869], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image shows a close-up of a cat's fur, which is predominantly white with dark brown patches. The fur appears soft and well-groomed, and the lighting is soft, suggesting an indoor setting with natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.9, "ram_available_mb": 38305.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 24543.5, "ram_available_mb": 38297.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.002, "power_cpu_cv_mean_watts": 2.197, "power_sys_5v0_mean_watts": 8.931}, "timestamp": "2026-01-23T08:56:11.345873"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11361.166, "latencies_ms": [11361.166], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a black and white cow is standing in a barn, with its head lowered towards the ground. The cow is positioned next to a metal gate, which is slightly ajar. The cow's head is resting on a metal pipe, which is located on the ground. The pipe is white and red in color, and it appears to be a part of a", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24543.7, "ram_available_mb": 38297.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.508, "power_cpu_cv_mean_watts": 2.254, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T08:56:24.755168"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9803.255, "latencies_ms": [9803.255], "images_per_second": 0.102, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "1. Cow: 1\n2. Feeder: 1\n3. Straw: 1\n4. Floor: 1\n5. Stick: 1\n6. Sticker: 1\n7. Sticker: 1\n8. Sticker: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.347, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 8.824}, "timestamp": "2026-01-23T08:56:36.571128"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11373.05, "latencies_ms": [11373.05], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there are two red and white objects that appear to be milking cups attached to the udder of a cow, which is positioned near the center of the image. The cow's hind legs are visible in the background, and there is a yellow tag on the cow's ear. The floor is covered with straw and hay, indicating the cow is", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.547, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.831}, "timestamp": "2026-01-23T08:56:49.960467"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8331.365, "latencies_ms": [8331.365], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "A cow is standing in a barn with its hind legs visible, and there are three red and white cylindrical objects attached to its udders. The cow is standing on a black mat with some straw and hay scattered around.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24550.5, "ram_available_mb": 38290.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.224, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 8.865}, "timestamp": "2026-01-23T08:57:00.302528"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8585.331, "latencies_ms": [8585.331], "images_per_second": 0.116, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image shows a close-up of a cow's udder with two red and white milking machines attached. The cow's fur is predominantly black with some white patches, and the environment appears to be indoors with artificial lighting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.5, "ram_available_mb": 38290.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.727, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T08:57:10.913850"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11351.86, "latencies_ms": [11351.86], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the center of the image, a sandwich with a slice taken out of it rests on a white plate with a floral pattern. The sandwich is made with two slices of white bread, and the filling is a vibrant red, suggesting it might be made of beetroot or a similar ingredient. The plate is placed on a green tablecloth, which", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.601, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.841}, "timestamp": "2026-01-23T08:57:24.298467"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8316.292, "latencies_ms": [8316.292], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "sandwich: 3\nbutter knife: 1\nplate: 1\ntablecloth: 1\ndark background: 1\nlight source: 1\nplate design: 1\nknife handle: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24560.2, "ram_available_mb": 38280.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.275, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T08:57:34.651431"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8008.964, "latencies_ms": [8008.964], "images_per_second": 0.125, "prompt_tokens": 44, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The sandwich is placed on the left side of the plate, which is in the foreground of the image. The knife is positioned on the right side of the plate, near the edge, indicating it is ready to be used.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24560.2, "ram_available_mb": 38280.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.067, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 8.935}, "timestamp": "2026-01-23T08:57:44.719061"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7034.132, "latencies_ms": [7034.132], "images_per_second": 0.142, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "A sandwich with a bite taken out of it is placed on a decorative plate with a knife beside it. The setting appears to be a table with a green tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24539.0, "ram_available_mb": 38301.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.992, "power_cpu_cv_mean_watts": 1.608, "power_sys_5v0_mean_watts": 8.916}, "timestamp": "2026-01-23T08:57:53.780094"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11322.198, "latencies_ms": [11322.198], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a sandwich with a visible filling of red berries, possibly raspberries or strawberries, nestled within a lightly toasted bread. The sandwich is placed on a plate with a delicate floral pattern, accompanied by a knife with a dark handle, all set against a dark background that contrasts with the warm tones of the food.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24539.0, "ram_available_mb": 38301.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24531.4, "ram_available_mb": 38309.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.594, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T08:58:07.137361"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11341.009, "latencies_ms": [11341.009], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a dining table with a tray containing a variety of food items. There are four different bowls on the tray, each filled with different dishes. One bowl contains a salad, another has pasta with meat and cheese, and the third bowl has carrots. The fourth bowl is filled with grapes. The arrangement of the bow", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24531.4, "ram_available_mb": 38309.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.582, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.827}, "timestamp": "2026-01-23T08:58:20.511873"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8532.504, "latencies_ms": [8532.504], "images_per_second": 0.117, "prompt_tokens": 39, "response_tokens_est": 53, "n_tiles": 16, "output_text": "salad: 1, carrots: 4, grapes: 6, pasta: 1, cheese: 1, tomato sauce: 1, meat: 1, zucchini: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24535.7, "ram_available_mb": 38305.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.005, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T08:58:31.075158"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11330.705, "latencies_ms": [11330.705], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a purple tray with four compartments, each containing different food items. The leftmost compartment has a salad with various vegetables, the second compartment contains sliced carrots, the third compartment has a pasta dish with cheese on top, and the fourth compartment contains green grapes. The background is dark", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24535.7, "ram_available_mb": 38305.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24542.2, "ram_available_mb": 38298.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.632, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T08:58:44.441319"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6818.945, "latencies_ms": [6818.945], "images_per_second": 0.147, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "The image shows a meal prep container with four different sections, each containing a different type of food. The container is placed on a dark surface, possibly a table or countertop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24542.2, "ram_available_mb": 38298.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24538.0, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.243, "power_cpu_cv_mean_watts": 1.538, "power_sys_5v0_mean_watts": 8.915}, "timestamp": "2026-01-23T08:58:53.281012"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8355.063, "latencies_ms": [8355.063], "images_per_second": 0.12, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image shows a meal prep container with vibrant colors, including a bright orange, green, and purple. The lighting appears to be artificial, likely from an indoor source, as there are no shadows or natural light indicators.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24538.0, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.864, "power_cpu_cv_mean_watts": 1.77, "power_sys_5v0_mean_watts": 8.923}, "timestamp": "2026-01-23T08:59:03.647836"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11328.885, "latencies_ms": [11328.885], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene scene of a cherry blossom tree in full bloom, its branches adorned with delicate pink flowers. The tree stands tall against a backdrop of a clear blue sky. A traffic light, painted in shades of red and white, is affixed to a pole in the foreground. The traffic light is currently displaying a red signal", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24545.8, "ram_available_mb": 38295.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.594, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T08:59:17.028039"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6414.182, "latencies_ms": [6414.182], "images_per_second": 0.156, "prompt_tokens": 39, "response_tokens_est": 34, "n_tiles": 16, "output_text": "- Trees: numerous\n- Flowers: numerous\n- Traffic lights: 2\n- Red light: 1\n- Black background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.8, "ram_available_mb": 38295.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24548.3, "ram_available_mb": 38292.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.737, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T08:59:25.461981"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9782.921, "latencies_ms": [9782.921], "images_per_second": 0.102, "prompt_tokens": 44, "response_tokens_est": 65, "n_tiles": 16, "output_text": "The traffic lights are positioned in the foreground on the left side of the image, while the cherry blossom trees cover the background and extend to the right side of the image. The trees appear to be in the near foreground, with the traffic lights being closer to the viewer than the trees.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24548.3, "ram_available_mb": 38292.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24542.8, "ram_available_mb": 38298.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.192, "power_cpu_cv_mean_watts": 1.838, "power_sys_5v0_mean_watts": 8.898}, "timestamp": "2026-01-23T08:59:37.305639"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10396.566, "latencies_ms": [10396.566], "images_per_second": 0.096, "prompt_tokens": 37, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The image captures a vibrant scene of a traffic light with a red signal, set against a backdrop of cherry blossom trees in full bloom. The trees, adorned with delicate pink flowers, create a picturesque and serene setting, enhancing the visual appeal of the traffic light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.8, "ram_available_mb": 38298.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24543.1, "ram_available_mb": 38297.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.166, "power_cpu_cv_mean_watts": 1.847, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T08:59:49.741581"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9433.593, "latencies_ms": [9433.593], "images_per_second": 0.106, "prompt_tokens": 36, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The image features a traffic light with a red signal illuminated, set against a backdrop of cherry blossoms in full bloom. The blossoms are predominantly white with hints of pink, and the trees are densely packed, creating a canopy of flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.1, "ram_available_mb": 38297.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.434, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 8.88}, "timestamp": "2026-01-23T09:00:01.224391"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11375.947, "latencies_ms": [11375.947], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a white plate filled with a delicious meal consisting of broccoli and meat. The plate is placed on a dining table, and the food is arranged in a visually appealing manner. The broccoli is spread across the plate, with some pieces located closer to the edges and others near the center. The meat, possibly chicken, is placed in the middle", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.577, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T09:00:14.625127"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8775.645, "latencies_ms": [8775.645], "images_per_second": 0.114, "prompt_tokens": 39, "response_tokens_est": 55, "n_tiles": 16, "output_text": "plate: 1\nchicken: 1\nbroccoli: 10\nonions: 5\ngarlic: 2\npepper: 1\nherbs: 1\nsalt: 1\npepper: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.971, "power_cpu_cv_mean_watts": 2.252, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T09:00:25.427459"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10906.132, "latencies_ms": [10906.132], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "In the foreground of the image, there is a pile of cooked broccoli with some bits of red and white, possibly onions or garlic, scattered around. In the background, there is a piece of grilled salmon with grill marks on it. The broccoli is in the front and the salmon is in the back.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 24561.5, "ram_available_mb": 38279.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.783, "power_cpu_cv_mean_watts": 2.161, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T09:00:38.370912"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8084.753, "latencies_ms": [8084.753], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A plate of food is shown with a piece of grilled salmon and a mix of cooked vegetables, including broccoli and cauliflower. The dish appears to be a healthy and balanced meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24561.5, "ram_available_mb": 38279.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24552.8, "ram_available_mb": 38288.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.224, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T09:00:48.502990"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8925.021, "latencies_ms": [8925.021], "images_per_second": 0.112, "prompt_tokens": 36, "response_tokens_est": 58, "n_tiles": 16, "output_text": "The image shows a plate of food with a piece of grilled salmon and a mix of cooked broccoli. The lighting in the image highlights the vibrant green color of the broccoli and the golden-brown hue of the salmon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.8, "ram_available_mb": 38288.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.55, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T09:00:59.457800"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11355.901, "latencies_ms": [11355.901], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment in a dimly lit restaurant, where three individuals are seated at a table. The person on the left, clad in a black shirt, is engrossed in their phone, perhaps browsing or texting. The middle person, wearing a red shirt, is captured mid-bite, savoring a piece of food. The person on", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.589, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.832}, "timestamp": "2026-01-23T09:01:12.854740"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9581.58, "latencies_ms": [9581.58], "images_per_second": 0.104, "prompt_tokens": 39, "response_tokens_est": 62, "n_tiles": 16, "output_text": "1. Person: 3\n2. Table: 1\n3. Chair: 1\n4. Cell phone: 1\n5. Napkin: 1\n6. Glass: 1\n7. Plate: 1\n8. Silverware: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24543.5, "ram_available_mb": 38297.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.601, "power_cpu_cv_mean_watts": 1.779, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T09:01:24.475122"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11317.576, "latencies_ms": [11317.576], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a person on the left side of the image, partially obscured by a metal headboard with a decorative design. In the background, there are two other individuals seated across from each other, with one person slightly closer to the camera than the other. The person on the right appears to be the farthest away from the camera, with a glass of", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.5, "ram_available_mb": 38297.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.713, "power_cpu_cv_mean_watts": 1.947, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T09:01:37.823015"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7823.795, "latencies_ms": [7823.795], "images_per_second": 0.128, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The image depicts a group of people sitting at a table in a dimly lit restaurant or bar. The atmosphere appears to be casual and relaxed, with the individuals engaged in conversation and enjoying their time together.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.52, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T09:01:47.693563"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7760.245, "latencies_ms": [7760.245], "images_per_second": 0.129, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image features a warm, dimly lit interior with a dominant orange hue, likely from artificial lighting. A metal railing with ornate designs is visible in the background, suggesting an indoor setting with decorative elements.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.37, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 8.92}, "timestamp": "2026-01-23T09:01:57.474384"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11338.068, "latencies_ms": [11338.068], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a bustling city scene. Dominating the foreground is a yellow bus, its vibrant color contrasting with the gray of the cityscape. The bus is in motion, driving on a road that cuts through the scene. \n\nTo the right of the bus, a sidewalk stretches out, lined with trees that provide a touch", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24544.7, "ram_available_mb": 38296.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.562, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.822}, "timestamp": "2026-01-23T09:02:10.863768"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7515.64, "latencies_ms": [7515.64], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "building: 1\nbus: 2\nvan: 2\ntree: 4\nbench: 1\ntrash can: 1\nsidewalk: 1\nroad: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24544.7, "ram_available_mb": 38296.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.743, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 8.883}, "timestamp": "2026-01-23T09:02:20.440200"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11127.595, "latencies_ms": [11127.595], "images_per_second": 0.09, "prompt_tokens": 44, "response_tokens_est": 77, "n_tiles": 16, "output_text": "In the foreground, there is a yellow bus on the right side of the image, near a bus stop with a bench. In the background, there is a large building with many windows, and a few cars and vans parked in front of it. The bus is on the right side of the image, while the building and cars are on the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24544.6, "ram_available_mb": 38296.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.72, "power_cpu_cv_mean_watts": 1.917, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T09:02:33.587163"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11313.23, "latencies_ms": [11313.23], "images_per_second": 0.088, "prompt_tokens": 37, "response_tokens_est": 77, "n_tiles": 16, "output_text": "The image depicts a city street with a yellow bus parked on the side of the road. There are several buildings in the background, including a large multi-story building with a curved facade. The street is lined with trees and there are a few cars parked along the curb. The sky is clear and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.6, "ram_available_mb": 38296.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24548.0, "ram_available_mb": 38292.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.694, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 8.813}, "timestamp": "2026-01-23T09:02:46.927229"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8810.45, "latencies_ms": [8810.45], "images_per_second": 0.114, "prompt_tokens": 36, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image shows a clear day with sunlight casting shadows on the ground, which is paved with rectangular bricks. The bus is predominantly white with a yellow front, and the building in the background has a modern design with a mix of glass and concrete.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.0, "ram_available_mb": 38292.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.588, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 8.896}, "timestamp": "2026-01-23T09:02:57.763430"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11311.066, "latencies_ms": [11311.066], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a vibrant scene on a city street. Dominating the foreground is a red stop sign, its octagonal shape and bold color standing out against the urban backdrop. The sign is affixed to a sturdy metal pole, which is slightly tilted to the left, adding a dynamic element to the composition. \n\nThe pole is not alone", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24540.3, "ram_available_mb": 38300.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.64, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T09:03:11.105710"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8664.014, "latencies_ms": [8664.014], "images_per_second": 0.115, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "- Stop sign: 1\n- Pole: 1\n- Street: 1\n- Sun: 1\n- Buildings: 1\n- Trees: 1\n- Bushes: 1\n- Fence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.3, "ram_available_mb": 38300.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.988, "power_cpu_cv_mean_watts": 1.738, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T09:03:21.782610"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10902.317, "latencies_ms": [10902.317], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "The stop sign is positioned in the foreground on the right side of the image, while the buildings and vehicles are in the background, indicating that the sign is closer to the viewer than the buildings and vehicles. The sun is shining from the left side, casting a shadow of the stop sign to the right, showing that the sun is behind the sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.845, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T09:03:34.720097"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7070.744, "latencies_ms": [7070.744], "images_per_second": 0.141, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "The image shows a red stop sign mounted on a metal pole at an intersection. The sign is positioned in front of a metal fence, with buildings and a street visible in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.123, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.885}, "timestamp": "2026-01-23T09:03:43.828238"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8282.186, "latencies_ms": [8282.186], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The image features a red stop sign with white lettering, mounted on a metal pole. The sign is positioned on the side of a road with buildings in the background, and the sun is shining brightly, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24549.9, "ram_available_mb": 38291.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.099, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T09:03:54.163971"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11368.622, "latencies_ms": [11368.622], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the center of this image, a white and brown cat is the main subject. The cat is lying on its side, its body stretched out in a relaxed manner. Its head is tilted slightly to the left, and its eyes are looking directly at the camera, giving an impression of curiosity or alertness. The cat's fur is a mix of white and brown, with", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24549.9, "ram_available_mb": 38291.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.504, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T09:04:07.571634"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7532.716, "latencies_ms": [7532.716], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "cat: 1, mouse: 1, computer mouse: 1, cord: 1, black surface: 1, white surface: 1, paw: 1, ear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.752, "power_cpu_cv_mean_watts": 1.633, "power_sys_5v0_mean_watts": 8.899}, "timestamp": "2026-01-23T09:04:17.148355"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11304.886, "latencies_ms": [11304.886], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 80, "n_tiles": 16, "output_text": "The cat is lying in the foreground on a black surface, with its body stretched out and its head turned towards the camera. The computer mouse is positioned to the left of the cat, slightly in the background, and is connected to the cat by a white cord. The cord extends from the mouse towards the right side of the image, indicating that the mouse is near the cat.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 24547.2, "ram_available_mb": 38293.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.718, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T09:04:30.510704"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9326.804, "latencies_ms": [9326.804], "images_per_second": 0.107, "prompt_tokens": 37, "response_tokens_est": 60, "n_tiles": 16, "output_text": "A cat with a white and brown coat is lying on a black surface, possibly a couch or a bed, with its paws stretched out in front of it. Next to the cat is a computer mouse, suggesting that the cat may be a pet of someone who uses the computer.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24547.2, "ram_available_mb": 38293.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.511, "power_cpu_cv_mean_watts": 2.352, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T09:04:41.894547"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6204.699, "latencies_ms": [6204.699], "images_per_second": 0.161, "prompt_tokens": 36, "response_tokens_est": 34, "n_tiles": 16, "output_text": "The image features a cat with a white and brown coat, lying on a dark surface. The lighting in the image is dim, creating a moody atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 24558.5, "ram_available_mb": 38282.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.543, "power_cpu_cv_mean_watts": 1.841, "power_sys_5v0_mean_watts": 9.023}, "timestamp": "2026-01-23T09:04:50.153382"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11333.038, "latencies_ms": [11333.038], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a bustling city scene, dominated by a large bus terminal. The terminal is a hive of activity, with numerous buses parked in neat rows, ready to embark on their respective journeys. The buses, painted in a variety of colors, add a vibrant touch to the otherwise monochrome cityscape.\n\nThe terminal", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24558.5, "ram_available_mb": 38282.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24566.7, "ram_available_mb": 38274.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.603, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T09:05:03.531654"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9105.882, "latencies_ms": [9105.882], "images_per_second": 0.11, "prompt_tokens": 39, "response_tokens_est": 58, "n_tiles": 16, "output_text": "- Buses: 10\n- Buildings: 12\n- Trees: 5\n- Power lines: 4\n- Clouds: 10\n- Sky: 1\n- Fence: 1\n- Signs: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24566.7, "ram_available_mb": 38274.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24562.7, "ram_available_mb": 38278.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.684, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T09:05:14.653337"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11334.418, "latencies_ms": [11334.418], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there are several buses parked under a covered area, with one bus prominently in the center. The buses are positioned near a road that curves to the left in the background. Further back, there are multiple high-rise buildings, with the tallest one located on the right side of the image. The sky is visible in the upper part of", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24562.7, "ram_available_mb": 38278.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24561.8, "ram_available_mb": 38279.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.64, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T09:05:28.040704"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7066.159, "latencies_ms": [7066.159], "images_per_second": 0.142, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "The image depicts a bustling city scene with multiple buses parked at a bus station. The station is located in a densely populated urban area with tall buildings surrounding it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24561.8, "ram_available_mb": 38279.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24603.0, "ram_available_mb": 38237.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.148, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.899}, "timestamp": "2026-01-23T09:05:37.121010"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9063.973, "latencies_ms": [9063.973], "images_per_second": 0.11, "prompt_tokens": 36, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image shows a clear day with a few clouds in the sky, and the lighting suggests it is daytime. The buses are predominantly white with some having green and blue accents, and they are parked in a large, open area with a concrete structure overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24603.0, "ram_available_mb": 38237.9, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24559.6, "ram_available_mb": 38281.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.452, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 8.889}, "timestamp": "2026-01-23T09:05:48.226023"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11468.615, "latencies_ms": [11468.615], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is skillfully riding a skateboard down the side of a ramp. He is wearing a cowboy hat and appears to be enjoying the activity. The skateboarder is positioned in the center of the scene, with the ramp beneath him. \n\nIn the background, there are several chairs placed around the area, possibly", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24559.6, "ram_available_mb": 38281.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24551.3, "ram_available_mb": 38289.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.062, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.808}, "timestamp": "2026-01-23T09:06:01.735299"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8442.101, "latencies_ms": [8442.101], "images_per_second": 0.118, "prompt_tokens": 39, "response_tokens_est": 52, "n_tiles": 16, "output_text": "skateboard: 1\nskateboarder: 1\ntent: 3\nsandals: 1\nshade: 1\ntable: 1\nchairs: 1\numbrella: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24551.3, "ram_available_mb": 38289.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.178, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T09:06:12.203536"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9643.024, "latencies_ms": [9643.024], "images_per_second": 0.104, "prompt_tokens": 44, "response_tokens_est": 64, "n_tiles": 16, "output_text": "The skateboarder is in the foreground, performing a trick on a ramp. In the background, there are large green tents set up, and a few people can be seen sitting or standing near them. The tents appear to be further away from the camera than the skateboarder.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24555.1, "ram_available_mb": 38285.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.406, "power_cpu_cv_mean_watts": 1.867, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T09:06:23.884269"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7407.892, "latencies_ms": [7407.892], "images_per_second": 0.135, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "A person is skateboarding on a ramp in an outdoor setting with large green tents in the background. The skateboarder is wearing a cowboy hat and black shorts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.1, "ram_available_mb": 38285.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24547.1, "ram_available_mb": 38293.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.797, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.88}, "timestamp": "2026-01-23T09:06:33.352770"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8264.64, "latencies_ms": [8264.64], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The image shows a person skateboarding on a ramp with a clear blue sky in the background. The skateboarder is wearing a black tank top and shorts, and the ramp is made of wood with red markings.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24547.1, "ram_available_mb": 38293.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24547.6, "ram_available_mb": 38293.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.05, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T09:06:43.647295"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12329.867, "latencies_ms": [12329.867], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a dynamic scene of a person windsurfing on a sunny day. The individual is standing on a white surfboard, which is equipped with a blue sail. The windsurfer is positioned in the water, with the sail fully extended, harnessing the power of the wind to glide across the waves. The ocean, painted in shades of", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 24547.6, "ram_available_mb": 38293.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24554.3, "ram_available_mb": 38286.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.626, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 9.05}, "timestamp": "2026-01-23T09:06:58.013806"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8446.996, "latencies_ms": [8446.996], "images_per_second": 0.118, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "person: 1, surfboard: 1, kite: 4, wave: multiple, ocean: multiple, sky: multiple, wind: multiple, kite surfing: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24554.3, "ram_available_mb": 38286.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.522, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 9.075}, "timestamp": "2026-01-23T09:07:08.494080"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12311.876, "latencies_ms": [12311.876], "images_per_second": 0.081, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a person standing on a surfboard with a sail, positioned near the water's edge. The waves are in the middle ground, with the person closer to the surfboard than the waves. In the background, there are multiple kites flying high in the sky, with the closest kite being the highest and the farthest kite being", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24540.2, "ram_available_mb": 38300.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.626, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 9.031}, "timestamp": "2026-01-23T09:07:22.819769"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7288.864, "latencies_ms": [7288.864], "images_per_second": 0.137, "prompt_tokens": 37, "response_tokens_est": 33, "n_tiles": 16, "output_text": "A person is windsurfing on a sunny day with several kites flying in the sky. The ocean is rough with waves suitable for the sport.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.2, "ram_available_mb": 38300.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 24584.7, "ram_available_mb": 38256.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.206, "power_cpu_cv_mean_watts": 1.326, "power_sys_5v0_mean_watts": 9.048}, "timestamp": "2026-01-23T09:07:32.125677"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8717.148, "latencies_ms": [8717.148], "images_per_second": 0.115, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image captures a bright and sunny day at the beach with clear blue skies and a few clouds. The ocean is a deep blue-green color, and the waves are white-capped, indicating strong winds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24584.7, "ram_available_mb": 38256.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24543.4, "ram_available_mb": 38297.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.932, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 9.101}, "timestamp": "2026-01-23T09:07:42.866064"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11347.094, "latencies_ms": [11347.094], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the heart of a lush garden, a vibrant red fire hydrant stands as a beacon of safety. Its black cap and nozzles are a stark contrast to its bright color, adding an element of intrigue to its appearance. The hydrant is nestled in a bed of vibrant green grass, which is dotted with delicate white flowers, adding a touch", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24543.4, "ram_available_mb": 38297.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24553.1, "ram_available_mb": 38287.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.556, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.825}, "timestamp": "2026-01-23T09:07:56.256131"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8339.244, "latencies_ms": [8339.244], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "fire hydrant: 1, grass: numerous, dandelions: 8, house: 1, tree: 1, window: 1, flowers: 1, roof: 1, wisteria: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.1, "ram_available_mb": 38287.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.14, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T09:08:06.615013"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9548.333, "latencies_ms": [9548.333], "images_per_second": 0.105, "prompt_tokens": 44, "response_tokens_est": 63, "n_tiles": 16, "output_text": "The fire hydrant is located in the foreground of the image, standing on a grassy area. In the background, there is a white house with a thatched roof and a tree with purple flowers. The fire hydrant is positioned closer to the viewer than the house and the tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24546.6, "ram_available_mb": 38294.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.507, "power_cpu_cv_mean_watts": 1.843, "power_sys_5v0_mean_watts": 8.899}, "timestamp": "2026-01-23T09:08:18.216942"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6620.43, "latencies_ms": [6620.43], "images_per_second": 0.151, "prompt_tokens": 37, "response_tokens_est": 36, "n_tiles": 16, "output_text": "A red fire hydrant is situated in a grassy area with a white house in the background. The house has a thatched roof and is surrounded by trees and flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.6, "ram_available_mb": 38294.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24540.3, "ram_available_mb": 38300.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.547, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 8.912}, "timestamp": "2026-01-23T09:08:26.886232"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6566.981, "latencies_ms": [6566.981], "images_per_second": 0.152, "prompt_tokens": 36, "response_tokens_est": 37, "n_tiles": 16, "output_text": "The fire hydrant in the image is bright red and appears to be made of metal. It is situated in a grassy area with a white house and trees in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24540.3, "ram_available_mb": 38300.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24537.6, "ram_available_mb": 38303.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.491, "power_cpu_cv_mean_watts": 1.558, "power_sys_5v0_mean_watts": 8.971}, "timestamp": "2026-01-23T09:08:35.483413"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11367.262, "latencies_ms": [11367.262], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of a bird in flight, with its wings spread wide and its head turned towards the camera. The bird is perched on a wooden surface, which is painted in a light blue color. The surface is composed of multiple wooden planks, each with a slightly different shade of blue, creating a subtle pattern. The bird's feathers are a mix of", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24537.6, "ram_available_mb": 38303.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 24558.5, "ram_available_mb": 38282.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.631, "power_cpu_cv_mean_watts": 2.148, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T09:08:48.882979"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8576.665, "latencies_ms": [8576.665], "images_per_second": 0.117, "prompt_tokens": 39, "response_tokens_est": 53, "n_tiles": 16, "output_text": "bird: 2, wooden plank: 5, paint peeling: 3, color blue: 1, color green: 1, color brown: 1, bird's wing: 1, bird's head: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24558.5, "ram_available_mb": 38282.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24565.7, "ram_available_mb": 38275.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.869, "power_cpu_cv_mean_watts": 2.091, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T09:08:59.509750"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11368.141, "latencies_ms": [11368.141], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a bird with its wings spread, positioned on the left side of the image, closer to the viewer. In the background, there are two more birds, one partially visible on the left and another on the right, both are further away from the viewer. The main object, the bird with spread wings, is in the center and appears to be in", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24565.7, "ram_available_mb": 38275.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 24562.2, "ram_available_mb": 38278.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.578, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T09:09:12.894047"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9339.048, "latencies_ms": [9339.048], "images_per_second": 0.107, "prompt_tokens": 37, "response_tokens_est": 60, "n_tiles": 16, "output_text": "A small bird is captured in mid-flight, with its wings spread wide, as it appears to be landing on a wooden surface with peeling blue paint. The surface has a rough texture and shows signs of wear and tear, with visible cracks and chips in the paint.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24562.2, "ram_available_mb": 38278.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24567.3, "ram_available_mb": 38273.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.491, "power_cpu_cv_mean_watts": 1.779, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T09:09:24.247545"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9834.821, "latencies_ms": [9834.821], "images_per_second": 0.102, "prompt_tokens": 36, "response_tokens_est": 66, "n_tiles": 16, "output_text": "The image features a close-up of a bird with a dark body and a lighter underbelly, perched on a weathered wooden surface with peeling blue paint. The lighting is soft and diffused, casting gentle shadows and highlighting the texture of the wood and the bird's feathers.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24567.3, "ram_available_mb": 38273.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24560.6, "ram_available_mb": 38280.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.125, "power_cpu_cv_mean_watts": 1.854, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T09:09:36.115296"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11328.312, "latencies_ms": [11328.312], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a woman is standing in a barn, watching a brown horse with a red halter walking around. The horse is positioned in the center of the barn, and the woman is standing to the right of it. The barn is filled with various items, including a clock on the wall, a truck, and a couple of buckets. There are also two", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24560.6, "ram_available_mb": 38280.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.677, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T09:09:49.479628"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7176.48, "latencies_ms": [7176.48], "images_per_second": 0.139, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "door: 1, horse: 1, bucket: 1, wall: 1, window: 1, floor: 1, person: 1, desk: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.156, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T09:09:58.682153"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11414.809, "latencies_ms": [11414.809], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a brown horse with a red halter, positioned near the center of the image, walking towards the right side. A person, wearing blue jeans and a grey shirt, is standing to the right of the horse, closer to the background. The background features a wooden barn with a red door on the left, a window, and various items", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.461, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.809}, "timestamp": "2026-01-23T09:10:12.115813"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6816.702, "latencies_ms": [6816.702], "images_per_second": 0.147, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A woman is standing in a barn with a horse that is walking towards her. The barn has wooden walls and a red door, and there is a window in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.37, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.945}, "timestamp": "2026-01-23T09:10:20.968937"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6754.7, "latencies_ms": [6754.7], "images_per_second": 0.148, "prompt_tokens": 36, "response_tokens_est": 39, "n_tiles": 16, "output_text": "The image depicts an indoor setting with wooden walls and a concrete floor. The lighting appears to be natural daylight coming from a window, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.019, "power_cpu_cv_mean_watts": 1.594, "power_sys_5v0_mean_watts": 8.969}, "timestamp": "2026-01-23T09:10:29.742976"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11342.372, "latencies_ms": [11342.372], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a lush green field with a variety of animals grazing and roaming around. There are several zebras and a couple of rhinos in the field, with some of them standing close to each other. A herd of zebras can be seen in the middle of the field, while a couple of rhinos are located towards the left side of the scene.\n", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.603, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T09:10:43.134783"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9214.339, "latencies_ms": [9214.339], "images_per_second": 0.109, "prompt_tokens": 39, "response_tokens_est": 59, "n_tiles": 16, "output_text": "grass: 1\n\ntree: 10\n\nrock: 5\n\nwild boar: 2\n\nzebra: 2\n\ngiraffe: 1\n\nantelope: 2\n\nelephant: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.759, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T09:10:54.367039"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10095.369, "latencies_ms": [10095.369], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 68, "n_tiles": 16, "output_text": "In the foreground, there is a grassy field with a zebra grazing on the right side and a few other animals scattered around. In the background, there are trees and a pond, with a few more animals near the water's edge. The sky is visible in the top left corner of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.169, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 8.907}, "timestamp": "2026-01-23T09:11:06.523953"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7850.938, "latencies_ms": [7850.938], "images_per_second": 0.127, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The image depicts a lush green field with a variety of animals grazing and roaming around. There are zebras, wildebeests, and other animals in the field, with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.2, "ram_available_mb": 38292.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24554.0, "ram_available_mb": 38286.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.428, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T09:11:16.423068"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8576.611, "latencies_ms": [8576.611], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image depicts a sunny day with clear skies, as evidenced by the bright lighting and shadows cast on the ground. The landscape is a mix of green grass and brown rocks, with trees in the background providing a natural backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24554.0, "ram_available_mb": 38286.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24560.5, "ram_available_mb": 38280.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.772, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 8.881}, "timestamp": "2026-01-23T09:11:27.020578"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11340.637, "latencies_ms": [11340.637], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment in a bustling theme park, where a white horse-drawn carriage, adorned with a green and gold canopy, is the centerpiece. The carriage, labeled \"Disneyland\", is being pulled by a majestic white horse, its muscles rippling under the canopy. The horse's harness is a striking", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 24560.5, "ram_available_mb": 38280.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.633, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.814}, "timestamp": "2026-01-23T09:11:40.385003"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7863.86, "latencies_ms": [7863.86], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "people: 10, disneyland sign: 1, horse: 1, carriage: 1, bench: 1, trees: 5, sky: 1, umbrella: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.585, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T09:11:50.272178"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9829.191, "latencies_ms": [9829.191], "images_per_second": 0.102, "prompt_tokens": 44, "response_tokens_est": 66, "n_tiles": 16, "output_text": "In the foreground, there is a white horse pulling a Disneyland trolley with several passengers on board. The trolley is on a street with a green canopy and a sign that reads \"Disneyland.\" In the background, there are people walking on the sidewalk and trees lining the street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24548.3, "ram_available_mb": 38292.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.21, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T09:12:02.138713"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7838.733, "latencies_ms": [7838.733], "images_per_second": 0.128, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The image captures a vintage scene of a horse-drawn carriage on Main Street, U.S.A. in Disneyland, with a white horse pulling the carriage and a man seated at the front.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24548.3, "ram_available_mb": 38292.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.483, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 8.888}, "timestamp": "2026-01-23T09:12:11.993875"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10080.543, "latencies_ms": [10080.543], "images_per_second": 0.099, "prompt_tokens": 36, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The image features a vibrant scene with a horse-drawn carriage in the center, painted in green and gold with a red roof, indicating a festive or touristic setting. The lighting suggests it's a sunny day, casting shadows on the ground, and the weather appears to be clear and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24545.6, "ram_available_mb": 38295.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.017, "power_cpu_cv_mean_watts": 1.867, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T09:12:24.089593"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11372.03, "latencies_ms": [11372.03], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of older men sitting on benches in a public area, likely a park or a waiting area. There are at least five men visible, with some sitting on the benches and others standing nearby. They are all engaged in various activities, such as reading newspapers, looking at their cell phones, or simply enjoying the outdoors.\n\nThere are multiple", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 24545.6, "ram_available_mb": 38295.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24538.8, "ram_available_mb": 38302.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.606, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.833}, "timestamp": "2026-01-23T09:12:37.486033"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7746.25, "latencies_ms": [7746.25], "images_per_second": 0.129, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "bench: 5\nman: 5\nnewspaper: 1\ntrash can: 1\nwindow: 1\ndoor: 1\nplant: 1\nposter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.8, "ram_available_mb": 38302.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.664, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T09:12:47.255314"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9834.485, "latencies_ms": [9834.485], "images_per_second": 0.102, "prompt_tokens": 44, "response_tokens_est": 66, "n_tiles": 16, "output_text": "In the foreground, there is a man sitting on a green bench reading a newspaper. Behind him, there are several other benches with people sitting on them, and a building with a sign that reads \"SOCIETY\". The man on the left bench is closer to the camera than the others.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 24543.7, "ram_available_mb": 38297.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.218, "power_cpu_cv_mean_watts": 1.964, "power_sys_5v0_mean_watts": 8.881}, "timestamp": "2026-01-23T09:12:59.110805"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8061.35, "latencies_ms": [8061.35], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image depicts a group of older men sitting on benches in a public area, with one man reading a newspaper. The setting appears to be a park or a public square with multiple benches and a building in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24543.7, "ram_available_mb": 38297.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 24551.4, "ram_available_mb": 38289.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.302, "power_cpu_cv_mean_watts": 2.208, "power_sys_5v0_mean_watts": 8.915}, "timestamp": "2026-01-23T09:13:09.212990"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5829.815, "latencies_ms": [5829.815], "images_per_second": 0.172, "prompt_tokens": 36, "response_tokens_est": 31, "n_tiles": 16, "output_text": "The image shows a sunny day with clear skies, casting shadows on the ground. The men are seated on green metal benches.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.4, "ram_available_mb": 38289.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 24558.4, "ram_available_mb": 38282.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.015, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 9.024}, "timestamp": "2026-01-23T09:13:17.067784"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11353.344, "latencies_ms": [11353.344], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a desk with a laptop computer sitting on top of it. The laptop is open, and the screen is turned on, displaying a desktop wallpaper. A glass of orange juice is placed on the desk, and a book is also visible nearby. A lamp is situated on the desk, providing light for the workspace.\n\nIn addition to the laptop, there", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 24558.4, "ram_available_mb": 38282.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24548.8, "ram_available_mb": 38292.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.616, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T09:13:30.476839"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8900.909, "latencies_ms": [8900.909], "images_per_second": 0.112, "prompt_tokens": 39, "response_tokens_est": 55, "n_tiles": 16, "output_text": "- Desk: 1\n- Laptop: 1\n- Phone: 1\n- Glass: 1\n- Lamp: 1\n- Candle holder: 1\n- Picture: 1\n- Drawer: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.8, "ram_available_mb": 38292.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24598.9, "ram_available_mb": 38242.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.746, "power_cpu_cv_mean_watts": 1.789, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T09:13:41.403492"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10257.51, "latencies_ms": [10257.51], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The laptop is positioned on the left side of the desk, closer to the foreground, while the lamp is on the right side, further back. The phone is placed to the left of the laptop, and the glass of orange juice is on the right side of the laptop, closer to the edge of the desk.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24598.9, "ram_available_mb": 38242.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.103, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T09:13:53.713918"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8351.153, "latencies_ms": [8351.153], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image depicts a well-lit workspace with a laptop open on a wooden desk, displaying a desktop screen. A lamp with a black shade is placed to the right of the laptop, providing additional lighting to the area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.271, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 8.814}, "timestamp": "2026-01-23T09:14:04.091125"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7144.956, "latencies_ms": [7144.956], "images_per_second": 0.14, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image features a desk with a laptop, a lamp, and a glass of orange juice. The lamp is turned on, casting a warm glow on the desk and the laptop screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24551.4, "ram_available_mb": 38289.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.696, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 8.942}, "timestamp": "2026-01-23T09:14:13.264142"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12603.476, "latencies_ms": [12603.476], "images_per_second": 0.079, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene beach scene. In the foreground, there's a blue and white striped towel neatly spread out on the sand. A blue surfboard with a white stripe is placed next to the towel, ready for a day of fun in the water. A red and white striped bag is also visible, perhaps containing personal belongings or beach", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 24551.4, "ram_available_mb": 38289.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.919, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 9.056}, "timestamp": "2026-01-23T09:14:27.934877"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9787.156, "latencies_ms": [9787.156], "images_per_second": 0.102, "prompt_tokens": 39, "response_tokens_est": 52, "n_tiles": 16, "output_text": "beach chair: 2, umbrella: 1, surfboard: 2, towel: 1, cooler: 1, flip flops: 1, handbag: 1, backpack: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.248, "power_cpu_cv_mean_watts": 1.549, "power_sys_5v0_mean_watts": 9.026}, "timestamp": "2026-01-23T09:14:39.738764"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12647.944, "latencies_ms": [12647.944], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a blue and white striped towel laid out on the sand, with a pink and white surfboard placed next to it. In the background, there is a beach chair with an umbrella, and a person is visible in the water further back. The surfboard and towel are near the edge of the frame, while the chair and", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24588.5, "ram_available_mb": 38252.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.024, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 9.121}, "timestamp": "2026-01-23T09:14:54.410561"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11724.632, "latencies_ms": [11724.632], "images_per_second": 0.085, "prompt_tokens": 37, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The image depicts a beach scene with a blue and white striped towel laid out on the sand, a pink and white surfboard, and a blue surfboard. There is a green umbrella and a chair set up for relaxation, and a person can be seen in the water in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24588.5, "ram_available_mb": 38252.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24590.6, "ram_available_mb": 38250.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.56, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 9.043}, "timestamp": "2026-01-23T09:15:08.155572"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11692.45, "latencies_ms": [11692.45], "images_per_second": 0.086, "prompt_tokens": 36, "response_tokens_est": 71, "n_tiles": 16, "output_text": "The beach scene features a bright blue sky and calm ocean waves, with a clear day that suggests good weather for outdoor activities. The sand is a light beige color, and there are various items scattered on it, including a blue and white striped towel, a pink and white surfboard, and a brown leather bag.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24590.6, "ram_available_mb": 38250.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24595.7, "ram_available_mb": 38245.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.353, "power_cpu_cv_mean_watts": 1.723, "power_sys_5v0_mean_watts": 9.132}, "timestamp": "2026-01-23T09:15:21.879925"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11332.749, "latencies_ms": [11332.749], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a solitary sheep stands majestically on a rocky outcropping. The sheep, with its white wool, is facing to the left, as if gazing into the distance. The rocky outcropping, a rugged terrain of gray and black rocks, provides a stark contrast to the sheep's soft wool. The sky above is a clear blue", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24595.7, "ram_available_mb": 38245.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.628, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T09:15:35.249508"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7624.341, "latencies_ms": [7624.341], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "rock: 10\nsheep: 1\ncloud: 10\nblue: 1\nwhite: 1\ngrass: 1\nmountain: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24550.2, "ram_available_mb": 38290.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.725, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.921}, "timestamp": "2026-01-23T09:15:44.918964"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9085.409, "latencies_ms": [9085.409], "images_per_second": 0.11, "prompt_tokens": 44, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The sheep is positioned in the foreground on the left side of the image, standing on a rocky outcrop. The sky occupies the background, with clouds scattered across it, and the grassy area is in the far background, providing a natural setting for the sheep.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.2, "ram_available_mb": 38290.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.587, "power_cpu_cv_mean_watts": 1.804, "power_sys_5v0_mean_watts": 8.896}, "timestamp": "2026-01-23T09:15:56.039251"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6833.319, "latencies_ms": [6833.319], "images_per_second": 0.146, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A sheep stands alone on a rocky outcrop under a clear blue sky with scattered clouds. The terrain is rugged and the sheep appears to be gazing into the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24592.4, "ram_available_mb": 38248.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.349, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T09:16:04.889482"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7478.716, "latencies_ms": [7478.716], "images_per_second": 0.134, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The sheep is standing on a rocky outcrop with a clear blue sky and fluffy white clouds in the background. The rocks are dark and jagged, and the sheep is a light tan color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24592.4, "ram_available_mb": 38248.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24552.4, "ram_available_mb": 38288.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.644, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 8.939}, "timestamp": "2026-01-23T09:16:14.415548"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11292.545, "latencies_ms": [11292.545], "images_per_second": 0.089, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a person with striking blue hair is captured in a moment of self-reflection. They are wearing a blue shirt and a black tie, adding a touch of professionalism to their appearance. The person is holding a phone in their right hand, which is displaying a vibrant image of a red flower. The background is a simple beige wall, providing a neutral", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24552.4, "ram_available_mb": 38288.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24538.2, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.617, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 8.865}, "timestamp": "2026-01-23T09:16:27.770247"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7316.868, "latencies_ms": [7316.868], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "person: 1, hair: 1, phone: 1, tie: 1, shirt: 1, button: 1, pocket: 1, earring: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.2, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24538.7, "ram_available_mb": 38302.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.919, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T09:16:37.114854"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11042.009, "latencies_ms": [11042.009], "images_per_second": 0.091, "prompt_tokens": 44, "response_tokens_est": 76, "n_tiles": 16, "output_text": "The person with blue hair is in the foreground, taking a selfie with a smartphone held in their right hand. The phone is positioned in the right hand, slightly in front of the person's face, capturing the image. The background is a plain wall with a door handle visible on the left side, indicating the photo was taken indoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.7, "ram_available_mb": 38302.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24538.5, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.815, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T09:16:50.214278"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4447.202, "latencies_ms": [4447.202], "images_per_second": 0.225, "prompt_tokens": 37, "response_tokens_est": 17, "n_tiles": 16, "output_text": "A person with blue hair is taking a selfie in a bathroom mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.5, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.738, "power_cpu_cv_mean_watts": 1.104, "power_sys_5v0_mean_watts": 9.055}, "timestamp": "2026-01-23T09:16:56.698981"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8859.292, "latencies_ms": [8859.292], "images_per_second": 0.113, "prompt_tokens": 36, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The person in the image has vibrant blue hair and is wearing a dark blue shirt with a black tie. They are holding a smartphone in their right hand, taking a selfie in an indoor setting with a neutral-colored wall in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24540.8, "ram_available_mb": 38300.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.708, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T09:17:07.590648"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11289.945, "latencies_ms": [11289.945], "images_per_second": 0.089, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a room steeped in history, possibly a museum exhibit. Dominating the scene is a fireplace, its mantel adorned with a black and gold frame, housing a painting of a man and a woman. The fireplace, a symbol of warmth and comfort, is flanked by two lamps, their light casting a soft glow on the", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24540.8, "ram_available_mb": 38300.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.79, "power_cpu_cv_mean_watts": 2.369, "power_sys_5v0_mean_watts": 8.895}, "timestamp": "2026-01-23T09:17:20.924501"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7075.516, "latencies_ms": [7075.516], "images_per_second": 0.141, "prompt_tokens": 39, "response_tokens_est": 40, "n_tiles": 16, "output_text": "object: 1, object: 1, object: 1, object: 1, object: 1, object: 1, object: 1, object: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 24570.6, "ram_available_mb": 38270.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.985, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 8.939}, "timestamp": "2026-01-23T09:17:30.040366"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10298.049, "latencies_ms": [10298.049], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "In the foreground of the image, there is a fireplace with a white mantel and a fire burning inside. To the right of the fireplace, there is a wooden cabinet with a red curtain hanging in front of it. In the background, there are two paintings hanging on the wall, one above the other.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24570.6, "ram_available_mb": 38270.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24561.6, "ram_available_mb": 38279.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.002, "power_cpu_cv_mean_watts": 1.868, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T09:17:42.350172"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8185.089, "latencies_ms": [8185.089], "images_per_second": 0.122, "prompt_tokens": 37, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image depicts a cozy room with a fireplace, a wooden cabinet, a chair, and a table. There are also two paintings hanging on the wall, one above the fireplace and the other above the cabinet.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24561.6, "ram_available_mb": 38279.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24565.7, "ram_available_mb": 38275.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.179, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T09:17:52.548543"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7876.581, "latencies_ms": [7876.581], "images_per_second": 0.127, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The room is dimly lit with natural light coming from the window, and the furniture is made of wood with a dark finish. The floor is covered with a patterned carpet in shades of green, red, and black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24565.7, "ram_available_mb": 38275.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.272, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 8.953}, "timestamp": "2026-01-23T09:18:02.441737"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12510.593, "latencies_ms": [12510.593], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a brown dog is captured in mid-air, leaping energetically to catch a red frisbee. The dog's body is stretched out, and its front paws are extended forward, ready to grasp the frisbee. The frisbee is positioned above the dog's head, slightly to the right. The dog is surrounded", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.016, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 9.077}, "timestamp": "2026-01-23T09:18:17.005887"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8694.71, "latencies_ms": [8694.71], "images_per_second": 0.115, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "tree: 1, frisbee: 1, dog: 1, car: 1, grass: 1, bush: 1, path: 1, leaf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 24599.5, "ram_available_mb": 38241.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.883, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 9.107}, "timestamp": "2026-01-23T09:18:27.720052"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12633.749, "latencies_ms": [12633.749], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a brown dog is captured in mid-air, leaping towards a red frisbee that is positioned near the top right corner of the image, suggesting the dog is attempting to catch it. The frisbee is closer to the camera than the dog, creating a sense of depth. In the background, there is a black car parked on the left", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24599.5, "ram_available_mb": 38241.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24555.4, "ram_available_mb": 38285.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.074, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 9.118}, "timestamp": "2026-01-23T09:18:42.380784"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10290.085, "latencies_ms": [10290.085], "images_per_second": 0.097, "prompt_tokens": 37, "response_tokens_est": 57, "n_tiles": 16, "output_text": "A brown dog is in mid-air, leaping towards a red frisbee with its mouth open, attempting to catch it. The scene is set in a grassy area with a black car parked in the background and a tree to the left of the dog.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24555.4, "ram_available_mb": 38285.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24597.6, "ram_available_mb": 38243.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.051, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 9.079}, "timestamp": "2026-01-23T09:18:54.703534"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8359.694, "latencies_ms": [8359.694], "images_per_second": 0.12, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image features a brown dog in mid-air, reaching for a red frisbee. The dog is positioned in a grassy area with a black car and a tree in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24597.6, "ram_available_mb": 38243.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24592.7, "ram_available_mb": 38248.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.844, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 9.141}, "timestamp": "2026-01-23T09:19:05.082387"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11332.974, "latencies_ms": [11332.974], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the heart of a verdant landscape, a giraffe stands tall and majestic. Its long neck, a marvel of nature's design, stretches upwards towards the sky, while its large ears, adorned with black tips, are alert and attentive. The giraffe's coat is a beautiful mosaic of brown and white spots,", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24592.7, "ram_available_mb": 38248.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24558.2, "ram_available_mb": 38282.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.607, "power_cpu_cv_mean_watts": 1.961, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T09:19:18.447335"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7274.689, "latencies_ms": [7274.689], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "ear: 2\neye: 2\nnose: 1\nmouth: 1\nfur: 1\near: 1\near: 1\near: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24558.2, "ram_available_mb": 38282.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.777, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.936}, "timestamp": "2026-01-23T09:19:27.779131"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8481.521, "latencies_ms": [8481.521], "images_per_second": 0.118, "prompt_tokens": 44, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The giraffe is in the foreground, standing near the center of the image, with trees and foliage in the background. The person's head is partially visible on the left side of the image, suggesting they are behind the giraffe.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24551.1, "ram_available_mb": 38289.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.854, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T09:19:38.286456"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9449.342, "latencies_ms": [9449.342], "images_per_second": 0.106, "prompt_tokens": 37, "response_tokens_est": 61, "n_tiles": 16, "output_text": "In the image, a giraffe is standing in a lush green environment, surrounded by trees and foliage. The giraffe is looking directly at the camera, with its head slightly tilted to the left, giving a sense of curiosity and engagement with the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.1, "ram_available_mb": 38289.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.488, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T09:19:49.795143"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6491.339, "latencies_ms": [6491.339], "images_per_second": 0.154, "prompt_tokens": 36, "response_tokens_est": 37, "n_tiles": 16, "output_text": "The giraffe has a light brown coat with darker brown spots. The background is a mix of green and yellow hues, indicating a natural, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.38, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 9.014}, "timestamp": "2026-01-23T09:19:58.319978"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11370.532, "latencies_ms": [11370.532], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there are two zebras standing in a grassy field. The zebras are facing away from the camera, showcasing their distinctive black and white stripes. They are positioned close to each other, with one zebra slightly ahead of the other. The background features a chain-link fence, indicating that they are in a protected area, possibly", "error": null, "sys_before": {"cpu_percent": 9.4, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.568, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T09:20:11.758938"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7183.599, "latencies_ms": [7183.599], "images_per_second": 0.139, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "zebra: 2, fence: 1, leaves: many, ground: dry, rocks: 1, sunlight: bright, trees: 1, sky: not visible", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.999, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T09:20:21.003825"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11409.953, "latencies_ms": [11409.953], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "The two zebras are standing close to each other, with one slightly in front of the other, creating a sense of depth in the image. They are positioned in the foreground, while the chain-link fence and the background of trees and foliage are in the background. The zebras are near the camera, making them the main focus of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24547.6, "ram_available_mb": 38293.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.667, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T09:20:34.465042"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7206.113, "latencies_ms": [7206.113], "images_per_second": 0.139, "prompt_tokens": 37, "response_tokens_est": 41, "n_tiles": 16, "output_text": "Two zebras are standing in a grassy area with a chain-link fence in the background. The zebras are facing away from the camera, and their tails are raised.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24547.6, "ram_available_mb": 38293.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24537.9, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.865, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T09:20:43.734070"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8368.076, "latencies_ms": [8368.076], "images_per_second": 0.12, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The zebras have distinct black and white stripes, and the image is taken in natural daylight with shadows cast on the ground. The background shows a wire fence, indicating the zebras are likely in a zoo or wildlife park.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24537.9, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24545.5, "ram_available_mb": 38295.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.047, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 8.923}, "timestamp": "2026-01-23T09:20:54.117232"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11374.94, "latencies_ms": [11374.94], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a group of horses is walking down a road, with some of them standing near the side of the road. There are at least four horses visible, with one horse standing closer to the left side of the road and the other three horses positioned more towards the center. \n\nA car is parked on the right side of the road, occupying a significant portion of", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24545.5, "ram_available_mb": 38295.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24547.5, "ram_available_mb": 38293.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.65, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T09:21:07.539911"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7782.11, "latencies_ms": [7782.11], "images_per_second": 0.128, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "fence: 1\nhorses: 3\ncar: 1\nroad: 1\ntrees: 1\nleaves: 1\ngrass: 1\ndirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24547.5, "ram_available_mb": 38293.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.432, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T09:21:17.362052"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10225.829, "latencies_ms": [10225.829], "images_per_second": 0.098, "prompt_tokens": 44, "response_tokens_est": 69, "n_tiles": 16, "output_text": "In the foreground, there is a silver car parked on the right side of the road. In the background, there are three horses walking on the road, with one horse closer to the camera and two others further away. The car is positioned near the middle of the road, while the horses are walking parallel to the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 24557.7, "ram_available_mb": 38283.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.975, "power_cpu_cv_mean_watts": 2.085, "power_sys_5v0_mean_watts": 8.865}, "timestamp": "2026-01-23T09:21:29.614128"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8089.695, "latencies_ms": [8089.695], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A group of horses are standing on the side of a road, with a silver car parked nearby. The scene appears to be in a rural or countryside area, with trees and a wooden fence visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24557.7, "ram_available_mb": 38283.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.296, "power_cpu_cv_mean_watts": 2.121, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T09:21:39.743177"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7775.929, "latencies_ms": [7775.929], "images_per_second": 0.129, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image shows a sunny day with clear skies, casting natural light on the scene. A silver car is parked on the side of a road, and there is a wooden fence on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 24571.3, "ram_available_mb": 38269.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.247, "power_cpu_cv_mean_watts": 1.839, "power_sys_5v0_mean_watts": 8.94}, "timestamp": "2026-01-23T09:21:49.540242"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11337.148, "latencies_ms": [11337.148], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a wooden desk with a chair positioned in front of it. On the desk, there is a stack of books, an apple, and a bottle. The chair is placed close to the desk, providing a comfortable seating area for someone to sit and work or study. The books are arranged in a pile, with the apple placed on top of the stack", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 24571.3, "ram_available_mb": 38269.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24565.8, "ram_available_mb": 38275.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.645, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T09:22:02.901425"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8320.899, "latencies_ms": [8320.899], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "- Chair: 1\n- Desk: 1\n- Book: 3\n- Apple: 1\n- Desk lamp: 1\n- Chair: 1\n- Chair: 1\n- Chair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24565.8, "ram_available_mb": 38275.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24562.5, "ram_available_mb": 38278.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.097, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T09:22:13.267162"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11341.321, "latencies_ms": [11341.321], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a wooden desk with a stack of books leaning against it, and a red apple resting on the desk. To the left of the desk, there is a wooden chair with a curved backrest. In the background, there is a large blackboard mounted on the wall, and a small picture frame is hanging on the wall to the", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24562.5, "ram_available_mb": 38278.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24576.7, "ram_available_mb": 38264.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.597, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T09:22:26.632008"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8651.448, "latencies_ms": [8651.448], "images_per_second": 0.116, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image depicts a classroom setting with a wooden desk in the foreground. On the desk, there is a stack of books, an apple, and a quill pen. The background features a chalkboard with some writing on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24576.7, "ram_available_mb": 38264.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24569.9, "ram_available_mb": 38270.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.936, "power_cpu_cv_mean_watts": 1.734, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T09:22:37.309140"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10104.877, "latencies_ms": [10104.877], "images_per_second": 0.099, "prompt_tokens": 36, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The image features a blackboard with a chalkboard texture, and the lighting appears to be coming from the left side, casting shadows to the right. The desk is made of wood with a dark finish, and there is a red apple and a blue book on it, adding a pop of color to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24569.9, "ram_available_mb": 38270.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24565.2, "ram_available_mb": 38275.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.989, "power_cpu_cv_mean_watts": 1.867, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T09:22:49.436017"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11351.434, "latencies_ms": [11351.434], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment on a bustling street in India. Dominating the scene is a yellow and white bus, adorned with a red and white stripe running along its side. The bus is in motion, as indicated by the blurred background, suggesting it's speeding down the road. The license plate of the bus reads \"DL-10 3", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24565.2, "ram_available_mb": 38275.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24560.1, "ram_available_mb": 38280.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.589, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T09:23:02.831093"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7506.111, "latencies_ms": [7506.111], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "bus: 1, van: 1, motorcycle: 1, car: 1, license plate: 1, rear light: 2, side mirror: 1, window: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24560.1, "ram_available_mb": 38280.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24561.1, "ram_available_mb": 38279.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.633, "power_cpu_cv_mean_watts": 1.658, "power_sys_5v0_mean_watts": 8.888}, "timestamp": "2026-01-23T09:23:12.362905"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9069.358, "latencies_ms": [9069.358], "images_per_second": 0.11, "prompt_tokens": 44, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The bus is in the foreground on the left side of the image, moving towards the right. There is a white van on the right side of the image, further back in the scene. The background is less distinct but appears to be an urban street with other vehicles and possibly buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24561.1, "ram_available_mb": 38279.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.563, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.905}, "timestamp": "2026-01-23T09:23:23.461948"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6944.162, "latencies_ms": [6944.162], "images_per_second": 0.144, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "A yellow and white bus with the number 475 and some text in Hindi is driving on a busy street. There are other vehicles and a motorcycle visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24564.7, "ram_available_mb": 38276.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.047, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T09:23:32.454482"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6745.705, "latencies_ms": [6745.705], "images_per_second": 0.148, "prompt_tokens": 36, "response_tokens_est": 39, "n_tiles": 16, "output_text": "The bus in the image is predominantly yellow with red and white accents. The weather appears to be overcast, as the sky is grey and the overall lighting is dim.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24564.7, "ram_available_mb": 38276.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24557.7, "ram_available_mb": 38283.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.033, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.933}, "timestamp": "2026-01-23T09:23:41.255283"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11309.436, "latencies_ms": [11309.436], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment in a bathroom, where the primary focus is a television mounted on the wall. The television, which is the central object in the image, is turned on and broadcasting a football game. The game is in progress, with players actively engaged in the action.\n\nThe bathroom itself is well-equipped, featuring a sink and a toilet", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 24557.7, "ram_available_mb": 38283.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24567.7, "ram_available_mb": 38273.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.622, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 8.827}, "timestamp": "2026-01-23T09:23:54.638444"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10856.197, "latencies_ms": [10856.197], "images_per_second": 0.092, "prompt_tokens": 39, "response_tokens_est": 73, "n_tiles": 16, "output_text": "- Television: 1\n\n- Mirror: 1\n\n- Sink: 1\n\n- Faucet: 1\n\n- Tiles: Multiple (exact count not determinable)\n\n- Towel dispenser: 1\n\n- Trash can: 1\n\n- Door: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24567.7, "ram_available_mb": 38273.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24561.7, "ram_available_mb": 38279.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.0, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 8.815}, "timestamp": "2026-01-23T09:24:07.513224"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10574.89, "latencies_ms": [10574.89], "images_per_second": 0.095, "prompt_tokens": 44, "response_tokens_est": 72, "n_tiles": 16, "output_text": "In the foreground of the image, there is a bathroom sink with a white basin and a silver faucet. The television is mounted on the wall in the background, above the sink. The toilet paper dispenser is located to the right of the television, and the trash can is situated to the left of the television.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24561.7, "ram_available_mb": 38279.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.039, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T09:24:20.099858"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6968.133, "latencies_ms": [6968.133], "images_per_second": 0.144, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "The image shows a bathroom with a large mirror reflecting a television screen displaying a football game. The bathroom has beige tiles on the walls and a granite countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24566.6, "ram_available_mb": 38274.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.184, "power_cpu_cv_mean_watts": 1.554, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T09:24:29.082592"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7251.13, "latencies_ms": [7251.13], "images_per_second": 0.138, "prompt_tokens": 36, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image shows a bathroom with beige tiled walls and a dark brown door. A television is mounted on the wall, displaying a blue-toned image of what appears to be a football game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24566.6, "ram_available_mb": 38274.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24552.3, "ram_available_mb": 38288.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.856, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.935}, "timestamp": "2026-01-23T09:24:38.369370"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12548.967, "latencies_ms": [12548.967], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In this black and white photograph, a solitary figure is captured in a moment of quiet contemplation. The person, dressed in a white shirt and dark pants, is seated on a wooden bench. Their gaze is directed downwards, suggesting a moment of introspection or deep thought.\n\nThe bench is situated in a park, surrounded by lush greenery", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24552.3, "ram_available_mb": 38288.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24588.8, "ram_available_mb": 38252.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.865, "power_cpu_cv_mean_watts": 1.793, "power_sys_5v0_mean_watts": 9.066}, "timestamp": "2026-01-23T09:24:52.968276"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10650.692, "latencies_ms": [10650.692], "images_per_second": 0.094, "prompt_tokens": 39, "response_tokens_est": 60, "n_tiles": 16, "output_text": "1. Bench: 1\n2. Man: 1\n3. Tree: 1\n4. Street lamp: 1\n5. Bush: 1\n6. Hedge: 1\n7. Bush: 1\n8. Bush: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 24588.8, "ram_available_mb": 38252.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24573.5, "ram_available_mb": 38267.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.888, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 9.059}, "timestamp": "2026-01-23T09:25:05.643376"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12558.49, "latencies_ms": [12558.49], "images_per_second": 0.08, "prompt_tokens": 44, "response_tokens_est": 78, "n_tiles": 16, "output_text": "In the foreground, there is a person sitting on a bench, positioned on the left side of the image. The bench is located in a park-like setting with trees and bushes around it. In the background, there is a tall clock tower with a steeple, situated behind the trees and bushes, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24573.5, "ram_available_mb": 38267.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24545.4, "ram_available_mb": 38295.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.904, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 9.075}, "timestamp": "2026-01-23T09:25:20.230026"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8484.952, "latencies_ms": [8484.952], "images_per_second": 0.118, "prompt_tokens": 37, "response_tokens_est": 41, "n_tiles": 16, "output_text": "A man is sitting on a bench in a park-like setting with a tall clock tower in the background. The scene is in black and white, giving it a timeless and classic feel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.4, "ram_available_mb": 38295.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.926, "power_cpu_cv_mean_watts": 1.465, "power_sys_5v0_mean_watts": 9.094}, "timestamp": "2026-01-23T09:25:30.767546"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 12617.885, "latencies_ms": [12617.885], "images_per_second": 0.079, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image is a black and white photograph, giving it a timeless and classic feel. The lighting is soft and natural, with the sunlight filtering through the trees and casting shadows on the ground. The weather appears to be overcast, with a cloudy sky and no visible sun. The photograph is taken in a park-like setting, with a man sitting on a bench in", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 24553.2, "ram_available_mb": 38287.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.086, "power_cpu_cv_mean_watts": 2.006, "power_sys_5v0_mean_watts": 9.105}, "timestamp": "2026-01-23T09:25:45.398366"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11352.477, "latencies_ms": [11352.477], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a bustling street scene under a clear blue sky. A row of cars, each with its own unique color and model, are parked neatly along the side of the road. The cars are of various sizes and colors, including white, black, and silver. They are parked in an orderly fashion, with some closer to the foreground and others further in", "error": null, "sys_before": {"cpu_percent": 18.5, "ram_used_mb": 24553.2, "ram_available_mb": 38287.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.617, "power_cpu_cv_mean_watts": 2.184, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T09:25:58.808534"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7398.374, "latencies_ms": [7398.374], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "car: 8, truck: 2, person: 3, building: 1, sign: 2, tree: 1, street light: 1, bus stop: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24561.4, "ram_available_mb": 38279.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.899, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.888}, "timestamp": "2026-01-23T09:26:08.219145"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11355.339, "latencies_ms": [11355.339], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a busy street scene with multiple cars and a bus, indicating a high-traffic area. The cars are parked and in motion, with some near the bus stop and others further down the road. In the background, there is a large stone wall, which appears to be part of a historical or significant building, adding to the urban environment. The sky is", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24561.4, "ram_available_mb": 38279.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24557.7, "ram_available_mb": 38283.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.546, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T09:26:21.614564"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7392.939, "latencies_ms": [7392.939], "images_per_second": 0.135, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image depicts a busy street scene with multiple cars and a bus stopped at a bus stop. There are several people walking on the sidewalk, and a stone wall can be seen in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24557.7, "ram_available_mb": 38283.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24547.3, "ram_available_mb": 38293.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.877, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T09:26:31.023027"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8478.45, "latencies_ms": [8478.45], "images_per_second": 0.118, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image shows a clear blue sky with sunlight casting shadows on the road, indicating it is a sunny day. The road is paved with asphalt, and there are multiple vehicles, including cars and a bus, indicating a busy traffic scenario.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24547.3, "ram_available_mb": 38293.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24551.2, "ram_available_mb": 38289.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.731, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.91}, "timestamp": "2026-01-23T09:26:41.543693"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11345.218, "latencies_ms": [11345.218], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of tranquility, featuring a wooden table set for a meal. On the table, there's a white plate holding a slice of pizza, a bowl filled with an assortment of fruits including bananas, apples, and watermelon, and a white cup filled with a red liquid, possibly juice or wine. The", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 24551.2, "ram_available_mb": 38289.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24547.2, "ram_available_mb": 38293.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.572, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T09:26:54.946449"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7868.418, "latencies_ms": [7868.418], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "plate: 2, cup: 2, spoon: 1, fork: 2, knife: 1, bowl: 1, watermelon: 1, banana: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24547.2, "ram_available_mb": 38293.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.547, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 8.883}, "timestamp": "2026-01-23T09:27:04.858966"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11351.261, "latencies_ms": [11351.261], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The main objects are arranged on a wooden table. In the foreground, there is a white plate with a folded omelette and a slice being lifted, a bowl of fruit salad with a fork and knife, and a cup of tea in the background. The table is positioned on a tiled floor, and the shadows of the objects are cast on the floor,", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.559, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T09:27:18.248308"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7405.911, "latencies_ms": [7405.911], "images_per_second": 0.135, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image shows a wooden table with a plate of food and a cup of tea on it. The table is placed on a tiled floor, and there is a shadow of a person visible on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.701, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T09:27:27.700473"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7233.01, "latencies_ms": [7233.01], "images_per_second": 0.138, "prompt_tokens": 36, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image shows a wooden table with a plate of food and a cup of tea on it. The lighting is natural, coming from the top left corner, casting shadows on the table and the floor.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24528.1, "ram_available_mb": 38312.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.579, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.945}, "timestamp": "2026-01-23T09:27:36.982085"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11344.33, "latencies_ms": [11344.33], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 80, "n_tiles": 16, "output_text": "In the image, an elderly woman is standing at a dining table, cutting dough with a knife. The table is filled with various food items, including rolls, cookies, and a pizza. There are also cups and a bowl on the table. The woman is wearing an apron, and the scene appears to be a kitchen or dining area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24528.1, "ram_available_mb": 38312.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24531.5, "ram_available_mb": 38309.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.612, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T09:27:50.385244"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10866.235, "latencies_ms": [10866.235], "images_per_second": 0.092, "prompt_tokens": 39, "response_tokens_est": 73, "n_tiles": 16, "output_text": "- Bread: 12\n\n- Cookie cutter: 1\n\n- Cookie dough: 1\n\n- Baking sheet: 1\n\n- Baking pan: 1\n\n- Baking powder: 1\n\n- Flour: 1\n\n- Rolling pin: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24531.5, "ram_available_mb": 38309.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.931, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T09:28:03.282486"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10245.113, "latencies_ms": [10245.113], "images_per_second": 0.098, "prompt_tokens": 44, "response_tokens_est": 69, "n_tiles": 16, "output_text": "In the foreground, there is a table with various baked goods and items scattered across its surface. To the left, a person is standing and appears to be reaching for something on the table. In the background, there is a couch and a door, suggesting that the table is located in a living room or dining area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24532.3, "ram_available_mb": 38308.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.937, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T09:28:15.547300"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8095.814, "latencies_ms": [8095.814], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "An elderly woman is standing at a kitchen table, cutting dough with a knife. The table is covered with various baked goods, including rolls and cookies, and there are cups and a bowl on the table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24532.3, "ram_available_mb": 38308.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24527.9, "ram_available_mb": 38313.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.382, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T09:28:25.663371"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10008.924, "latencies_ms": [10008.924], "images_per_second": 0.1, "prompt_tokens": 36, "response_tokens_est": 67, "n_tiles": 16, "output_text": "The image shows an indoor setting with warm lighting, likely from artificial sources, as there are no visible windows or natural light. The table is covered with a patterned tablecloth, and the person is wearing a striped shirt with a pink apron, suggesting a casual, homey atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24527.9, "ram_available_mb": 38313.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24528.1, "ram_available_mb": 38312.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.162, "power_cpu_cv_mean_watts": 1.856, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T09:28:37.722455"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11322.213, "latencies_ms": [11322.213], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is standing in front of a traffic light, which is currently displaying a red light. The man is wearing a white shirt and shorts, and he appears to be smiling. The traffic light is positioned on the right side of the image.\n\nThe scene is set in a lush, green environment with various plants surrounding the man and the traffic", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24528.1, "ram_available_mb": 38312.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24524.4, "ram_available_mb": 38316.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.59, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T09:28:51.096598"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8804.952, "latencies_ms": [8804.952], "images_per_second": 0.114, "prompt_tokens": 39, "response_tokens_est": 55, "n_tiles": 16, "output_text": "- Man: 1\n- Traffic light: 1\n- Bushes: 1\n- Flowers: 1\n- Sign: 1\n- Gravel: 1\n- Sandals: 1\n- Pole: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24524.4, "ram_available_mb": 38316.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24527.4, "ram_available_mb": 38313.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.968, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T09:29:01.939691"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11398.338, "latencies_ms": [11398.338], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 80, "n_tiles": 16, "output_text": "A man is standing in the foreground on the left side of the image, near a traffic light that is in the middle ground. The traffic light is positioned between the man and a sign that reads \"AUSTRALIA TRAFFIC LIGHT\" in the background. There are plants and shrubs surrounding the scene, with some in the background and others in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24527.4, "ram_available_mb": 38313.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24530.2, "ram_available_mb": 38310.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.666, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T09:29:15.365791"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6847.05, "latencies_ms": [6847.05], "images_per_second": 0.146, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A man is standing in front of a traffic light that is showing a red signal. The traffic light is located in a tropical setting with lush green foliage in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24530.2, "ram_available_mb": 38310.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.333, "power_cpu_cv_mean_watts": 1.553, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T09:29:24.254918"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6811.018, "latencies_ms": [6811.018], "images_per_second": 0.147, "prompt_tokens": 36, "response_tokens_est": 39, "n_tiles": 16, "output_text": "A man wearing a white t-shirt and khaki shorts stands in front of a traffic light. The traffic light is red and there are green plants in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24523.3, "ram_available_mb": 38317.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.182, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.956}, "timestamp": "2026-01-23T09:29:33.099799"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11347.879, "latencies_ms": [11347.879], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a large group of colorful kites flying in the sky, creating a vibrant and lively scene. The kites are of various shapes and sizes, with some resembling fish and others resembling birds. They are spread across the sky, with some kites flying higher and others lower.\n\nThere are several people in the image, likely enjoying the", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 24523.3, "ram_available_mb": 38317.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24528.6, "ram_available_mb": 38312.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.509, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T09:29:46.494550"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9581.528, "latencies_ms": [9581.528], "images_per_second": 0.104, "prompt_tokens": 39, "response_tokens_est": 62, "n_tiles": 16, "output_text": "Kites: 10\nFish-shaped kites: 5\nFlagpoles: 10\nGrassy field: 1\nBuilding in background: 1\nPeople: 10\nBags: 1\nCooler: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24528.6, "ram_available_mb": 38312.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.57, "power_cpu_cv_mean_watts": 2.032, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T09:29:58.099727"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9490.127, "latencies_ms": [9490.127], "images_per_second": 0.105, "prompt_tokens": 44, "response_tokens_est": 63, "n_tiles": 16, "output_text": "The colorful kites are flying in the sky, with some positioned higher and others lower. The kites are spread out across the field, with some closer to the foreground and others further away in the background. The kites are flying in different directions, creating a dynamic and lively scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.336, "power_cpu_cv_mean_watts": 2.19, "power_sys_5v0_mean_watts": 8.925}, "timestamp": "2026-01-23T09:30:09.644290"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7057.835, "latencies_ms": [7057.835], "images_per_second": 0.142, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "A group of colorful kites resembling fish are flying in the sky above a grassy field. People are gathered on the ground, enjoying the kite-flying event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.113, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 8.937}, "timestamp": "2026-01-23T09:30:18.734771"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6863.105, "latencies_ms": [6863.105], "images_per_second": 0.146, "prompt_tokens": 36, "response_tokens_est": 40, "n_tiles": 16, "output_text": "The kites in the image are predominantly red, white, and purple, with some blue accents. They are flying in a cloudy sky, suggesting overcast weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24553.2, "ram_available_mb": 38287.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.826, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.942}, "timestamp": "2026-01-23T09:30:27.625046"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11326.087, "latencies_ms": [11326.087], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man and a young boy are sitting on the floor, sharing a slice of pizza. The man is wearing a blue shirt and the boy is wearing a blue sweater. They are both focused on the pizza, with the man holding the slice and the boy looking at it. The pizza is placed on a red tray. In the background,", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24553.2, "ram_available_mb": 38287.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.666, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T09:30:41.012615"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8551.883, "latencies_ms": [8551.883], "images_per_second": 0.117, "prompt_tokens": 39, "response_tokens_est": 53, "n_tiles": 16, "output_text": "- Man: 1\n- Child: 1\n- Pizza slice: 1\n- Bottle: 1\n- Toy: 1\n- Chair: 1\n- Couch: 1\n- Box: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24543.7, "ram_available_mb": 38297.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.06, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T09:30:51.600630"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11338.787, "latencies_ms": [11338.787], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a man in a blue patterned jacket is seated on the floor, holding a slice of pizza towards a young child who is standing in front of him. The child, wearing a blue sweatshirt, is looking down at the pizza with interest. In the background, there is a couch with a red blanket and a green object with", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.7, "ram_available_mb": 38297.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.573, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T09:31:04.957225"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7514.669, "latencies_ms": [7514.669], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A man and a young child are sitting on the floor, sharing a slice of pizza. The man is wearing a blue patterned jacket and the child is wearing a blue sweatshirt.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24540.3, "ram_available_mb": 38300.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.741, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T09:31:14.513837"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7538.525, "latencies_ms": [7538.525], "images_per_second": 0.133, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image shows a man and a child sitting indoors with a bottle of water on the table. The man is wearing a blue patterned jacket and the child is in a blue sweatshirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.3, "ram_available_mb": 38300.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24539.3, "ram_available_mb": 38301.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.494, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 8.95}, "timestamp": "2026-01-23T09:31:24.105717"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11350.426, "latencies_ms": [11350.426], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a woman is sitting in a camping chair, enjoying a meal outdoors. She is holding a hot dog in her hand and has a plate of chips in front of her. The woman appears to be eating the hot dog while looking at the camera. The setting is a camping area, with a backpack placed nearby, indicating that she might be", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 24539.3, "ram_available_mb": 38301.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24537.9, "ram_available_mb": 38303.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.555, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.824}, "timestamp": "2026-01-23T09:31:37.492908"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7740.056, "latencies_ms": [7740.056], "images_per_second": 0.129, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "person: 1, plate: 1, tortilla chip: 1, bite of food: 1, chair: 1, backpack: 1, rocks: 5, branches: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.9, "ram_available_mb": 38303.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24541.2, "ram_available_mb": 38299.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.42, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T09:31:47.256873"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9728.489, "latencies_ms": [9728.489], "images_per_second": 0.103, "prompt_tokens": 44, "response_tokens_est": 65, "n_tiles": 16, "output_text": "The person is seated in the foreground on the left side of the image, holding a sandwich near their mouth. In the background, there is a plate with what appears to be tortilla chips on the right side, and the setting seems to be outdoors with rocks and foliage around.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24541.2, "ram_available_mb": 38299.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.249, "power_cpu_cv_mean_watts": 1.836, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T09:31:59.001391"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8099.048, "latencies_ms": [8099.048], "images_per_second": 0.123, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A person is sitting in a camping chair outdoors at night, eating a hot dog and enjoying a plate of tortilla chips. The setting appears to be a campsite with a natural, outdoor environment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.203, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.872}, "timestamp": "2026-01-23T09:32:09.137833"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8116.271, "latencies_ms": [8116.271], "images_per_second": 0.123, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows a person sitting outdoors at night, illuminated by the light of a campfire. The person is wearing a striped, long-sleeved shirt and is seated on a blue camping chair.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.027, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 8.91}, "timestamp": "2026-01-23T09:32:19.299029"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11401.551, "latencies_ms": [11401.551], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a large group of people gathered around a dining table, enjoying a meal together. There are at least 13 people in the scene, with some sitting and others standing. The table is filled with various food items, including multiple plates of food, bowls, and cups. \n\nThe dining table is covered with a purple tablecloth", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.496, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 8.806}, "timestamp": "2026-01-23T09:32:32.730073"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9899.118, "latencies_ms": [9899.118], "images_per_second": 0.101, "prompt_tokens": 39, "response_tokens_est": 65, "n_tiles": 16, "output_text": "- People: 15\n- Plates: 20\n- Glasses: 10\n- Wine glasses: 5\n- Wine bottles: 2\n- Silverware: 15\n- Dishes: 10\n- Fruits: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.36, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T09:32:44.655724"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11335.546, "latencies_ms": [11335.546], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a long dining table is filled with plates of food, glasses, and cutlery, indicating a family gathering. The people are seated around the table, with some standing in the background, suggesting a casual and intimate atmosphere. The table is the central focus of the image, with the people arranged around it, creating a sense of togeth", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24531.8, "ram_available_mb": 38309.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.657, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T09:32:58.010597"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7977.493, "latencies_ms": [7977.493], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "A large group of people are gathered around a long dining table, enjoying a meal together. The table is filled with various dishes, drinks, and utensils, indicating a festive or celebratory occasion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24531.8, "ram_available_mb": 38309.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24527.2, "ram_available_mb": 38313.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.392, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T09:33:08.027893"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11322.589, "latencies_ms": [11322.589], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image shows a group of people gathered around a long dining table covered with a purple tablecloth. The table is set with various dishes, glasses, and utensils, indicating a meal is being shared. The lighting in the room is warm and natural, coming from the windows in the background, creating a cozy and inviting atmosphere. The materials used for", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24527.2, "ram_available_mb": 38313.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24539.2, "ram_available_mb": 38301.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.613, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T09:33:21.392156"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11324.748, "latencies_ms": [11324.748], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment from a baseball game. The central focus is a baseball player, dressed in a black uniform, who is sliding into a base. The base is marked by a white line on the dirt ground. The player's body is parallel to the ground, and his legs are extended, indicating a swift movement. \n\nIn the background, there are other players", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.2, "ram_available_mb": 38301.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24533.4, "ram_available_mb": 38307.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.661, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.826}, "timestamp": "2026-01-23T09:33:34.741504"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9232.314, "latencies_ms": [9232.314], "images_per_second": 0.108, "prompt_tokens": 39, "response_tokens_est": 59, "n_tiles": 16, "output_text": "players: 4, catcher: 1, umpire: 1, batter: 1, pitcher: 1, home plate: 1, base: 1, fence: 1, trash can: 1, bench: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24533.4, "ram_available_mb": 38307.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.556, "power_cpu_cv_mean_watts": 1.789, "power_sys_5v0_mean_watts": 8.835}, "timestamp": "2026-01-23T09:33:45.994699"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11228.66, "latencies_ms": [11228.66], "images_per_second": 0.089, "prompt_tokens": 44, "response_tokens_est": 78, "n_tiles": 16, "output_text": "In the foreground, a baseball player is sliding into a base, with the base and home plate clearly visible. The catcher and umpire are in the middle ground, closely positioned to the action at the plate. In the background, spectators are seated on bleachers, and a blue trash can is visible on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24536.7, "ram_available_mb": 38304.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.683, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T09:33:59.246769"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8093.145, "latencies_ms": [8093.145], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image captures a moment during a baseball game on a field with a dirt infield and a grass outfield. A player is sliding into home plate while another player, the catcher, is attempting to tag him out.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24536.7, "ram_available_mb": 38304.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 24536.5, "ram_available_mb": 38304.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.202, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T09:34:09.390481"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10515.748, "latencies_ms": [10515.748], "images_per_second": 0.095, "prompt_tokens": 36, "response_tokens_est": 72, "n_tiles": 16, "output_text": "The image captures a baseball game in progress under clear skies, with the sun casting shadows on the field, which is a vibrant green with a red dirt infield. The players are wearing a mix of dark and light-colored uniforms, and the stands in the background are mostly empty with a few spectators.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 24536.5, "ram_available_mb": 38304.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 24563.8, "ram_available_mb": 38277.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.885, "power_cpu_cv_mean_watts": 2.39, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T09:34:21.965144"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12514.249, "latencies_ms": [12514.249], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a dynamic scene at a skatepark. A skateboarder, clad in a black t-shirt and helmet, is in the midst of performing a trick on a concrete ramp. The skateboarder's body is angled towards the ground, with one foot on the skateboard and the other extended outwards, suggesting a moment of", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24563.8, "ram_available_mb": 38277.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 24599.9, "ram_available_mb": 38241.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.971, "power_cpu_cv_mean_watts": 1.909, "power_sys_5v0_mean_watts": 9.089}, "timestamp": "2026-01-23T09:34:36.505078"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8697.329, "latencies_ms": [8697.329], "images_per_second": 0.115, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "skateboard: 1, person: 1, fence: 2, trees: 3, grass: 2, buildings: 1, sky: 1, shadow: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24599.9, "ram_available_mb": 38241.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 24552.0, "ram_available_mb": 38288.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.834, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 9.111}, "timestamp": "2026-01-23T09:34:47.226890"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11796.587, "latencies_ms": [11796.587], "images_per_second": 0.085, "prompt_tokens": 44, "response_tokens_est": 72, "n_tiles": 16, "output_text": "The skateboarder is in the foreground, performing a trick on a concrete ramp. The railing is in the middle ground, and the grassy area with trees is in the background. The shadow of the skateboarder is cast on the ramp, indicating the light source is coming from the upper left side of the image.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24552.0, "ram_available_mb": 38288.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24599.3, "ram_available_mb": 38241.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.321, "power_cpu_cv_mean_watts": 1.738, "power_sys_5v0_mean_watts": 9.138}, "timestamp": "2026-01-23T09:35:01.060065"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7681.07, "latencies_ms": [7681.07], "images_per_second": 0.13, "prompt_tokens": 37, "response_tokens_est": 34, "n_tiles": 16, "output_text": "A person is skateboarding at a skate park, performing a trick on a rail. The skate park is surrounded by trees and grassy areas.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24599.3, "ram_available_mb": 38241.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 24553.7, "ram_available_mb": 38287.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.55, "power_cpu_cv_mean_watts": 1.3, "power_sys_5v0_mean_watts": 9.123}, "timestamp": "2026-01-23T09:35:10.773748"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 12149.326, "latencies_ms": [12149.326], "images_per_second": 0.082, "prompt_tokens": 36, "response_tokens_est": 75, "n_tiles": 16, "output_text": "The image captures a skateboarder in mid-air, performing a trick at a skatepark. The skateboarder is wearing a black helmet and t-shirt, and the skatepark has a concrete surface with some graffiti. The weather appears to be sunny and clear, with shadows cast on the ground.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24553.7, "ram_available_mb": 38287.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24591.2, "ram_available_mb": 38249.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.227, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 9.072}, "timestamp": "2026-01-23T09:35:24.954766"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11421.188, "latencies_ms": [11421.188], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a dining table with a plate of food placed on it. The plate contains a variety of items, including a sandwich, fries, and a salad. The sandwich is accompanied by a side of fries, and the salad consists of a tomato and a pickle. There are also two bottles of condiments, possibly ketchup and mustard", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24591.2, "ram_available_mb": 38249.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.418, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.819}, "timestamp": "2026-01-23T09:35:38.408306"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10383.237, "latencies_ms": [10383.237], "images_per_second": 0.096, "prompt_tokens": 39, "response_tokens_est": 69, "n_tiles": 16, "output_text": "- Fries: 12\n\n- Bread: 1\n\n- Meat patty: 1\n\n- Tomato: 1\n\n- Lettuce: 1\n\n- Pickles: 1\n\n- Mayonnaise: 2\n\n- Ketchup: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.126, "power_cpu_cv_mean_watts": 1.861, "power_sys_5v0_mean_watts": 8.824}, "timestamp": "2026-01-23T09:35:50.850532"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11326.982, "latencies_ms": [11326.982], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "On the left side of the image, there is a plate with a burger and fries, which is positioned in the foreground and appears to be the main focus of the meal. In the background, there is a plate with a salad, containing lettuce, tomato, and pickles, which is slightly less prominent. The bottles of condiments are placed on the", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24541.9, "ram_available_mb": 38299.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.608, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T09:36:04.207790"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8800.491, "latencies_ms": [8800.491], "images_per_second": 0.114, "prompt_tokens": 37, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image shows a meal consisting of a hamburger, French fries, and a side salad with a slice of lemon on a table. There are also condiment bottles and a glass of water on the table, suggesting a dining setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.9, "ram_available_mb": 38299.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24543.4, "ram_available_mb": 38297.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.809, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T09:36:15.051601"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9714.963, "latencies_ms": [9714.963], "images_per_second": 0.103, "prompt_tokens": 36, "response_tokens_est": 65, "n_tiles": 16, "output_text": "The image shows a meal on a table with a white plate containing a hamburger, fries, and a side of pickles and tomato, accompanied by a glass of water and condiment bottles. The lighting appears to be artificial, and the table has a textured white tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.4, "ram_available_mb": 38297.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24549.3, "ram_available_mb": 38291.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.19, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 8.88}, "timestamp": "2026-01-23T09:36:26.798831"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 8353.504, "latencies_ms": [8353.504], "images_per_second": 0.12, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image shows a red Harley Davidson motorcycle parked on a paved area with a sandy beach in the background. There are palm trees and a wooden fence visible. The sky is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 24549.3, "ram_available_mb": 38291.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.95, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 8.931}, "timestamp": "2026-01-23T09:36:37.219574"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8002.416, "latencies_ms": [8002.416], "images_per_second": 0.125, "prompt_tokens": 39, "response_tokens_est": 48, "n_tiles": 16, "output_text": "motorcycle: 1, palm tree: 3, fence post: 1, fence: 1, sand dune: 1, grass: 1, sky: 1, shadow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.8, "ram_available_mb": 38296.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24541.2, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.388, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T09:36:47.268266"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8242.388, "latencies_ms": [8242.388], "images_per_second": 0.121, "prompt_tokens": 44, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The motorcycle is parked in the foreground on the right side of the image, near the center. The palm trees are in the background, behind the motorcycle, and there is a wooden fence to the right of the motorcycle.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 24541.2, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24552.0, "ram_available_mb": 38288.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.954, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 8.917}, "timestamp": "2026-01-23T09:36:57.546572"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8416.572, "latencies_ms": [8416.572], "images_per_second": 0.119, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "A red motorcycle with a sidecar is parked on a paved area near a wooden fence, with palm trees and a sandy beach in the background. The sky is clear and blue, suggesting a sunny day at the beach.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.041, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T09:37:08.003061"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6742.821, "latencies_ms": [6742.821], "images_per_second": 0.148, "prompt_tokens": 36, "response_tokens_est": 39, "n_tiles": 16, "output_text": "The motorcycle is red and black, parked on a sunny day with clear blue skies. The sand is light beige, and there are palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24536.9, "ram_available_mb": 38304.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.073, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.942}, "timestamp": "2026-01-23T09:37:16.801937"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11341.872, "latencies_ms": [11341.872], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of quiet introspection. A man, dressed in a formal black suit and tie, stands against a stark white wall. His face is turned away from the camera, suggesting a moment of contemplation or perhaps a desire for privacy. The lighting in the room is dim, casting a soft glow on his suit and creating a sense of solitude. The", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 24536.9, "ram_available_mb": 38304.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24539.4, "ram_available_mb": 38301.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.582, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 8.818}, "timestamp": "2026-01-23T09:37:30.190664"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7050.062, "latencies_ms": [7050.062], "images_per_second": 0.142, "prompt_tokens": 39, "response_tokens_est": 40, "n_tiles": 16, "output_text": "object: 1, object: 1, object: 1, object: 1, object: 1, object: 1, object: 1, object: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24539.4, "ram_available_mb": 38301.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24532.1, "ram_available_mb": 38308.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.034, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T09:37:39.283007"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11346.765, "latencies_ms": [11346.765], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The man is positioned in the foreground of the image, with his upper body and attire in clear focus. The electrical outlet is located on the wall in the background, slightly to the left of the man's body. The man is standing close to the wall, with a small gap between his suit jacket and the wall, indicating he is not too far from the background", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24532.1, "ram_available_mb": 38308.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24526.4, "ram_available_mb": 38314.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.614, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T09:37:52.647674"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6724.282, "latencies_ms": [6724.282], "images_per_second": 0.149, "prompt_tokens": 37, "response_tokens_est": 37, "n_tiles": 16, "output_text": "A man in a dark suit with a white shirt and a patterned tie is standing in a dimly lit room. The light switch is visible on the wall behind him.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24526.4, "ram_available_mb": 38314.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24534.6, "ram_available_mb": 38306.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.371, "power_cpu_cv_mean_watts": 1.538, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T09:38:01.387151"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7186.862, "latencies_ms": [7186.862], "images_per_second": 0.139, "prompt_tokens": 36, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image shows a person wearing a dark suit with a white shirt and a patterned tie. The lighting is dim, highlighting the person's attire and creating a moody atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.6, "ram_available_mb": 38306.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24527.8, "ram_available_mb": 38313.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.753, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.954}, "timestamp": "2026-01-23T09:38:10.588653"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11357.009, "latencies_ms": [11357.009], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a gray and white cat is peacefully sleeping on a pair of shoes. The cat is curled up, with its head resting on the shoes, and its eyes closed. The shoes are placed on a wooden floor, and the cat is positioned in the center of the image. The background features a white wall, providing a neutral backdrop that contrast", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24527.8, "ram_available_mb": 38313.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 24535.4, "ram_available_mb": 38305.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.572, "power_cpu_cv_mean_watts": 1.982, "power_sys_5v0_mean_watts": 8.835}, "timestamp": "2026-01-23T09:38:23.998167"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4426.824, "latencies_ms": [4426.824], "images_per_second": 0.226, "prompt_tokens": 39, "response_tokens_est": 17, "n_tiles": 16, "output_text": "shoe: 2\ncat: 1\nwall: 1\n", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.4, "ram_available_mb": 38305.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 24538.6, "ram_available_mb": 38302.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.731, "power_cpu_cv_mean_watts": 1.613, "power_sys_5v0_mean_watts": 9.06}, "timestamp": "2026-01-23T09:38:30.460618"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11359.633, "latencies_ms": [11359.633], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The cat is resting on top of a shoe, which is placed on the ground in the foreground of the image. The shoe is positioned to the left of the image, and there is a white wall in the background. The cat is near the front edge of the image, and the shoe is in the immediate foreground, making the cat appear to be closer to the", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24539.0, "ram_available_mb": 38301.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 24528.5, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.638, "power_cpu_cv_mean_watts": 2.244, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T09:38:43.836891"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6350.677, "latencies_ms": [6350.677], "images_per_second": 0.157, "prompt_tokens": 37, "response_tokens_est": 34, "n_tiles": 16, "output_text": "A cat is sleeping peacefully on a pair of shoes. The shoes are placed on a wooden surface, and the background is a plain white wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24528.5, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.737, "power_cpu_cv_mean_watts": 1.52, "power_sys_5v0_mean_watts": 8.96}, "timestamp": "2026-01-23T09:38:52.245852"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7887.361, "latencies_ms": [7887.361], "images_per_second": 0.127, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image features a gray and white cat with a white chest and paws, sleeping on a pair of blue and white sneakers. The cat is resting on a wooden surface, with a white wall in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.175, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 8.921}, "timestamp": "2026-01-23T09:39:02.170387"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11343.119, "latencies_ms": [11343.119], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a vibrant scene on a city street. Dominating the frame is a large green dump truck, its body adorned with a red and white striped pattern on the front bumper. The truck is in motion, driving on the right side of the road, as indicated by the white line on the left side of the image. \n\nOn", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24535.4, "ram_available_mb": 38305.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.629, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T09:39:15.539632"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7628.542, "latencies_ms": [7628.542], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "truck: 1, people: 3, buildings: 2, trees: 2, vehicles: 2, traffic lights: 1, signs: 2, pedestrians: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24535.4, "ram_available_mb": 38305.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24532.5, "ram_available_mb": 38308.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.682, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.888}, "timestamp": "2026-01-23T09:39:25.202570"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11348.332, "latencies_ms": [11348.332], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The green truck is in the foreground of the image, occupying the lower half of the frame, and is positioned on the right side of the road. There are two individuals on the truck's bed, with one seated on the left side and the other on the right, both facing forward. In the background, there is a red bus on the left side and a", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24532.5, "ram_available_mb": 38308.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24535.7, "ram_available_mb": 38305.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.613, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T09:39:38.561988"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8648.481, "latencies_ms": [8648.481], "images_per_second": 0.116, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "A green Isuzu truck with a red and white striped front bumper is on a city street. There are two people sitting on the back of the truck, one wearing a yellow hat and the other wearing a green jacket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.7, "ram_available_mb": 38305.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.85, "power_cpu_cv_mean_watts": 1.759, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T09:39:49.231460"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8553.018, "latencies_ms": [8553.018], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "A green Isuzu FTR truck with a red and white striped front bumper is on the road. The truck has a license plate that reads \"77-6921\" and is marked with the logo of \"Thailand\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.8, "ram_available_mb": 38301.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.871, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 8.927}, "timestamp": "2026-01-23T09:39:59.824364"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12327.144, "latencies_ms": [12327.144], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a bird is standing on a rocky shore near a river. The bird is positioned in the center of the scene, surrounded by various rocks and pebbles. The river appears to be shallow, with the bird standing on the rocks close to the water's edge.\n\nIn the background, there is a bridge spanning across the river, with multiple cars", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.635, "power_cpu_cv_mean_watts": 1.808, "power_sys_5v0_mean_watts": 9.037}, "timestamp": "2026-01-23T09:40:14.200303"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7548.798, "latencies_ms": [7548.798], "images_per_second": 0.132, "prompt_tokens": 39, "response_tokens_est": 35, "n_tiles": 16, "output_text": "rocks: numerous\nwater: river\ntrees: greenery\nbridge: overpass\ncars: on bridge\nbird: standing on rocks\nfish: in water", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 24577.7, "ram_available_mb": 38263.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.975, "power_cpu_cv_mean_watts": 1.339, "power_sys_5v0_mean_watts": 9.04}, "timestamp": "2026-01-23T09:40:23.811290"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12267.07, "latencies_ms": [12267.07], "images_per_second": 0.082, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a rocky riverbed with various sized rocks scattered across the water's surface. Further back, on the riverbank, there is a bridge spanning across the river, with vegetation growing on the banks. The bird is standing on the rocks in the middle ground, closer to the camera than the bridge, but further away from the camera than the rocks", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24577.7, "ram_available_mb": 38263.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.655, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 9.033}, "timestamp": "2026-01-23T09:40:38.113149"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7999.686, "latencies_ms": [7999.686], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "The image depicts a serene river scene with a bridge in the background and a bird standing on the rocky shore. The bird appears to be searching for food among the rocks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24577.4, "ram_available_mb": 38263.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.649, "power_cpu_cv_mean_watts": 1.399, "power_sys_5v0_mean_watts": 9.031}, "timestamp": "2026-01-23T09:40:48.150793"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8034.48, "latencies_ms": [8034.48], "images_per_second": 0.124, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image depicts a serene river scene with a bridge in the background and a clear sky above. The river is filled with rocks and boulders, and the water appears calm and still.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24577.4, "ram_available_mb": 38263.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24533.8, "ram_available_mb": 38307.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.327, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 9.117}, "timestamp": "2026-01-23T09:40:58.203914"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11360.563, "latencies_ms": [11360.563], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a row of parked motor scooters lined up along a street. There are at least 13 motor scooters visible, with some positioned closer to the camera and others further away. The scooters are parked in a neat row, occupying a significant portion of the street.\n\nIn addition to the motor scooters, there are several", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24533.8, "ram_available_mb": 38307.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24525.7, "ram_available_mb": 38315.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.596, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T09:41:11.605286"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8429.863, "latencies_ms": [8429.863], "images_per_second": 0.119, "prompt_tokens": 39, "response_tokens_est": 52, "n_tiles": 16, "output_text": "- scooters: 10\n- people: 5\n- buildings: 2\n- windows: 14\n- doors: 2\n- signs: 3\n- trees: 1\n- plants: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24525.7, "ram_available_mb": 38315.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24531.6, "ram_available_mb": 38309.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.01, "power_cpu_cv_mean_watts": 1.709, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T09:41:22.050371"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11388.919, "latencies_ms": [11388.919], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a row of scooters parked on the side of the street, with the closest scooters being nearest to the viewer and the farthest ones being the last in the row. The background features a building with a red awning and a sign that reads \"BAR BRASERIE.\" There are also several people walking on the sidewalk", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24531.6, "ram_available_mb": 38309.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24527.1, "ram_available_mb": 38313.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.465, "power_cpu_cv_mean_watts": 1.938, "power_sys_5v0_mean_watts": 8.817}, "timestamp": "2026-01-23T09:41:35.473339"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8543.527, "latencies_ms": [8543.527], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image depicts a street scene with a row of parked scooters and motorcycles in front of a building with a red awning. There are several people walking on the sidewalk and a few individuals standing near the parked vehicles.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24527.1, "ram_available_mb": 38313.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24531.9, "ram_available_mb": 38309.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.991, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T09:41:46.058657"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7645.657, "latencies_ms": [7645.657], "images_per_second": 0.131, "prompt_tokens": 36, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The image shows a row of scooters parked on a street, with a variety of colors including black, silver, and green. The weather appears to be overcast, with no direct sunlight visible in the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24531.9, "ram_available_mb": 38309.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24528.9, "ram_available_mb": 38312.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.295, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.932}, "timestamp": "2026-01-23T09:41:55.720793"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 10306.926, "latencies_ms": [10306.926], "images_per_second": 0.097, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The image shows a close-up of a person's hand holding a piece of broccoli. The broccoli is green with a few brown spots, indicating it may be slightly overripe or cooked. The background is blurred, but it appears to be a kitchen setting with a tiled backsplash.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24528.9, "ram_available_mb": 38312.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24527.6, "ram_available_mb": 38313.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.933, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T09:42:08.082753"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7056.547, "latencies_ms": [7056.547], "images_per_second": 0.142, "prompt_tokens": 39, "response_tokens_est": 40, "n_tiles": 16, "output_text": "object: 1, object: 1, object: 1, object: 1, object: 1, object: 1, object: 1, object: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24527.6, "ram_available_mb": 38313.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24524.2, "ram_available_mb": 38316.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.235, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.899}, "timestamp": "2026-01-23T09:42:17.194055"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10420.801, "latencies_ms": [10420.801], "images_per_second": 0.096, "prompt_tokens": 44, "response_tokens_est": 71, "n_tiles": 16, "output_text": "The main object, which is a piece of broccoli, is held in the foreground of the image, appearing large and in focus. It is positioned in the center of the image, with a blurred background that suggests a kitchen setting. The broccoli is held up, indicating it is the primary subject of the photo.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24524.2, "ram_available_mb": 38316.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24519.7, "ram_available_mb": 38321.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.921, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T09:42:29.653794"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6701.415, "latencies_ms": [6701.415], "images_per_second": 0.149, "prompt_tokens": 37, "response_tokens_est": 37, "n_tiles": 16, "output_text": "A person is holding a piece of broccoli with a mushroom attached to it, against a backdrop of a kitchen with a black pot and a tiled wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24519.7, "ram_available_mb": 38321.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 24530.7, "ram_available_mb": 38310.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.255, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 8.979}, "timestamp": "2026-01-23T09:42:38.410339"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9485.736, "latencies_ms": [9485.736], "images_per_second": 0.105, "prompt_tokens": 36, "response_tokens_est": 63, "n_tiles": 16, "output_text": "The image shows a close-up of a hand holding a piece of broccoli with a dark, possibly roasted, mushroom on top. The lighting is bright and appears to be coming from the upper left, casting a shadow to the right of the broccoli and mushroom.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 24530.7, "ram_available_mb": 38310.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 24529.3, "ram_available_mb": 38311.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.311, "power_cpu_cv_mean_watts": 2.323, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T09:42:49.913347"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11353.341, "latencies_ms": [11353.341], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there are two individuals standing close to each other. The person on the left is wearing a black jacket and has their mouth wide open, as if they are shouting or laughing. The person on the right is wearing a green jacket with a fur hood, and they are looking upwards. The background is blurred, but it appears to be", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24529.3, "ram_available_mb": 38311.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 24538.4, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.499, "power_cpu_cv_mean_watts": 2.101, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T09:43:03.301981"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7053.002, "latencies_ms": [7053.002], "images_per_second": 0.142, "prompt_tokens": 39, "response_tokens_est": 40, "n_tiles": 16, "output_text": "object: 1, object: 1, object: 1, object: 1, object: 1, object: 1, object: 1, object: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.4, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24532.2, "ram_available_mb": 38308.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.999, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T09:43:12.400759"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7683.975, "latencies_ms": [7683.975], "images_per_second": 0.13, "prompt_tokens": 44, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The person on the left is in the foreground and appears to be facing the camera, while the person on the right is slightly behind and to the right of the first person, both are in the middle ground of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24532.2, "ram_available_mb": 38308.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24532.2, "ram_available_mb": 38308.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.313, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.916}, "timestamp": "2026-01-23T09:43:22.138368"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8299.584, "latencies_ms": [8299.584], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows two individuals in a blurred motion, suggesting movement or a quick capture of the moment. They appear to be outdoors, possibly in a public space, as indicated by the presence of other people and structures in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24532.2, "ram_available_mb": 38308.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.077, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T09:43:32.494422"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9150.06, "latencies_ms": [9150.06], "images_per_second": 0.109, "prompt_tokens": 36, "response_tokens_est": 60, "n_tiles": 16, "output_text": "The image features a person wearing a dark jacket with a fur-lined hood, and the lighting appears to be artificial, possibly from an indoor source. The background is blurred, but there seems to be a hint of a snowy environment, suggesting cold weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24534.1, "ram_available_mb": 38306.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.472, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T09:43:43.655696"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11401.951, "latencies_ms": [11401.951], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a man standing on a tennis court, holding a tennis racket and preparing to hit a tennis ball. He is positioned near the center of the court, and the ball is located slightly to his right. The man appears to be focused on the ball, getting ready to make a shot.\n\nThe court is surrounded by numerous chairs, with some placed closer to the", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 24534.1, "ram_available_mb": 38306.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.582, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.816}, "timestamp": "2026-01-23T09:43:57.093762"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9226.219, "latencies_ms": [9226.219], "images_per_second": 0.108, "prompt_tokens": 39, "response_tokens_est": 59, "n_tiles": 16, "output_text": "- Chair: 11\n- Tennis ball: 1\n- Tennis racket: 1\n- Tennis player: 1\n- Shoe: 1\n- Sock: 1\n- Wristband: 1\n- Wristband: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.635, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T09:44:08.379194"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11351.858, "latencies_ms": [11351.858], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a tennis player is positioned on the left side of the image, holding a tennis racket and preparing to hit a tennis ball that is near the center of the image. The background consists of multiple rows of white stadium seats, which are arranged in a pattern that recedes towards the right side of the image. The tennis court itself is a vibrant blue", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.618, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T09:44:21.753203"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6783.907, "latencies_ms": [6783.907], "images_per_second": 0.147, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A tennis player is on a blue tennis court, holding a racket and preparing to hit a yellow tennis ball. The court is surrounded by rows of white folding chairs.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24528.1, "ram_available_mb": 38312.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.342, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 8.96}, "timestamp": "2026-01-23T09:44:30.549472"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5957.148, "latencies_ms": [5957.148], "images_per_second": 0.168, "prompt_tokens": 36, "response_tokens_est": 32, "n_tiles": 16, "output_text": "The tennis player is wearing a white sleeveless shirt and black shorts. The court is blue with white lines marking the boundaries.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24528.1, "ram_available_mb": 38312.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.115, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 9.049}, "timestamp": "2026-01-23T09:44:38.522684"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11354.502, "latencies_ms": [11354.502], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image presents a serene indoor setting. At the center of the scene is a **red glass vase** with a unique design, featuring a **floral pattern**. The vase is placed on a **green glass coaster**, which is positioned on a **wooden table**. The table is adorned with a **white candle**, adding a touch", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24529.0, "ram_available_mb": 38311.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.59, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T09:44:51.896689"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7618.523, "latencies_ms": [7618.523], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "candle: 1, vase: 1, plate: 1, string lights: multiple, wooden frame: 1, wall: 1, table: 1, candle holder: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24529.0, "ram_available_mb": 38311.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24535.8, "ram_available_mb": 38305.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.762, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 8.898}, "timestamp": "2026-01-23T09:45:01.539521"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8032.391, "latencies_ms": [8032.391], "images_per_second": 0.124, "prompt_tokens": 44, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The glass vase is placed in the foreground on the right side of the image, while the white candle is in the foreground on the left side. The candle is positioned closer to the viewer than the vase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.8, "ram_available_mb": 38305.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24529.7, "ram_available_mb": 38311.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.987, "power_cpu_cv_mean_watts": 1.729, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T09:45:11.599930"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11497.07, "latencies_ms": [11497.07], "images_per_second": 0.087, "prompt_tokens": 37, "response_tokens_est": 79, "n_tiles": 16, "output_text": "The image shows a decorative setting with a large, ornate glass vase placed on a glass coaster, surrounded by a string of warm white lights that create a cozy ambiance. The vase is situated on a wooden surface, possibly a table, and there is a white candle to the left of the vase, suggesting a tranquil and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24529.7, "ram_available_mb": 38311.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24592.1, "ram_available_mb": 38248.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.677, "power_cpu_cv_mean_watts": 1.908, "power_sys_5v0_mean_watts": 8.818}, "timestamp": "2026-01-23T09:45:25.123485"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6976.007, "latencies_ms": [6976.007], "images_per_second": 0.143, "prompt_tokens": 36, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The image features a clear glass vase with a red interior, placed on a green coaster. The vase contains orange flowers, and the setting is illuminated by warm white string lights.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24592.1, "ram_available_mb": 38248.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.872, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.953}, "timestamp": "2026-01-23T09:45:34.153939"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.035, "latencies_ms": [11335.035], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there is a man in a room with a brown couch. He is wearing a black shirt and is bending over, possibly adjusting something on the couch. The room is equipped with a tripod and a light, suggesting that the man might be setting up for a photoshoot or a video recording. The man's face is blurred", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24533.9, "ram_available_mb": 38307.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.666, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.833}, "timestamp": "2026-01-23T09:45:47.527783"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9782.725, "latencies_ms": [9782.725], "images_per_second": 0.102, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "- Couch: 1\n\n- Jacket: 1\n\n- Microphone stand: 1\n\n- Cable: 1\n\n- Suitcase: 1\n\n- Lighting equipment: 1\n\n- Chair: 1\n\n- Table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24533.9, "ram_available_mb": 38307.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24527.6, "ram_available_mb": 38313.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.428, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T09:45:59.334733"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9632.61, "latencies_ms": [9632.61], "images_per_second": 0.104, "prompt_tokens": 44, "response_tokens_est": 64, "n_tiles": 16, "output_text": "In the foreground, there is a person bending over, seemingly interacting with the equipment. Behind them, another person is standing and appears to be operating a lighting setup. The lighting equipment is positioned to the left of the scene, while the person operating it is to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24527.6, "ram_available_mb": 38313.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24520.9, "ram_available_mb": 38320.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.221, "power_cpu_cv_mean_watts": 1.851, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T09:46:10.987859"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8081.9, "latencies_ms": [8081.9], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "In a room with a beige carpet, a man is bending over a couch while another man stands behind him, holding a white umbrella. There is a suitcase and a coat hanging on the couch.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24520.9, "ram_available_mb": 38320.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24522.8, "ram_available_mb": 38318.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.201, "power_cpu_cv_mean_watts": 1.712, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T09:46:21.082419"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6947.874, "latencies_ms": [6947.874], "images_per_second": 0.144, "prompt_tokens": 36, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The image shows a person in a room with a wooden floor and a beige carpet. There is a white umbrella in the background and a brown jacket hanging on a chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24522.8, "ram_available_mb": 38318.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24530.8, "ram_available_mb": 38310.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.931, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 8.995}, "timestamp": "2026-01-23T09:46:30.059202"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12501.844, "latencies_ms": [12501.844], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In this black and white photo, a woman is the central figure. She is adorned in a wide-brimmed hat that casts a shadow over her face, adding an air of mystery. Her eyes are closed, and a smile graces her lips, suggesting she is savoring the moment. In her hand, she holds a cigarette, its smoke curling upwards", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24530.8, "ram_available_mb": 38310.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24567.1, "ram_available_mb": 38273.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.89, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 9.067}, "timestamp": "2026-01-23T09:46:44.606507"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9263.11, "latencies_ms": [9263.11], "images_per_second": 0.108, "prompt_tokens": 39, "response_tokens_est": 48, "n_tiles": 16, "output_text": "hat: 1, earring: 1, necklace: 1, striped top: 1, cigarette: 1, hand: 1, bracelet: 1, smile: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24567.1, "ram_available_mb": 38273.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 24584.2, "ram_available_mb": 38256.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.556, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 9.089}, "timestamp": "2026-01-23T09:46:55.910760"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12683.811, "latencies_ms": [12683.811], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The woman is positioned in the foreground, wearing a wide-brimmed hat that extends to the left side of the frame, and a striped top that is visible in the mid-ground. She is holding a cigarette to her mouth, which is near the center of the image. The background is plain and unadorned, providing no additional context or objects to", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24584.2, "ram_available_mb": 38256.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.048, "power_cpu_cv_mean_watts": 2.207, "power_sys_5v0_mean_watts": 9.111}, "timestamp": "2026-01-23T09:47:10.628914"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11103.091, "latencies_ms": [11103.091], "images_per_second": 0.09, "prompt_tokens": 37, "response_tokens_est": 64, "n_tiles": 16, "output_text": "A woman is seen wearing a wide-brimmed hat and a striped tank top, with a necklace and a bracelet on her wrist, smiling and holding a cigarette in her hand. The image is in black and white, giving it a timeless and classic feel.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24540.0, "ram_available_mb": 38300.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24596.6, "ram_available_mb": 38244.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.759, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 9.087}, "timestamp": "2026-01-23T09:47:23.754770"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9128.617, "latencies_ms": [9128.617], "images_per_second": 0.11, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image is in black and white, featuring a person wearing a wide-brimmed hat and a striped tank top. The lighting appears to be natural, casting soft shadows on the person's face and hat.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24596.6, "ram_available_mb": 38244.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24580.2, "ram_available_mb": 38260.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.289, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 9.16}, "timestamp": "2026-01-23T09:47:34.919668"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11338.851, "latencies_ms": [11338.851], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there are two zebras grazing in a grassy field. One zebra is located on the left side of the field, while the other is on the right side. They are both eating grass and appear to be enjoying their meal. The field is surrounded by a rock wall, providing a natural boundary for the zebras. The scene captures", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24580.2, "ram_available_mb": 38260.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.658, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T09:47:48.293739"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7471.796, "latencies_ms": [7471.796], "images_per_second": 0.134, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "zebra: 2, rock: 1, tree: 1, grass: many, dirt path: 1, stone wall: 1, building: 1, shadow: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24529.7, "ram_available_mb": 38311.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.75, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 8.927}, "timestamp": "2026-01-23T09:47:57.800154"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10302.945, "latencies_ms": [10302.945], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "In the foreground of the image, there are two zebras grazing on the grass. One zebra is positioned slightly to the left of the other, and both are facing the same direction. In the background, there is a rocky wall and a few trees, providing a natural habitat setting for the zebras.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24529.7, "ram_available_mb": 38311.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24536.2, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.955, "power_cpu_cv_mean_watts": 1.903, "power_sys_5v0_mean_watts": 8.892}, "timestamp": "2026-01-23T09:48:10.124535"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6807.986, "latencies_ms": [6807.986], "images_per_second": 0.147, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "Two zebras are grazing in a grassy enclosure with a rocky wall and trees in the background. The sun is shining, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24536.2, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.205, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.943}, "timestamp": "2026-01-23T09:48:18.969668"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7191.742, "latencies_ms": [7191.742], "images_per_second": 0.139, "prompt_tokens": 36, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image features two zebras grazing in a grassy field with a backdrop of trees and a rocky wall. The lighting is natural and bright, suggesting it is a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24534.6, "ram_available_mb": 38306.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.641, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 8.966}, "timestamp": "2026-01-23T09:48:28.190825"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11323.603, "latencies_ms": [11323.603], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene of urban decay and neglect. Dominating the frame is a fire hydrant, its once vibrant orange color now faded to a dull brown, a testament to the passage of time. The hydrant, showing signs of rust and wear, stands on a sidewalk, its once gleaming surface now marred by the elements. \n\nA", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24534.6, "ram_available_mb": 38306.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.587, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T09:48:41.562739"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7323.106, "latencies_ms": [7323.106], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "Fire hydrant: 1, chain: 2, cap: 1, step: 1, stone: 1, plant: 1, leaf: 1, flower: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24533.5, "ram_available_mb": 38307.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.787, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.88}, "timestamp": "2026-01-23T09:48:50.909335"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10788.69, "latencies_ms": [10788.69], "images_per_second": 0.093, "prompt_tokens": 44, "response_tokens_est": 74, "n_tiles": 16, "output_text": "The fire hydrant is positioned in the foreground of the image, appearing large and detailed. It is situated on the left side of the frame, with a blurred background that includes a stone wall and some greenery. The hydrant is also the main focus, with other elements like the chain and cap being secondary and placed on its right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24531.3, "ram_available_mb": 38309.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.826, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T09:49:03.719661"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6182.752, "latencies_ms": [6182.752], "images_per_second": 0.162, "prompt_tokens": 37, "response_tokens_est": 32, "n_tiles": 16, "output_text": "The image shows an old, rusted fire hydrant on a sidewalk. It is located next to a wall with a painted green hedge design.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24531.3, "ram_available_mb": 38309.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24539.6, "ram_available_mb": 38301.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.906, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T09:49:11.929288"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8068.257, "latencies_ms": [8068.257], "images_per_second": 0.124, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The fire hydrant is a faded orange color with a black top and is situated on a concrete step. It appears to be an older model, with visible rust and wear, indicating it has been in use for a considerable amount of time.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.6, "ram_available_mb": 38301.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24545.6, "ram_available_mb": 38295.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.189, "power_cpu_cv_mean_watts": 1.737, "power_sys_5v0_mean_watts": 8.909}, "timestamp": "2026-01-23T09:49:22.037288"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11352.904, "latencies_ms": [11352.904], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there are two brown bears walking on a dirt road. The bear in the foreground is walking towards the camera, while the other bear is walking away from the camera. The road they are walking on is surrounded by dry grass and shrubs. The bears appear to be in a natural habitat, possibly a forest or a wildlife reserve. The image does not contain", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 24545.6, "ram_available_mb": 38295.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24529.6, "ram_available_mb": 38311.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.607, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T09:49:35.434957"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7165.532, "latencies_ms": [7165.532], "images_per_second": 0.14, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "bear: 2, road: 1, vegetation: 1, ground: 1, sky: 1, sun: 1, shadow: 1, rocks: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24529.6, "ram_available_mb": 38311.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24524.4, "ram_available_mb": 38316.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.093, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T09:49:44.638444"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10151.716, "latencies_ms": [10151.716], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 69, "n_tiles": 16, "output_text": "In the foreground, there is a large brown bear walking towards the right side of the image, while a smaller bear is seen in the background, slightly to the left and behind the first bear. The background consists of a barren landscape with dry grass and a dirt road, which appears to be quite far from the bears.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24524.4, "ram_available_mb": 38316.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24524.2, "ram_available_mb": 38316.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.077, "power_cpu_cv_mean_watts": 1.886, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T09:49:56.806450"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6942.092, "latencies_ms": [6942.092], "images_per_second": 0.144, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "Two brown bears are walking on a rocky terrain with dry grass in the background. The bears appear to be in a natural habitat, possibly a forest or wilderness area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24524.2, "ram_available_mb": 38316.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.122, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T09:50:05.782331"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7334.474, "latencies_ms": [7334.474], "images_per_second": 0.136, "prompt_tokens": 36, "response_tokens_est": 44, "n_tiles": 16, "output_text": "The image features two brown bears in a natural setting with a clear sky. The bears are walking on a dirt ground with sparse vegetation, and the lighting suggests it is a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24534.2, "ram_available_mb": 38306.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.589, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 8.929}, "timestamp": "2026-01-23T09:50:15.131756"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11305.718, "latencies_ms": [11305.718], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young child is playing in a garden. The child is wearing a white shirt and a colorful tie, and is squatting down to interact with the ground. The child is holding a shovel and digging into a large metal tub filled with dirt. The child appears to be enjoying the outdoor activity, possibly exploring or engaging in a", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 24534.2, "ram_available_mb": 38306.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24539.7, "ram_available_mb": 38301.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.639, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T09:50:28.472252"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7296.018, "latencies_ms": [7296.018], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "bucket: 1, shovel: 1, child: 1, tie: 1, leaves: many, ground: 1, sunlight: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24539.7, "ram_available_mb": 38301.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24526.3, "ram_available_mb": 38314.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.939, "power_cpu_cv_mean_watts": 1.608, "power_sys_5v0_mean_watts": 8.926}, "timestamp": "2026-01-23T09:50:37.789717"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11396.941, "latencies_ms": [11396.941], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a young child is kneeling on the ground, reaching into a metal tub filled with dark material, likely soil or sand. The child is positioned to the left of the image, with the tub in the lower left quadrant. In the background, there is a dense arrangement of dark leaves, possibly a hedge or shrubbery, which occupies the upper", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24526.3, "ram_available_mb": 38314.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24528.5, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.664, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T09:50:51.220285"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8420.034, "latencies_ms": [8420.034], "images_per_second": 0.119, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "A young child is playing in a large metal tub filled with black sand, surrounded by green foliage. The child is wearing a white shirt and a colorful tie, and appears to be enjoying the sensory experience of the sand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24528.5, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.335, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T09:51:01.671775"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8866.201, "latencies_ms": [8866.201], "images_per_second": 0.113, "prompt_tokens": 36, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image features a child with light-colored hair, wearing a white shirt and a colorful tie with a pattern of leaves and the letter \"B\". The child is crouched down and appears to be playing with a black substance in a metal tub.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 24542.3, "ram_available_mb": 38298.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.702, "power_cpu_cv_mean_watts": 2.04, "power_sys_5v0_mean_watts": 8.904}, "timestamp": "2026-01-23T09:51:12.595643"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11464.961, "latencies_ms": [11464.961], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene of a desert landscape, where a small table is set up in the middle of the sandy terrain. The table is adorned with various items, including a bottle of beer, a can of soda, and a bouquet of yellow flowers. A teddy bear, dressed in a red shirt and a blue hat, is seated on the", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24542.3, "ram_available_mb": 38298.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.229, "power_cpu_cv_mean_watts": 2.264, "power_sys_5v0_mean_watts": 8.818}, "timestamp": "2026-01-23T09:51:26.102451"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11297.271, "latencies_ms": [11297.271], "images_per_second": 0.089, "prompt_tokens": 39, "response_tokens_est": 77, "n_tiles": 16, "output_text": "object: teddy bear, count: 2\nobject: bottle, count: 2\nobject: can, count: 1\nobject: cardboard box, count: 1\nobject: table, count: 1\nobject: chair, count: 1\nobject: bag, count: 1\nobject: flower, count: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.658, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 8.824}, "timestamp": "2026-01-23T09:51:39.454837"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10421.555, "latencies_ms": [10421.555], "images_per_second": 0.096, "prompt_tokens": 44, "response_tokens_est": 71, "n_tiles": 16, "output_text": "In the foreground, there is a table with various items on it, positioned slightly to the right of the center of the image. The background features a vast, open desert landscape that stretches out to the horizon. The table and its contents are in the middle ground, creating a sense of depth against the expansive backdrop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24553.3, "ram_available_mb": 38287.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.891, "power_cpu_cv_mean_watts": 1.899, "power_sys_5v0_mean_watts": 8.86}, "timestamp": "2026-01-23T09:51:51.890237"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10102.831, "latencies_ms": [10102.831], "images_per_second": 0.099, "prompt_tokens": 37, "response_tokens_est": 67, "n_tiles": 16, "output_text": "The image depicts a desert-like setting with a small table holding various items, including a bottle of beer and a can of soda. The table is surrounded by a few stuffed animals and a couch with a red cross on it, suggesting a makeshift outdoor gathering or picnic.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24553.3, "ram_available_mb": 38287.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24547.5, "ram_available_mb": 38293.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.159, "power_cpu_cv_mean_watts": 1.841, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T09:52:04.018310"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8334.568, "latencies_ms": [8334.568], "images_per_second": 0.12, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image depicts a desert landscape with a table set up in the middle, featuring a variety of items. The table is covered with a green cloth and has a red can, a bottle, and a small vase with yellow flowers on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24547.5, "ram_available_mb": 38293.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24547.7, "ram_available_mb": 38293.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.898, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 8.925}, "timestamp": "2026-01-23T09:52:14.384662"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12510.214, "latencies_ms": [12510.214], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a harbor with several boats docked at a pier. There are two boats prominently visible in the foreground, one on the left and another on the right. The boats are of different sizes and are moored to the pier. \n\nIn the background, there are more boats scattered across the water, with some closer to the shore and others further away. The", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24547.7, "ram_available_mb": 38293.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24548.8, "ram_available_mb": 38292.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.992, "power_cpu_cv_mean_watts": 1.8, "power_sys_5v0_mean_watts": 9.087}, "timestamp": "2026-01-23T09:52:28.950070"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9071.423, "latencies_ms": [9071.423], "images_per_second": 0.11, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "boat: 2\nfish: 0\nperson: 2\nmountain: 1\nhouse: 0\nboat: 1\nlife preserver: 1\npaddle: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.8, "ram_available_mb": 38292.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.577, "power_cpu_cv_mean_watts": 1.456, "power_sys_5v0_mean_watts": 9.05}, "timestamp": "2026-01-23T09:52:40.036755"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12177.893, "latencies_ms": [12177.893], "images_per_second": 0.082, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "In the foreground, there is a green boat with the number 9 on it, docked at a pier. To the left of this boat, there is another boat with a yellow structure on top, and further back, there are more boats in the water. In the background, there are hills covered in greenery and a few people standing on the pier.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24563.9, "ram_available_mb": 38277.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.229, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 9.093}, "timestamp": "2026-01-23T09:52:54.273201"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9867.463, "latencies_ms": [9867.463], "images_per_second": 0.101, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image depicts a serene harbor scene with several boats docked at a pier. The boats are moored to the pier, and there are a few people visible on the pier, possibly attending to their boats or enjoying the view.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24563.9, "ram_available_mb": 38277.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24658.5, "ram_available_mb": 38182.4, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.163, "power_cpu_cv_mean_watts": 1.569, "power_sys_5v0_mean_watts": 9.051}, "timestamp": "2026-01-23T09:53:06.172420"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9946.52, "latencies_ms": [9946.52], "images_per_second": 0.101, "prompt_tokens": 36, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image features a serene harbor scene with boats docked at a pier. The boats are primarily green and white, with some wooden structures and ropes visible. The weather appears to be overcast, with a cloudy sky casting a soft light over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24658.5, "ram_available_mb": 38182.4, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24668.1, "ram_available_mb": 38172.8, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.056, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 9.136}, "timestamp": "2026-01-23T09:53:18.139131"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11322.432, "latencies_ms": [11322.432], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a person is captured in the act of taking a bite out of a hot dog. The individual is wearing a black jacket, and their face is partially visible, with their mouth open wide as they bite into the hot dog. The hot dog itself is golden brown and appears to be freshly cooked. The background of the image is blurred, but", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24600.3, "ram_available_mb": 38240.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.553, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T09:53:31.534940"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7272.132, "latencies_ms": [7272.132], "images_per_second": 0.138, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "face: 1, mouth: 1, tongue: 1, chin: 1, nose: 1, ear: 1, eye: 1, cheek: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.9, "ram_available_mb": 38303.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24547.8, "ram_available_mb": 38293.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.697, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T09:53:40.848400"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8230.901, "latencies_ms": [8230.901], "images_per_second": 0.121, "prompt_tokens": 44, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The person is in the foreground, holding a hot dog with their right hand, which is near the front of the image. The background is blurred but appears to be an outdoor setting with lights that could suggest a street or public area.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24547.8, "ram_available_mb": 38293.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24531.8, "ram_available_mb": 38309.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.008, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 8.931}, "timestamp": "2026-01-23T09:53:51.103543"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7865.68, "latencies_ms": [7865.68], "images_per_second": 0.127, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "A person is seen holding a hot dog with their mouth wide open, as if they are about to take a bite. The background is blurred, but it appears to be an outdoor setting with some lights visible.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24531.8, "ram_available_mb": 38309.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.518, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 8.895}, "timestamp": "2026-01-23T09:54:00.986082"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7794.455, "latencies_ms": [7794.455], "images_per_second": 0.128, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The image features a person with short hair, wearing a dark jacket, holding a hot dog with a bite taken out of it. The lighting is dim with a warm tone, suggesting an evening or nighttime setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24528.3, "ram_available_mb": 38312.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.206, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.922}, "timestamp": "2026-01-23T09:54:10.816378"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11297.259, "latencies_ms": [11297.259], "images_per_second": 0.089, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man and a woman are standing side by side in a room. The man is dressed in a black suit with a white shirt and a black tie, and he is holding a martini glass in his right hand. The woman is wearing a gray dress and has blonde hair. They are both looking to the left, and the man is holding a black purse", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24528.3, "ram_available_mb": 38312.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24531.1, "ram_available_mb": 38309.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.637, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T09:54:24.165371"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7405.639, "latencies_ms": [7405.639], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "woman: 1, man: 1, dress: 1, wine glass: 1, door: 1, wall: 1, curtain: 1, shelf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24531.1, "ram_available_mb": 38309.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24531.7, "ram_available_mb": 38309.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.803, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T09:54:33.611624"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9166.754, "latencies_ms": [9166.754], "images_per_second": 0.109, "prompt_tokens": 44, "response_tokens_est": 60, "n_tiles": 16, "output_text": "The man is standing to the right of the woman, slightly closer to the camera, creating a sense of depth in the image. The woman is positioned to the left of the man, and both are standing in the foreground with a blurred background that suggests an indoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24531.7, "ram_available_mb": 38309.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24530.5, "ram_available_mb": 38310.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.647, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 8.93}, "timestamp": "2026-01-23T09:54:44.799181"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8075.789, "latencies_ms": [8075.789], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A man and a woman are standing in a room, with the man holding a glass of wine. The woman is wearing a grey dress and the man is wearing a black suit with a white shirt and a maroon tie.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24530.5, "ram_available_mb": 38310.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24562.2, "ram_available_mb": 38278.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.308, "power_cpu_cv_mean_watts": 1.712, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T09:54:54.908629"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7947.504, "latencies_ms": [7947.504], "images_per_second": 0.126, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image features a man and a woman in an indoor setting with soft, warm lighting. The man is wearing a dark suit with a white shirt and a dark tie, while the woman is dressed in a grey dress.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24562.2, "ram_available_mb": 38278.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24525.9, "ram_available_mb": 38315.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.172, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 8.906}, "timestamp": "2026-01-23T09:55:04.876166"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12318.481, "latencies_ms": [12318.481], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a blue shelf with various objects placed on it. There are several cups and bottles of different sizes and shapes, some of which are placed on the top of the shelf. A spoon is also visible on the shelf, resting near the cups. \n\nIn addition to the shelf, there is a dining table in the scene, with", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24525.9, "ram_available_mb": 38315.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24578.1, "ram_available_mb": 38262.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.596, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 9.054}, "timestamp": "2026-01-23T09:55:19.253848"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8058.232, "latencies_ms": [8058.232], "images_per_second": 0.124, "prompt_tokens": 39, "response_tokens_est": 40, "n_tiles": 16, "output_text": "object: 1, object: 2, object: 3, object: 4, object: 5, object: 6, object: 7, object: 8", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24578.1, "ram_available_mb": 38262.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 24551.0, "ram_available_mb": 38289.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.759, "power_cpu_cv_mean_watts": 1.867, "power_sys_5v0_mean_watts": 9.103}, "timestamp": "2026-01-23T09:55:29.331476"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12301.731, "latencies_ms": [12301.731], "images_per_second": 0.081, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a blue shelf with various objects placed on it, including a silver teapot and a small blue box. Behind the shelf, there is a yellow chair and a green table with a wooden base. In the background, there is a white chair and a brown table with a green base. The objects are arranged in a way that creates a sense of", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24551.0, "ram_available_mb": 38289.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 24590.2, "ram_available_mb": 38250.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.616, "power_cpu_cv_mean_watts": 2.18, "power_sys_5v0_mean_watts": 9.065}, "timestamp": "2026-01-23T09:55:43.658397"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8210.725, "latencies_ms": [8210.725], "images_per_second": 0.122, "prompt_tokens": 37, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The image shows a blue wooden cabinet with a green top, placed on a concrete floor. It has a few items on top, including a vase, a small box, and some cups.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24590.2, "ram_available_mb": 38250.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24586.4, "ram_available_mb": 38254.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.558, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 9.05}, "timestamp": "2026-01-23T09:55:53.894942"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8819.465, "latencies_ms": [8819.465], "images_per_second": 0.113, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image shows a blue wooden cabinet with a green top, placed outdoors under natural lighting. There are various items on the cabinet, including a silver teapot, a yellow chair, and a basket with a red cloth.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24586.4, "ram_available_mb": 38254.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24580.8, "ram_available_mb": 38260.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.891, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 9.094}, "timestamp": "2026-01-23T09:56:04.737033"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11386.323, "latencies_ms": [11386.323], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a white plate with several pieces of bread covered in cheese, placed on a dining table. The bread appears to be toasted, and the cheese is melted on top of it. The table also has a keyboard and a mouse, suggesting that the setting might be a workspace or a casual dining area. The focus of the image is on the che", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 24580.8, "ram_available_mb": 38260.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24550.2, "ram_available_mb": 38290.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.577, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.836}, "timestamp": "2026-01-23T09:56:18.145436"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7599.798, "latencies_ms": [7599.798], "images_per_second": 0.132, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "cheese: 5\ncracker: 5\nplate: 1\nkeyboard: 1\nmouse: 1\nbowl: 1\ndrink: 1\nbook: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.2, "ram_available_mb": 38290.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24536.8, "ram_available_mb": 38304.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.69, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 8.901}, "timestamp": "2026-01-23T09:56:27.781676"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9404.794, "latencies_ms": [9404.794], "images_per_second": 0.106, "prompt_tokens": 44, "response_tokens_est": 62, "n_tiles": 16, "output_text": "In the foreground, there are four pieces of bread with cheese on top, arranged in a square pattern on a white plate. In the background, there is a blurred image of a keyboard and a mouse, suggesting that the bread is on a desk or table near a computer setup.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.8, "ram_available_mb": 38304.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.359, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 8.904}, "timestamp": "2026-01-23T09:56:39.219810"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8312.875, "latencies_ms": [8312.875], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows a white plate with four pieces of bread topped with cheese, placed on a desk. In the background, there is a keyboard and a mouse, suggesting that the setting is likely a workspace or a computer desk.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24537.5, "ram_available_mb": 38303.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.198, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T09:56:49.548188"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10176.454, "latencies_ms": [10176.454], "images_per_second": 0.098, "prompt_tokens": 36, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The image shows a white plate with four pieces of food, each topped with a white, creamy substance that could be cheese or a sauce. The lighting in the image is warm and artificial, coming from a source that is not visible in the frame, casting a soft glow on the plate and its contents.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24545.3, "ram_available_mb": 38295.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.995, "power_cpu_cv_mean_watts": 1.892, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T09:57:01.769817"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12532.271, "latencies_ms": [12532.271], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is standing against a dark gray background. He is dressed in a black suit and tie, and he is wearing glasses. His hair is dark and styled in a messy manner. The man is adjusting his tie, which is adorned with a string of colorful lights. The lights on the tie are arranged in a vertical line, with each", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 24545.3, "ram_available_mb": 38295.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24538.5, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.966, "power_cpu_cv_mean_watts": 1.808, "power_sys_5v0_mean_watts": 9.087}, "timestamp": "2026-01-23T09:57:16.353312"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11626.464, "latencies_ms": [11626.464], "images_per_second": 0.086, "prompt_tokens": 39, "response_tokens_est": 68, "n_tiles": 16, "output_text": "- Man: 1\n\n- Glasses: 1\n\n- Tie: 1\n\n- Jacket: 1\n\n- Pocket: 1\n\n- Ring: 1\n\n- Beads on tie: 1\n\n- Colorful lights on tie: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24538.5, "ram_available_mb": 38302.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24543.5, "ram_available_mb": 38297.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.495, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 9.009}, "timestamp": "2026-01-23T09:57:30.025061"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12628.064, "latencies_ms": [12628.064], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The man is positioned in the foreground, standing against a dark background. He is wearing a black suit jacket and a white shirt, and is adjusting a red and green LED light strip on his tie, which is located in the mid-ground of the image. The lights on the tie are arranged in a vertical line, with the red lights at the top and the green", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.5, "ram_available_mb": 38297.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24581.3, "ram_available_mb": 38259.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.073, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 9.075}, "timestamp": "2026-01-23T09:57:44.686084"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7788.386, "latencies_ms": [7788.386], "images_per_second": 0.128, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "A man in a suit is adjusting a tie with a unique design of red and green lights. The background is dark, making the man and his tie stand out.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24581.3, "ram_available_mb": 38259.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 24579.3, "ram_available_mb": 38261.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.337, "power_cpu_cv_mean_watts": 1.347, "power_sys_5v0_mean_watts": 9.076}, "timestamp": "2026-01-23T09:57:54.519479"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11487.41, "latencies_ms": [11487.41], "images_per_second": 0.087, "prompt_tokens": 36, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The image features a man in a dark suit with a white shirt and a tie that has a series of lights along its length, emitting a spectrum of colors from red to green. The lighting is dramatic, with a spotlight effect highlighting the man and the illuminated tie against a dark, shadowy background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24579.3, "ram_available_mb": 38261.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24559.8, "ram_available_mb": 38281.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.172, "power_cpu_cv_mean_watts": 1.733, "power_sys_5v0_mean_watts": 9.07}, "timestamp": "2026-01-23T09:58:08.026006"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11310.412, "latencies_ms": [11310.412], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a woman crossing the street at a crosswalk during the evening. She is wearing a brown jacket and carrying a handbag. The scene is set in a city environment, with a traffic light visible in the background. There are several other people in the scene, some of whom are also carrying handbags.\n\nIn the background, there is a building with a", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24559.8, "ram_available_mb": 38281.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24537.6, "ram_available_mb": 38303.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.604, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T09:58:21.406826"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7387.29, "latencies_ms": [7387.29], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "pedestrian: 1, traffic light: 1, building: 2, window: multiple, streetlight: 1, sign: 1, restaurant: 1, car: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24537.6, "ram_available_mb": 38303.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24530.0, "ram_available_mb": 38310.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.959, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.927}, "timestamp": "2026-01-23T09:58:30.848181"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11365.898, "latencies_ms": [11365.898], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a person walking across the street, positioned near the center of the image. The background features a large, ornate building with a sign that reads \"TADURIA,\" which is situated on the right side of the image. The sky is visible in the upper part of the image, indicating that the scene is set outdoors during the evening or night", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24530.0, "ram_available_mb": 38310.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24534.5, "ram_available_mb": 38306.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.761, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T09:58:44.243272"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9138.48, "latencies_ms": [9138.48], "images_per_second": 0.109, "prompt_tokens": 37, "response_tokens_est": 58, "n_tiles": 16, "output_text": "The image depicts a street scene at night with a person crossing the road. The person is wearing a brown jacket and jeans, and is carrying a black bag. The street is illuminated by streetlights and the buildings in the background have lit windows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.5, "ram_available_mb": 38306.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24568.8, "ram_available_mb": 38272.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.757, "power_cpu_cv_mean_watts": 1.763, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T09:58:55.420979"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7596.98, "latencies_ms": [7596.98], "images_per_second": 0.132, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image depicts a night scene with artificial lighting, including street lamps and building lights, casting a warm glow on the scene. The sky is dark blue, indicating it is likely evening or night time.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24568.8, "ram_available_mb": 38272.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.5, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 8.931}, "timestamp": "2026-01-23T09:59:05.055724"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11348.433, "latencies_ms": [11348.433], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a woman in a bikini riding a surfboard on a wave in the ocean. She is skillfully balancing on the surfboard as the wave carries her. There are several other people in the water, some of them also on surfboards, while others are swimming or floating. The scene captures the excitement and enjoyment of surfing", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24529.7, "ram_available_mb": 38311.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.64, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T09:59:18.431751"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7501.89, "latencies_ms": [7501.89], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "girl: 1, surfboard: 1, wave: 1, water: 1, person: 3, swimsuit: 2, arm: 1, leg: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24529.7, "ram_available_mb": 38311.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24531.2, "ram_available_mb": 38309.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.726, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T09:59:27.993701"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11317.678, "latencies_ms": [11317.678], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a person is surfing on a blue surfboard, riding a wave towards the right side of the image. In the background, there are two other individuals; one is lying on a surfboard further out at sea, and the other is standing on a surfboard closer to the shore, holding a blue surfboard. The main surfer is", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24531.2, "ram_available_mb": 38309.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 24537.6, "ram_available_mb": 38303.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.713, "power_cpu_cv_mean_watts": 2.057, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T09:59:41.328735"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8899.046, "latencies_ms": [8899.046], "images_per_second": 0.112, "prompt_tokens": 37, "response_tokens_est": 56, "n_tiles": 16, "output_text": "A young girl is surfing on a wave in the ocean, with two other people in the background, one of whom is holding a surfboard. The girl is wearing a bikini and appears to be enjoying herself as she rides the wave.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24537.6, "ram_available_mb": 38303.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.866, "power_cpu_cv_mean_watts": 2.232, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T09:59:52.288810"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7324.837, "latencies_ms": [7324.837], "images_per_second": 0.137, "prompt_tokens": 36, "response_tokens_est": 44, "n_tiles": 16, "output_text": "The image captures a vibrant scene at the beach with a person surfing on a blue surfboard. The water is a mix of light blue and green hues, indicating clear weather conditions.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 24544.3, "ram_available_mb": 38296.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.61, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 8.947}, "timestamp": "2026-01-23T10:00:01.633752"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11336.78, "latencies_ms": [11336.78], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is standing in a fenced area, reaching out to pet an elephant. The elephant is standing on a concrete platform, and the man is wearing a white shirt and a black belt. There are two other people in the background, one of whom is wearing a hat. The scene takes place in a lush green environment, with", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24544.3, "ram_available_mb": 38296.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24591.9, "ram_available_mb": 38249.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.606, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T10:00:15.001698"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7646.949, "latencies_ms": [7646.949], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "elephant: 1, fence: 2, hand: 1, trunk: 1, watch: 1, shirt: 1, belt: 1, trees: multiple", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24591.9, "ram_available_mb": 38249.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.455, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T10:00:24.671727"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11309.054, "latencies_ms": [11309.054], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a person is standing to the right of a fence, reaching out to touch an elephant on the left side of the image. The elephant is positioned behind the fence, in the middle ground of the image, and is facing the person. The background is filled with greenery and another person is visible behind the fence, slightly to the right", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.656, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.879}, "timestamp": "2026-01-23T10:00:38.038467"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9797.247, "latencies_ms": [9797.247], "images_per_second": 0.102, "prompt_tokens": 37, "response_tokens_est": 64, "n_tiles": 16, "output_text": "In the image, a person is seen feeding an elephant with a stick, while another person watches from behind a fence. The scene takes place in a zoo or wildlife sanctuary, where the elephant is standing on a concrete platform and the person is interacting with it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24540.9, "ram_available_mb": 38300.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.33, "power_cpu_cv_mean_watts": 1.824, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T10:00:49.896687"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9179.271, "latencies_ms": [9179.271], "images_per_second": 0.109, "prompt_tokens": 36, "response_tokens_est": 60, "n_tiles": 16, "output_text": "The image shows a scene with an elephant and a human interacting. The elephant is grey, and the human is wearing a white shirt and dark pants. The lighting appears to be natural daylight, and the weather seems to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.9, "ram_available_mb": 38300.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24541.9, "ram_available_mb": 38299.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.367, "power_cpu_cv_mean_watts": 1.836, "power_sys_5v0_mean_watts": 8.896}, "timestamp": "2026-01-23T10:01:01.088841"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11315.913, "latencies_ms": [11315.913], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the center of the image, a brown dog with a white chest is sitting on a bed, surrounded by a mess of clothes and various items. The dog appears to be looking directly at the camera, giving the impression that it is posing for the photo. The bed is covered with clothes, and there are multiple items scattered around, including a pillow and a jacket. The scene", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24541.9, "ram_available_mb": 38299.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24540.3, "ram_available_mb": 38300.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.627, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T10:01:14.452988"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9094.188, "latencies_ms": [9094.188], "images_per_second": 0.11, "prompt_tokens": 39, "response_tokens_est": 58, "n_tiles": 16, "output_text": "- Bed: 1\n- Blanket: 1\n- Pillow: 1\n- Pillowcase: 1\n- Clothes: 1\n- Bags: 1\n- Box: 1\n- Dog: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.3, "ram_available_mb": 38300.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24536.9, "ram_available_mb": 38304.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.758, "power_cpu_cv_mean_watts": 1.779, "power_sys_5v0_mean_watts": 8.86}, "timestamp": "2026-01-23T10:01:25.602681"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7442.813, "latencies_ms": [7442.813], "images_per_second": 0.134, "prompt_tokens": 44, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The dog is sitting in the foreground on the left side of the image, near the center. The bed is in the background, with various items scattered on it, including a brown pillow on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.9, "ram_available_mb": 38304.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.554, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.936}, "timestamp": "2026-01-23T10:01:35.088945"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6132.166, "latencies_ms": [6132.166], "images_per_second": 0.163, "prompt_tokens": 37, "response_tokens_est": 32, "n_tiles": 16, "output_text": "A dog is sitting on a bed surrounded by a pile of clothes and a pillow. The room appears to be messy and disorganized.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24541.4, "ram_available_mb": 38299.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.963, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.932}, "timestamp": "2026-01-23T10:01:43.250177"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11319.444, "latencies_ms": [11319.444], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a dog sitting amidst a pile of clothes and bags on a bed. The dog appears to be a large breed with a dark coat and white markings on its face. The bed is covered with a white sheet, and the background shows a window with white curtains. The lighting in the room is natural, coming from the window. The clothes and b", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.4, "ram_available_mb": 38299.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.551, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T10:01:56.586708"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11380.359, "latencies_ms": [11380.359], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is seated at a desk in an office environment. He is dressed in a white shirt and a blue tie, and he is holding a pen in his right hand, poised to write on a piece of paper that is placed on the desk. His left hand is raised to his chin, suggesting a moment of contemplation or deep thought.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24529.1, "ram_available_mb": 38311.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.456, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.817}, "timestamp": "2026-01-23T10:02:09.986172"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7416.42, "latencies_ms": [7416.42], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "laptop: 1, pen: 1, paper: 1, clipboard: 1, glasses: 1, shirt: 1, tie: 1, background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24529.1, "ram_available_mb": 38311.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24528.4, "ram_available_mb": 38312.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.713, "power_cpu_cv_mean_watts": 1.64, "power_sys_5v0_mean_watts": 8.877}, "timestamp": "2026-01-23T10:02:19.415301"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10982.224, "latencies_ms": [10982.224], "images_per_second": 0.091, "prompt_tokens": 44, "response_tokens_est": 76, "n_tiles": 16, "output_text": "The laptop is positioned to the left of the image, placed on a desk in the foreground. A person is seated at the desk, with their right hand resting on their chin, suggesting a thoughtful or contemplative pose. The background is blurred, indicating that the focus is on the person and the immediate surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24528.4, "ram_available_mb": 38312.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.793, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T10:02:32.445140"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7851.714, "latencies_ms": [7851.714], "images_per_second": 0.127, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "A man in a white shirt and blue tie is sitting at a desk with a laptop and papers in front of him, looking thoughtful. He is holding a pen in his hand and appears to be deep in thought.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24540.1, "ram_available_mb": 38300.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.371, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T10:02:42.319920"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8344.821, "latencies_ms": [8344.821], "images_per_second": 0.12, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image shows a person wearing a white shirt and a blue tie, sitting at a desk with a laptop open in front of them. The desk appears to be made of wood, and there is a pen in the person's hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24540.1, "ram_available_mb": 38300.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.852, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T10:02:52.694449"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12526.911, "latencies_ms": [12526.911], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene scene of a clear blue sky, where a large, full moon is visible in the lower left corner, casting a soft glow. A commercial airplane, painted in white with a red and blue tail, is seen flying from the right to the left of the frame. The airplane's wings are fully extended, indicating it is in the process of taking", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24578.4, "ram_available_mb": 38262.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.919, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 9.057}, "timestamp": "2026-01-23T10:03:07.268286"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8811.616, "latencies_ms": [8811.616], "images_per_second": 0.113, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "airplane: 1, moon: 1, sky: 1, day: 1, flight: 1, aircraft: 1, celestial body: 1, horizon: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24578.4, "ram_available_mb": 38262.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24576.8, "ram_available_mb": 38264.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.748, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 9.085}, "timestamp": "2026-01-23T10:03:18.118351"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10660.026, "latencies_ms": [10660.026], "images_per_second": 0.094, "prompt_tokens": 44, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The airplane is flying in the background, higher up in the sky compared to the moon, which is closer to the viewer in the foreground. The moon appears to be partially obscured by the airplane's shadow, indicating that the airplane is between the moon and the viewer.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24576.8, "ram_available_mb": 38264.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24553.5, "ram_available_mb": 38287.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.588, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 9.1}, "timestamp": "2026-01-23T10:03:30.796284"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9966.99, "latencies_ms": [9966.99], "images_per_second": 0.1, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image captures a serene scene of a clear blue sky with a large, pale orange moon visible in the bottom left corner. A commercial airplane with a red and white tail is seen flying from left to right in the upper right corner of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24553.5, "ram_available_mb": 38287.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24551.7, "ram_available_mb": 38289.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.029, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 9.066}, "timestamp": "2026-01-23T10:03:42.775990"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9958.35, "latencies_ms": [9958.35], "images_per_second": 0.1, "prompt_tokens": 36, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image features a clear blue sky with a large, pale orange moon visible in the lower left corner. An airplane with a predominantly white body and blue tail is captured in flight, with its landing gear extended, suggesting it is either taking off or landing.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24551.7, "ram_available_mb": 38289.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24574.1, "ram_available_mb": 38266.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.002, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 9.12}, "timestamp": "2026-01-23T10:03:54.752190"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12522.056, "latencies_ms": [12522.056], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young man is captured in the midst of performing a skateboard trick at a skate park. He is wearing a tie-dye shirt and black pants, and his skateboard is adorned with a vibrant design. The skate park itself is a concrete ramp, and the background is filled with palm trees and a play", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 24574.1, "ram_available_mb": 38266.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 24594.2, "ram_available_mb": 38246.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.014, "power_cpu_cv_mean_watts": 2.294, "power_sys_5v0_mean_watts": 9.111}, "timestamp": "2026-01-23T10:04:09.298771"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9080.325, "latencies_ms": [9080.325], "images_per_second": 0.11, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "palm tree: 3, skateboard: 1, person: 1, earphones: 1, building: 1, tree: 2, slide: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 24594.2, "ram_available_mb": 38246.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 24582.4, "ram_available_mb": 38258.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.452, "power_cpu_cv_mean_watts": 1.658, "power_sys_5v0_mean_watts": 9.087}, "timestamp": "2026-01-23T10:04:20.422850"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12262.874, "latencies_ms": [12262.874], "images_per_second": 0.082, "prompt_tokens": 44, "response_tokens_est": 76, "n_tiles": 16, "output_text": "The skateboarder is in the foreground, performing a trick on a ramp. In the background, there are palm trees and a playground structure, indicating the skate park is located in a park-like setting. The skateboarder is near the edge of the ramp, suggesting they are in the process of executing a jump or trick.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24582.4, "ram_available_mb": 38258.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24558.9, "ram_available_mb": 38282.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.258, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 9.142}, "timestamp": "2026-01-23T10:04:34.707472"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8353.703, "latencies_ms": [8353.703], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "A person is performing a skateboard trick on a ramp at a skate park. The skateboarder is wearing a tie-dye shirt and black pants.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24558.9, "ram_available_mb": 38282.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 24558.8, "ram_available_mb": 38282.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.131, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 9.091}, "timestamp": "2026-01-23T10:04:45.102027"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9369.05, "latencies_ms": [9369.05], "images_per_second": 0.107, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The skateboarder is wearing a tie-dye shirt with a mix of purple, blue, and white colors. The lighting is natural, suggesting it is daytime, and the weather appears to be partly cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24558.8, "ram_available_mb": 38282.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24535.7, "ram_available_mb": 38305.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.313, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 9.183}, "timestamp": "2026-01-23T10:04:56.505708"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.589, "latencies_ms": [11335.589], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there is a sheep with a thick, shaggy coat of wool, standing behind a wire fence. The sheep is facing the camera, and its expression is calm and attentive. The fence is made of metal wires, and the sheep is positioned behind it, with its body partially obscured by the fence. The background of the image features", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24535.7, "ram_available_mb": 38305.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.635, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T10:05:09.907773"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7621.989, "latencies_ms": [7621.989], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "wire: 10, sheep: 1, wool: 1, grass: 1, trees: 10, sky: 1, rocks: 1, fence post: 2", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24539.9, "ram_available_mb": 38301.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.713, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T10:05:19.569351"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7194.445, "latencies_ms": [7194.445], "images_per_second": 0.139, "prompt_tokens": 44, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The sheep is positioned in the foreground of the image, behind a wire fence that is in the middle ground. The background consists of a lush green field with trees and a clear sky above.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.756, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.983}, "timestamp": "2026-01-23T10:05:28.792837"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7956.363, "latencies_ms": [7956.363], "images_per_second": 0.126, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "A sheep is lying down in a wire fenced area with a lush green background of trees and grass. The sheep appears to be resting or possibly sleeping, with its woolly body partially covered by the fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.5, "ram_available_mb": 38298.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24534.2, "ram_available_mb": 38306.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.433, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T10:05:38.766738"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9955.711, "latencies_ms": [9955.711], "images_per_second": 0.1, "prompt_tokens": 36, "response_tokens_est": 67, "n_tiles": 16, "output_text": "The image features a sheep with a thick, shaggy coat of wool, predominantly in a light brown color, with some white areas. The lighting is natural and soft, suggesting an overcast day, and the sheep is behind a wire fence, indicating it is likely in a farm or rural setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24534.2, "ram_available_mb": 38306.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.095, "power_cpu_cv_mean_watts": 1.87, "power_sys_5v0_mean_watts": 8.879}, "timestamp": "2026-01-23T10:05:50.774234"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11393.321, "latencies_ms": [11393.321], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a close-up view of a Nokia phone, bathed in a soft, golden hue. The phone's back cover, a pristine white, contrasts with the black buttons that are visible. The camera lens, a silver circle, is positioned on the top right corner of the phone, ready to capture moments. The volume rocker,", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24544.6, "ram_available_mb": 38296.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.537, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.816}, "timestamp": "2026-01-23T10:06:04.236866"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7840.485, "latencies_ms": [7840.485], "images_per_second": 0.128, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "camera: 1, flash: 1, volume rocker: 1, power button: 1, camera lens: 1, camera button: 1, camera icon: 1, logo: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24544.6, "ram_available_mb": 38296.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24536.9, "ram_available_mb": 38304.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.619, "power_cpu_cv_mean_watts": 1.698, "power_sys_5v0_mean_watts": 8.922}, "timestamp": "2026-01-23T10:06:14.111492"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11341.987, "latencies_ms": [11341.987], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The camera is positioned in the foreground of the image, with its buttons and lens clearly visible. In the background, there is a blurred image of what appears to be a colorful object, possibly a poster or a screen displaying an image. The main object, the camera, is in sharp focus and occupies the central space of the image, while the background is out of", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24536.9, "ram_available_mb": 38304.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24536.1, "ram_available_mb": 38304.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.602, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T10:06:27.473703"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9903.154, "latencies_ms": [9903.154], "images_per_second": 0.101, "prompt_tokens": 37, "response_tokens_est": 65, "n_tiles": 16, "output_text": "The image shows a close-up of a Huawei smartphone with its power button illuminated, indicating that the device is either turned on or about to be turned on. The focus is on the power button and the camera lens, with the Huawei logo visible on the side of the phone.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24536.1, "ram_available_mb": 38304.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24533.7, "ram_available_mb": 38307.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.325, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.872}, "timestamp": "2026-01-23T10:06:39.412272"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8691.448, "latencies_ms": [8691.448], "images_per_second": 0.115, "prompt_tokens": 36, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image showcases a close-up of a device with a metallic finish, featuring a prominent circular button with a red and white logo in the center. The device is illuminated by a soft light, highlighting its sleek design and reflective surface.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24533.7, "ram_available_mb": 38307.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.667, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 8.89}, "timestamp": "2026-01-23T10:06:50.142593"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12533.824, "latencies_ms": [12533.824], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a woman is standing in a kitchen, holding a wine glass and smiling. She is wearing a black dress and black heels. The kitchen features a refrigerator, a sink, and a counter. There are also several bottles on the counter, and a bowl is visible in the background. The woman appears to be enjoying her time in the kitchen", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24572.0, "ram_available_mb": 38268.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.996, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 9.066}, "timestamp": "2026-01-23T10:07:04.704420"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9645.226, "latencies_ms": [9645.226], "images_per_second": 0.104, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "refrigerator: 1, woman: 1, wine bottle: 1, wine glass: 1, bowl: 1, knife block: 1, tiles: 1, drawer: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24572.0, "ram_available_mb": 38268.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24527.4, "ram_available_mb": 38313.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.318, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 9.061}, "timestamp": "2026-01-23T10:07:16.409301"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12647.511, "latencies_ms": [12647.511], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The woman is standing in the foreground on a kitchen floor, with a refrigerator behind her to her right. The refrigerator is in the background, and there is a countertop to the left of the refrigerator with various items on it. The woman is positioned near the center of the image, with the refrigerator to her right and the counter", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24527.4, "ram_available_mb": 38313.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24539.7, "ram_available_mb": 38301.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.092, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 9.111}, "timestamp": "2026-01-23T10:07:31.074303"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8719.064, "latencies_ms": [8719.064], "images_per_second": 0.115, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "A woman in a black dress is standing in a kitchen, holding a glass of champagne in front of an open refrigerator. The kitchen has wooden cabinets and a tiled backsplash.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 24539.7, "ram_available_mb": 38301.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24576.5, "ram_available_mb": 38264.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.793, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 9.073}, "timestamp": "2026-01-23T10:07:41.827002"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9365.2, "latencies_ms": [9365.2], "images_per_second": 0.107, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows a person standing in a kitchen with wooden cabinets and a stainless steel refrigerator. The person is wearing a black dress with sparkles and black heels, and is holding a glass with a yellow drink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24576.5, "ram_available_mb": 38264.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.259, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 9.135}, "timestamp": "2026-01-23T10:07:53.210622"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11326.06, "latencies_ms": [11326.06], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment on a road, viewed through the reflection of a round mirror. The mirror, attached to a black pole, is the main focus of the image. It reflects a yellow school bus, a white car, and a blue sky. The bus and car are in motion, driving on the road. The pole holding the mirror is positioned in front of a building,", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24530.3, "ram_available_mb": 38310.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.605, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T10:08:06.592625"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7159.107, "latencies_ms": [7159.107], "images_per_second": 0.14, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "bus: 1, car: 1, traffic light: 2, building: 1, sky: 1, clouds: 1, road: 1, mirror: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24530.3, "ram_available_mb": 38310.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.04, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.92}, "timestamp": "2026-01-23T10:08:15.805855"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11323.25, "latencies_ms": [11323.25], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a close-up of a rearview mirror reflecting a yellow school bus on the road behind it. The bus is positioned in the middle ground of the reflection, with other vehicles and a building visible in the background. The mirror is attached to a pole on the left side of the image, and the reflection shows the bus moving away from the mirror's", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.598, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T10:08:29.158784"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8774.107, "latencies_ms": [8774.107], "images_per_second": 0.114, "prompt_tokens": 37, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image shows a rearview mirror of a vehicle, likely a car or a bus, reflecting the road ahead. The mirror captures the image of a yellow school bus and other vehicles on the road, indicating that the vehicle is on a busy road or highway.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24534.7, "ram_available_mb": 38306.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24533.8, "ram_available_mb": 38307.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.961, "power_cpu_cv_mean_watts": 1.737, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T10:08:39.950319"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7206.391, "latencies_ms": [7206.391], "images_per_second": 0.139, "prompt_tokens": 36, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The mirror shows a yellow school bus with a reflection of a car and a building in the background. The sky is cloudy and the lighting is dim, suggesting it might be early morning or late afternoon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.8, "ram_available_mb": 38307.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.579, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.955}, "timestamp": "2026-01-23T10:08:49.189043"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11352.116, "latencies_ms": [11352.116], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a gray cat and a brown dog are sitting on a wooden table, looking at a potted plant. The cat is positioned on the right side of the table, while the dog is on the left side. The potted plant is placed in the center of the table, capturing the attention of both the cat and the dog. The scene appears to be set in a", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24528.5, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.537, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T10:09:02.608014"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7156.959, "latencies_ms": [7156.959], "images_per_second": 0.14, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "cat: 1, dog: 1, window: 1, plant: 1, pot: 1, soil: 1, label: 1, sunlight: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24528.5, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.847, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.925}, "timestamp": "2026-01-23T10:09:11.795456"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10893.314, "latencies_ms": [10893.314], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "In the foreground, there is a potted plant on the right side of the image, which is near the cat that is on the right side of the image. The dog is in the background, behind the cat, and appears to be looking towards the plant. The plant is closer to the camera than the dog, making it appear larger in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24528.8, "ram_available_mb": 38312.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24533.2, "ram_available_mb": 38307.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.796, "power_cpu_cv_mean_watts": 1.911, "power_sys_5v0_mean_watts": 8.831}, "timestamp": "2026-01-23T10:09:24.736721"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7326.243, "latencies_ms": [7326.243], "images_per_second": 0.136, "prompt_tokens": 37, "response_tokens_est": 42, "n_tiles": 16, "output_text": "A gray cat and a brown dog are sitting on a windowsill, looking at a potted plant. The cat is on the right side of the image, while the dog is on the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.2, "ram_available_mb": 38307.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24528.7, "ram_available_mb": 38312.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.561, "power_cpu_cv_mean_watts": 1.633, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T10:09:34.095403"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7400.093, "latencies_ms": [7400.093], "images_per_second": 0.135, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image features a gray cat and a brown dog standing on a wooden surface, with a potted plant in front of them. The lighting in the room is natural, coming from the large window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24528.7, "ram_available_mb": 38312.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24521.1, "ram_available_mb": 38319.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.541, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.943}, "timestamp": "2026-01-23T10:09:43.524105"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11340.081, "latencies_ms": [11340.081], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young woman is the main focus, dressed in a blue sports jersey and shorts, actively engaged in a game of soccer. She is skillfully maneuvering a soccer ball with her right hand, showcasing her athletic prowess. The soccer ball is positioned in the lower left corner of the image, indicating that she", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 24521.1, "ram_available_mb": 38319.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24523.9, "ram_available_mb": 38317.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.612, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T10:09:56.905528"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7285.727, "latencies_ms": [7285.727], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "ball: 1, player: 2, jersey: 2, hand: 2, foot: 2, grass: 1, field: 1, team: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24523.9, "ram_available_mb": 38317.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24526.2, "ram_available_mb": 38314.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.897, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.885}, "timestamp": "2026-01-23T10:10:06.215783"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11362.674, "latencies_ms": [11362.674], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The main object, a person in a blue sports jersey, is in the foreground and appears to be running towards the left side of the image, holding a soccer ball. Another person, wearing a yellow jersey, is in the background and seems to be slightly behind and to the right of the main object. The background is out of focus, emphasizing the main object", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24526.2, "ram_available_mb": 38314.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 24537.3, "ram_available_mb": 38303.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.631, "power_cpu_cv_mean_watts": 2.184, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T10:10:19.619735"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7990.064, "latencies_ms": [7990.064], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "A female soccer player in a blue jersey is in possession of the ball and appears to be running with it. Another player in a yellow jersey is in the background, possibly preparing to challenge for the ball.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24537.3, "ram_available_mb": 38303.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.375, "power_cpu_cv_mean_watts": 2.17, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T10:10:29.621839"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11282.479, "latencies_ms": [11282.479], "images_per_second": 0.089, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a person in a blue sports jersey with the word \"Acronis\" prominently displayed across the chest, indicating a sponsorship or branding element. The jersey has a V-neck design and is paired with shorts, suggesting a casual or athletic setting. The person is holding a soccer ball, which is white with", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.7, "ram_available_mb": 38295.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 24549.6, "ram_available_mb": 38291.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.6, "power_cpu_cv_mean_watts": 2.055, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T10:10:42.922956"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11321.131, "latencies_ms": [11321.131], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there are two giraffes in a grassy enclosure. The giraffe on the left is bending down to eat some grass, while the one on the right is standing tall and looking around. The enclosure is surrounded by a wooden fence, and there are trees in the background. The giraffes are the main focus of the image, and", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 24549.6, "ram_available_mb": 38291.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.658, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T10:10:56.266528"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7395.452, "latencies_ms": [7395.452], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "giraffe: 2, fence: 1, tree: multiple, grass: large area, path: small dirt area, enclosure: large, wall: wooden, building: not visible", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24551.7, "ram_available_mb": 38289.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.871, "power_cpu_cv_mean_watts": 1.64, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T10:11:05.687804"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9624.42, "latencies_ms": [9624.42], "images_per_second": 0.104, "prompt_tokens": 44, "response_tokens_est": 64, "n_tiles": 16, "output_text": "In the foreground, there is a giraffe standing on the left side of a wooden fence, while another giraffe is standing on the right side of the same fence. The background is filled with lush green trees, creating a natural and serene environment for the giraffes.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24551.7, "ram_available_mb": 38289.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24536.9, "ram_available_mb": 38304.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.243, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 8.88}, "timestamp": "2026-01-23T10:11:17.358233"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7632.485, "latencies_ms": [7632.485], "images_per_second": 0.131, "prompt_tokens": 37, "response_tokens_est": 45, "n_tiles": 16, "output_text": "Two giraffes are standing in a grassy enclosure with a wooden fence, surrounded by trees. One giraffe is bending down to eat grass, while the other stands tall and looks around.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24536.9, "ram_available_mb": 38304.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24539.2, "ram_available_mb": 38301.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.543, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T10:11:27.028537"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7105.347, "latencies_ms": [7105.347], "images_per_second": 0.141, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image shows two giraffes in a grassy enclosure with a wooden fence. The lighting appears to be natural daylight, and the weather seems to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24539.2, "ram_available_mb": 38301.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.733, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 8.954}, "timestamp": "2026-01-23T10:11:36.147324"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12545.198, "latencies_ms": [12545.198], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of travel preparation. A gray suitcase, equipped with a handle and wheels, sits on a carpeted floor, ready for a journey. It's accompanied by a black trash bag, perhaps filled with discarded items, and a black bag, possibly containing personal belongings. The backdrop is a white curtain, adding a touch", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.812, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 9.043}, "timestamp": "2026-01-23T10:11:50.722305"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6960.35, "latencies_ms": [6960.35], "images_per_second": 0.144, "prompt_tokens": 39, "response_tokens_est": 28, "n_tiles": 16, "output_text": "bag: 2\nsuitcase: 1\nbox: 1\ncarpet: 1\ncurtain: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24535.5, "ram_available_mb": 38305.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 24591.2, "ram_available_mb": 38249.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.284, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 9.127}, "timestamp": "2026-01-23T10:11:59.712983"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12620.079, "latencies_ms": [12620.079], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground of the image, there is a suitcase standing upright with its handle extended to the right, suggesting it is ready to be picked up. Behind the suitcase, there is a trash bin to its left, partially obscured by the suitcase. The trash bin appears to be on the same floor level as the suitcase. The background consists of a", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24591.2, "ram_available_mb": 38249.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24562.1, "ram_available_mb": 38278.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.056, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 9.068}, "timestamp": "2026-01-23T10:12:14.363974"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11218.804, "latencies_ms": [11218.804], "images_per_second": 0.089, "prompt_tokens": 37, "response_tokens_est": 65, "n_tiles": 16, "output_text": "The image shows a collection of luggage items, including a suitcase and a duffel bag, placed on a carpeted floor against a backdrop of sheer curtains. It appears to be a hotel room or a similar setting where someone is packing or unpacking their belongings.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24562.1, "ram_available_mb": 38278.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24564.4, "ram_available_mb": 38276.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.718, "power_cpu_cv_mean_watts": 1.676, "power_sys_5v0_mean_watts": 9.063}, "timestamp": "2026-01-23T10:12:27.597993"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10623.778, "latencies_ms": [10623.778], "images_per_second": 0.094, "prompt_tokens": 36, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The image is in black and white, featuring a suitcase, a bag, and a trash can against a backdrop of sheer curtains. The materials appear to be typical for travel items, with the suitcase and bag made of fabric and the trash bag made of plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24564.4, "ram_available_mb": 38276.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24608.6, "ram_available_mb": 38232.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.707, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 9.131}, "timestamp": "2026-01-23T10:12:40.277853"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11348.511, "latencies_ms": [11348.511], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man wearing a red bandana and a blue shirt is standing in a forest, looking at two horses that are walking down a rocky path. The man appears to be observing the horses as they make their way through the forest. The horses are positioned in the middle of the scene, with one horse closer to the left side and the other horse closer to", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24537.8, "ram_available_mb": 38303.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.635, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T10:12:53.676290"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9554.767, "latencies_ms": [9554.767], "images_per_second": 0.105, "prompt_tokens": 39, "response_tokens_est": 62, "n_tiles": 16, "output_text": "- Trees: numerous\n\n- Rocks: numerous\n\n- Horses: 2\n\n- Person: 1\n\n- Backpack: 1\n\n- Hat: 1\n\n- Grass: patches of green\n\n- Dirt path: visible", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24531.6, "ram_available_mb": 38309.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.455, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T10:13:05.253462"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11362.074, "latencies_ms": [11362.074], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a person wearing a blue shirt and a red bandana on their head, with a backpack on their back, looking towards the left side of the image. In the background, there are two individuals on horseback, one of whom is wearing a hat, and they are situated between the person in the foreground and the trees. The person on", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24531.6, "ram_available_mb": 38309.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.517, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T10:13:18.650987"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8415.729, "latencies_ms": [8415.729], "images_per_second": 0.119, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "In a forested area with a rocky path, a person is riding a horse, while another person with a backpack is watching. The scene suggests a leisurely outdoor activity, possibly hiking or horseback riding.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24529.9, "ram_available_mb": 38311.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.057, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 8.872}, "timestamp": "2026-01-23T10:13:29.091831"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8370.253, "latencies_ms": [8370.253], "images_per_second": 0.119, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image features a bright and sunny day with clear skies, casting natural light that illuminates the scene. The colors are vibrant, with the green of the trees contrasting against the blue of the sky and the brown of the horses.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24543.2, "ram_available_mb": 38297.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24540.1, "ram_available_mb": 38300.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.819, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 8.922}, "timestamp": "2026-01-23T10:13:39.519389"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11371.839, "latencies_ms": [11371.839], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In this black and white photo, a man is riding a horse on a bridge. The man is wearing a jacket and is holding the reins of the horse, guiding it as it moves. The horse is positioned in the center of the image, with the man standing on its back. The bridge they are on is made of wood and has a railing on the side", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 24540.1, "ram_available_mb": 38300.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.572, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T10:13:52.940959"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10024.256, "latencies_ms": [10024.256], "images_per_second": 0.1, "prompt_tokens": 39, "response_tokens_est": 66, "n_tiles": 16, "output_text": "1. Man: 1\n2. Horse: 1\n3. Stick: 1\n4. Sweater: 1\n5. Rider: 1\n6. Blanket: 1\n7. Saddle: 1\n8. Grass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24531.5, "ram_available_mb": 38309.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.415, "power_cpu_cv_mean_watts": 1.83, "power_sys_5v0_mean_watts": 8.876}, "timestamp": "2026-01-23T10:14:04.991230"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10213.352, "latencies_ms": [10213.352], "images_per_second": 0.098, "prompt_tokens": 44, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The person is standing on the back of the horse, which is in the foreground of the image. The background is blurred, but it appears to be a flat landscape with no other objects in the immediate vicinity. The horse and rider are the main focus of the image, with the background serving as a backdrop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24531.5, "ram_available_mb": 38309.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24534.9, "ram_available_mb": 38306.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.112, "power_cpu_cv_mean_watts": 1.886, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T10:14:17.228483"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6710.634, "latencies_ms": [6710.634], "images_per_second": 0.149, "prompt_tokens": 37, "response_tokens_est": 37, "n_tiles": 16, "output_text": "A man is riding a horse, and the horse is moving at a fast pace. The man is wearing a jacket with the word \"Rio\" on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.9, "ram_available_mb": 38306.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.349, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 8.932}, "timestamp": "2026-01-23T10:14:25.985566"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7542.886, "latencies_ms": [7542.886], "images_per_second": 0.133, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image is in black and white, with a high contrast between the light and dark areas. The weather appears to be overcast, as the sky is filled with clouds and the overall lighting is soft and diffused.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.336, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 8.947}, "timestamp": "2026-01-23T10:14:35.581533"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11372.009, "latencies_ms": [11372.009], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene scene of a group of geese swimming in a calm body of water. There are at least six geese visible in the water, with some of them closer to the foreground and others further away. The geese are floating peacefully, enjoying their time in the water.\n\nThe water appears to be a lake or a pond, surrounded", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24528.5, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.57, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.819}, "timestamp": "2026-01-23T10:14:48.991804"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4180.198, "latencies_ms": [4180.198], "images_per_second": 0.239, "prompt_tokens": 39, "response_tokens_est": 15, "n_tiles": 16, "output_text": "geese: 5, trees: numerous, grasses: dense", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24528.5, "ram_available_mb": 38312.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.421, "power_cpu_cv_mean_watts": 1.052, "power_sys_5v0_mean_watts": 9.162}, "timestamp": "2026-01-23T10:14:55.184484"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11347.0, "latencies_ms": [11347.0], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there are three ducks swimming in the water, with one duck slightly closer to the viewer than the others. In the background, there are trees and grasses surrounding the body of water, creating a natural and serene environment. The ducks are positioned near the center of the image, with the trees and grasses appearing further away, creating a sense", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24538.3, "ram_available_mb": 38302.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24524.0, "ram_available_mb": 38316.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.637, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T10:15:08.563723"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7173.597, "latencies_ms": [7173.597], "images_per_second": 0.139, "prompt_tokens": 37, "response_tokens_est": 41, "n_tiles": 16, "output_text": "A group of geese is swimming in a calm body of water surrounded by lush greenery and tall grasses. The tranquil scene depicts a peaceful moment in nature.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24524.0, "ram_available_mb": 38316.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24527.6, "ram_available_mb": 38313.3, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.92, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.915}, "timestamp": "2026-01-23T10:15:17.774441"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6937.843, "latencies_ms": [6937.843], "images_per_second": 0.144, "prompt_tokens": 36, "response_tokens_est": 40, "n_tiles": 16, "output_text": "The image features a serene body of water with a group of geese swimming in it. The water is reflecting the surrounding trees and grass, creating a calm and peaceful atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24527.6, "ram_available_mb": 38313.3, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24533.4, "ram_available_mb": 38307.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.723, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T10:15:26.737268"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11361.046, "latencies_ms": [11361.046], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a cat with a coat of white and orange fur is perched on the hood of a black Mercedes-Benz car. The car is parked in front of a brick building, and a green fence can be seen in the background. The cat appears to be looking down at the car, perhaps curious about its surroundings or simply enjoying the view from", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24533.4, "ram_available_mb": 38307.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24531.0, "ram_available_mb": 38309.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.523, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.832}, "timestamp": "2026-01-23T10:15:40.136819"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7514.594, "latencies_ms": [7514.594], "images_per_second": 0.133, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "car: 1\nmercedes logo: 1\nwindow: 4\ngrill: 1\ncat: 1\nbuilding: 1\nplant: 1\nflower: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24531.0, "ram_available_mb": 38309.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24526.1, "ram_available_mb": 38314.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.708, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.888}, "timestamp": "2026-01-23T10:15:49.666640"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7342.132, "latencies_ms": [7342.132], "images_per_second": 0.136, "prompt_tokens": 44, "response_tokens_est": 44, "n_tiles": 16, "output_text": "The cat is sitting on the hood of a black Mercedes car, which is in the foreground of the image. In the background, there is a building with windows and a fence with green plants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24526.1, "ram_available_mb": 38314.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24533.1, "ram_available_mb": 38307.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.62, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 8.943}, "timestamp": "2026-01-23T10:15:59.063427"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8826.133, "latencies_ms": [8826.133], "images_per_second": 0.113, "prompt_tokens": 37, "response_tokens_est": 55, "n_tiles": 16, "output_text": "A cat is sitting on the hood of a black Mercedes-Benz car, with its reflection visible in the glossy surface. The car is parked in front of a building with a brick facade and a green fence with plants behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.1, "ram_available_mb": 38307.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24530.9, "ram_available_mb": 38310.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.77, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 8.816}, "timestamp": "2026-01-23T10:16:09.948856"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7552.512, "latencies_ms": [7552.512], "images_per_second": 0.132, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image features a black Mercedes-Benz car with a cat sitting on the hood. The car is parked in front of a building with a brick facade and a green fence with plants behind it.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24530.9, "ram_available_mb": 38310.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24528.4, "ram_available_mb": 38312.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.449, "power_cpu_cv_mean_watts": 1.701, "power_sys_5v0_mean_watts": 8.928}, "timestamp": "2026-01-23T10:16:19.512625"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11343.793, "latencies_ms": [11343.793], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a snowboarder is captured in mid-air, performing a daring trick on a snowy mountain. The snowboarder is wearing a brown jacket and yellow pants, and is holding onto a snowboard with both hands. The snowboarder is suspended in the air, with the snowboard angled upwards, indicating a high jump. The background", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24528.4, "ram_available_mb": 38312.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24533.1, "ram_available_mb": 38307.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.498, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T10:16:32.909464"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9360.137, "latencies_ms": [9360.137], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 60, "n_tiles": 16, "output_text": "sky: 1\n\nsnowboard: 1\n\nsnowflakes: numerous\n\nsnow: 1\n\nsnowboarder: 1\n\nsweater: 1\n\npants: 1\n\njacket: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.1, "ram_available_mb": 38307.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24549.0, "ram_available_mb": 38291.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.454, "power_cpu_cv_mean_watts": 1.779, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T10:16:44.307062"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8839.607, "latencies_ms": [8839.607], "images_per_second": 0.113, "prompt_tokens": 44, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The snowboarder is in the foreground, performing a trick in the air above a snowy hill. The clear blue sky forms the background, and the snowflakes are scattered throughout the image, indicating that the photo was taken on a cold, snowy day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.0, "ram_available_mb": 38291.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.573, "power_cpu_cv_mean_watts": 1.793, "power_sys_5v0_mean_watts": 8.885}, "timestamp": "2026-01-23T10:16:55.163075"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8529.37, "latencies_ms": [8529.37], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "A snowboarder is captured in mid-air, performing a trick against a clear blue sky backdrop. The snowboarder is wearing a brown jacket and yellow pants, and is in the process of jumping off a snowy hill.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24547.0, "ram_available_mb": 38293.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.924, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 8.879}, "timestamp": "2026-01-23T10:17:05.746763"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7782.158, "latencies_ms": [7782.158], "images_per_second": 0.128, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The snowboarder is wearing a brown jacket and bright yellow pants, and is performing a trick in the air. The sky is a clear blue, and there are snowflakes falling around the snowboarder.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24547.0, "ram_available_mb": 38293.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.2, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.943}, "timestamp": "2026-01-23T10:17:15.563900"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11314.138, "latencies_ms": [11314.138], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a quaint, small bathroom bathed in soft light. Dominating the scene is a pristine white toilet, its lid closed, standing on a wooden floor. The toilet is positioned against a white wall, which is adorned with a single light switch. Above the toilet, a white pipe runs along the wall, its", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24535.4, "ram_available_mb": 38305.5, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.548, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T10:17:28.945818"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10261.057, "latencies_ms": [10261.057], "images_per_second": 0.097, "prompt_tokens": 39, "response_tokens_est": 68, "n_tiles": 16, "output_text": "- Toilet: 1\n\n- Bathtub: 1\n\n- Pipes: 10\n\n- Chain: 1\n\n- Tiles: 1\n\n- Door: 1\n\n- Light fixture: 1\n\n- Graffiti: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24535.4, "ram_available_mb": 38305.5, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24536.5, "ram_available_mb": 38304.4, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.23, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 8.833}, "timestamp": "2026-01-23T10:17:41.245962"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11387.51, "latencies_ms": [11387.51], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground of the image, there is a toilet positioned on the left side, which is relatively close to the viewer. Behind the toilet, there is a white bathtub on the right side, which is further away from the viewer. The pipes and tanks are mounted on the wall in the background, creating a sense of depth in the", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24536.5, "ram_available_mb": 38304.4, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.573, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T10:17:54.693026"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11534.943, "latencies_ms": [11534.943], "images_per_second": 0.087, "prompt_tokens": 37, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image depicts a small, old-fashioned bathroom with a toilet and a bathtub. The toilet has a unique design with a wooden seat and a chain hanging from the wall above it. The bathtub is white and appears to be made of porcelain. The walls are painted white and there are several pipes running along the wall", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24545.2, "ram_available_mb": 38295.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.705, "power_cpu_cv_mean_watts": 1.908, "power_sys_5v0_mean_watts": 8.824}, "timestamp": "2026-01-23T10:18:08.261364"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11384.228, "latencies_ms": [11384.228], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image shows a bathroom with a vintage or industrial aesthetic, featuring a white toilet with a wooden seat and lid, a white bathtub with metal fixtures, and a complex network of white pipes and chains hanging from the ceiling. The lighting is dim, and the walls are painted in a light color, possibly white or cre", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24535.0, "ram_available_mb": 38305.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24549.6, "ram_available_mb": 38291.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.659, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T10:18:21.680685"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11348.105, "latencies_ms": [11348.105], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a statue of a man is depicted flying a kite. The statue is positioned on a pedestal, and the kite is soaring high in the sky. The man appears to be enjoying the activity, as he is holding the kite string with both hands. The kite itself is multicolored, adding a vibrant touch to the scene", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24549.6, "ram_available_mb": 38291.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 24552.1, "ram_available_mb": 38288.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.601, "power_cpu_cv_mean_watts": 2.094, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T10:18:35.079994"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10733.284, "latencies_ms": [10733.284], "images_per_second": 0.093, "prompt_tokens": 39, "response_tokens_est": 72, "n_tiles": 16, "output_text": "1. Kite: 1\n2. Statue: 1\n3. Building: 1\n4. Skyscraper: 1\n5. Clouds: 1\n6. Sculpture: 1\n7. Statue base: 1\n8. Sculpture base: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24552.1, "ram_available_mb": 38288.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 24561.7, "ram_available_mb": 38279.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.027, "power_cpu_cv_mean_watts": 2.336, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T10:18:47.848757"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11393.155, "latencies_ms": [11393.155], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a statue of a person holding a kite, which is positioned near the top right corner of the image. The kite is flying in the air, slightly above the statue's head. In the background, there is a tall building with a glass facade, and the sky is visible above it. The statue appears to be in front of the building", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24561.7, "ram_available_mb": 38279.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.613, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T10:19:01.272088"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7424.613, "latencies_ms": [7424.613], "images_per_second": 0.135, "prompt_tokens": 37, "response_tokens_est": 43, "n_tiles": 16, "output_text": "A statue of a person holding a kite is located in front of a modern building with glass windows. The kite is flying high in the sky, and the person appears to be enjoying the activity.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24552.8, "ram_available_mb": 38288.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.847, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T10:19:10.720154"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7939.373, "latencies_ms": [7939.373], "images_per_second": 0.126, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image features a statue of a person holding a kite, with the kite displaying a colorful pattern. The statue is located in front of a modern building with a glass facade, and the sky appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24552.8, "ram_available_mb": 38288.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24554.5, "ram_available_mb": 38286.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.374, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 8.901}, "timestamp": "2026-01-23T10:19:20.686403"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11409.407, "latencies_ms": [11409.407], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a table filled with a variety of fresh vegetables and fruits. There are several bowls and baskets containing different types of produce. The table is covered with a diverse assortment of vegetables, including carrots, broccoli, and potatoes. \n\nIn addition to the vegetables, there are also some fruits present, such as st", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 24554.5, "ram_available_mb": 38286.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24557.6, "ram_available_mb": 38283.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.4, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 8.796}, "timestamp": "2026-01-23T10:19:34.144880"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9217.671, "latencies_ms": [9217.671], "images_per_second": 0.108, "prompt_tokens": 39, "response_tokens_est": 59, "n_tiles": 16, "output_text": "strawberries: 20, broccoli: 1, cucumber: 1, radishes: 12, carrots: 5, potatoes: 8, green beans: 10, asparagus: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24557.6, "ram_available_mb": 38283.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24549.7, "ram_available_mb": 38291.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.647, "power_cpu_cv_mean_watts": 1.799, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T10:19:45.407003"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10292.461, "latencies_ms": [10292.461], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "In the foreground, there are bright red strawberries in a wooden bowl on the left side of the image. Behind them, in the middle ground, are green beans in a white plastic bag. In the background, there are various vegetables including radishes, carrots, and asparagus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.7, "ram_available_mb": 38291.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.045, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T10:19:57.748715"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10149.847, "latencies_ms": [10149.847], "images_per_second": 0.099, "prompt_tokens": 37, "response_tokens_est": 67, "n_tiles": 16, "output_text": "The image showcases a variety of fresh vegetables and fruits arranged on a table, including strawberries, broccoli, carrots, and potatoes. The setting appears to be a market or a display of produce, with the vegetables and fruits presented in an appealing and colorful manner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24546.6, "ram_available_mb": 38294.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.193, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T10:20:09.941226"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9931.065, "latencies_ms": [9931.065], "images_per_second": 0.101, "prompt_tokens": 36, "response_tokens_est": 67, "n_tiles": 16, "output_text": "The image showcases a variety of fresh produce, including vibrant red strawberries, green asparagus, and pink radishes, all laid out on a wooden surface. The lighting is bright and natural, suggesting the photo was taken outdoors or in a well-lit indoor area.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24546.6, "ram_available_mb": 38294.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.17, "power_cpu_cv_mean_watts": 1.878, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T10:20:21.908491"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11336.975, "latencies_ms": [11336.975], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of joy and camaraderie among three individuals, likely friends, as they engage in a shared activity of playing video games. The room is dimly lit, with the primary source of light coming from a television screen that is visible in the background. The television is turned on, and the screen is displaying a game, although the specific game is not discern", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24544.9, "ram_available_mb": 38296.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.548, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T10:20:35.315834"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8085.793, "latencies_ms": [8085.793], "images_per_second": 0.124, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "person: 3\ngame controller: 2\ncouch: 1\ntv: 1\nremote control: 2\nwii: 1\nwii remote: 2\nwii remote holder: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24544.9, "ram_available_mb": 38296.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.389, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T10:20:45.454683"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11335.601, "latencies_ms": [11335.601], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a person on the left side of the image, holding a gaming controller and facing towards the right side of the image where another person is seated on a couch. The third person is on the far right, also holding a controller and facing the left. The couch is positioned in the middle ground, and there is a bed with a backpack", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.614, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T10:20:58.842826"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7057.123, "latencies_ms": [7057.123], "images_per_second": 0.142, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "Three people are sitting on a couch in a dimly lit room, laughing and playing video games together. The room appears to be a living space with a comfortable and casual atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.249, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 8.924}, "timestamp": "2026-01-23T10:21:07.935260"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8048.204, "latencies_ms": [8048.204], "images_per_second": 0.124, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image is dimly lit with a focus on the three individuals who are seated on a patterned couch. The lighting appears to be coming from a television screen in front of them, casting a blue hue on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24548.9, "ram_available_mb": 38292.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.065, "power_cpu_cv_mean_watts": 1.737, "power_sys_5v0_mean_watts": 8.889}, "timestamp": "2026-01-23T10:21:17.995495"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11327.876, "latencies_ms": [11327.876], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene pastoral scene. In the foreground, a lone white cow is lying down on a lush green field, its body relaxed and at ease. A little distance away, a group of black and white cows are also resting, their bodies stretched out in a similar fashion. The field they are in is a vibrant green, indic", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24548.9, "ram_available_mb": 38292.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 24544.7, "ram_available_mb": 38296.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.618, "power_cpu_cv_mean_watts": 1.939, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T10:21:31.376789"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7430.251, "latencies_ms": [7430.251], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "tree: 1\ncows: 5\ngrass: many\nfield: 1\nsky: 1\nleaves: many\nstones: 0\nbirds: 0", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24544.7, "ram_available_mb": 38296.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24546.4, "ram_available_mb": 38294.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.866, "power_cpu_cv_mean_watts": 1.633, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T10:21:40.839120"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11341.595, "latencies_ms": [11341.595], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a lone cow lying on the grass, closer to the viewer than the other cows. The cows are spread out in the background, with some lying down and others standing, all at a distance from the viewer. The tree trunk is in the foreground on the right side of the image, while the cows are scattered in the middle", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.4, "ram_available_mb": 38294.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.631, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T10:21:54.196915"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7524.234, "latencies_ms": [7524.234], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A group of cows is resting in a lush green field, with one cow lying down close to a tree trunk. The cows appear to be at ease, enjoying the peaceful environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24536.6, "ram_available_mb": 38304.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.507, "power_cpu_cv_mean_watts": 1.658, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T10:22:03.734686"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6971.564, "latencies_ms": [6971.564], "images_per_second": 0.143, "prompt_tokens": 36, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The image features a lush green field with a clear sky, indicating a sunny day. A tree with a rough bark texture is prominently visible on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.6, "ram_available_mb": 38304.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24552.6, "ram_available_mb": 38288.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.905, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 8.93}, "timestamp": "2026-01-23T10:22:12.748096"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11342.111, "latencies_ms": [11342.111], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image is a black and white photograph of a large group of young boys, likely students, posing for a group photo. They are all dressed in formal attire, with some wearing ties. The boys are arranged in rows, with some sitting on the ground and others standing. The photograph appears to be from the early 20th century, as indicated by the style of cl", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 24552.6, "ram_available_mb": 38288.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24548.6, "ram_available_mb": 38292.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.632, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.811}, "timestamp": "2026-01-23T10:22:26.119464"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11401.27, "latencies_ms": [11401.27], "images_per_second": 0.088, "prompt_tokens": 39, "response_tokens_est": 78, "n_tiles": 16, "output_text": "group of boys: 50, boys wearing ties: 30, boys wearing suits: 10, boys wearing sweaters: 10, boys wearing shorts: 10, boys wearing socks: 10, boys wearing shoes: 10, boys wearing hats: 10", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24548.6, "ram_available_mb": 38292.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.752, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 8.824}, "timestamp": "2026-01-23T10:22:39.554374"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9956.539, "latencies_ms": [9956.539], "images_per_second": 0.1, "prompt_tokens": 44, "response_tokens_est": 67, "n_tiles": 16, "output_text": "In the image, the group of boys is arranged in two distinct formations. The larger group is seated in the foreground, with boys spaced out evenly across the ground, while the smaller group is standing in the background, positioned behind the seated boys, creating a clear spatial separation between the two groups.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.0, "ram_available_mb": 38303.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 24553.7, "ram_available_mb": 38287.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.16, "power_cpu_cv_mean_watts": 2.03, "power_sys_5v0_mean_watts": 8.873}, "timestamp": "2026-01-23T10:22:51.563153"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8843.352, "latencies_ms": [8843.352], "images_per_second": 0.113, "prompt_tokens": 37, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image is a black and white photograph of a large group of students at Goodmayes Boys' School, taken in April 1929. The students are arranged in rows, with some standing and others sitting, and they are all dressed in formal attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.7, "ram_available_mb": 38287.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 24561.8, "ram_available_mb": 38279.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.133, "power_cpu_cv_mean_watts": 2.264, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T10:23:02.422826"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8120.529, "latencies_ms": [8120.529], "images_per_second": 0.123, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image is a black and white photograph, indicating it was taken in an era before color photography was common. The lighting is even, suggesting it was taken on a clear day, and the attire of the individuals suggests a formal occasion.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24561.8, "ram_available_mb": 38279.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 24556.6, "ram_available_mb": 38284.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.995, "power_cpu_cv_mean_watts": 1.938, "power_sys_5v0_mean_watts": 8.921}, "timestamp": "2026-01-23T10:23:12.574569"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11316.088, "latencies_ms": [11316.088], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a vibrant scene of a kite soaring high in the sky. The kite, a striking combination of orange and blue, is tilted slightly to the left, adding a dynamic element to the composition. It's flying over a lush green field, which is dotted with trees and buildings in the background. The sky above is a clear blue,", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.6, "ram_available_mb": 38284.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.66, "power_cpu_cv_mean_watts": 1.953, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T10:23:25.957438"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6493.059, "latencies_ms": [6493.059], "images_per_second": 0.154, "prompt_tokens": 39, "response_tokens_est": 35, "n_tiles": 16, "output_text": "kite: 1, cloud: multiple, tree: multiple, building: multiple, grass: multiple, sky: multiple, person: 1, car: multiple", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24566.2, "ram_available_mb": 38274.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.486, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 8.93}, "timestamp": "2026-01-23T10:23:34.468926"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11332.397, "latencies_ms": [11332.397], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "The kite is flying in the sky, positioned in the upper right quadrant of the image, while the buildings are in the background, located in the lower left quadrant. The trees are situated between the buildings and the kite, creating a sense of depth in the image. The kite appears to be flying closer to the viewer, while the buildings seem further away.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24566.2, "ram_available_mb": 38274.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24564.8, "ram_available_mb": 38276.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.603, "power_cpu_cv_mean_watts": 1.939, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T10:23:47.841515"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7498.737, "latencies_ms": [7498.737], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A colorful kite is flying high in the sky above a park with trees and buildings in the background. The kite appears to be a rainbow-colored butterfly or dragonfly design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24564.8, "ram_available_mb": 38276.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.553, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 8.86}, "timestamp": "2026-01-23T10:23:57.382698"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9133.316, "latencies_ms": [9133.316], "images_per_second": 0.109, "prompt_tokens": 36, "response_tokens_est": 60, "n_tiles": 16, "output_text": "The kite in the image has a gradient of colors, transitioning from red at the tip to blue at the tail, with a hint of orange near the tail. It is flying high in the sky with a backdrop of a partly cloudy blue sky and fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.481, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 8.885}, "timestamp": "2026-01-23T10:24:08.577967"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11337.769, "latencies_ms": [11337.769], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of anticipation, just before the first slice of a freshly baked pizza is taken. The pizza, with its golden brown crust, sits in a cardboard box, its surface adorned with a generous layer of melted cheese that has turned a light golden color. The cheese is speckled with red pepper", "error": null, "sys_before": {"cpu_percent": 5.7, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24555.0, "ram_available_mb": 38285.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.607, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T10:24:21.993058"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8312.341, "latencies_ms": [8312.341], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "pizza: 1\nbox: 1\ncheese: 1\ntomato sauce: 1\npepperoni: 1\nmushroom: 1\nolive: 1\nbasil: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.0, "ram_available_mb": 38285.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24547.5, "ram_available_mb": 38293.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.174, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T10:24:32.349827"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11366.263, "latencies_ms": [11366.263], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The pizza is centrally located in the image, occupying the majority of the space. It is placed within a cardboard pizza box, which is positioned on a flat surface that appears to be a table or countertop. The pizza is in the foreground, making it the main focus of the image, while the background is less distinct but seems to be the edge of", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24547.5, "ram_available_mb": 38293.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.553, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.865}, "timestamp": "2026-01-23T10:24:45.750140"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7254.074, "latencies_ms": [7254.074], "images_per_second": 0.138, "prompt_tokens": 37, "response_tokens_est": 42, "n_tiles": 16, "output_text": "A large pizza with melted cheese and tomato sauce is placed in a cardboard pizza box. The pizza appears to be freshly baked and ready to be served.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.864, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 8.906}, "timestamp": "2026-01-23T10:24:55.040849"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10141.732, "latencies_ms": [10141.732], "images_per_second": 0.099, "prompt_tokens": 36, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The pizza in the image has a golden-brown crust with a generous amount of melted cheese on top, which is slightly browned in spots. It is placed in a cardboard pizza box, and the lighting in the image highlights the texture of the cheese and the crust.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24541.0, "ram_available_mb": 38299.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.102, "power_cpu_cv_mean_watts": 1.909, "power_sys_5v0_mean_watts": 8.879}, "timestamp": "2026-01-23T10:25:07.234977"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11367.0, "latencies_ms": [11367.0], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, two women are sitting on a refrigerator placed on the sidewalk. One woman is sitting on the left side of the refrigerator, while the other woman is sitting on the right side. They both appear to be enjoying their time together, possibly having a conversation or sharing a drink.\n\nThere are two cups visible in the scene, one near", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.549, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.826}, "timestamp": "2026-01-23T10:25:20.645929"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8671.019, "latencies_ms": [8671.019], "images_per_second": 0.115, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "- Woman: 2\n- Refrigerator: 1\n- Beer: 2\n- Cup: 2\n- Street: 1\n- Sidewalk: 1\n- Pavement: 1\n- Chair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.8, "ram_available_mb": 38299.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.888, "power_cpu_cv_mean_watts": 1.753, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T10:25:31.378081"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9388.466, "latencies_ms": [9388.466], "images_per_second": 0.107, "prompt_tokens": 44, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The woman sitting on the left is positioned in the foreground and is closer to the camera than the woman sitting in the fridge. The fridge is located on the right side of the image, near the curb, and is further away from the camera than the woman sitting on the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24550.5, "ram_available_mb": 38290.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.413, "power_cpu_cv_mean_watts": 1.847, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T10:25:42.780459"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6904.569, "latencies_ms": [6904.569], "images_per_second": 0.145, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "Two women are sitting on a small refrigerator placed on the sidewalk. One woman is talking on her cell phone while the other woman is sitting inside the refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.5, "ram_available_mb": 38290.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24545.5, "ram_available_mb": 38295.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.337, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.928}, "timestamp": "2026-01-23T10:25:51.726510"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7087.053, "latencies_ms": [7087.053], "images_per_second": 0.141, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image shows a sunny day with clear skies, as indicated by the bright lighting and shadows cast on the ground. The weather appears to be mild, suitable for outdoor activities.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.5, "ram_available_mb": 38295.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24533.3, "ram_available_mb": 38307.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.777, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.951}, "timestamp": "2026-01-23T10:26:00.856558"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11315.587, "latencies_ms": [11315.587], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man wearing a hat is sitting at a dining table, enjoying a meal of hot dogs. There are several hot dogs on the table, with some placed in buns and others laid out on a tray. The man appears to be focused on the food, possibly taking a bite or preparing to eat. The scene suggests a casual outdoor", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24533.3, "ram_available_mb": 38307.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.566, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T10:26:14.230521"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8657.512, "latencies_ms": [8657.512], "images_per_second": 0.116, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "- Hot dog: 10\n- Bun: 10\n- Man: 1\n- Hat: 1\n- Chair: 1\n- Tray: 1\n- Grass: 1\n- Grill: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.965, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T10:26:24.901699"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9325.352, "latencies_ms": [9325.352], "images_per_second": 0.107, "prompt_tokens": 44, "response_tokens_est": 61, "n_tiles": 16, "output_text": "In the foreground, there is a tray of hot dogs with one being held by a person. The person is seated to the right of the tray, wearing a green shirt and a straw hat. The background shows a grassy area, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24545.4, "ram_available_mb": 38295.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.464, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T10:26:36.267837"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8999.81, "latencies_ms": [8999.81], "images_per_second": 0.111, "prompt_tokens": 37, "response_tokens_est": 57, "n_tiles": 16, "output_text": "A man wearing a straw hat and a green polo shirt is sitting at a table with a tray of hot dogs in front of him. He appears to be enjoying a meal outdoors, possibly at a picnic or a barbecue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.4, "ram_available_mb": 38295.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.871, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T10:26:47.303772"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9470.595, "latencies_ms": [9470.595], "images_per_second": 0.106, "prompt_tokens": 36, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The image shows a person wearing a straw hat and a green polo shirt, sitting in a white chair outdoors. The person is holding a tray with several hot dogs, some of which have red and some with black toppings, on a foil-lined tray.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.413, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.863}, "timestamp": "2026-01-23T10:26:58.833848"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11366.652, "latencies_ms": [11366.652], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image depicts a small, cluttered room with a desk and a chair. On the desk, there is a laptop computer, a book, and a mouse. The chair is positioned in front of the desk, providing a comfortable seating area for the user. \n\nIn the room, there are numerous books scattered around, with some placed on the des", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 24536.3, "ram_available_mb": 38304.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 24550.3, "ram_available_mb": 38290.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.519, "power_cpu_cv_mean_watts": 2.225, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T10:27:12.264281"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10027.232, "latencies_ms": [10027.232], "images_per_second": 0.1, "prompt_tokens": 39, "response_tokens_est": 66, "n_tiles": 16, "output_text": "- Chair: 1\n- Book: multiple (exact count not possible)\n- Laptop: 1\n- Star decoration: 1\n- Cords: multiple (exact count not possible)\n- Fan: 1\n- Couch: 1\n- Bed: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.3, "ram_available_mb": 38290.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 24559.3, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.264, "power_cpu_cv_mean_watts": 2.275, "power_sys_5v0_mean_watts": 8.876}, "timestamp": "2026-01-23T10:27:24.334387"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11331.669, "latencies_ms": [11331.669], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a wooden desk with a laptop and a chair positioned to the left side of the desk. The chair is in front of the desk, suggesting it is used for sitting while working at the desk. In the background, there is a bookshelf filled with books, and a white radiator is located to the right of the bookshelf", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 24559.3, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 24564.0, "ram_available_mb": 38276.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.632, "power_cpu_cv_mean_watts": 1.968, "power_sys_5v0_mean_watts": 8.877}, "timestamp": "2026-01-23T10:27:37.693615"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8647.014, "latencies_ms": [8647.014], "images_per_second": 0.116, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image depicts a cluttered room with a desk, a chair, and a bookshelf filled with books. There is a laptop on the desk, and various items scattered around the room, including a backpack and a radiator.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24564.0, "ram_available_mb": 38276.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24572.2, "ram_available_mb": 38268.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.934, "power_cpu_cv_mean_watts": 1.727, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T10:27:48.380784"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7785.947, "latencies_ms": [7785.947], "images_per_second": 0.128, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The room is dimly lit with natural light coming from the window on the left. The walls are painted in a light beige color, and the furniture includes a wooden desk and a bookshelf filled with various books.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24572.2, "ram_available_mb": 38268.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24561.8, "ram_available_mb": 38279.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.157, "power_cpu_cv_mean_watts": 1.723, "power_sys_5v0_mean_watts": 8.908}, "timestamp": "2026-01-23T10:27:58.190711"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11323.182, "latencies_ms": [11323.182], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the heart of a verdant landscape, two majestic elephants stand in a field of tall grass. The elephant on the left, with its dark brown skin, is facing the camera, its trunk extended towards the ground as if exploring the terrain. Its companion, on the right, is facing away from the camera, its trunk raised high in the air, perhaps", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24561.8, "ram_available_mb": 38279.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24554.5, "ram_available_mb": 38286.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.576, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.83}, "timestamp": "2026-01-23T10:28:11.568737"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6922.638, "latencies_ms": [6922.638], "images_per_second": 0.144, "prompt_tokens": 39, "response_tokens_est": 39, "n_tiles": 16, "output_text": "elephant: 2, grass: numerous, trees: scattered, sky: hazy, clouds: visible, sun: not visible, water: not visible, birds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24554.5, "ram_available_mb": 38286.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24557.1, "ram_available_mb": 38283.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.413, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 8.96}, "timestamp": "2026-01-23T10:28:20.545252"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10088.032, "latencies_ms": [10088.032], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The two elephants are positioned in the background of the image, standing close to each other in a grassy field. They appear to be near the center of the image, with trees and shrubs in the foreground. The elephants are farther away from the camera compared to the vegetation in the foreground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24557.1, "ram_available_mb": 38283.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24549.6, "ram_available_mb": 38291.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.048, "power_cpu_cv_mean_watts": 1.876, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T10:28:32.646877"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6368.604, "latencies_ms": [6368.604], "images_per_second": 0.157, "prompt_tokens": 37, "response_tokens_est": 34, "n_tiles": 16, "output_text": "Two elephants are standing in a grassy field with trees in the background. They appear to be interacting with each other, possibly playing or communicating.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24549.6, "ram_available_mb": 38291.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.728, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 8.941}, "timestamp": "2026-01-23T10:28:41.030632"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7093.04, "latencies_ms": [7093.04], "images_per_second": 0.141, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "Two elephants are standing in a grassy field with green vegetation around them. The sky is overcast, and the lighting is soft, giving the scene a calm and serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.761, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 8.949}, "timestamp": "2026-01-23T10:28:50.187090"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11330.877, "latencies_ms": [11330.877], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is standing in a grassy field, holding a Frisbee in his right hand. He is wearing a baseball cap and appears to be preparing to throw the Frisbee. Another person is visible in the background, standing further away from the main subject. The scene suggests that the man is participating in a game of Frisbee or", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24557.5, "ram_available_mb": 38283.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.688, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T10:29:03.554739"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7279.44, "latencies_ms": [7279.44], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "person: 2, frisbee: 1, bottle: 1, trees: many, grass: field, sky: clear, sun: visible, shirtless: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24557.5, "ram_available_mb": 38283.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.862, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T10:29:12.877232"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11362.066, "latencies_ms": [11362.066], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the foreground, there is a man standing with his left arm extended, holding a frisbee in his right hand. He is wearing a cap, sunglasses, and shorts. In the background, there is another person who appears to be running or walking towards the left side of the image. The background is filled with trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24556.0, "ram_available_mb": 38284.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.586, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T10:29:26.266411"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6829.253, "latencies_ms": [6829.253], "images_per_second": 0.146, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A man is standing in a grassy field, throwing a frisbee while another person is in the background. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24556.0, "ram_available_mb": 38284.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.188, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.895}, "timestamp": "2026-01-23T10:29:35.125015"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8845.096, "latencies_ms": [8845.096], "images_per_second": 0.113, "prompt_tokens": 36, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image shows a sunny day with clear blue skies and bright sunlight casting shadows on the ground. The man in the foreground is wearing a white cap and sunglasses, and he is shirtless, revealing a muscular torso.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24544.4, "ram_available_mb": 38296.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24549.9, "ram_available_mb": 38291.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.54, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T10:29:45.986516"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11327.963, "latencies_ms": [11327.963], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young boy is sitting at a dining table, cutting a cake with a knife. The cake is placed on a plate, and the boy is focused on cutting it. The table is covered with a dining tablecloth, and there are several cups and a knife on the table. The boy is wearing a blue shirt, and he", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 24549.9, "ram_available_mb": 38291.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24553.1, "ram_available_mb": 38287.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.602, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T10:29:59.351348"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10508.062, "latencies_ms": [10508.062], "images_per_second": 0.095, "prompt_tokens": 39, "response_tokens_est": 70, "n_tiles": 16, "output_text": "- Cake: 1\n\n- Knife: 1\n\n- Frosting: 1\n\n- Plates: 2\n\n- Tablecloth: 1\n\n- Cake pan: 1\n\n- Cake decorations: 1\n\n- Cake topper: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24553.1, "ram_available_mb": 38287.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24542.6, "ram_available_mb": 38298.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.051, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 8.821}, "timestamp": "2026-01-23T10:30:11.875083"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9645.999, "latencies_ms": [9645.999], "images_per_second": 0.104, "prompt_tokens": 44, "response_tokens_est": 64, "n_tiles": 16, "output_text": "In the foreground, a child in a blue shirt is cutting a chocolate cake with a knife. The cake is placed on a colorful tablecloth that covers the table. The child is seated at the table, and the cake is positioned in front of them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24542.6, "ram_available_mb": 38298.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24540.6, "ram_available_mb": 38300.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.355, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 8.873}, "timestamp": "2026-01-23T10:30:23.544612"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7312.756, "latencies_ms": [7312.756], "images_per_second": 0.137, "prompt_tokens": 37, "response_tokens_est": 42, "n_tiles": 16, "output_text": "A young boy in a blue sports jersey is cutting a chocolate cake with a knife. The cake is decorated with a baseball theme, featuring a baseball bat and ball.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24540.6, "ram_available_mb": 38300.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24546.2, "ram_available_mb": 38294.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.953, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T10:30:32.873204"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9542.803, "latencies_ms": [9542.803], "images_per_second": 0.105, "prompt_tokens": 36, "response_tokens_est": 63, "n_tiles": 16, "output_text": "The image shows a person wearing a blue sports jersey with a white logo, cutting a chocolate cake on a table covered with a colorful tablecloth. The cake is decorated to look like a chocolate bar with pieces of chocolate and other decorations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.2, "ram_available_mb": 38294.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24534.3, "ram_available_mb": 38306.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.28, "power_cpu_cv_mean_watts": 1.834, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T10:30:44.439470"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11339.324, "latencies_ms": [11339.324], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, there are two zebras standing close to each other, with one zebra partially visible on the left side and the other zebra fully visible on the right side. They are standing near a metal fence, which is likely part of their enclosure. The zebras appear to be in a zoo or wildlife park setting, as they are in a conf", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24534.3, "ram_available_mb": 38306.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24550.8, "ram_available_mb": 38290.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.637, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.832}, "timestamp": "2026-01-23T10:30:57.809743"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9092.745, "latencies_ms": [9092.745], "images_per_second": 0.11, "prompt_tokens": 39, "response_tokens_est": 58, "n_tiles": 16, "output_text": "zebra: 2, pipe: 1, rock: 1, leaves: 1, background: 1, zebra's mane: 1, zebra's eye: 1, zebra's ear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.8, "ram_available_mb": 38290.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24543.0, "ram_available_mb": 38297.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.814, "power_cpu_cv_mean_watts": 1.799, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T10:31:08.957795"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10091.53, "latencies_ms": [10091.53], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The zebra on the left is in the foreground and appears to be facing the camera, while the zebra on the right is slightly behind and to the right, partially obscured by the zebra in the foreground. The background is blurred but seems to be a natural environment with trees and rocks.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24543.0, "ram_available_mb": 38297.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.122, "power_cpu_cv_mean_watts": 1.856, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T10:31:21.073080"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7904.968, "latencies_ms": [7904.968], "images_per_second": 0.127, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "Two zebras are standing close to each other, with one facing the camera and the other partially visible in the background. They appear to be in a zoo enclosure, as there is a metal fence visible in the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.7, "ram_available_mb": 38299.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.589, "power_cpu_cv_mean_watts": 2.205, "power_sys_5v0_mean_watts": 8.941}, "timestamp": "2026-01-23T10:31:31.022438"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7558.461, "latencies_ms": [7558.461], "images_per_second": 0.132, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The zebra's stripes are black and white, and the lighting appears to be natural sunlight. The zebra is standing next to a metal pole, and there is a rock in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 24548.7, "ram_available_mb": 38292.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.331, "power_cpu_cv_mean_watts": 1.971, "power_sys_5v0_mean_watts": 8.954}, "timestamp": "2026-01-23T10:31:40.617458"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11353.761, "latencies_ms": [11353.761], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment at the La Spezia Centrale train station in Italy. The station, bathed in the soft glow of daylight, is a symphony of grayscale hues. The platform, constructed of brick, stretches out in the foreground, leading the eye towards the train tracks that disappear into the distance. \n\nTwo trains, one on each", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 24548.7, "ram_available_mb": 38292.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.556, "power_cpu_cv_mean_watts": 2.006, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T10:31:54.038425"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7418.484, "latencies_ms": [7418.484], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "platform: 1, bench: 1, train: 1, train tracks: 2, train car: 1, building: 1, sign: 1, mountains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24559.3, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.795, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 8.904}, "timestamp": "2026-01-23T10:32:03.490029"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11337.815, "latencies_ms": [11337.815], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The train tracks extend from the foreground into the background, converging towards the center of the image where a train is positioned on the right side, suggesting it is moving away from the viewer. A bench is placed in the foreground on the left side, indicating it is closer to the viewer than the train. The overhead structure spans across the image, connecting the two ends", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24559.3, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24560.3, "ram_available_mb": 38280.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.635, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T10:32:16.848227"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7255.035, "latencies_ms": [7255.035], "images_per_second": 0.138, "prompt_tokens": 37, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image depicts a train station named \"La Spezia Centrale\" with a train on the tracks and a bench on the platform. The station appears to be quiet with no visible passengers.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24560.3, "ram_available_mb": 38280.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24557.2, "ram_available_mb": 38283.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.786, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.91}, "timestamp": "2026-01-23T10:32:26.117508"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5284.372, "latencies_ms": [5284.372], "images_per_second": 0.189, "prompt_tokens": 36, "response_tokens_est": 26, "n_tiles": 16, "output_text": "The image is a black and white photograph of a train station. The station has a brick platform and a metal roof structure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24557.2, "ram_available_mb": 38283.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.698, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 9.046}, "timestamp": "2026-01-23T10:32:33.457366"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11329.125, "latencies_ms": [11329.125], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a person is sitting on a red surfboard in the middle of the ocean. The surfer is wearing a black wetsuit and is facing away from the camera, looking out at the horizon. The sky is filled with dark clouds, suggesting an impending storm. The ocean is calm, with a few small waves visible. The surfer appears to be waiting for", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24553.4, "ram_available_mb": 38287.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.573, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T10:32:46.814552"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6813.799, "latencies_ms": [6813.799], "images_per_second": 0.147, "prompt_tokens": 39, "response_tokens_est": 38, "n_tiles": 16, "output_text": "person: 1, surfboard: 1, ocean: multiple, waves: multiple, sky: multiple, clouds: multiple, sun: 1, horizon: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.4, "ram_available_mb": 38287.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24551.6, "ram_available_mb": 38289.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.242, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 8.92}, "timestamp": "2026-01-23T10:32:55.657240"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10095.185, "latencies_ms": [10095.185], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The person is seated on a surfboard in the foreground, positioned near the water's edge. The ocean extends towards the horizon, with the sky above and the beach in the far background. The clouds are closer to the viewer, creating a sense of depth as they appear to be floating above the water.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24551.6, "ram_available_mb": 38289.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24559.3, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.076, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T10:33:07.781296"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8403.038, "latencies_ms": [8403.038], "images_per_second": 0.119, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "A person is sitting on a red surfboard in the ocean, facing away from the camera, with a dramatic cloudy sky in the background. The sun is setting, casting a warm glow on the horizon and creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24559.3, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.18, "power_cpu_cv_mean_watts": 1.737, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T10:33:18.227717"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9271.665, "latencies_ms": [9271.665], "images_per_second": 0.108, "prompt_tokens": 36, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The image features a surfer in a black wetsuit sitting on a red surfboard, with the ocean in the background under a cloudy sky. The lighting is dim, with the sun setting or rising, casting a warm glow on the horizon and creating a moody atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24549.3, "ram_available_mb": 38291.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.369, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T10:33:29.533577"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11330.702, "latencies_ms": [11330.702], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man and a woman are sitting together on a train, enjoying a meal. The man is holding chopsticks and a plate of food, while the woman is also holding a plate of food. They are both smiling and appear to be having a pleasant time.\n\nThe train has several chairs, with one near the man and woman, and another", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24549.3, "ram_available_mb": 38291.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 24550.4, "ram_available_mb": 38290.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.602, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T10:33:42.918002"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9789.993, "latencies_ms": [9789.993], "images_per_second": 0.102, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "1. Chair: 2\n2. Tray: 1\n3. Chopsticks: 2\n4. Food items: 5\n5. Train car: 1\n6. Window: 1\n7. Curtain: 1\n8. Sign: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24550.4, "ram_available_mb": 38290.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24555.6, "ram_available_mb": 38285.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.362, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 8.819}, "timestamp": "2026-01-23T10:33:54.737496"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6913.875, "latencies_ms": [6913.875], "images_per_second": 0.145, "prompt_tokens": 44, "response_tokens_est": 40, "n_tiles": 16, "output_text": "The man is seated to the left of the woman, and they are both in the foreground of the image. In the background, there is a train station with various signs and structures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.6, "ram_available_mb": 38285.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24551.1, "ram_available_mb": 38289.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.2, "power_cpu_cv_mean_watts": 1.608, "power_sys_5v0_mean_watts": 8.967}, "timestamp": "2026-01-23T10:34:03.679723"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7037.47, "latencies_ms": [7037.47], "images_per_second": 0.142, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "A man and a woman are sitting in a train, enjoying a meal together. The woman is holding chopsticks and the man is holding a tray with various food items.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24551.1, "ram_available_mb": 38289.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.397, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.936}, "timestamp": "2026-01-23T10:34:12.728561"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11393.03, "latencies_ms": [11393.03], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image shows a man and a woman seated in a train, with the man wearing a plaid shirt and the woman in a pink top. They are both holding chopsticks and appear to be eating, with a tray of food in front of them that includes sushi and other items. The train interior is well-lit, and the seats are u", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24541.5, "ram_available_mb": 38299.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24550.9, "ram_available_mb": 38290.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.669, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T10:34:26.149123"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11366.954, "latencies_ms": [11366.954], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, two men are walking down a sidewalk at night. One man is wearing a white shirt and black pants, while the other is wearing a pink shirt and black pants. They are both dressed in business attire, with ties and dress shoes. The sidewalk is lined with metal poles and there are cars parked on the", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24550.9, "ram_available_mb": 38290.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24551.2, "ram_available_mb": 38289.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.664, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.831}, "timestamp": "2026-01-23T10:34:39.541038"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9250.831, "latencies_ms": [9250.831], "images_per_second": 0.108, "prompt_tokens": 39, "response_tokens_est": 59, "n_tiles": 16, "output_text": "- People: 2\n\n- Pole: 2\n\n- Building: 1\n\n- Sign: 1\n\n- Car: 1\n\n- Street light: 1\n\n- Sidewalk: 1\n\n- Stairs: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.2, "ram_available_mb": 38289.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.634, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T10:34:50.822345"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7886.539, "latencies_ms": [7886.539], "images_per_second": 0.127, "prompt_tokens": 44, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The two men are walking on a sidewalk in the foreground of the image. The building with the sign 'Hierro Y Albero' is in the background, and there are street lamps and cars visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.9, "ram_available_mb": 38295.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24545.6, "ram_available_mb": 38295.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.321, "power_cpu_cv_mean_watts": 1.733, "power_sys_5v0_mean_watts": 8.939}, "timestamp": "2026-01-23T10:35:00.745973"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8913.864, "latencies_ms": [8913.864], "images_per_second": 0.112, "prompt_tokens": 37, "response_tokens_est": 56, "n_tiles": 16, "output_text": "Two men are walking on a sidewalk at night, one wearing a white shirt and black pants, the other wearing a pink shirt and black pants. They appear to be in a city setting with buildings and a street lamp in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.6, "ram_available_mb": 38295.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.687, "power_cpu_cv_mean_watts": 1.77, "power_sys_5v0_mean_watts": 8.819}, "timestamp": "2026-01-23T10:35:11.696404"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8578.558, "latencies_ms": [8578.558], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image depicts two individuals in business attire walking on a street at night. The lighting is artificial, with street lamps casting a warm glow on the scene, and the weather appears to be clear as there are no signs of rain or snow.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.767, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 8.907}, "timestamp": "2026-01-23T10:35:22.326061"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11371.554, "latencies_ms": [11371.554], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a man standing in a wine cellar, holding a wine bottle and a cloth. He is surrounded by numerous wine bottles, some of which are placed on shelves and others are scattered around the room. There are also wine glasses placed on the table, with one near the man and another further away. The man appears to be cleaning the wine bottle with", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24539.3, "ram_available_mb": 38301.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.531, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.826}, "timestamp": "2026-01-23T10:35:35.740912"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9499.778, "latencies_ms": [9499.778], "images_per_second": 0.105, "prompt_tokens": 39, "response_tokens_est": 61, "n_tiles": 16, "output_text": "- Wine bottles: 15\n- Wine glasses: 3\n- Glass: 1\n- Table: 1\n- Menu: 1\n- Chair: 1\n- Wine bottle: 1\n- Wine glass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24539.3, "ram_available_mb": 38301.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24556.6, "ram_available_mb": 38284.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.521, "power_cpu_cv_mean_watts": 2.151, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T10:35:47.253681"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11406.854, "latencies_ms": [11406.854], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a man is standing and holding a wine bottle with a cloth, positioned near a large glass and a smaller wine glass on the table in front of him. In the background, there are multiple wine bottles on shelves, indicating a wine cellar or a wine tasting room. The man is closer to the camera than the wine bottles on the", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24556.6, "ram_available_mb": 38284.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.697, "power_cpu_cv_mean_watts": 2.3, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T10:36:00.702966"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7530.813, "latencies_ms": [7530.813], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A man is standing in a wine cellar, holding a bottle of wine and cleaning a glass with a cloth. The cellar is filled with numerous wine bottles on shelves and racks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24571.7, "ram_available_mb": 38269.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.711, "power_cpu_cv_mean_watts": 1.658, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T10:36:10.255678"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9126.166, "latencies_ms": [9126.166], "images_per_second": 0.11, "prompt_tokens": 36, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image shows a man in a dimly lit room with wooden furnishings, holding a bottle of wine and a cloth. There are multiple wine bottles on the shelves in the background, and the room has a cozy, intimate atmosphere with warm lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24571.7, "ram_available_mb": 38269.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24564.2, "ram_available_mb": 38276.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.609, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T10:36:21.404265"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11318.123, "latencies_ms": [11318.123], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a tennis player is captured in the midst of a powerful swing. The player, dressed in a crisp white shirt and shorts, is poised on a vibrant green tennis court. The player's right arm is extended upwards, holding a blue and green tennis racket, ready to strike the yellow tennis ball that hovers in the air above. The", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24564.2, "ram_available_mb": 38276.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24557.7, "ram_available_mb": 38283.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.574, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.819}, "timestamp": "2026-01-23T10:36:34.755288"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7572.106, "latencies_ms": [7572.106], "images_per_second": 0.132, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "grass: numerous\nwhite lines: numerous\nracket: 1\nball: 1\nperson: 1\nshirt: 1\nshorts: 1\nwristband: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24557.7, "ram_available_mb": 38283.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24559.2, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.702, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T10:36:44.359083"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10069.85, "latencies_ms": [10069.85], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 67, "n_tiles": 16, "output_text": "The tennis player is positioned in the foreground, appearing large and in focus, while the tennis ball is in the background, slightly out of focus and higher in the air. The lines on the tennis court create a sense of depth, with the player closer to the viewer and the lines leading the eye towards the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24559.2, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.153, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T10:36:56.477249"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8230.639, "latencies_ms": [8230.639], "images_per_second": 0.121, "prompt_tokens": 37, "response_tokens_est": 50, "n_tiles": 16, "output_text": "A tennis player is captured in the midst of a powerful serve on a grass court, with a tennis ball suspended in the air above his racket. The player is dressed in white attire, and the court is marked with white lines.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24564.1, "ram_available_mb": 38276.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.305, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T10:37:06.718720"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9131.78, "latencies_ms": [9131.78], "images_per_second": 0.11, "prompt_tokens": 36, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image captures a moment of intense action on a vibrant green tennis court, bathed in natural daylight. The player, dressed in white, is in the midst of a powerful serve, with a blue and green tennis racket poised to strike the yellow ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24564.1, "ram_available_mb": 38276.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24550.5, "ram_available_mb": 38290.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.572, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T10:37:17.896167"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11369.655, "latencies_ms": [11369.655], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the center of the image, a white and orange cat is the main subject. The cat is standing on a wooden shelf, its body facing the television screen. The television, which is turned on, displays a man in a suit. The man appears to be in a state of surprise or shock. The shelf is positioned against a beige wall, and a white mug is", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 24550.5, "ram_available_mb": 38290.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24556.3, "ram_available_mb": 38284.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.585, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T10:37:31.289367"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8320.403, "latencies_ms": [8320.403], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "Television: 1\nCat: 1\nTv stand: 1\nDvd player: 1\nCable box: 1\nRemote control: 1\nCoffee cup: 1\nWall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.3, "ram_available_mb": 38284.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24545.8, "ram_available_mb": 38295.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.188, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T10:37:41.635835"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9031.68, "latencies_ms": [9031.68], "images_per_second": 0.111, "prompt_tokens": 44, "response_tokens_est": 59, "n_tiles": 16, "output_text": "In the foreground, there is a cat standing on a wooden shelf. The shelf is positioned in front of a television that is mounted on the wall. The cat is closer to the camera than the television, and the television is further away from the camera than the cat.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24545.8, "ram_available_mb": 38295.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.6, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.892}, "timestamp": "2026-01-23T10:37:52.696823"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6934.904, "latencies_ms": [6934.904], "images_per_second": 0.144, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "A cat is standing on a wooden entertainment center, with a television displaying a man in a suit in the background. The entertainment center has a DVD player and a cup on it.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 24546.9, "ram_available_mb": 38294.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.212, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 8.88}, "timestamp": "2026-01-23T10:38:01.651566"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6184.112, "latencies_ms": [6184.112], "images_per_second": 0.162, "prompt_tokens": 36, "response_tokens_est": 34, "n_tiles": 16, "output_text": "The television is placed on a wooden stand with a black remote control in front of it. The cat is white with orange patches and is standing on the stand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.1, "ram_available_mb": 38290.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.633, "power_cpu_cv_mean_watts": 1.517, "power_sys_5v0_mean_watts": 8.998}, "timestamp": "2026-01-23T10:38:09.859369"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11345.598, "latencies_ms": [11345.598], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene of a blue circular sign with a white border, prominently displayed against a backdrop of a clear blue sky. The sign is affixed to a metal pole, which is adorned with a white rectangular sign bearing Chinese characters. The pole is situated in a verdant area, surrounded by lush green trees that add a touch of nature to the urban", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.611, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T10:38:23.265951"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10012.488, "latencies_ms": [10012.488], "images_per_second": 0.1, "prompt_tokens": 39, "response_tokens_est": 66, "n_tiles": 16, "output_text": "1. Sign: 1\n2. Bicycle symbol: 1\n3. Pedestrian symbol: 1\n4. Traffic light: 1\n5. Street light: 1\n6. Tree: 1\n7. Sky: 1\n8. Sun: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24547.2, "ram_available_mb": 38293.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.212, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T10:38:35.298387"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10343.127, "latencies_ms": [10343.127], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The sign with the pedestrian and bicycle symbol is in the background, mounted on a pole that is positioned in the foreground. The sign with the Chinese characters is in the foreground, attached to the same pole. The background is a clear blue sky with some green foliage from trees partially visible behind the pole.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24547.2, "ram_available_mb": 38293.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24550.5, "ram_available_mb": 38290.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.917, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T10:38:47.667961"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9217.921, "latencies_ms": [9217.921], "images_per_second": 0.108, "prompt_tokens": 37, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image shows a blue circular sign with a white pictogram of a person and a bicycle, indicating a shared path for pedestrians and cyclists. Below it, there is a rectangular sign with Japanese characters, likely providing additional information or instructions for the path.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24550.5, "ram_available_mb": 38290.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24545.8, "ram_available_mb": 38295.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.713, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.827}, "timestamp": "2026-01-23T10:38:58.906296"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7112.793, "latencies_ms": [7112.793], "images_per_second": 0.141, "prompt_tokens": 36, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The sign is circular with a blue background and features symbols of a pedestrian and a bicycle. It is mounted on a metal pole with a rectangular sign below it that has Chinese characters.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.8, "ram_available_mb": 38295.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24545.3, "ram_available_mb": 38295.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.742, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.937}, "timestamp": "2026-01-23T10:39:08.043533"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11340.245, "latencies_ms": [11340.245], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a woman sitting at a dining table in a restaurant. She is holding a slice of pizza in her hand, and there are two other pizza slices on the table in front of her. The table is surrounded by chairs, and there are a few more chairs visible in the background. \n\nIn addition to the pizza, there are two cups", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 24545.3, "ram_available_mb": 38295.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.612, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T10:39:21.431556"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10034.314, "latencies_ms": [10034.314], "images_per_second": 0.1, "prompt_tokens": 39, "response_tokens_est": 66, "n_tiles": 16, "output_text": "- Chairs: 10\n\n- Tables: 3\n\n- Glasses: 2\n\n- Pizza slices: 1\n\n- Napkin: 1\n\n- Book: 1\n\n- Water glass: 1\n\n- Paper: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.248, "power_cpu_cv_mean_watts": 1.847, "power_sys_5v0_mean_watts": 8.832}, "timestamp": "2026-01-23T10:39:33.499689"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10697.004, "latencies_ms": [10697.004], "images_per_second": 0.093, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "In the foreground, there is a table with a glass of water and a slice of pizza, indicating a meal in progress. The person is seated at the table, which is in the middle ground of the image. In the background, there are other tables and chairs, suggesting this is a dining area with multiple seating options.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24554.7, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.79, "power_cpu_cv_mean_watts": 1.911, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T10:39:46.257719"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6899.625, "latencies_ms": [6899.625], "images_per_second": 0.145, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "A person is sitting at a table in a restaurant, with a slice of pizza on the plate in front of them. The table has a glass of water and a book on it.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.17, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.923}, "timestamp": "2026-01-23T10:39:55.184780"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7907.543, "latencies_ms": [7907.543], "images_per_second": 0.126, "prompt_tokens": 36, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The image shows an indoor setting with warm lighting, likely from hanging lamps or ceiling lights. The walls are adorned with various framed pictures and a notice board, and the flooring appears to be wooden.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24538.0, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.143, "power_cpu_cv_mean_watts": 1.733, "power_sys_5v0_mean_watts": 8.916}, "timestamp": "2026-01-23T10:40:05.128179"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11358.748, "latencies_ms": [11358.748], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a dining table with a variety of food items spread across its surface. There are several bowls containing different dishes, including a plate of broccoli and cauliflower, a plate of rice, and a plate of meat. A spoon is also present on the table, likely used for serving or eating the food. \n\nIn addition to the main", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24538.0, "ram_available_mb": 38302.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24543.0, "ram_available_mb": 38297.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.579, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.832}, "timestamp": "2026-01-23T10:40:18.515772"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11506.965, "latencies_ms": [11506.965], "images_per_second": 0.087, "prompt_tokens": 39, "response_tokens_est": 81, "n_tiles": 16, "output_text": "- bowl of broccoli: 1\n\n- bowl of cauliflower: 1\n\n- bowl of dumplings: 1\n\n- bowl of rice: 1\n\n- bowl of mixed vegetables: 1\n\n- bowl of butter: 1\n\n- glass of water: 1\n\n", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24543.0, "ram_available_mb": 38297.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24544.0, "ram_available_mb": 38296.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.717, "power_cpu_cv_mean_watts": 1.914, "power_sys_5v0_mean_watts": 8.794}, "timestamp": "2026-01-23T10:40:32.079933"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11346.559, "latencies_ms": [11346.559], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a plate of food with a red sauce and rice, and a glass of water to its right. Behind it, there is a bowl of broccoli and cauliflower, and further back, there are two plates of food, one with doughnuts and the other with a yellow sauce. The food items are arranged on", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.0, "ram_available_mb": 38296.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.611, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T10:40:45.443382"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8894.636, "latencies_ms": [8894.636], "images_per_second": 0.112, "prompt_tokens": 37, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image shows a dining table with a variety of food items including a bowl of broccoli, a plate of rice with vegetables, and a plate of dumplings. There is also a glass of water and a box of matches on the table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.609, "power_cpu_cv_mean_watts": 1.77, "power_sys_5v0_mean_watts": 8.833}, "timestamp": "2026-01-23T10:40:56.370705"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10297.988, "latencies_ms": [10297.988], "images_per_second": 0.097, "prompt_tokens": 36, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The image shows a meal spread on a wooden table with a mix of warm and cool colors, such as the green of the broccoli, the white of the cauliflower, and the orange of the tomato-based dish. The lighting appears to be natural daylight, casting soft shadows on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.951, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T10:41:08.686080"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11333.623, "latencies_ms": [11333.623], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a busy city street scene with a mix of vehicles and pedestrians. There are several cars, a bus, and a truck on the street, with some cars stopped at a traffic light. The traffic light is located on the left side of the scene, and a person can be seen standing near it.\n\nThere are multiple pedestrians walking along the", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.634, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T10:41:22.047539"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9224.764, "latencies_ms": [9224.764], "images_per_second": 0.108, "prompt_tokens": 39, "response_tokens_est": 59, "n_tiles": 16, "output_text": "- Cars: 6\n- Buses: 1\n- Trucks: 1\n- Trees: 4\n- Buildings: 3\n- Traffic lights: 1\n- Signs: 3\n- Pedestrians: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.0, "ram_available_mb": 38306.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24534.9, "ram_available_mb": 38306.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.447, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.827}, "timestamp": "2026-01-23T10:41:33.307437"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10747.526, "latencies_ms": [10747.526], "images_per_second": 0.093, "prompt_tokens": 44, "response_tokens_est": 74, "n_tiles": 16, "output_text": "In the foreground, there is a red car and a black car positioned near the center of the image, with a bus in the background slightly to the right. The red car is in the foreground on the right side, while the black car is in the center foreground. The bus is in the background, to the right of the black car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.9, "ram_available_mb": 38306.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24536.0, "ram_available_mb": 38304.9, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.898, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.884}, "timestamp": "2026-01-23T10:41:46.106549"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7743.031, "latencies_ms": [7743.031], "images_per_second": 0.129, "prompt_tokens": 37, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image depicts a busy urban street scene with multiple vehicles, including a bus and cars, and a pedestrian crossing the street. Buildings line the street, and there are various signs and traffic lights visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24536.0, "ram_available_mb": 38304.9, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.541, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T10:41:55.880749"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10002.349, "latencies_ms": [10002.349], "images_per_second": 0.1, "prompt_tokens": 36, "response_tokens_est": 67, "n_tiles": 16, "output_text": "The image shows a busy urban street scene with a mix of vehicles, including a green and yellow bus, cars, and a white van with a \"GOLD SEAL PLUMBING\" sign. The weather appears to be overcast, and the lighting is natural, suggesting it might be a cloudy day.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.038, "power_cpu_cv_mean_watts": 2.37, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T10:42:07.917601"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 9847.246, "latencies_ms": [9847.246], "images_per_second": 0.102, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 16, "output_text": "The image shows a black Toshiba laptop open on a white table. Next to the laptop, there is a silver pen and a black smartphone. A person in a red shirt is standing behind the table, partially visible. The laptop screen displays a desktop wallpaper with a blue background and a white star.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 24566.9, "ram_available_mb": 38274.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.286, "power_cpu_cv_mean_watts": 2.321, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T10:42:19.804285"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7606.909, "latencies_ms": [7606.909], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "table: 1, laptop: 1, pen: 1, cell phone: 1, mouse: 1, screwdriver: 1, flashlight: 1, keypad: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24566.9, "ram_available_mb": 38274.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24563.8, "ram_available_mb": 38277.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.725, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T10:42:29.467923"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11340.077, "latencies_ms": [11340.077], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The laptop is positioned in the foreground on a white surface, with a smartphone placed to its right side. A pen is lying vertically on the left side of the laptop, and a small device, possibly a digital camera or a remote control, is placed to the left of the pen. The background is less distinct but appears to be an indoor setting with a partial view of a", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24563.8, "ram_available_mb": 38277.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24563.0, "ram_available_mb": 38277.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.643, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T10:42:42.829157"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7151.723, "latencies_ms": [7151.723], "images_per_second": 0.14, "prompt_tokens": 37, "response_tokens_est": 41, "n_tiles": 16, "output_text": "A person is standing behind a table with a Toshiba laptop open, displaying a desktop wallpaper. Next to the laptop, there is a pen and a smartphone lying on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24563.0, "ram_available_mb": 38277.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24552.5, "ram_available_mb": 38288.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.118, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.931}, "timestamp": "2026-01-23T10:42:51.994033"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8019.441, "latencies_ms": [8019.441], "images_per_second": 0.125, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image shows a black Toshiba laptop on a white surface with a bright light reflecting off its screen. There is a silver pen lying next to the laptop, and a black smartphone is placed to the right of the laptop.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24552.5, "ram_available_mb": 38288.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.096, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 8.907}, "timestamp": "2026-01-23T10:43:02.049036"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.794, "latencies_ms": [11335.794], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a desk with a computer setup, including a desktop computer and a laptop. The desktop computer is positioned on the left side of the desk, while the laptop is placed on the right side. A keyboard and a mouse are also present on the desk, with the keyboard located in front of the desktop computer and the mouse in front of the laptop.\n\nThere are", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24553.2, "ram_available_mb": 38287.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.688, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T10:43:15.412980"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8889.08, "latencies_ms": [8889.08], "images_per_second": 0.112, "prompt_tokens": 39, "response_tokens_est": 56, "n_tiles": 16, "output_text": "- Computer monitor: 1\n- Keyboard: 1\n- Laptop: 1\n- Books: 10\n- Cable: 1\n- Computer mouse: 1\n- Water bottle: 1\n- Wall: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24553.2, "ram_available_mb": 38287.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24562.4, "ram_available_mb": 38278.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.905, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.877}, "timestamp": "2026-01-23T10:43:26.354650"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10866.071, "latencies_ms": [10866.071], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "The computer monitor is positioned in the center of the desk, with the keyboard in front of it and the laptop to its right. The books are stacked on the left side of the desk, and the mouse is located in the foreground on the right side. The window with blinds is in the background, providing natural light to the workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24562.4, "ram_available_mb": 38278.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24540.4, "ram_available_mb": 38300.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.774, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T10:43:39.239750"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8416.399, "latencies_ms": [8416.399], "images_per_second": 0.119, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The image shows a home office setup with a desk containing a desktop computer with a monitor, keyboard, and mouse. There is also a laptop and a water bottle on the desk, and a bookshelf with several books in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24540.4, "ram_available_mb": 38300.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.07, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T10:43:49.687342"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7500.266, "latencies_ms": [7500.266], "images_per_second": 0.133, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image shows an indoor setting with a desk that has a computer monitor, a keyboard, a mouse, and a laptop. The room has a window with blinds, and the walls are a light color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.325, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 8.901}, "timestamp": "2026-01-23T10:43:59.228122"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11364.362, "latencies_ms": [11364.362], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a thrilling moment of a skateboarder performing a trick in mid-air. The skateboarder is in the center of the scene, skillfully balancing on his skateboard while flying through the air. \n\nThere are several people around the skateboarder, some of them holding cell phones to capture the exciting moment. A few", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24538.9, "ram_available_mb": 38302.0, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24542.9, "ram_available_mb": 38298.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.507, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T10:44:12.645952"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8105.385, "latencies_ms": [8105.385], "images_per_second": 0.123, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "skateboarder: 1, skateboard: 1, camera: 3, spectators: 10, barrier: 1, ramp: 1, logo: 2, logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.9, "ram_available_mb": 38298.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.408, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T10:44:22.766075"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11394.163, "latencies_ms": [11394.163], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a skateboarder is captured in mid-air, performing a trick above a rail, with a crowd of spectators and photographers in the background. The skateboarder is positioned near the rail, indicating proximity to the obstacle being used for the trick. The photographers are standing at various distances from the rail, with some closer to the for", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.5, "ram_available_mb": 38294.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.62, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T10:44:36.217756"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9698.69, "latencies_ms": [9698.69], "images_per_second": 0.103, "prompt_tokens": 37, "response_tokens_est": 63, "n_tiles": 16, "output_text": "A skateboarder is performing a trick in mid-air above a ramp, with a crowd of spectators and photographers capturing the moment. The setting appears to be an indoor skatepark or a similar venue, with a high ceiling and a large audience watching the performance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.3, "ram_available_mb": 38297.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24548.9, "ram_available_mb": 38292.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.411, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 8.825}, "timestamp": "2026-01-23T10:44:47.953324"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11367.682, "latencies_ms": [11367.682], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a skateboarder performing a trick in mid-air with a dark background and a pattern of red and white lines. The skateboarder is wearing a black shirt and white pants, and the skateboard is green and white. The audience is visible in the foreground, with some people holding up their phones to take pictures. The lighting in", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24548.9, "ram_available_mb": 38292.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24534.3, "ram_available_mb": 38306.6, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.688, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T10:45:01.363555"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11306.583, "latencies_ms": [11306.583], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a red fire hydrant with a smiley face painted on it, located on the side of a street. The fire hydrant is positioned near a tree, adding a touch of nature to the urban setting. In the background, there are several cars parked along the street, indicating that this is a populated area. The fire hydrant's cheerful face adds a play", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 24534.3, "ram_available_mb": 38306.6, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.675, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T10:45:14.698669"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9147.13, "latencies_ms": [9147.13], "images_per_second": 0.109, "prompt_tokens": 39, "response_tokens_est": 58, "n_tiles": 16, "output_text": "- Fire hydrant: 1\n- Tree: 1\n- Cars: 3\n- Buildings: 2\n- Sidewalk: 1\n- Road: 1\n- Bike lane: 1\n- Parking meter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.764, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T10:45:25.885639"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9295.672, "latencies_ms": [9295.672], "images_per_second": 0.108, "prompt_tokens": 44, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The fire hydrant is located in the foreground of the image, positioned on the right side. It is near the curb of a street, with a yellow line running parallel to it. In the background, there are cars parked along the street and trees lining the sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24536.7, "ram_available_mb": 38304.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.627, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 8.896}, "timestamp": "2026-01-23T10:45:37.219462"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7625.864, "latencies_ms": [7625.864], "images_per_second": 0.131, "prompt_tokens": 37, "response_tokens_est": 45, "n_tiles": 16, "output_text": "A red fire hydrant with a smiley face painted on it is located on the side of a street. The hydrant is positioned near a tree and there are cars parked on the street in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24536.7, "ram_available_mb": 38304.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.634, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 8.894}, "timestamp": "2026-01-23T10:45:46.860874"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8044.617, "latencies_ms": [8044.617], "images_per_second": 0.124, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The fire hydrant in the image is bright red with a black top and has a smiley face drawn on it. It is located on the side of a street with a yellow curb and is surrounded by trees and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.2, "ram_available_mb": 38296.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24536.1, "ram_available_mb": 38304.8, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.241, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T10:45:56.964807"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11359.952, "latencies_ms": [11359.952], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a green luggage cart loaded with various suitcases and trunks. The cart is positioned in front of a green door, and the suitcases are stacked on top of each other, occupying most of the cart's space. The suitcases come in different sizes and colors, creating a visually interesting scene.\n\nIn addition to the suitcases, there", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24536.1, "ram_available_mb": 38304.8, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24543.9, "ram_available_mb": 38297.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.557, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.836}, "timestamp": "2026-01-23T10:46:10.375243"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7870.484, "latencies_ms": [7870.484], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "cart: 1\ntrunk: 1\nsuitcase: 1\nsuitcase: 1\nsuitcase: 1\nsuitcase: 1\nsuitcase: 1\nsuitcase: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.9, "ram_available_mb": 38297.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 24546.2, "ram_available_mb": 38294.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.422, "power_cpu_cv_mean_watts": 1.954, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T10:46:20.265251"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9846.399, "latencies_ms": [9846.399], "images_per_second": 0.102, "prompt_tokens": 44, "response_tokens_est": 66, "n_tiles": 16, "output_text": "In the foreground, there is a green cart with a stack of old, worn-out suitcases on top of it. The suitcases are arranged in a pile, with the largest at the bottom and the smallest at the top. In the background, there is a green door and a poster on the wall.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24546.2, "ram_available_mb": 38294.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 24591.0, "ram_available_mb": 38249.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.217, "power_cpu_cv_mean_watts": 2.313, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T10:46:32.153497"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9559.936, "latencies_ms": [9559.936], "images_per_second": 0.105, "prompt_tokens": 37, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The image depicts a green luggage cart loaded with various old and worn suitcases in front of a green door and a green wall with a poster. The suitcases appear to be in a state of disrepair, suggesting they may have been abandoned or unused for a long time.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24591.0, "ram_available_mb": 38249.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 24589.6, "ram_available_mb": 38251.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.584, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T10:46:43.768635"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9374.541, "latencies_ms": [9374.541], "images_per_second": 0.107, "prompt_tokens": 36, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The image features a collection of old, worn suitcases in various colors such as brown, blue, and green, stacked on a green cart. The lighting appears to be natural daylight, casting soft shadows on the ground, which suggests the photo was taken outdoors during the day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24589.6, "ram_available_mb": 38251.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24636.6, "ram_available_mb": 38204.3, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.365, "power_cpu_cv_mean_watts": 1.83, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T10:46:55.193247"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11355.56, "latencies_ms": [11355.56], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young girl is standing in front of a couch, holding a Wii remote in her hand. She appears to be playing a video game, possibly on a Nintendo Wii console. The girl is wearing a pink dress, and her focus is on the game she is playing. The couch is positioned behind her, and the girl is standing close to", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 24636.6, "ram_available_mb": 38204.3, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24563.1, "ram_available_mb": 38277.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.626, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.831}, "timestamp": "2026-01-23T10:47:08.581734"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7829.566, "latencies_ms": [7829.566], "images_per_second": 0.128, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "couch: 1\ndress: 1\nflowers: 5\ncontroller: 1\nwindows: 2\nblinds: 2\nred curtain: 1\ngirl: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24563.1, "ram_available_mb": 38277.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24557.2, "ram_available_mb": 38283.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.45, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.889}, "timestamp": "2026-01-23T10:47:18.449369"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8971.796, "latencies_ms": [8971.796], "images_per_second": 0.111, "prompt_tokens": 44, "response_tokens_est": 58, "n_tiles": 16, "output_text": "The girl is standing in the foreground, holding a Wii controller in her right hand, which is positioned near her body. The couch is in the background, behind her, and the window with blinds is further back, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24557.2, "ram_available_mb": 38283.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24561.1, "ram_available_mb": 38279.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.525, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.883}, "timestamp": "2026-01-23T10:47:29.437292"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7503.776, "latencies_ms": [7503.776], "images_per_second": 0.133, "prompt_tokens": 37, "response_tokens_est": 44, "n_tiles": 16, "output_text": "A young girl in a pink dress is standing in front of a couch, holding a Wii remote control in her hands. She appears to be playing a video game or possibly preparing to play one.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24561.1, "ram_available_mb": 38279.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24578.5, "ram_available_mb": 38262.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.717, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T10:47:38.965275"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8457.598, "latencies_ms": [8457.598], "images_per_second": 0.118, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image shows a young girl in a pink dress with a floral pattern, standing in a room with a beige couch. The room has white blinds on the window, and the lighting appears to be natural daylight coming from the window.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24578.5, "ram_available_mb": 38262.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24551.3, "ram_available_mb": 38289.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.91, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T10:47:49.435898"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11376.126, "latencies_ms": [11376.126], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene of a home office setup. Dominating the space is a glass desk, which houses a laptop and a keyboard, suggesting a workspace. A black office chair is positioned in front of the desk, ready for use. The desk is situated against a white wall, and a window with blinds is visible in the background, allowing natural light to filter", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24551.3, "ram_available_mb": 38289.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24547.0, "ram_available_mb": 38293.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.618, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.832}, "timestamp": "2026-01-23T10:48:02.874401"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10707.676, "latencies_ms": [10707.676], "images_per_second": 0.093, "prompt_tokens": 39, "response_tokens_est": 72, "n_tiles": 16, "output_text": "- Computer monitor: 1\n\n- Keyboard: 1\n\n- Computer mouse: 1\n\n- Headphones: 1\n\n- Glass desk: 1\n\n- Glass desk surface: 1\n\n- Glass desk edge: 1\n\n- Wire: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24547.0, "ram_available_mb": 38293.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.04, "power_cpu_cv_mean_watts": 1.87, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T10:48:15.622714"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10446.733, "latencies_ms": [10446.733], "images_per_second": 0.096, "prompt_tokens": 44, "response_tokens_est": 71, "n_tiles": 16, "output_text": "The laptop is positioned on the left side of the glass desk, which is in the foreground of the image. The chair is placed in front of the desk, occupying the right side of the desk space. The computer tower on the floor is in the background, behind the desk and to the left of the chair.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24543.4, "ram_available_mb": 38297.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.867, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T10:48:28.107836"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8689.246, "latencies_ms": [8689.246], "images_per_second": 0.115, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image depicts a home office setting with a glass desk, a laptop, a keyboard, and a pair of headphones. There is a chair in front of the desk and a trash can with a plastic bag on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24543.4, "ram_available_mb": 38297.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24544.3, "ram_available_mb": 38296.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.842, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 8.815}, "timestamp": "2026-01-23T10:48:38.833199"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7444.72, "latencies_ms": [7444.72], "images_per_second": 0.134, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image shows an indoor setting with a laptop on a glass desk, a keyboard, and headphones placed beside it. The room has white walls, a window with blinds, and a wooden floor.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24544.3, "ram_available_mb": 38296.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.507, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 8.923}, "timestamp": "2026-01-23T10:48:48.301370"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11380.022, "latencies_ms": [11380.022], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image shows a close-up of a pizza on a white plate, which is placed on a table with a red and white checkered tablecloth. The pizza has a golden-brown crust and is topped with red tomato sauce, melted cheese, and slices of yellow bell pepper. The bell pepper slices are arranged in a", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24542.0, "ram_available_mb": 38298.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24542.7, "ram_available_mb": 38298.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.451, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.826}, "timestamp": "2026-01-23T10:49:01.740720"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8085.077, "latencies_ms": [8085.077], "images_per_second": 0.124, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "pizza: 1\npepperoni: 1\nmushrooms: 1\nonions: 2\ntomatoes: 1\ncheese: 1\nfork: 1\nplate: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.7, "ram_available_mb": 38298.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24552.0, "ram_available_mb": 38288.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.228, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T10:49:11.858183"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10301.361, "latencies_ms": [10301.361], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The pizza is positioned in the foreground of the image, occupying the majority of the frame. It is placed on a white plate which is on a tablecloth with a red and white checkered pattern. A fork is held in the upper right corner, suggesting the action of eating or about to eat the pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.0, "ram_available_mb": 38288.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24548.6, "ram_available_mb": 38292.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.022, "power_cpu_cv_mean_watts": 1.878, "power_sys_5v0_mean_watts": 8.865}, "timestamp": "2026-01-23T10:49:24.187974"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8400.362, "latencies_ms": [8400.362], "images_per_second": 0.119, "prompt_tokens": 37, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The image shows a pizza with various toppings on a white plate, which is placed on a table with a red and white checkered tablecloth. A person's hand is visible, holding a fork, ready to eat the pizza.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24548.6, "ram_available_mb": 38292.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24551.7, "ram_available_mb": 38289.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.997, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T10:49:34.628988"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10514.937, "latencies_ms": [10514.937], "images_per_second": 0.095, "prompt_tokens": 36, "response_tokens_est": 72, "n_tiles": 16, "output_text": "The pizza is topped with red tomato sauce, melted cheese, slices of yellow bell pepper, and mushrooms, all resting on a thin, golden crust. The pizza is served on a white plate, which is placed on a table covered with a red and white checkered tablecloth.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24551.7, "ram_available_mb": 38289.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24540.5, "ram_available_mb": 38300.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.936, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T10:49:47.178393"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12503.106, "latencies_ms": [12503.106], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a white and red bus parked on the side of a street. The bus is a part of the Metropolitan Transit System, as indicated by the sign on the front. Several people are visible inside the bus, waiting for their ride or preparing to board. \n\nIn addition to the bus, there are a few cars parked along the street, with one car located", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 24540.2, "ram_available_mb": 38300.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24570.9, "ram_available_mb": 38270.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.924, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 9.098}, "timestamp": "2026-01-23T10:50:01.745150"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8818.95, "latencies_ms": [8818.95], "images_per_second": 0.113, "prompt_tokens": 39, "response_tokens_est": 44, "n_tiles": 16, "output_text": "bus: 1\nwindow: 6\nseat: 0\npassenger: 4\nwheel: 1\ntrunk: 1\nflag: 1\ntree: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24570.9, "ram_available_mb": 38270.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24563.9, "ram_available_mb": 38277.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.707, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 9.063}, "timestamp": "2026-01-23T10:50:12.616108"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11687.545, "latencies_ms": [11687.545], "images_per_second": 0.086, "prompt_tokens": 44, "response_tokens_est": 71, "n_tiles": 16, "output_text": "The bus is in the foreground of the image, positioned on the left side, and appears to be in motion. It is a large vehicle with a red and white color scheme, and it is part of the Metropolitan Transit System. In the background, there are other vehicles and buildings, indicating that the bus is in an urban environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24563.9, "ram_available_mb": 38277.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24558.7, "ram_available_mb": 38282.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.39, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 9.114}, "timestamp": "2026-01-23T10:50:26.342658"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9299.752, "latencies_ms": [9299.752], "images_per_second": 0.108, "prompt_tokens": 37, "response_tokens_est": 48, "n_tiles": 16, "output_text": "A white and red Metropolitan Transit System bus is parked on the side of a street with trees in the background. The bus has the number 805 and the destination \"DOWNTOWN\" displayed on the front.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24558.7, "ram_available_mb": 38282.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 24584.7, "ram_available_mb": 38256.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.49, "power_cpu_cv_mean_watts": 1.734, "power_sys_5v0_mean_watts": 9.083}, "timestamp": "2026-01-23T10:50:37.661391"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6865.699, "latencies_ms": [6865.699], "images_per_second": 0.146, "prompt_tokens": 36, "response_tokens_est": 29, "n_tiles": 16, "output_text": "The bus is predominantly white with red and blue accents. The sky is clear and it appears to be a sunny day.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24585.1, "ram_available_mb": 38255.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 24563.6, "ram_available_mb": 38277.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.754, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 9.23}, "timestamp": "2026-01-23T10:50:46.564764"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12502.51, "latencies_ms": [12502.51], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of tranquility on a baseball field. A black and gold baseball glove, with a white logo on the back, is resting on the ground. The glove is positioned in such a way that it partially covers a blue baseball cap with a white logo. The cap is leaning against a green pole, suggesting a pause in action. The background is", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24563.6, "ram_available_mb": 38277.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 24584.7, "ram_available_mb": 38256.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.936, "power_cpu_cv_mean_watts": 1.983, "power_sys_5v0_mean_watts": 9.119}, "timestamp": "2026-01-23T10:51:01.102780"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9607.991, "latencies_ms": [9607.991], "images_per_second": 0.104, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "baseball glove: 1, baseball cap: 1, baseball cleat: 1, baseball bat: 1, baseball: 1, baseball glove: 1, baseball cap: 1, baseball cleat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24584.7, "ram_available_mb": 38256.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24588.8, "ram_available_mb": 38252.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.534, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 9.113}, "timestamp": "2026-01-23T10:51:12.722795"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11576.679, "latencies_ms": [11576.679], "images_per_second": 0.086, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The baseball cap is positioned in the foreground, resting on top of the baseball glove which is lying on the ground. The glove is near the base of the metal pole, suggesting it is placed close to the pole. The background is less distinct but appears to be an outdoor setting with some gravel or dirt.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24588.8, "ram_available_mb": 38252.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24577.6, "ram_available_mb": 38263.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.365, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 9.136}, "timestamp": "2026-01-23T10:51:26.353757"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9410.203, "latencies_ms": [9410.203], "images_per_second": 0.106, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A baseball cap and a glove are placed on the ground, suggesting a casual or relaxed setting, possibly after a game or practice. The cap has a logo on it, indicating it might be from a specific team or brand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24577.6, "ram_available_mb": 38263.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 24580.0, "ram_available_mb": 38260.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.398, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 9.038}, "timestamp": "2026-01-23T10:51:37.793577"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8777.577, "latencies_ms": [8777.577], "images_per_second": 0.114, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The baseball cap is navy blue with a white logo, and the glove is black with gold accents. The image has a warm, natural lighting, likely from the sun, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24580.0, "ram_available_mb": 38260.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24565.8, "ram_available_mb": 38275.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.583, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 9.154}, "timestamp": "2026-01-23T10:51:48.611238"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11363.126, "latencies_ms": [11363.126], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a surfer is skillfully riding a wave on a sunny day. The surfer is wearing a red shirt and is positioned on a white surfboard. The wave, a beautiful shade of blue-green, is breaking to the right of the surfer. The surfer is leaning into the wave, demonstrating their control and balance.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24565.8, "ram_available_mb": 38275.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24551.0, "ram_available_mb": 38289.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.535, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T10:52:02.034857"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8646.02, "latencies_ms": [8646.02], "images_per_second": 0.116, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "wave: 1\nsurfboard: 1\nsurfer: 1\nred shirt: 1\nblack shorts: 1\nnumber 7: 1\ngreen stripe: 1\nwhite surfboard: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24551.0, "ram_available_mb": 38289.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24548.0, "ram_available_mb": 38292.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.97, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 8.889}, "timestamp": "2026-01-23T10:52:12.696368"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8803.925, "latencies_ms": [8803.925], "images_per_second": 0.114, "prompt_tokens": 44, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The surfer is positioned in the foreground, riding a wave that is breaking to the right of the frame. The wave originates in the background and extends towards the left side of the image, creating a dynamic spatial relationship between the surfer and the moving water.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24548.0, "ram_available_mb": 38292.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24553.8, "ram_available_mb": 38287.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.686, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 8.941}, "timestamp": "2026-01-23T10:52:23.526416"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6825.685, "latencies_ms": [6825.685], "images_per_second": 0.147, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A surfer in a red shirt is riding a wave on a sunny day. The ocean is a beautiful shade of blue and the wave is breaking to the right.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24553.8, "ram_available_mb": 38287.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24559.0, "ram_available_mb": 38281.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.358, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.911}, "timestamp": "2026-01-23T10:52:32.371524"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7994.293, "latencies_ms": [7994.293], "images_per_second": 0.125, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The surfer is wearing a red shirt and is riding a wave that is a vibrant shade of blue-green. The water is splashing around the surfer, indicating active movement and possibly windy conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24559.0, "ram_available_mb": 38281.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.104, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 8.935}, "timestamp": "2026-01-23T10:52:42.409738"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.931, "latencies_ms": [11335.931], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "This image captures a quaint, small bathroom bathed in the soft glow of a black and white filter. The floor, a dark expanse of tiles, contrasts with the lighter walls. On the left, a pristine white toilet stands, its lid closed, exuding an air of cleanliness. To the right, a white sink is", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 24554.1, "ram_available_mb": 38286.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24547.0, "ram_available_mb": 38293.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.673, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T10:52:55.781460"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9334.66, "latencies_ms": [9334.66], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 60, "n_tiles": 16, "output_text": "toilet: 1, sink: 1, toilet paper: 6, toilet brush: 1, garbage can: 1, trash bag: 1, toilet paper roll: 1, toilet paper holder: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24547.0, "ram_available_mb": 38293.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24554.0, "ram_available_mb": 38286.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.533, "power_cpu_cv_mean_watts": 1.779, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T10:53:07.175794"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8614.304, "latencies_ms": [8614.304], "images_per_second": 0.116, "prompt_tokens": 44, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The toilet is positioned in the foreground on the left side of the image, while the sink is in the background on the right side. The toilet is closer to the viewer than the sink, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24554.0, "ram_available_mb": 38286.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24555.5, "ram_available_mb": 38285.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.758, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T10:53:17.803730"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7263.346, "latencies_ms": [7263.346], "images_per_second": 0.138, "prompt_tokens": 37, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image depicts a bathroom with a toilet and a sink. The toilet is positioned on the left side of the image, while the sink is on the right side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24555.5, "ram_available_mb": 38285.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.74, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.896}, "timestamp": "2026-01-23T10:53:27.095765"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7548.819, "latencies_ms": [7548.819], "images_per_second": 0.132, "prompt_tokens": 36, "response_tokens_est": 46, "n_tiles": 16, "output_text": "The image is in black and white, featuring a toilet and a sink in a bathroom. The tiles on the wall are made of marble, and there is a picture frame hanging above the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.363, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 8.926}, "timestamp": "2026-01-23T10:53:36.672330"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.869, "latencies_ms": [11335.869], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene scene of a white clock tower standing tall against a clear blue sky. The tower, adorned with a green dome, is the centerpiece of the image. It's surrounded by a white fence that adds a touch of elegance to the structure. The tower is nestled amidst lush green trees, creating a harmonious bl", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24543.6, "ram_available_mb": 38297.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24551.4, "ram_available_mb": 38289.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.554, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T10:53:50.057257"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10458.062, "latencies_ms": [10458.062], "images_per_second": 0.096, "prompt_tokens": 39, "response_tokens_est": 70, "n_tiles": 16, "output_text": "1. Dome: 1\n2. Clock: 1\n3. Bell: 1\n4. Roof tiles: 100\n5. Trees: 100\n6. Fence: 1\n7. Pole: 1\n8. Canopy: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24551.4, "ram_available_mb": 38289.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24548.6, "ram_available_mb": 38292.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.197, "power_cpu_cv_mean_watts": 1.861, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T10:54:02.543185"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11338.822, "latencies_ms": [11338.822], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The ornate structure on the left is in the foreground and appears to be closer to the viewer than the white tower with a blue dome in the background. The tower is situated on a higher elevation, as indicated by the perspective, and is surrounded by a clear blue sky. The roof tiles in the foreground are at a lower elevation compared to the tower, creating a", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24548.6, "ram_available_mb": 38292.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.614, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.852}, "timestamp": "2026-01-23T10:54:15.899016"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11490.459, "latencies_ms": [11490.459], "images_per_second": 0.087, "prompt_tokens": 37, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene scene of a white clock tower with a green dome, standing majestically against a clear blue sky. The tower is adorned with a clock face, and a weather vane on top, indicating the direction of the wind. The perspective of the image is from a low angle, looking up at the tower, giving it a grand and imposing appearance", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24546.1, "ram_available_mb": 38294.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24544.7, "ram_available_mb": 38296.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.676, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.821}, "timestamp": "2026-01-23T10:54:29.420311"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6084.167, "latencies_ms": [6084.167], "images_per_second": 0.164, "prompt_tokens": 36, "response_tokens_est": 33, "n_tiles": 16, "output_text": "The image features a clear blue sky and a white clock tower with a green dome. The roof of the building is covered in terracotta tiles.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24544.7, "ram_available_mb": 38296.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24544.7, "ram_available_mb": 38296.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.725, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 8.971}, "timestamp": "2026-01-23T10:54:37.555762"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11334.569, "latencies_ms": [11334.569], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene moment in the wild, featuring a group of elephants in their natural habitat. The elephant in the foreground, a majestic creature with a dark gray skin, is the focal point of the image. Its trunk, a symbol of strength and dexterity, is extended towards the ground, perhaps in search of food or simply exploring", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24544.7, "ram_available_mb": 38296.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 24533.6, "ram_available_mb": 38307.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.629, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T10:54:50.916203"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7718.407, "latencies_ms": [7718.407], "images_per_second": 0.13, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "elephant: 5, tree: 10, grass: 15, dirt: 20, path: 1, water: 0, rock: 2, bush: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24533.6, "ram_available_mb": 38307.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.722, "power_cpu_cv_mean_watts": 2.107, "power_sys_5v0_mean_watts": 8.926}, "timestamp": "2026-01-23T10:55:00.647011"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10652.477, "latencies_ms": [10652.477], "images_per_second": 0.094, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "In the foreground, there is a single elephant standing on the left side of the image, facing towards the right. Behind it, there is a group of elephants, with one partially visible on the right side and others in the background. The elephants are positioned in a natural setting with trees and vegetation surrounding them.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24555.3, "ram_available_mb": 38285.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24572.4, "ram_available_mb": 38268.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.864, "power_cpu_cv_mean_watts": 2.274, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T10:55:13.318713"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8888.639, "latencies_ms": [8888.639], "images_per_second": 0.113, "prompt_tokens": 37, "response_tokens_est": 56, "n_tiles": 16, "output_text": "A herd of elephants is gathered in a natural setting, possibly a forest or a grassland, with trees and vegetation in the background. The elephants are standing close together, with one elephant in the foreground looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 24572.4, "ram_available_mb": 38268.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24568.2, "ram_available_mb": 38272.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.846, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T10:55:24.219398"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10091.224, "latencies_ms": [10091.224], "images_per_second": 0.099, "prompt_tokens": 36, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The image features a group of elephants with a prominent one in the foreground that has its trunk curled up towards its mouth, showcasing its tusks. The lighting is natural and soft, suggesting the photo was taken during the day in a shaded area, possibly under the canopy of trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24568.2, "ram_available_mb": 38272.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.943, "power_cpu_cv_mean_watts": 1.878, "power_sys_5v0_mean_watts": 8.856}, "timestamp": "2026-01-23T10:55:36.331965"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11317.911, "latencies_ms": [11317.911], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of tranquility in a kitchen, where a white refrigerator stands as the centerpiece. The refrigerator, pristine and clean, is open, revealing its empty shelves and drawers. The top shelf is devoid of any items, while the bottom shelf houses a single carton of eggs. The re", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.648, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T10:55:49.689033"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10520.54, "latencies_ms": [10520.54], "images_per_second": 0.095, "prompt_tokens": 39, "response_tokens_est": 70, "n_tiles": 16, "output_text": "1. Refrigerator: 1\n2. Drawer: 1\n3. Shelf: 1\n4. Egg carton: 1\n5. Bottle: 1\n6. Door: 1\n7. Shelf: 1\n8. Drawer: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.119, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 8.824}, "timestamp": "2026-01-23T10:56:02.247515"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10922.623, "latencies_ms": [10922.623], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "The refrigerator is the main object in the foreground, with its door open revealing the interior. The shelves and drawers are empty, with the top shelf containing a carton of eggs and a bottle of condiment. The background is less distinct, but it appears to be the interior of a kitchen with a tiled floor.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.825, "power_cpu_cv_mean_watts": 1.907, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T10:56:15.195631"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8808.649, "latencies_ms": [8808.649], "images_per_second": 0.114, "prompt_tokens": 37, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image shows an open refrigerator with its door wide open, revealing the empty shelves and drawers inside. The refrigerator is placed in a room with a tiled floor, and the lighting suggests it might be nighttime.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.7, "ram_available_mb": 38290.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24557.2, "ram_available_mb": 38283.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.895, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T10:56:26.064424"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7271.024, "latencies_ms": [7271.024], "images_per_second": 0.138, "prompt_tokens": 36, "response_tokens_est": 43, "n_tiles": 16, "output_text": "The image shows an open refrigerator with a light interior, possibly white or light gray. The shelves are empty, and there is a bottle of beer on the top shelf.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24557.2, "ram_available_mb": 38283.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24548.1, "ram_available_mb": 38292.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.843, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.939}, "timestamp": "2026-01-23T10:56:35.376218"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12556.637, "latencies_ms": [12556.637], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a close-up view of a bunch of bananas resting on a shelf. The bananas are yellow, indicating they are ripe and ready to eat. They are arranged in a neat row, with each banana slightly overlapping the one next to it. The shelf they are on is metallic, reflecting a soft purple light that ill", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24548.1, "ram_available_mb": 38292.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24560.0, "ram_available_mb": 38280.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.878, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 9.062}, "timestamp": "2026-01-23T10:56:49.967570"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10973.48, "latencies_ms": [10973.48], "images_per_second": 0.091, "prompt_tokens": 39, "response_tokens_est": 63, "n_tiles": 16, "output_text": "banana: 8\n\nbananas: 8\n\nbanana bunch: 1\n\nbanana peel: 0\n\nbanana sticker: 2\n\nbanana label: 2\n\nbanana skin: 0\n\nbanana stem: 0", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24560.0, "ram_available_mb": 38280.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24566.0, "ram_available_mb": 38274.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.824, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 9.05}, "timestamp": "2026-01-23T10:57:02.960536"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12610.06, "latencies_ms": [12610.06], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The bananas are arranged in a diagonal line from the top left to the bottom right of the image, creating a sense of depth. The left side of the image is blurred, making it difficult to discern any details, while the right side is in focus, showing the individual bananas and their sticker labels clearly. The bananas in the foreground appear larger and more detailed than", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24566.0, "ram_available_mb": 38274.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.11, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 9.105}, "timestamp": "2026-01-23T10:57:17.596664"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10322.592, "latencies_ms": [10322.592], "images_per_second": 0.097, "prompt_tokens": 37, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The image shows a close-up of a bunch of bananas with a sticker on them, placed on a surface with a blurred background. The focus is on the bananas, and the background is out of focus, making it difficult to determine the exact setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24569.6, "ram_available_mb": 38271.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.979, "power_cpu_cv_mean_watts": 1.606, "power_sys_5v0_mean_watts": 9.061}, "timestamp": "2026-01-23T10:57:29.931937"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 12603.151, "latencies_ms": [12603.151], "images_per_second": 0.079, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a close-up of a bunch of bananas with a focus on their yellow skin, which has a slight greenish tint at the top, indicating they are ripe. The lighting in the image is soft and diffused, casting a gentle shadow on the bananas, which are placed against a blurred background with a purple hue that suggests a cooler", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24569.6, "ram_available_mb": 38271.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24559.3, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.041, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 9.085}, "timestamp": "2026-01-23T10:57:44.560731"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12491.854, "latencies_ms": [12491.854], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 16, "output_text": "The image captures a city street scene with three large, orange, cylindrical objects that resemble fire hydrants. They are placed on a sidewalk, and the street is wet, suggesting recent rain or snow. In the background, there are buildings with a mix of architectural styles, and the sky is overcast. The overall atmosphere is quiet and serene.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 24559.3, "ram_available_mb": 38281.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.892, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 9.061}, "timestamp": "2026-01-23T10:57:59.090825"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 12517.553, "latencies_ms": [12517.553], "images_per_second": 0.08, "prompt_tokens": 39, "response_tokens_est": 76, "n_tiles": 16, "output_text": "object: 3, count: 3\nobject: trees, count: 4\nobject: buildings, count: 3\nobject: street, count: 1\nobject: snow, count: 1\nobject: traffic lights, count: 2\nobject: sidewalk, count: 1\nobject: bench, count: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24562.3, "ram_available_mb": 38278.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.201, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 9.039}, "timestamp": "2026-01-23T10:58:13.641341"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12638.697, "latencies_ms": [12638.697], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there are three large, copper-colored bollards with circular designs on top, positioned close to the viewer. They are situated on a sidewalk that leads the eye towards the background, where a large, ornate building with many windows and a sign that reads 'IGN' can be seen. The bollards are in the near foreground,", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24562.3, "ram_available_mb": 38278.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24570.1, "ram_available_mb": 38270.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.019, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 9.084}, "timestamp": "2026-01-23T10:58:28.336487"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 12242.67, "latencies_ms": [12242.67], "images_per_second": 0.082, "prompt_tokens": 37, "response_tokens_est": 73, "n_tiles": 16, "output_text": "The image depicts a city street with a row of large, ornate, copper-colored fire hydrants in the foreground, each with a unique design on top. The background features a mix of modern and older buildings, and the ground is covered with a layer of snow, suggesting a cold, winter day in an urban environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24570.1, "ram_available_mb": 38270.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.139, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 9.008}, "timestamp": "2026-01-23T10:58:42.606408"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 12646.682, "latencies_ms": [12646.682], "images_per_second": 0.079, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a series of three large, copper-colored fire hydrants with ornate designs on top, set against a backdrop of a snowy urban street. The hydrants are positioned on a sidewalk that is partially covered with snow, and the buildings in the background have a mix of architectural styles, with one prominent building displaying a blue glass facade.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24561.1, "ram_available_mb": 38279.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.877, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 9.091}, "timestamp": "2026-01-23T10:58:57.307573"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12546.381, "latencies_ms": [12546.381], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a jockey is seen riding a brown horse on a dirt track. The jockey, clad in a yellow and green uniform, is wearing a white helmet. The horse, adorned with a black bridle, is in motion, its legs lifted off the ground, indicating a gallop. The track is marked by a white fence on the", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 24561.1, "ram_available_mb": 38279.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 24559.8, "ram_available_mb": 38281.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.89, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 9.063}, "timestamp": "2026-01-23T10:59:11.896893"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11170.416, "latencies_ms": [11170.416], "images_per_second": 0.09, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "- Horse: 1\n\n- Jockey: 1\n\n- Cart: 1\n\n- Number 8 sign: 1\n\n- Grass: 1\n\n- Fence: 1\n\n- Cart track: 1\n\n- Signs: 2", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24559.8, "ram_available_mb": 38281.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24573.1, "ram_available_mb": 38267.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.621, "power_cpu_cv_mean_watts": 2.167, "power_sys_5v0_mean_watts": 9.086}, "timestamp": "2026-01-23T10:59:25.127037"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12670.773, "latencies_ms": [12670.773], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a person wearing a helmet and a yellow and green outfit, riding a brown horse with the number 8 on its back. The horse is in motion, likely racing, and is positioned in the center of the image. In the background, there are banners with the words \"MAGNUM\" and \"WINSTONE\" along", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24573.1, "ram_available_mb": 38267.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 24582.6, "ram_available_mb": 38258.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.986, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 9.095}, "timestamp": "2026-01-23T10:59:39.860565"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8241.514, "latencies_ms": [8241.514], "images_per_second": 0.121, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "A jockey is riding a brown horse with the number 8 on its saddle, racing on a track with banners for Magnum and Winstone in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24582.6, "ram_available_mb": 38258.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 24602.1, "ram_available_mb": 38238.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.153, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 9.101}, "timestamp": "2026-01-23T10:59:50.115827"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9813.61, "latencies_ms": [9813.61], "images_per_second": 0.102, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image captures a moment of a horse race, with the horse and jockey in motion on a dirt track. The lighting is natural, suggesting it is daytime, and the weather appears to be clear with no signs of rain or adverse conditions.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24602.1, "ram_available_mb": 38238.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24680.8, "ram_available_mb": 38160.1, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.061, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 9.145}, "timestamp": "2026-01-23T11:00:01.960543"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11328.239, "latencies_ms": [11328.239], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a brown dog is standing on a concrete ledge in a backyard. The dog is positioned in the center of the frame, looking directly at the camera with a focused expression. The backyard is enclosed by a wooden fence, and there is a tree nearby.\n\nThere are several oranges scattered around the area, with some close to the dog and others", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24593.1, "ram_available_mb": 38247.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24636.2, "ram_available_mb": 38204.7, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.667, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.833}, "timestamp": "2026-01-23T11:00:15.342521"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7299.775, "latencies_ms": [7299.775], "images_per_second": 0.137, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "dog: 1, tree: 1, lemon: 3, fence: 1, bush: 1, step: 1, house: 1, shadow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24567.7, "ram_available_mb": 38273.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24568.5, "ram_available_mb": 38272.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.788, "power_cpu_cv_mean_watts": 1.608, "power_sys_5v0_mean_watts": 8.904}, "timestamp": "2026-01-23T11:00:24.654179"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7929.141, "latencies_ms": [7929.141], "images_per_second": 0.126, "prompt_tokens": 44, "response_tokens_est": 49, "n_tiles": 16, "output_text": "The dog is standing on a ledge in the foreground of the image, with a garden and a fence in the background. The tree with green leaves is behind the dog, and there are yellow fruits hanging from it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24568.5, "ram_available_mb": 38272.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24556.7, "ram_available_mb": 38284.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.144, "power_cpu_cv_mean_watts": 1.727, "power_sys_5v0_mean_watts": 8.919}, "timestamp": "2026-01-23T11:00:34.634786"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7290.24, "latencies_ms": [7290.24], "images_per_second": 0.137, "prompt_tokens": 37, "response_tokens_est": 42, "n_tiles": 16, "output_text": "A dog is standing on a concrete ledge in a backyard. The backyard has a wooden fence, a small tree with green leaves, and a few yellow fruits hanging from it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.7, "ram_available_mb": 38284.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24638.5, "ram_available_mb": 38202.4, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.883, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T11:00:43.947767"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6528.656, "latencies_ms": [6528.656], "images_per_second": 0.153, "prompt_tokens": 36, "response_tokens_est": 37, "n_tiles": 16, "output_text": "The dog is a light brown color with a white chest and paws. It is standing on a concrete ledge with a wooden fence and green trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24638.5, "ram_available_mb": 38202.4, "ram_percent": 39.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24646.8, "ram_available_mb": 38194.1, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.463, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 9.014}, "timestamp": "2026-01-23T11:00:52.524813"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11369.439, "latencies_ms": [11369.439], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a person is standing on a wooden bench that is placed on a brick sidewalk. The person is wearing red pants and blue shoes. The bench is positioned against a gray concrete wall. On the bench, there is a blue sign with the text \"WETENER\" written on it. The person's feet are resting on the", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 24574.9, "ram_available_mb": 38266.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24559.8, "ram_available_mb": 38281.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.548, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 8.836}, "timestamp": "2026-01-23T11:01:05.963202"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7864.172, "latencies_ms": [7864.172], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "bench: 1, person: 1, brick: 100, wall: 1, paper: 1, screw: 4, screwdriver: 1, shoes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24559.8, "ram_available_mb": 38281.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24548.6, "ram_available_mb": 38292.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.462, "power_cpu_cv_mean_watts": 1.674, "power_sys_5v0_mean_watts": 8.892}, "timestamp": "2026-01-23T11:01:15.854949"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9521.996, "latencies_ms": [9521.996], "images_per_second": 0.105, "prompt_tokens": 44, "response_tokens_est": 63, "n_tiles": 16, "output_text": "A person is standing on a wooden bench that is positioned against a concrete wall. The bench is in the foreground of the image, while the concrete wall serves as the background. The person's feet are near the edge of the bench, indicating they are close to the bench.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24548.6, "ram_available_mb": 38292.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.244, "power_cpu_cv_mean_watts": 1.846, "power_sys_5v0_mean_watts": 8.866}, "timestamp": "2026-01-23T11:01:27.404791"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7846.839, "latencies_ms": [7846.839], "images_per_second": 0.127, "prompt_tokens": 37, "response_tokens_est": 47, "n_tiles": 16, "output_text": "A person is standing on a wooden bench with a handwritten note that says \"Wetener you got to be sitting on me.\" The bench is located on a brick pavement with a concrete wall in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.279, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 8.888}, "timestamp": "2026-01-23T11:01:37.290460"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8002.722, "latencies_ms": [8002.722], "images_per_second": 0.125, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "A person is standing on a wooden bench with a blue sign that reads \"WETENER you got to be sitting on me!\" The bench is made of wood and the person is wearing red pants and blue shoes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24537.7, "ram_available_mb": 38303.2, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.182, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 8.915}, "timestamp": "2026-01-23T11:01:47.315992"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11341.736, "latencies_ms": [11341.736], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a well-decorated living room with a red couch positioned on the left side of the room. A dining table is set up in the middle of the room, surrounded by chairs. The table is adorned with a white tablecloth, and there are various items on it, including a vase, a bowl, and a cup. \n", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24551.5, "ram_available_mb": 38289.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.545, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T11:02:00.708628"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8742.599, "latencies_ms": [8742.599], "images_per_second": 0.114, "prompt_tokens": 39, "response_tokens_est": 55, "n_tiles": 16, "output_text": "- Couch: 2\n- Table: 2\n- Chair: 2\n- Lamp: 2\n- Picture frame: 1\n- Sofa: 1\n- Carpet: 1\n- Tablecloth: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.5, "ram_available_mb": 38289.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.91, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T11:02:11.477199"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11324.61, "latencies_ms": [11324.61], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The living room features a red sofa in the foreground, positioned near a wooden side table with a lamp and a vase of flowers. In the background, there is a dining area with a white tablecloth, chairs, and a TV mounted on the wall. The curtains in the room create a separation between the living and dining areas, with the living area", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24557.6, "ram_available_mb": 38283.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.63, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T11:02:24.841591"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9446.053, "latencies_ms": [9446.053], "images_per_second": 0.106, "prompt_tokens": 37, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The image depicts a well-lit and cozy living room with a red sofa, a small round table with a white tablecloth, and a TV mounted on the wall. The room is decorated with a framed picture on the wall and a lamp on a side table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24557.6, "ram_available_mb": 38283.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.522, "power_cpu_cv_mean_watts": 1.799, "power_sys_5v0_mean_watts": 8.826}, "timestamp": "2026-01-23T11:02:36.335796"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8809.882, "latencies_ms": [8809.882], "images_per_second": 0.114, "prompt_tokens": 36, "response_tokens_est": 57, "n_tiles": 16, "output_text": "The room is well-lit with natural light coming through the sheer curtains, and the furniture is made of wood with a warm brown finish. The walls are painted in a light beige color, and there is a large painting hanging above the sofa.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.2, "ram_available_mb": 38288.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24558.2, "ram_available_mb": 38282.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.616, "power_cpu_cv_mean_watts": 1.799, "power_sys_5v0_mean_watts": 8.879}, "timestamp": "2026-01-23T11:02:47.165942"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11328.906, "latencies_ms": [11328.906], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image shows a close-up of a cooking pan on a stove containing a stir-fry dish. The dish consists of various pieces of broccoli, carrots, and what appears to be diced ham or sausage. The vegetables are cut into bite-sized pieces and are mixed together, suggesting they are being cooked. The pan is", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24558.2, "ram_available_mb": 38282.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.683, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 8.858}, "timestamp": "2026-01-23T11:03:00.555762"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8328.396, "latencies_ms": [8328.396], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "broccoli: 12, carrots: 5, meat: 8, tomatoes: 2, onions: 1, garlic: 1, pepper: 1, olive oil: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24545.1, "ram_available_mb": 38295.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.157, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T11:03:10.911244"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11326.864, "latencies_ms": [11326.864], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a skillet containing a mix of diced vegetables and meat, with the broccoli occupying the most space and being the most prominent object. The carrots and tomatoes are scattered around the broccoli, with the carrots being more towards the left side and the tomatoes more towards the right. The meat is interspersed", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24547.3, "ram_available_mb": 38293.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.669, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T11:03:24.259747"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9226.561, "latencies_ms": [9226.561], "images_per_second": 0.108, "prompt_tokens": 37, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image shows a skillet on a stove containing a mix of diced vegetables and chunks of meat, likely being cooked. The vegetables include broccoli and carrots, and the meat appears to be diced ham or a similar type of pork.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24547.3, "ram_available_mb": 38293.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 24561.4, "ram_available_mb": 38279.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.732, "power_cpu_cv_mean_watts": 2.243, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T11:03:35.512852"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8111.379, "latencies_ms": [8111.379], "images_per_second": 0.123, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows a skillet on a stove containing a mix of cooked vegetables and meat. The vegetables appear to be broccoli and carrots, and the meat looks like it could be diced ham or sausage.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24561.4, "ram_available_mb": 38279.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.195, "power_cpu_cv_mean_watts": 2.155, "power_sys_5v0_mean_watts": 8.959}, "timestamp": "2026-01-23T11:03:45.676744"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11310.132, "latencies_ms": [11310.132], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a delightful scene of a meal in progress. At the center of the frame, a brown plate holds four hot dogs, each nestled in a soft bun. The hot dogs are generously topped with a vibrant yellow mustard, adding a pop of color to the scene. The plate is placed on a black countertop, providing a stark contrast to", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 24560.1, "ram_available_mb": 38280.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.626, "power_cpu_cv_mean_watts": 2.048, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T11:03:59.034496"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5710.806, "latencies_ms": [5710.806], "images_per_second": 0.175, "prompt_tokens": 39, "response_tokens_est": 28, "n_tiles": 16, "output_text": "hot dog: 4, bun: 4, mustard: 4, plate: 1, magazine: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24560.1, "ram_available_mb": 38280.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24558.4, "ram_available_mb": 38282.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.528, "power_cpu_cv_mean_watts": 1.376, "power_sys_5v0_mean_watts": 8.957}, "timestamp": "2026-01-23T11:04:06.780191"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9216.456, "latencies_ms": [9216.456], "images_per_second": 0.109, "prompt_tokens": 44, "response_tokens_est": 60, "n_tiles": 16, "output_text": "The hot dogs are arranged in a row, with one in the foreground and two slightly behind it, all positioned towards the left side of the plate. The plate is placed on a surface that appears to be a kitchen counter, with a magazine partially visible in the background to the right.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 24558.4, "ram_available_mb": 38282.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.522, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.873}, "timestamp": "2026-01-23T11:04:18.012845"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8916.465, "latencies_ms": [8916.465], "images_per_second": 0.112, "prompt_tokens": 37, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image shows a plate with four hot dogs, each with a bun and a generous amount of yellow mustard on top. The plate is placed on a granite countertop, and there is a magazine with the title \"Sports\" visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24562.6, "ram_available_mb": 38278.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.894, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T11:04:28.962289"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8782.594, "latencies_ms": [8782.594], "images_per_second": 0.114, "prompt_tokens": 36, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image shows three hot dogs with bright yellow mustard on a brown plate, which is placed on a granite countertop. The lighting in the image is bright, highlighting the glossy texture of the mustard and the softness of the buns.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24562.6, "ram_available_mb": 38278.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24553.0, "ram_available_mb": 38287.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.831, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 8.889}, "timestamp": "2026-01-23T11:04:39.780989"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12505.947, "latencies_ms": [12505.947], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene beach scene. A green umbrella, adorned with a floral pattern, stands tall on the sandy beach, providing a vibrant contrast to the surrounding environment. Two blue and one pink beach chair are positioned under the umbrella, offering a spot of shade for those who prefer to relax there. The beach is not crow", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24553.0, "ram_available_mb": 38287.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24577.3, "ram_available_mb": 38263.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.943, "power_cpu_cv_mean_watts": 1.808, "power_sys_5v0_mean_watts": 9.059}, "timestamp": "2026-01-23T11:04:54.326076"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8560.409, "latencies_ms": [8560.409], "images_per_second": 0.117, "prompt_tokens": 39, "response_tokens_est": 42, "n_tiles": 16, "output_text": "umbrella: 1, chair: 2, person: 4, beach: 1, water: 1, sand: 1, wave: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24577.3, "ram_available_mb": 38263.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24578.4, "ram_available_mb": 38262.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.102, "power_cpu_cv_mean_watts": 1.429, "power_sys_5v0_mean_watts": 9.085}, "timestamp": "2026-01-23T11:05:04.910960"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12620.541, "latencies_ms": [12620.541], "images_per_second": 0.079, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there are two beach chairs, one pink and one blue, positioned close to each other under a green umbrella. The umbrella is on the sand, and the chairs are near the water's edge. In the background, there are four individuals in the water, with one person closer to the shore and the others further out. The water", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24578.4, "ram_available_mb": 38262.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24575.5, "ram_available_mb": 38265.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.056, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 9.095}, "timestamp": "2026-01-23T11:05:19.570442"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7202.15, "latencies_ms": [7202.15], "images_per_second": 0.139, "prompt_tokens": 37, "response_tokens_est": 30, "n_tiles": 16, "output_text": "A group of people are swimming in the ocean near a beach with a green umbrella and two folding chairs on the sand.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24575.5, "ram_available_mb": 38265.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 24598.8, "ram_available_mb": 38242.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.976, "power_cpu_cv_mean_watts": 1.221, "power_sys_5v0_mean_watts": 9.103}, "timestamp": "2026-01-23T11:05:28.818442"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9811.801, "latencies_ms": [9811.801], "images_per_second": 0.102, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "A vibrant green umbrella is open on the sandy beach, providing shade for two colorful beach chairs, one pink and one blue. The sky is overcast, and the water appears calm with small waves lapping at the shore.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24598.8, "ram_available_mb": 38242.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24579.2, "ram_available_mb": 38261.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.064, "power_cpu_cv_mean_watts": 1.597, "power_sys_5v0_mean_watts": 9.116}, "timestamp": "2026-01-23T11:05:40.665634"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11373.242, "latencies_ms": [11373.242], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a vintage kitchen with a green and white color scheme. The kitchen is filled with various appliances and items, including a sink, a refrigerator, a microwave, and a toaster. There are also several bowls placed on the countertops, and a dining table is situated in the room.\n\nA wooden chair is positioned", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 24579.2, "ram_available_mb": 38261.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24557.6, "ram_available_mb": 38283.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.516, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.831}, "timestamp": "2026-01-23T11:05:54.081800"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8807.254, "latencies_ms": [8807.254], "images_per_second": 0.114, "prompt_tokens": 39, "response_tokens_est": 55, "n_tiles": 16, "output_text": "- Table: 1\n- Chair: 1\n- Cabinet: 1\n- Stove: 1\n- Oven: 1\n- Microwave: 1\n- Countertop: 1\n- Jar: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24557.6, "ram_available_mb": 38283.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.712, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 8.835}, "timestamp": "2026-01-23T11:06:04.934481"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11357.809, "latencies_ms": [11357.809], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a wooden chair positioned near the center of the image, with a table in front of it. The table is surrounded by various kitchen items such as a pot, a bowl, and a jar. In the background, there is a green refrigerator on the right side and a wooden cabinet on the left side. The walls are adorned with", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24548.5, "ram_available_mb": 38292.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24547.6, "ram_available_mb": 38293.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.592, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T11:06:18.304185"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8533.164, "latencies_ms": [8533.164], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The image depicts a vintage kitchen with green walls and a patterned wallpaper. The kitchen is furnished with a white refrigerator, a sink, a stove, a table with various items on it, and a chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24547.6, "ram_available_mb": 38293.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24553.3, "ram_available_mb": 38287.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.997, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T11:06:28.883659"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8575.248, "latencies_ms": [8575.248], "images_per_second": 0.117, "prompt_tokens": 36, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The kitchen is filled with vibrant green cabinets and a white sink, creating a contrast of colors. The lighting is warm and natural, coming from the windows with white curtains, and the wooden furniture adds a rustic touch to the room.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24553.3, "ram_available_mb": 38287.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24546.6, "ram_available_mb": 38294.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.729, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 8.902}, "timestamp": "2026-01-23T11:06:39.479641"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.8, "latencies_ms": [11335.8], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the heart of a serene woodland, a black and white dog is captured in a moment of pure joy. The dog, adorned with a blue collar, is in the midst of a playful chase, its body poised in mid-air as it leaps towards a red frisbee. The frisbee, a vibrant splash of", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 24546.6, "ram_available_mb": 38294.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24542.4, "ram_available_mb": 38298.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.628, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T11:06:52.874774"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6958.847, "latencies_ms": [6958.847], "images_per_second": 0.144, "prompt_tokens": 39, "response_tokens_est": 39, "n_tiles": 16, "output_text": "dog: 1, stick: 1, leaves: many, ground: dry, tree: 1, moss: patchy, sunlight: visible, shadows: visible", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24542.4, "ram_available_mb": 38298.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.104, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.898}, "timestamp": "2026-01-23T11:07:01.850532"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11352.038, "latencies_ms": [11352.038], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a black and white dog is positioned near the center of the image, holding a frisbee in its mouth. The dog is standing on a ground covered with brown leaves, which suggests it is in a park or a wooded area. To the right of the dog, there is a large green tree trunk, indicating that the dog is relatively close to the", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.593, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T11:07:15.221118"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7063.546, "latencies_ms": [7063.546], "images_per_second": 0.142, "prompt_tokens": 37, "response_tokens_est": 40, "n_tiles": 16, "output_text": "A black and white dog is playing with a frisbee in a wooded area with a large green tree. The ground is covered with fallen leaves, indicating that it is autumn.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.0, "ram_available_mb": 38295.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24540.8, "ram_available_mb": 38300.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.029, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 8.899}, "timestamp": "2026-01-23T11:07:24.307868"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10172.538, "latencies_ms": [10172.538], "images_per_second": 0.098, "prompt_tokens": 36, "response_tokens_est": 69, "n_tiles": 16, "output_text": "The image depicts a scene in a forest with a dog in the foreground. The ground is covered with brown leaves, and there is a large green tree trunk on the right side of the image. The lighting is natural and appears to be coming from the left side of the image, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24540.8, "ram_available_mb": 38300.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.999, "power_cpu_cv_mean_watts": 1.892, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T11:07:36.494793"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11362.332, "latencies_ms": [11362.332], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a person is cross-country skiing on a snowy trail. The skier is wearing a white hat, a red backpack, and green boots. They are holding ski poles and appear to be in motion. The trail is surrounded by trees, and the sky is clear and blue. The skier's posture suggests they are in the middle of", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24543.8, "ram_available_mb": 38297.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.6, "power_cpu_cv_mean_watts": 2.103, "power_sys_5v0_mean_watts": 8.843}, "timestamp": "2026-01-23T11:07:49.891815"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7395.559, "latencies_ms": [7395.559], "images_per_second": 0.135, "prompt_tokens": 39, "response_tokens_est": 43, "n_tiles": 16, "output_text": "person: 1, ski: 2, ski pole: 2, backpack: 1, ski boot: 2, ski trail: 1, tree: many, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.1, "ram_available_mb": 38284.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 24557.0, "ram_available_mb": 38283.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.858, "power_cpu_cv_mean_watts": 2.118, "power_sys_5v0_mean_watts": 8.951}, "timestamp": "2026-01-23T11:07:59.304977"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11409.39, "latencies_ms": [11409.39], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a skier is positioned on the left side of the image, moving towards the right along a snow-covered slope. The skier is closer to the viewer than the trees in the background, which line the edge of the slope. The trail in the snow leads from the skier's current position into the distance, suggesting a path that extends far beyond", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24557.0, "ram_available_mb": 38283.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 24559.7, "ram_available_mb": 38281.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.603, "power_cpu_cv_mean_watts": 2.254, "power_sys_5v0_mean_watts": 8.873}, "timestamp": "2026-01-23T11:08:12.739441"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6739.117, "latencies_ms": [6739.117], "images_per_second": 0.148, "prompt_tokens": 37, "response_tokens_est": 37, "n_tiles": 16, "output_text": "A person is cross-country skiing on a snowy trail in a forested area. They are wearing a backpack and using ski poles to navigate the terrain.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24559.7, "ram_available_mb": 38281.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.595, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 8.956}, "timestamp": "2026-01-23T11:08:21.499828"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9332.003, "latencies_ms": [9332.003], "images_per_second": 0.107, "prompt_tokens": 36, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The skier is wearing a white helmet, black pants, and a red backpack, with green boots and red ski poles. The snow is pristine and untouched except for the ski tracks, indicating a fresh snowfall or a well-preserved trail.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24564.6, "ram_available_mb": 38276.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.495, "power_cpu_cv_mean_watts": 1.814, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T11:08:32.856619"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12310.96, "latencies_ms": [12310.96], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the heart of a serene landscape, a BNSF Railway train, painted in vibrant hues of orange and black, is captured in motion. The locomotive, bearing the number 6309, is pulling a series of freight cars behind it. The train is traveling on a track that cuts through a tranquil wooded area, with trees standing", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24564.6, "ram_available_mb": 38276.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24562.5, "ram_available_mb": 38278.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11525.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.657, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 9.05}, "timestamp": "2026-01-23T11:08:47.196024"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9810.55, "latencies_ms": [9810.55], "images_per_second": 0.102, "prompt_tokens": 39, "response_tokens_est": 55, "n_tiles": 16, "output_text": "Train: 1\nCar: 1\nTrain car: 1\nTrain tracks: 1\nTrees: 1\nBNSF logo: 1\nNumber: 6309: 1\nFence: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24562.5, "ram_available_mb": 38278.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11559.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.687, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 9.015}, "timestamp": "2026-01-23T11:08:59.034244"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7125.149, "latencies_ms": [7125.149], "images_per_second": 0.14, "prompt_tokens": 44, "response_tokens_est": 34, "n_tiles": 16, "output_text": "The train is in the foreground of the image, moving from left to right. The trees in the background appear to be far away and are behind the train.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24585.6, "ram_available_mb": 38255.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11570.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.999, "power_cpu_cv_mean_watts": 1.375, "power_sys_5v0_mean_watts": 9.132}, "timestamp": "2026-01-23T11:09:08.175415"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9344.463, "latencies_ms": [9344.463], "images_per_second": 0.107, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "A BNSF train, numbered 6309, is traveling on a railway track with a clear blue sky in the background. The train is surrounded by trees with no leaves, indicating that it might be autumn or winter.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24585.6, "ram_available_mb": 38255.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24550.2, "ram_available_mb": 38290.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11554.8, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.882, "power_cpu_cv_mean_watts": 1.541, "power_sys_5v0_mean_watts": 9.028}, "timestamp": "2026-01-23T11:09:19.557347"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6305.98, "latencies_ms": [6305.98], "images_per_second": 0.159, "prompt_tokens": 36, "response_tokens_est": 27, "n_tiles": 16, "output_text": "The train is predominantly orange with black and yellow accents. The sky is clear and blue, indicating good weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.2, "ram_available_mb": 38290.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 24568.4, "ram_available_mb": 38272.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11552.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.809, "power_cpu_cv_mean_watts": 1.239, "power_sys_5v0_mean_watts": 9.206}, "timestamp": "2026-01-23T11:09:27.910480"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11364.972, "latencies_ms": [11364.972], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a dining table with a plate of food on it. The plate contains a variety of food items, including a bowl of broccoli, a piece of bread with guacamole, and a slice of bread with cream cheese. The broccoli is placed in a bowl, while the other food items are spread out on the plate. The arrangement of", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 24568.4, "ram_available_mb": 38272.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24555.6, "ram_available_mb": 38285.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.435, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T11:09:41.326210"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8091.101, "latencies_ms": [8091.101], "images_per_second": 0.124, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "plate: 2, piece of bread: 1, avocado spread: 1, broccoli: 1, bowl: 1, wooden table: 1, image: 1, website: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24555.6, "ram_available_mb": 38285.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24562.1, "ram_available_mb": 38278.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.329, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T11:09:51.463902"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11091.838, "latencies_ms": [11091.838], "images_per_second": 0.09, "prompt_tokens": 44, "response_tokens_est": 77, "n_tiles": 16, "output_text": "In the foreground, there is a plate with a piece of bread topped with a green spread, which is positioned to the left of a bowl containing a green vegetable dish. The bowl is placed on the right side of the plate, and both the plate and bowl are situated on a wooden surface that appears to be the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24562.1, "ram_available_mb": 38278.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24556.5, "ram_available_mb": 38284.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.739, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T11:10:04.599552"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10039.974, "latencies_ms": [10039.974], "images_per_second": 0.1, "prompt_tokens": 37, "response_tokens_est": 66, "n_tiles": 16, "output_text": "The image shows a meal consisting of a slice of bread with avocado spread, a bowl of broccoli, and a small bowl of cream cheese, all placed on a wooden table. The setting appears to be a casual dining environment, possibly at home or a cozy restaurant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24556.5, "ram_available_mb": 38284.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.157, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T11:10:16.692535"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11331.302, "latencies_ms": [11331.302], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image shows a meal on a wooden table with a blue plate. The plate contains a piece of bread with a green spread, a bowl of broccoli, and a dollop of cream cheese on another piece of bread. The lighting is warm and the colors are vibrant, with the green of the broccoli and avocado spread standing out against the", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24553.4, "ram_available_mb": 38287.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.58, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T11:10:30.065371"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11392.732, "latencies_ms": [11392.732], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a scene of a person wrapped in an orange sleeping bag, lying on a wooden bench in a park. The person appears to be in a state of rest or sleep, with their head resting on a blue backpack. The bench is situated on a grassy area, and there are two parking meters in the background, indicating that the location is likely a", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 24553.4, "ram_available_mb": 38287.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24553.6, "ram_available_mb": 38287.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.519, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.817}, "timestamp": "2026-01-23T11:10:43.485491"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7852.338, "latencies_ms": [7852.338], "images_per_second": 0.127, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "bench: 1, sleeping bag: 1, backpack: 1, coat: 1, parking meter: 2, fence: 1, grass: 1, car: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.6, "ram_available_mb": 38287.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.49, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T11:10:53.382913"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10082.847, "latencies_ms": [10082.847], "images_per_second": 0.099, "prompt_tokens": 44, "response_tokens_est": 68, "n_tiles": 16, "output_text": "In the foreground, there is a wooden bench with a sleeping bag and a jacket draped over it. Behind the bench, there are two parking meters standing upright. The parking meters are located further back in the image, behind the fence that runs parallel to the bench.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.112, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 8.875}, "timestamp": "2026-01-23T11:11:05.495371"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10139.772, "latencies_ms": [10139.772], "images_per_second": 0.099, "prompt_tokens": 37, "response_tokens_est": 67, "n_tiles": 16, "output_text": "A person is sleeping on a park bench, covered with an orange sleeping bag, with a blue backpack and a red jacket visible. Behind the bench, there are two parking meters and a wooden fence, indicating that this scene is likely in a public park or a similar outdoor area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.084, "power_cpu_cv_mean_watts": 1.852, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T11:11:17.668877"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8011.434, "latencies_ms": [8011.434], "images_per_second": 0.125, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image shows a person wrapped in an orange sleeping bag, lying on a wooden bench. The bench is situated in a grassy area with a wooden fence in the background and two parking meters are visible in the distance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24544.1, "ram_available_mb": 38296.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24544.3, "ram_available_mb": 38296.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.044, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 8.925}, "timestamp": "2026-01-23T11:11:27.712780"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11328.824, "latencies_ms": [11328.824], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a room with a white shelf displaying various vases and decorative items. The focal point is a large, colorful vase with a unique design, placed on the shelf. Surrounding the vase are several other vases of different sizes and shapes, as well as a few potted plants. \n\nIn addition to the vases and plants,", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24544.3, "ram_available_mb": 38296.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.611, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.847}, "timestamp": "2026-01-23T11:11:41.099432"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8336.603, "latencies_ms": [8336.603], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "Vase: 1\nPlants: 1\nLeaves: 1\nFlowers: 1\nStems: 1\nVases: 2\nCeramic art: 1\nPaper: 2", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24541.3, "ram_available_mb": 38299.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.175, "power_cpu_cv_mean_watts": 1.709, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T11:11:51.467864"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10452.183, "latencies_ms": [10452.183], "images_per_second": 0.096, "prompt_tokens": 44, "response_tokens_est": 71, "n_tiles": 16, "output_text": "The vase with dried flowers is in the foreground, placed on a white pedestal. To the right, there is a wall with various decorative items, including a circular object and a plaque with text. The vase is positioned closer to the viewer than the wall, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.045, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 8.833}, "timestamp": "2026-01-23T11:12:03.967583"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 11559.104, "latencies_ms": [11559.104], "images_per_second": 0.087, "prompt_tokens": 37, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image showcases a collection of vases and decorative items displayed on a shelf. The vases are of different shapes and sizes, with one being a tall, slender glass vase with a unique design, and another being a smaller, round glass vase. The decorative items include a vase with a bird design, a vase with a floral pattern, and a", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 24558.0, "ram_available_mb": 38282.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.716, "power_cpu_cv_mean_watts": 2.35, "power_sys_5v0_mean_watts": 8.825}, "timestamp": "2026-01-23T11:12:17.548488"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11364.986, "latencies_ms": [11364.986], "images_per_second": 0.088, "prompt_tokens": 36, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a vibrant and colorful display of various vases and decorative items. The vases are made of different materials, including ceramic and glass, and are adorned with various patterns and designs. The lighting in the image is bright and natural, highlighting the intricate details of the objects. The background is a warm orange color, which contrasts nicely", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24558.0, "ram_available_mb": 38282.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 24571.7, "ram_available_mb": 38269.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.721, "power_cpu_cv_mean_watts": 2.329, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T11:12:30.933897"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11346.771, "latencies_ms": [11346.771], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a skateboarder is performing a trick on a ramp at a skate park. The skateboarder is in the process of grinding the edge of the ramp with his skateboard, showcasing his skills and balance. The ramp is designed for skateboarders to perform various tricks and maneuvers.\n\nThere are several", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 24571.7, "ram_available_mb": 38269.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24553.3, "ram_available_mb": 38287.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.6, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 8.841}, "timestamp": "2026-01-23T11:12:44.324352"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11280.536, "latencies_ms": [11280.536], "images_per_second": 0.089, "prompt_tokens": 39, "response_tokens_est": 77, "n_tiles": 16, "output_text": "- Skateboard: 1\n- Skateboarder: 1\n- Skate park: 1\n- Concrete ramp: 1\n- Skateboard wheels: 4\n- Skateboard trucks: 4\n- Skateboard deck: 1\n- Skateboarder's shoes: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.3, "ram_available_mb": 38287.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24562.1, "ram_available_mb": 38278.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.855, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.824}, "timestamp": "2026-01-23T11:12:57.623877"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11341.147, "latencies_ms": [11341.147], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a skateboarder is captured in mid-air, performing a trick on a curved ramp. The skateboarder is positioned near the bottom of the ramp, which extends into the background of the image. There are other individuals in the background, likely spectators or other skateboarders, who are situated at various distances from the ramp", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24562.1, "ram_available_mb": 38278.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24560.0, "ram_available_mb": 38280.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.629, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.844}, "timestamp": "2026-01-23T11:13:11.017186"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8549.75, "latencies_ms": [8549.75], "images_per_second": 0.117, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "A skateboarder is performing a trick on a curved ramp at a skatepark. The skateboarder is wearing a white t-shirt, blue jeans, and a helmet with a colorful design on it.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24560.0, "ram_available_mb": 38280.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24571.3, "ram_available_mb": 38269.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.934, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.882}, "timestamp": "2026-01-23T11:13:21.589931"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8356.035, "latencies_ms": [8356.035], "images_per_second": 0.12, "prompt_tokens": 36, "response_tokens_est": 53, "n_tiles": 16, "output_text": "The skateboarder is wearing a white t-shirt and blue jeans, and the skateboard is black with blue and white designs. The skate park is made of concrete and the lighting is natural, likely from the sun.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24571.3, "ram_available_mb": 38269.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24554.5, "ram_available_mb": 38286.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.884, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 8.886}, "timestamp": "2026-01-23T11:13:31.958878"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11327.906, "latencies_ms": [11327.906], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a beautifully lit city square at night, featuring a large Christmas tree in the center. The tree is adorned with lights, creating a festive atmosphere. The square is surrounded by buildings, including a clock tower that stands out prominently in the scene.\n\nThere are several people walking around the square, enjoying the holiday ambiance. A few cars", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24554.5, "ram_available_mb": 38286.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.597, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T11:13:45.322331"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9215.409, "latencies_ms": [9215.409], "images_per_second": 0.109, "prompt_tokens": 39, "response_tokens_est": 59, "n_tiles": 16, "output_text": "- Clock tower: 1\n- Christmas tree: 1\n- Lights: multiple strings of lights\n- People: multiple individuals\n- Buildings: multiple buildings\n- Cars: 1\n- Trash can: 1\n- Signs: multiple signs", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.8, "ram_available_mb": 38294.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24557.2, "ram_available_mb": 38283.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.784, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T11:13:56.567243"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10310.573, "latencies_ms": [10310.573], "images_per_second": 0.097, "prompt_tokens": 44, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The large clock tower stands in the background, slightly to the left of the center of the image. In the foreground, there is a large Christmas tree decorated with blue lights on the right side of the image. The street in the middle ground is lined with buildings on both sides, and there are people walking along the sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24557.2, "ram_available_mb": 38283.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24552.3, "ram_available_mb": 38288.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.97, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T11:14:08.902424"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8640.617, "latencies_ms": [8640.617], "images_per_second": 0.116, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image depicts a festive city square at night, illuminated by string lights and adorned with a large Christmas tree. A prominent clock tower stands in the center, surrounded by buildings with lit windows, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24552.3, "ram_available_mb": 38288.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24556.3, "ram_available_mb": 38284.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.886, "power_cpu_cv_mean_watts": 1.761, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T11:14:19.601813"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8700.294, "latencies_ms": [8700.294], "images_per_second": 0.115, "prompt_tokens": 36, "response_tokens_est": 56, "n_tiles": 16, "output_text": "The image features a large, ornate clock tower in the center, adorned with twinkling Christmas lights that create a festive atmosphere. The tower is surrounded by a large, snow-covered Christmas tree, adding to the holiday charm of the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24556.3, "ram_available_mb": 38284.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.653, "power_cpu_cv_mean_watts": 1.78, "power_sys_5v0_mean_watts": 8.9}, "timestamp": "2026-01-23T11:14:30.328525"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11406.059, "latencies_ms": [11406.059], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young man is captured in the midst of a tennis match on a concrete court. He is dressed in a blue shirt and black shorts, and is holding a yellow tennis racket in his right hand. His left hand is extended, ready to strike the tennis ball that is suspended in the air above him. The court is enclosed by a black fence,", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24551.8, "ram_available_mb": 38289.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.519, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.81}, "timestamp": "2026-01-23T11:14:43.785969"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7754.229, "latencies_ms": [7754.229], "images_per_second": 0.129, "prompt_tokens": 39, "response_tokens_est": 46, "n_tiles": 16, "output_text": "boy: 1, tennis racket: 1, tennis ball: 1, tennis court: 1, fence: 1, trees: 1, sky: 1, shadows: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24554.6, "ram_available_mb": 38286.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.45, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 8.874}, "timestamp": "2026-01-23T11:14:53.579975"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11343.103, "latencies_ms": [11343.103], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The tennis player is positioned in the foreground on the left side of the image, preparing to hit the tennis ball that is in the air to the right of the player. The background consists of a chain-link fence and trees, indicating that the tennis court is likely located in a park or similar outdoor area. The player is near the baseline of the court, which is", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24555.1, "ram_available_mb": 38285.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.6, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T11:15:06.966621"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6828.713, "latencies_ms": [6828.713], "images_per_second": 0.146, "prompt_tokens": 37, "response_tokens_est": 38, "n_tiles": 16, "output_text": "A person is playing tennis on a court with a fence and trees in the background. The player is in the middle of a forehand swing, preparing to hit the ball.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24555.1, "ram_available_mb": 38285.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24547.9, "ram_available_mb": 38293.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.256, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T11:15:15.827712"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8448.338, "latencies_ms": [8448.338], "images_per_second": 0.118, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The image shows a person playing tennis on a court with a clear sky in the background, suggesting it might be a sunny day. The tennis player is wearing a blue shirt and black shorts, and the court has white lines marking the boundaries.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24547.9, "ram_available_mb": 38293.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.88, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 8.909}, "timestamp": "2026-01-23T11:15:26.290361"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11335.983, "latencies_ms": [11335.983], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a cozy living room with a fireplace as the focal point. The fireplace is surrounded by a white mantle, and there are two chairs placed in front of it. One chair is positioned on the left side of the fireplace, while the other is on the right side. \n\nIn addition to the chairs, there are two potted plants", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24548.0, "ram_available_mb": 38292.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.613, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.842}, "timestamp": "2026-01-23T11:15:39.646728"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9334.588, "latencies_ms": [9334.588], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 60, "n_tiles": 16, "output_text": "- Bookshelf: 100+ books\n- Picture frame: 1\n- Armchair: 1\n- End table: 2\n- Lamp: 2\n- Plant: 2\n- Fireplace: 1\n- Chair: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24548.0, "ram_available_mb": 38292.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24560.8, "ram_available_mb": 38280.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.721, "power_cpu_cv_mean_watts": 1.805, "power_sys_5v0_mean_watts": 8.867}, "timestamp": "2026-01-23T11:15:51.037329"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11337.202, "latencies_ms": [11337.202], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a white armchair positioned near the center of the image, with a lamp on a small wooden table to its left. Behind the armchair, a fireplace with a mantelpiece above it serves as a central focal point. To the right of the fireplace, there is a bookshelf filled with books, and further to", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24560.8, "ram_available_mb": 38280.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24547.9, "ram_available_mb": 38293.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.703, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.845}, "timestamp": "2026-01-23T11:16:04.405088"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8755.439, "latencies_ms": [8755.439], "images_per_second": 0.114, "prompt_tokens": 37, "response_tokens_est": 55, "n_tiles": 16, "output_text": "The image depicts a cozy living room with a fireplace, a chair, and a bookshelf filled with books. The room is furnished with a white sofa, a white armchair, and a small table with a lamp on it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24547.9, "ram_available_mb": 38293.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.803, "power_cpu_cv_mean_watts": 1.757, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T11:16:15.187545"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8468.725, "latencies_ms": [8468.725], "images_per_second": 0.118, "prompt_tokens": 36, "response_tokens_est": 54, "n_tiles": 16, "output_text": "The room is well-lit with natural light, and the walls are painted in a light color, giving it a bright and airy feel. The furniture is primarily white, with a mix of wood and leather materials, creating a classic and elegant atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24547.4, "ram_available_mb": 38293.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 24556.5, "ram_available_mb": 38284.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.815, "power_cpu_cv_mean_watts": 1.83, "power_sys_5v0_mean_watts": 8.885}, "timestamp": "2026-01-23T11:16:25.688926"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11337.34, "latencies_ms": [11337.34], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a group of three zebras is grazing in a grassy field. They are standing close to each other, with one zebra on the left side of the image, another in the middle, and the third one on the right side. The zebras are eating grass from the ground, and their distinctive black and white stripes are clearly visible.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 24556.5, "ram_available_mb": 38284.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 24648.0, "ram_available_mb": 38192.9, "ram_percent": 39.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.678, "power_cpu_cv_mean_watts": 2.386, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T11:16:39.068317"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6986.724, "latencies_ms": [6986.724], "images_per_second": 0.143, "prompt_tokens": 39, "response_tokens_est": 39, "n_tiles": 16, "output_text": "zebra: 3, grass: many, trees: sparse, sky: clear, dirt: patchy, sun: bright, shadows: visible, animals: 3", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24567.9, "ram_available_mb": 38273.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 24568.8, "ram_available_mb": 38272.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.008, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 8.909}, "timestamp": "2026-01-23T11:16:48.093181"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11149.06, "latencies_ms": [11149.06], "images_per_second": 0.09, "prompt_tokens": 44, "response_tokens_est": 77, "n_tiles": 16, "output_text": "In the foreground, there is a group of zebras with one partially obscured by the others. The zebra in the background is further away from the camera, making it appear smaller. The zebras are grazing on the grass, with one standing on the left side, another in the center, and the third on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24568.8, "ram_available_mb": 38272.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24572.4, "ram_available_mb": 38268.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.641, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T11:17:01.284608"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6687.388, "latencies_ms": [6687.388], "images_per_second": 0.15, "prompt_tokens": 37, "response_tokens_est": 37, "n_tiles": 16, "output_text": "Three zebras are grazing in a grassy field with dry grass and some bushes in the background. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24572.4, "ram_available_mb": 38268.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24559.7, "ram_available_mb": 38281.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.491, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.924}, "timestamp": "2026-01-23T11:17:10.030357"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6752.879, "latencies_ms": [6752.879], "images_per_second": 0.148, "prompt_tokens": 36, "response_tokens_est": 39, "n_tiles": 16, "output_text": "The zebras are grazing in a field with dry grass and sparse trees under a clear blue sky. The lighting is bright and natural, indicating it is a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24559.7, "ram_available_mb": 38281.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24570.7, "ram_available_mb": 38270.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.925, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.962}, "timestamp": "2026-01-23T11:17:18.798694"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11330.258, "latencies_ms": [11330.258], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of people sitting around a dining table in a restaurant. There are at least 13 people in the scene, with some sitting at the table and others standing or sitting at nearby tables. The dining area is furnished with multiple chairs, and the tables are adorned with cups, bowls, and bottles.\n\nThe restaurant has a", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24570.7, "ram_available_mb": 38270.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24573.2, "ram_available_mb": 38267.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.586, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.84}, "timestamp": "2026-01-23T11:17:32.185093"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8522.274, "latencies_ms": [8522.274], "images_per_second": 0.117, "prompt_tokens": 39, "response_tokens_est": 53, "n_tiles": 16, "output_text": "table: 1\nchairs: 4\npeople: 11\ncigars: 0\ncigarette butts: 0\nglasses: 0\nbottles: 0\ncash: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24573.2, "ram_available_mb": 38267.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24566.8, "ram_available_mb": 38274.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.187, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T11:17:42.740297"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11349.47, "latencies_ms": [11349.47], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a wooden table with several people seated around it, engaged in conversation. The table is surrounded by wooden chairs, and in the background, there are more people seated at other tables, as well as a bar area with a counter and shelves stocked with bottles. The room has a warm, inviting atmosphere with brick walls and hanging", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24566.8, "ram_available_mb": 38274.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24567.2, "ram_available_mb": 38273.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.611, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T11:17:56.108241"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7256.608, "latencies_ms": [7256.608], "images_per_second": 0.138, "prompt_tokens": 37, "response_tokens_est": 42, "n_tiles": 16, "output_text": "The image depicts a group of people, including two men in military uniforms, sitting around a wooden table in a restaurant. They appear to be engaged in a conversation or a meal together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24567.2, "ram_available_mb": 38273.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24555.2, "ram_available_mb": 38285.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.921, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.918}, "timestamp": "2026-01-23T11:18:05.412083"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7430.774, "latencies_ms": [7430.774], "images_per_second": 0.135, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image shows an indoor setting with warm lighting that highlights the wooden floors and furniture. The walls are adorned with brickwork, giving the space a rustic and cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24555.2, "ram_available_mb": 38285.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.49, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 8.94}, "timestamp": "2026-01-23T11:18:14.877398"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11352.816, "latencies_ms": [11352.816], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a group of white swans swimming in a body of water, possibly a lake or a pond. There are at least 13 swans in the scene, with some swimming close to the shore and others further away. The swans are spread out across the water, creating a beautiful and serene atmosphere.\n\nIn the background, there are several boats floating", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24556.9, "ram_available_mb": 38284.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24553.3, "ram_available_mb": 38287.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.564, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.816}, "timestamp": "2026-01-23T11:18:28.265616"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7050.309, "latencies_ms": [7050.309], "images_per_second": 0.142, "prompt_tokens": 39, "response_tokens_est": 40, "n_tiles": 16, "output_text": "swan: 14, boat: 12, water: many, sun: visible, marina: visible, birds: 14, water: many, sky: visible", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24553.3, "ram_available_mb": 38287.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24541.4, "ram_available_mb": 38299.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.043, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.903}, "timestamp": "2026-01-23T11:18:37.326657"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11323.136, "latencies_ms": [11323.136], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a group of white swans are swimming in the water, with some closer to the viewer and others further away. In the background, there are several boats docked at a marina, with some closer to the shore and others further out in the water. The swans are in the middle ground of the image, creating a sense of depth between the boats and", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 24541.4, "ram_available_mb": 38299.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.603, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T11:18:50.707664"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8077.741, "latencies_ms": [8077.741], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "A group of white swans are swimming in a body of water near a marina with several boats docked in the background. The scene is peaceful and serene, with the swans gracefully gliding through the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24542.1, "ram_available_mb": 38298.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24556.6, "ram_available_mb": 38284.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.249, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 8.868}, "timestamp": "2026-01-23T11:19:00.810636"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10913.117, "latencies_ms": [10913.117], "images_per_second": 0.092, "prompt_tokens": 36, "response_tokens_est": 75, "n_tiles": 16, "output_text": "The image features a serene scene with a group of white swans swimming in a body of water that reflects a purple hue, likely due to the lighting conditions. The water is calm, and the swans are scattered across the surface, with some closer to the foreground and others further away, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24556.6, "ram_available_mb": 38284.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24551.1, "ram_available_mb": 38289.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.703, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 8.835}, "timestamp": "2026-01-23T11:19:13.742407"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11339.9, "latencies_ms": [11339.9], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of joy and celebration, set against the backdrop of a beautifully decorated wedding venue. The room is adorned with a white canopy, from which a string of pink and green triangular flags hang, adding a touch of color to the otherwise monochrome setting. The floor, made of wood, adds a rustic charm to", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 24551.1, "ram_available_mb": 38289.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.537, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T11:19:27.132955"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8677.894, "latencies_ms": [8677.894], "images_per_second": 0.115, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "wedding cake: 1, guests: 2, triangular flags: 12, microphones: 2, musical instruments: 3, gift boxes: 2, tablecloths: 2, chairs: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24544.5, "ram_available_mb": 38296.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24534.8, "ram_available_mb": 38306.1, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.945, "power_cpu_cv_mean_watts": 1.759, "power_sys_5v0_mean_watts": 8.878}, "timestamp": "2026-01-23T11:19:37.842921"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11398.331, "latencies_ms": [11398.331], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, a couple is standing close together, with the woman in a white dress and the man in a suit, positioned near the center of the image. They are surrounded by a table with a white cloth and various items on it, which is located slightly to their right. In the background, there is a stage with musical equipment and a speaker, which is further away from the", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24534.8, "ram_available_mb": 38306.1, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24539.2, "ram_available_mb": 38301.7, "ram_percent": 39.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.645, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.841}, "timestamp": "2026-01-23T11:19:51.257438"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9290.991, "latencies_ms": [9290.991], "images_per_second": 0.108, "prompt_tokens": 37, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image captures a joyous moment at a wedding reception held in a large, elegantly decorated tent. A bride and groom are sharing a dance, surrounded by festive decorations and a band set up in the background, creating a warm and celebratory atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24539.2, "ram_available_mb": 38301.7, "ram_percent": 39.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.421, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.812}, "timestamp": "2026-01-23T11:20:02.580068"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10566.182, "latencies_ms": [10566.182], "images_per_second": 0.095, "prompt_tokens": 36, "response_tokens_est": 72, "n_tiles": 16, "output_text": "The image shows an indoor wedding reception with a large white tent-like ceiling, adorned with pink and green triangular bunting. The lighting is warm and ambient, with a mix of natural light coming from the windows and artificial light from the ceiling fixtures, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24554.2, "ram_available_mb": 38286.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.971, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T11:20:15.190582"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11358.013, "latencies_ms": [11358.013], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a cozy living room bathed in soft light. Dominating the scene is a blue sofa, its vibrant color contrasting beautifully with the red walls. The sofa is adorned with a white throw pillow, adding a touch of elegance to the room. \n\nTo the left of the sofa, a wooden coffee table stands,", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24554.2, "ram_available_mb": 38286.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 24552.1, "ram_available_mb": 38288.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.624, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T11:20:28.619661"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8317.318, "latencies_ms": [8317.318], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "- Couch: 1\n\n- Table: 2\n\n- Plant: 3\n\n- Picture: 2\n\n- Window: 2\n\n- Rug: 1\n\n- Lamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.1, "ram_available_mb": 38288.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.181, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 8.873}, "timestamp": "2026-01-23T11:20:38.958785"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11388.284, "latencies_ms": [11388.284], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the foreground, there is a blue sofa positioned against the wall, with a small wooden side table to its left. On the right side of the sofa, there is a round glass coffee table. In the background, there are two windows with white curtains; one is on the left side of the image and the other is on the right side. Above the so", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.622, "power_cpu_cv_mean_watts": 2.257, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T11:20:52.356192"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9140.126, "latencies_ms": [9140.126], "images_per_second": 0.109, "prompt_tokens": 37, "response_tokens_est": 58, "n_tiles": 16, "output_text": "The image depicts a cozy living room with a blue sofa, a small table with a lamp and a plant, and two windows with white curtains. The room has a warm and inviting atmosphere with a red wall and a colorful rug on the floor.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 24568.0, "ram_available_mb": 38272.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.745, "power_cpu_cv_mean_watts": 2.174, "power_sys_5v0_mean_watts": 8.862}, "timestamp": "2026-01-23T11:21:03.509055"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7788.039, "latencies_ms": [7788.039], "images_per_second": 0.128, "prompt_tokens": 36, "response_tokens_est": 48, "n_tiles": 16, "output_text": "The room has a warm and cozy atmosphere with red walls and a combination of natural and artificial lighting. The furniture includes a blue sofa, a wooden coffee table, and a round glass table with a plant on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24568.0, "ram_available_mb": 38272.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 24568.7, "ram_available_mb": 38272.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.365, "power_cpu_cv_mean_watts": 1.861, "power_sys_5v0_mean_watts": 8.947}, "timestamp": "2026-01-23T11:21:13.317061"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12542.644, "latencies_ms": [12542.644], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image presents a scene featuring a doll with long, flowing red hair and a white headband. The doll is positioned in the center of the image, with its head tilted slightly to the right. It is holding a book in its hands, which is open and resting on a wooden surface. The book appears to be a hardcover with a black cover and white pages.", "error": null, "sys_before": {"cpu_percent": 9.4, "ram_used_mb": 24568.7, "ram_available_mb": 38272.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24578.7, "ram_available_mb": 38262.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.835, "power_cpu_cv_mean_watts": 1.798, "power_sys_5v0_mean_watts": 9.099}, "timestamp": "2026-01-23T11:21:27.899632"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8466.929, "latencies_ms": [8466.929], "images_per_second": 0.118, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "doll: 1, clock: 2, book: 1, hair: 2, face: 1, eyes: 2, hands: 2, numbers: 12", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24578.7, "ram_available_mb": 38262.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 24579.0, "ram_available_mb": 38261.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.982, "power_cpu_cv_mean_watts": 1.44, "power_sys_5v0_mean_watts": 9.071}, "timestamp": "2026-01-23T11:21:38.427342"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11937.872, "latencies_ms": [11937.872], "images_per_second": 0.084, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "The clock is positioned to the left of the image, partially overlapping the figure on the right. The figure appears to be in the foreground, with the clock slightly behind it, creating a sense of depth. The background is a plain, light-colored surface that provides contrast to the darker tones of the figure and the clock.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24579.0, "ram_available_mb": 38261.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24582.3, "ram_available_mb": 38258.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.262, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 9.099}, "timestamp": "2026-01-23T11:21:52.418083"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 12877.489, "latencies_ms": [12877.489], "images_per_second": 0.078, "prompt_tokens": 37, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image depicts a whimsical scene with a doll sitting on a wooden surface, surrounded by two large clocks that are shaped like human heads. The doll has long red hair and is wearing a white headband, and the clocks have black numbers and hands. The background is a textured beige color, giving the impression of a dreamlike or surreal setting.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24582.3, "ram_available_mb": 38258.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24586.8, "ram_available_mb": 38254.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.145, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 9.015}, "timestamp": "2026-01-23T11:22:07.327232"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10648.687, "latencies_ms": [10648.687], "images_per_second": 0.094, "prompt_tokens": 36, "response_tokens_est": 62, "n_tiles": 16, "output_text": "The image features a doll with a warm, orange-toned hair and a clock with a yellow face and black numbers and hands. The doll is wearing a dark outfit with a white collar, and the clock is placed on a wooden surface with a shadow cast on the wall behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24586.8, "ram_available_mb": 38254.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24575.4, "ram_available_mb": 38265.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.677, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 9.128}, "timestamp": "2026-01-23T11:22:20.029110"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12322.515, "latencies_ms": [12322.515], "images_per_second": 0.081, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is sitting on a motorcycle, wearing a helmet and a tan jacket. He is holding a mirror in his hand, likely checking his reflection or looking for something. The motorcycle is parked, and there are other people in the background, possibly waiting or observing the scene.\n\nThere are two other motorcycles visible in the scene,", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 24575.4, "ram_available_mb": 38265.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24595.0, "ram_available_mb": 38245.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11579.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.693, "power_cpu_cv_mean_watts": 1.804, "power_sys_5v0_mean_watts": 9.027}, "timestamp": "2026-01-23T11:22:34.390120"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10535.063, "latencies_ms": [10535.063], "images_per_second": 0.095, "prompt_tokens": 39, "response_tokens_est": 61, "n_tiles": 16, "output_text": "- Helmet: 1\n\n- Motorcycle: 1\n\n- Mirror: 1\n\n- Man: 1\n\n- Pants: 1\n\n- Jacket: 1\n\n- Boot: 1\n\n- Seat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24595.0, "ram_available_mb": 38245.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11613.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.456, "power_cpu_cv_mean_watts": 1.647, "power_sys_5v0_mean_watts": 9.004}, "timestamp": "2026-01-23T11:22:46.951641"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 12289.318, "latencies_ms": [12289.318], "images_per_second": 0.081, "prompt_tokens": 44, "response_tokens_est": 80, "n_tiles": 16, "output_text": "The person is seated on a motorcycle, which is positioned in the foreground of the image. In the background, there are other individuals, one of whom is wearing a red helmet, suggesting a public or crowded space. The motorcycle and its rider are the main focus and are located near the bottom of the image, while the background figures are further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24560.7, "ram_available_mb": 38280.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24559.0, "ram_available_mb": 38281.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11624.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.683, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 9.059}, "timestamp": "2026-01-23T11:23:01.266294"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7998.327, "latencies_ms": [7998.327], "images_per_second": 0.125, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "A man is sitting on a motorcycle, wearing a helmet and holding onto the handlebars. He appears to be in a crowded area with other people and vehicles around him.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24559.0, "ram_available_mb": 38281.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 24561.6, "ram_available_mb": 38279.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11608.7, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.759, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 9.053}, "timestamp": "2026-01-23T11:23:11.308755"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 11970.921, "latencies_ms": [11970.921], "images_per_second": 0.084, "prompt_tokens": 36, "response_tokens_est": 76, "n_tiles": 16, "output_text": "The image shows a person wearing a light beige shirt and beige pants, sitting on a motorcycle. The motorcycle is predominantly white with red accents. The person is wearing a black helmet with a clear visor. The background is blurred, but it appears to be an outdoor setting with other people and vehicles.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24561.6, "ram_available_mb": 38279.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11606.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.758, "power_cpu_cv_mean_watts": 1.784, "power_sys_5v0_mean_watts": 9.058}, "timestamp": "2026-01-23T11:23:25.305312"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11344.666, "latencies_ms": [11344.666], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment in a kitchen where a large, freshly baked pizza is the star. The pizza, with its golden crust and a generous topping of melted cheese, is resting on a wooden table. The cheese is speckled with green herbs, adding a touch of color and hinting at the flavors within. ", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 24556.8, "ram_available_mb": 38284.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24560.1, "ram_available_mb": 38280.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.506, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T11:23:38.675371"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8316.798, "latencies_ms": [8316.798], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "pizza: 1\npiece: 1\ncheese: 1\ntomato sauce: 1\nbasil: 1\ngarlic: 1\nolive oil: 1\ndough: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24560.1, "ram_available_mb": 38280.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24555.8, "ram_available_mb": 38285.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.218, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T11:23:49.021775"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11351.557, "latencies_ms": [11351.557], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The pizza is positioned in the foreground of the image, occupying the majority of the space. It is placed on a wooden surface, which is in the middle ground of the image. In the background, there is a person's arm and a kitchen setting with various pots and pans, indicating that the pizza is likely being prepared or served in a restaurant or home kitchen", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24555.8, "ram_available_mb": 38285.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.733, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T11:24:02.410844"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10015.736, "latencies_ms": [10015.736], "images_per_second": 0.1, "prompt_tokens": 37, "response_tokens_est": 66, "n_tiles": 16, "output_text": "A large pizza with a golden-brown crust and melted cheese is being served by a person in a dark-colored shirt. The pizza is placed on a wooden table, and there are pots and pans in the background, suggesting a restaurant or pizzeria setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24546.3, "ram_available_mb": 38294.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.271, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 8.846}, "timestamp": "2026-01-23T11:24:14.456097"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7695.434, "latencies_ms": [7695.434], "images_per_second": 0.13, "prompt_tokens": 36, "response_tokens_est": 47, "n_tiles": 16, "output_text": "The pizza is topped with green herbs and melted cheese, with a golden-brown crust. The lighting in the image is dim, highlighting the pizza's texture and colors.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24560.9, "ram_available_mb": 38280.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24563.6, "ram_available_mb": 38277.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.494, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 8.927}, "timestamp": "2026-01-23T11:24:24.168126"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11315.588, "latencies_ms": [11315.588], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a female tennis player is captured in the midst of a powerful serve on a grass court. She is dressed in a white tennis outfit, complete with a white visor and a white cap, providing protection from the sun. The tennis racket she wields is blue and white, contrasting with the green of the grass court. Her right arm is extended upwards,", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24563.6, "ram_available_mb": 38277.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24551.6, "ram_available_mb": 38289.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.615, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.857}, "timestamp": "2026-01-23T11:24:37.530213"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8338.634, "latencies_ms": [8338.634], "images_per_second": 0.12, "prompt_tokens": 39, "response_tokens_est": 51, "n_tiles": 16, "output_text": "tennis player: 1\ntennis racket: 1\nnet: 1\ngrass court: 1\nwhite dress: 1\nwhite shoes: 1\nwater bottle: 1\nshadow: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24551.6, "ram_available_mb": 38289.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24562.0, "ram_available_mb": 38278.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.228, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T11:24:47.886472"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11403.607, "latencies_ms": [11403.607], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 79, "n_tiles": 16, "output_text": "In the foreground, a tennis player is positioned on the court, with her right arm raised high above her head, holding a tennis racket in her left hand. The net is visible in the background, stretching across the middle of the image. The court itself appears to be a lush green, indicating it is well-maintained and likely a professional tennis court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24562.0, "ram_available_mb": 38278.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 24553.8, "ram_available_mb": 38287.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.623, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T11:25:01.351825"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6965.893, "latencies_ms": [6965.893], "images_per_second": 0.144, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "A tennis player in a white dress is captured in a dynamic pose on a grass court, holding a tennis racket and wearing a visor, likely during a match or practice session.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24553.8, "ram_available_mb": 38287.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.104, "power_cpu_cv_mean_watts": 2.023, "power_sys_5v0_mean_watts": 8.916}, "timestamp": "2026-01-23T11:25:10.332673"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6188.55, "latencies_ms": [6188.55], "images_per_second": 0.162, "prompt_tokens": 36, "response_tokens_est": 34, "n_tiles": 16, "output_text": "The tennis player is wearing a white dress and is on a grass court. The lighting appears to be natural sunlight, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24561.9, "ram_available_mb": 38279.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 24564.2, "ram_available_mb": 38276.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.946, "power_cpu_cv_mean_watts": 2.126, "power_sys_5v0_mean_watts": 9.054}, "timestamp": "2026-01-23T11:25:18.583499"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11359.525, "latencies_ms": [11359.525], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a serene and well-organized bathroom. Dominating the left side of the frame is a pristine white toilet, its lid closed, standing against a wall painted in a soothing shade of yellow. Above it, a black towel hangs neatly, ready for use. \n\nOn the right, a white shower cur", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 24564.2, "ram_available_mb": 38276.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 24570.1, "ram_available_mb": 38270.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.592, "power_cpu_cv_mean_watts": 2.18, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T11:25:31.966358"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8647.557, "latencies_ms": [8647.557], "images_per_second": 0.116, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "toilet: 1, towel: 2, shower curtain: 1, toilet paper: 1, shelves: 4, towels: 2, bed: 1, closet: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24570.1, "ram_available_mb": 38270.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24571.8, "ram_available_mb": 38269.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.064, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 8.864}, "timestamp": "2026-01-23T11:25:42.629625"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9623.651, "latencies_ms": [9623.651], "images_per_second": 0.104, "prompt_tokens": 44, "response_tokens_est": 64, "n_tiles": 16, "output_text": "The toilet is located in the foreground on the left side of the image, while the shelves with folded towels are in the background on the right side. The shower curtain is hanging in the middle ground, separating the toilet area from the storage area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24571.8, "ram_available_mb": 38269.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24569.0, "ram_available_mb": 38271.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.238, "power_cpu_cv_mean_watts": 1.841, "power_sys_5v0_mean_watts": 8.881}, "timestamp": "2026-01-23T11:25:54.294654"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8334.053, "latencies_ms": [8334.053], "images_per_second": 0.12, "prompt_tokens": 37, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows a small, compact bathroom with a white toilet on the left side and a white shelving unit on the right side. The shelves are empty, and there is a towel hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24569.0, "ram_available_mb": 38271.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24554.6, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.016, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 8.861}, "timestamp": "2026-01-23T11:26:04.664905"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6983.272, "latencies_ms": [6983.272], "images_per_second": 0.143, "prompt_tokens": 36, "response_tokens_est": 41, "n_tiles": 16, "output_text": "The image shows a bathroom with a white toilet and a white door. The walls are painted in a light yellow color, and there is a brown towel hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24554.6, "ram_available_mb": 38286.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24555.6, "ram_available_mb": 38285.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.762, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.944}, "timestamp": "2026-01-23T11:26:13.708865"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11349.943, "latencies_ms": [11349.943], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man and a woman are standing close to each other, holding wine glasses and smiling. They appear to be enjoying a glass of wine together. The woman is wearing glasses, and they both seem to be in a happy and relaxed mood.\n\nThe scene also includes a dining table with a few chairs around it. There are additional", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 24555.6, "ram_available_mb": 38285.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24556.3, "ram_available_mb": 38284.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.62, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.838}, "timestamp": "2026-01-23T11:26:27.085681"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8759.755, "latencies_ms": [8759.755], "images_per_second": 0.114, "prompt_tokens": 39, "response_tokens_est": 55, "n_tiles": 16, "output_text": "- People: 3\n- Wine glasses: 2\n- Table: 1\n- Papers: 2\n- Chair: 1\n- Window: 1\n- Outdoor view: 1\n- Grill: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24556.3, "ram_available_mb": 38284.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24554.4, "ram_available_mb": 38286.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.933, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 8.849}, "timestamp": "2026-01-23T11:26:37.885261"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9290.061, "latencies_ms": [9290.061], "images_per_second": 0.108, "prompt_tokens": 44, "response_tokens_est": 61, "n_tiles": 16, "output_text": "In the foreground, a person in a green shirt is holding a glass of red wine up to the camera, with another person in a blue shirt partially visible in the background. The person in the green shirt is standing closer to the camera than the person in the blue shirt.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24554.4, "ram_available_mb": 38286.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24558.7, "ram_available_mb": 38282.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.414, "power_cpu_cv_mean_watts": 1.825, "power_sys_5v0_mean_watts": 8.887}, "timestamp": "2026-01-23T11:26:49.193759"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8083.615, "latencies_ms": [8083.615], "images_per_second": 0.124, "prompt_tokens": 37, "response_tokens_est": 49, "n_tiles": 16, "output_text": "In the image, a man and a woman are standing in a room with a dining table and chairs. They are holding up wine glasses and smiling, suggesting that they are enjoying a social gathering or celebration.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24558.7, "ram_available_mb": 38282.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24549.0, "ram_available_mb": 38291.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.212, "power_cpu_cv_mean_watts": 1.701, "power_sys_5v0_mean_watts": 8.869}, "timestamp": "2026-01-23T11:26:59.322389"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9287.301, "latencies_ms": [9287.301], "images_per_second": 0.108, "prompt_tokens": 36, "response_tokens_est": 61, "n_tiles": 16, "output_text": "The image shows two individuals holding up wine glasses, with a bright and natural light coming from the window in the background. The room has a casual and relaxed atmosphere, with a green t-shirt and a black t-shirt visible, and a metal container on the table.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24549.0, "ram_available_mb": 38291.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 24564.7, "ram_available_mb": 38276.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.418, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 8.872}, "timestamp": "2026-01-23T11:27:10.654280"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11334.138, "latencies_ms": [11334.138], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a surfer is skillfully riding a wave on a sunny day. The surfer is wearing a black wetsuit and is positioned on a white surfboard. The wave, a beautiful shade of green, is curling over the surfer, creating a tunnel-like effect. The surfer is crouched down on the surfboard", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 24564.7, "ram_available_mb": 38276.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24557.1, "ram_available_mb": 38283.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.517, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.841}, "timestamp": "2026-01-23T11:27:24.032646"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8095.813, "latencies_ms": [8095.813], "images_per_second": 0.124, "prompt_tokens": 39, "response_tokens_est": 49, "n_tiles": 16, "output_text": "wave: 1\nsurfboard: 1\nsurfer: 1\nwater: 1\nsand: 1\nsky: 1\nbathing suits: 1\nbeach: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24557.1, "ram_available_mb": 38283.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24564.3, "ram_available_mb": 38276.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.423, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 8.87}, "timestamp": "2026-01-23T11:27:34.152323"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11331.635, "latencies_ms": [11331.635], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 80, "n_tiles": 16, "output_text": "The surfer is positioned in the foreground, riding a wave that is curling over to the right side of the image. The wave is the main object, and it appears to be near the surfer, who is in the water. In the background, there is a sandy beach and a clear sky, which are farther away from the surfer compared to the wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24564.3, "ram_available_mb": 38276.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24555.0, "ram_available_mb": 38285.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.64, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T11:27:47.507907"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7278.278, "latencies_ms": [7278.278], "images_per_second": 0.137, "prompt_tokens": 37, "response_tokens_est": 42, "n_tiles": 16, "output_text": "A surfer is skillfully riding a large wave in the ocean, showcasing their expertise and balance. The wave is curling over the surfer, creating a beautiful and dynamic scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24555.0, "ram_available_mb": 38285.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24550.9, "ram_available_mb": 38290.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.796, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.893}, "timestamp": "2026-01-23T11:27:56.814428"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6643.622, "latencies_ms": [6643.622], "images_per_second": 0.151, "prompt_tokens": 36, "response_tokens_est": 38, "n_tiles": 16, "output_text": "The surfer is riding a wave with a clear blue sky in the background. The water is a beautiful shade of green and the wave is creating a tunnel-like effect.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24550.9, "ram_available_mb": 38290.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.08, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.975}, "timestamp": "2026-01-23T11:28:05.483432"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11333.491, "latencies_ms": [11333.491], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image features a wooden table with a backpack and several laptops placed on it. The backpack is positioned on the left side of the table, while the laptops are spread out across the table, with some closer to the backpack and others further away. The arrangement of the laptops and the backpack suggests that the person might be working on a project or prepar", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 24549.2, "ram_available_mb": 38291.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.558, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 8.837}, "timestamp": "2026-01-23T11:28:18.854249"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9567.885, "latencies_ms": [9567.885], "images_per_second": 0.105, "prompt_tokens": 39, "response_tokens_est": 62, "n_tiles": 16, "output_text": "- Laptop: 4\n- Backpack: 1\n- Wires: 1\n- Laptop charger: 1\n- Laptop mouse: 1\n- Laptop keyboard: 1\n- Laptop screen: 1\n- Laptop battery: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 24551.9, "ram_available_mb": 38289.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24554.9, "ram_available_mb": 38286.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.458, "power_cpu_cv_mean_watts": 1.8, "power_sys_5v0_mean_watts": 8.823}, "timestamp": "2026-01-23T11:28:30.481221"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11334.018, "latencies_ms": [11334.018], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 80, "n_tiles": 16, "output_text": "In the foreground, there is a red and black backpack placed on a wooden table. Behind the backpack, there are several laptops of different sizes and colors, with the largest one in the background and the smallest one in the foreground. Additionally, there are multiple cords scattered around the table, with some near the laptops and others near the backpack.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24554.9, "ram_available_mb": 38286.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24551.7, "ram_available_mb": 38289.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.625, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.854}, "timestamp": "2026-01-23T11:28:43.831074"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10484.327, "latencies_ms": [10484.327], "images_per_second": 0.095, "prompt_tokens": 37, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The image shows a collection of laptops and a backpack placed on a wooden table. The laptops are of different sizes and brands, and they are arranged in a disorganized manner. The backpack is placed in front of the laptops, and there are multiple cords and cables scattered around the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24551.7, "ram_available_mb": 38289.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.992, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 8.823}, "timestamp": "2026-01-23T11:28:56.372491"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8131.05, "latencies_ms": [8131.05], "images_per_second": 0.123, "prompt_tokens": 36, "response_tokens_est": 51, "n_tiles": 16, "output_text": "The image shows a collection of laptops on a wooden table, with one laptop open and displaying a green screen. There is a backpack with a red and black color scheme on the table, and various cables and chargers scattered around.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.6, "ram_available_mb": 38290.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 24557.2, "ram_available_mb": 38283.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.982, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.897}, "timestamp": "2026-01-23T11:29:06.545980"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11337.722, "latencies_ms": [11337.722], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a skier is captured in mid-air, performing a daring jump. The skier, clad in a vibrant red jacket and black pants, is holding ski poles and is in the process of executing a flip. The skis, adorned with yellow and black designs, are clearly visible beneath the skier's feet. The", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 24557.2, "ram_available_mb": 38283.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.581, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.829}, "timestamp": "2026-01-23T11:29:19.935986"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7165.778, "latencies_ms": [7165.778], "images_per_second": 0.14, "prompt_tokens": 39, "response_tokens_est": 41, "n_tiles": 16, "output_text": "person: 1, ski: 2, snow: 1, mountain: 1, sky: 1, snowboard: 1, snow: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.0, "ram_available_mb": 38290.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 24550.8, "ram_available_mb": 38290.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.271, "power_cpu_cv_mean_watts": 1.982, "power_sys_5v0_mean_watts": 8.949}, "timestamp": "2026-01-23T11:29:29.116770"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10808.019, "latencies_ms": [10808.019], "images_per_second": 0.093, "prompt_tokens": 44, "response_tokens_est": 75, "n_tiles": 16, "output_text": "In the foreground, there is a skier in mid-air, performing a jump with their skis crossed. They are positioned above the snowy slope, indicating they have launched off a jump. In the background, another person is standing on the slope, appearing much smaller due to the distance, and is likely waiting for their turn or watching the performance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24550.8, "ram_available_mb": 38290.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 24571.3, "ram_available_mb": 38269.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.025, "power_cpu_cv_mean_watts": 2.385, "power_sys_5v0_mean_watts": 8.944}, "timestamp": "2026-01-23T11:29:41.958211"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6476.678, "latencies_ms": [6476.678], "images_per_second": 0.154, "prompt_tokens": 37, "response_tokens_est": 35, "n_tiles": 16, "output_text": "A skier in a bright orange suit is performing a jump in the air above a snowy slope. In the background, another person is skiing down the slope.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 24571.3, "ram_available_mb": 38269.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 24573.8, "ram_available_mb": 38267.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.748, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 8.96}, "timestamp": "2026-01-23T11:29:50.474660"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7423.191, "latencies_ms": [7423.191], "images_per_second": 0.135, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The skier is wearing a bright orange suit and a green helmet, contrasting against the clear blue sky. The snow appears pristine and untouched, indicating fresh powder conditions for skiing.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24573.8, "ram_available_mb": 38267.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24559.6, "ram_available_mb": 38281.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.538, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.932}, "timestamp": "2026-01-23T11:29:59.917234"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11318.363, "latencies_ms": [11318.363], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a small bird is perched on a window sill, looking out at a body of water. The bird appears to be a pigeon, and it is positioned on the left side of the window. The window itself is rectangular and has a white frame. The view outside the window shows a calm body of water, possibly a lake or a river, with a", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 24559.6, "ram_available_mb": 38281.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24569.4, "ram_available_mb": 38271.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.615, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.848}, "timestamp": "2026-01-23T11:30:13.286204"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9367.098, "latencies_ms": [9367.098], "images_per_second": 0.107, "prompt_tokens": 39, "response_tokens_est": 60, "n_tiles": 16, "output_text": "1. Window: 1\n2. Seat: 1\n3. Bird: 1\n4. Water: 1\n5. Trees: 1\n6. Snow: 1\n7. Ground: 1\n8. Sky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24569.4, "ram_available_mb": 38271.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24564.0, "ram_available_mb": 38276.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.587, "power_cpu_cv_mean_watts": 1.779, "power_sys_5v0_mean_watts": 8.817}, "timestamp": "2026-01-23T11:30:24.694019"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10583.201, "latencies_ms": [10583.201], "images_per_second": 0.094, "prompt_tokens": 44, "response_tokens_est": 72, "n_tiles": 16, "output_text": "The image shows a bird in the foreground, perched on what appears to be a window ledge. The bird is facing towards the left side of the image, where a body of water is visible in the background. The window frame is rusted and has a handle on the right side, suggesting it may be an old or neglected structure.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24564.0, "ram_available_mb": 38276.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24563.5, "ram_available_mb": 38277.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.003, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T11:30:37.293504"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6951.227, "latencies_ms": [6951.227], "images_per_second": 0.144, "prompt_tokens": 37, "response_tokens_est": 39, "n_tiles": 16, "output_text": "A bird is perched on the edge of a window frame, looking out at a body of water. The window appears to be old and weathered, with peeling paint and rust.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24563.5, "ram_available_mb": 38277.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.328, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 8.925}, "timestamp": "2026-01-23T11:30:46.278638"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8065.511, "latencies_ms": [8065.511], "images_per_second": 0.124, "prompt_tokens": 36, "response_tokens_est": 50, "n_tiles": 16, "output_text": "The image shows a small bird perched on a window ledge, looking out at a body of water. The window is old and rusted, with a handle on the right side, and the surrounding area is dark and dimly lit.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24552.9, "ram_available_mb": 38288.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24555.0, "ram_available_mb": 38285.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.266, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 8.913}, "timestamp": "2026-01-23T11:30:56.369448"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11330.339, "latencies_ms": [11330.339], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is seen in a bathroom, standing next to a toilet. He is wearing a red hat and a gray shirt. The bathroom is equipped with a white toilet, a white trash can, and a white bucket. The man appears to be in the process of cleaning the toilet. The bathroom is well-", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 24555.0, "ram_available_mb": 38285.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24558.6, "ram_available_mb": 38282.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.625, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T11:31:09.762085"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8700.313, "latencies_ms": [8700.313], "images_per_second": 0.115, "prompt_tokens": 39, "response_tokens_est": 54, "n_tiles": 16, "output_text": "toilet: 1, trash bag: 1, paint can: 1, paintbrush: 1, paint roller: 1, paint tray: 1, paint bottle: 1, paint container: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24558.6, "ram_available_mb": 38282.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24551.4, "ram_available_mb": 38289.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.092, "power_cpu_cv_mean_watts": 1.734, "power_sys_5v0_mean_watts": 8.859}, "timestamp": "2026-01-23T11:31:20.479097"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10816.719, "latencies_ms": [10816.719], "images_per_second": 0.092, "prompt_tokens": 44, "response_tokens_est": 74, "n_tiles": 16, "output_text": "In the foreground, there is a toilet with a black trash bag in front of it, indicating recent use. In the background, there is a person bending over near the toilet, possibly engaged in cleaning or maintenance. The person is closer to the camera than the toilet, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24551.4, "ram_available_mb": 38289.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.867, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T11:31:33.329667"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7758.775, "latencies_ms": [7758.775], "images_per_second": 0.129, "prompt_tokens": 37, "response_tokens_est": 46, "n_tiles": 16, "output_text": "In a small, cluttered bathroom, a man is seen bending over a toilet, seemingly in the process of fixing or cleaning it. Another man is standing nearby, observing the situation.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24547.0, "ram_available_mb": 38293.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 24556.2, "ram_available_mb": 38284.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.637, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 8.871}, "timestamp": "2026-01-23T11:31:43.106713"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8290.727, "latencies_ms": [8290.727], "images_per_second": 0.121, "prompt_tokens": 36, "response_tokens_est": 52, "n_tiles": 16, "output_text": "The image is taken indoors with artificial lighting, and the colors are muted with a predominance of browns and whites. The floor is covered with a blue tarp, and there are various cleaning supplies and containers scattered around.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24556.2, "ram_available_mb": 38284.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24552.1, "ram_available_mb": 38288.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.093, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 8.905}, "timestamp": "2026-01-23T11:31:53.454983"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11332.96, "latencies_ms": [11332.96], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a person is standing in a hallway, holding an umbrella to protect themselves from the rain. The person is wearing a blue jacket and is positioned in the center of the scene. The hallway is narrow, with red walls on both sides. There are two doors visible in the image, one on the left and one on the right. The person appears", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 24552.1, "ram_available_mb": 38288.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.583, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.853}, "timestamp": "2026-01-23T11:32:06.820156"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9845.728, "latencies_ms": [9845.728], "images_per_second": 0.102, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "1. Umbrella: 1\n2. Person: 1\n3. Door: 2\n4. Wall: 2\n5. Rain: 1\n6. Light fixture: 1\n7. Mirror: 1\n8. Picture frame: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 24559.1, "ram_available_mb": 38281.8, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 24552.8, "ram_available_mb": 38288.1, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.347, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 8.826}, "timestamp": "2026-01-23T11:32:18.688750"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11377.297, "latencies_ms": [11377.297], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The person is standing in the foreground, holding an umbrella above their head. The umbrella is positioned in the upper left corner of the image, providing cover from the rain. The background consists of a red wall with a framed picture hanging on it, and a door to the left of the person. The person appears to be standing in a doorway or hallway", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24552.8, "ram_available_mb": 38288.1, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24555.0, "ram_available_mb": 38285.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.61, "power_cpu_cv_mean_watts": 1.92, "power_sys_5v0_mean_watts": 8.839}, "timestamp": "2026-01-23T11:32:32.106505"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8687.864, "latencies_ms": [8687.864], "images_per_second": 0.115, "prompt_tokens": 37, "response_tokens_est": 54, "n_tiles": 16, "output_text": "A person is standing in a hallway, holding an umbrella with the words \"Capsa Mo\" written on it, suggesting that it is raining. The person is wearing a blue jacket and appears to be walking through the hallway.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 24555.0, "ram_available_mb": 38285.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 24545.4, "ram_available_mb": 38295.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.047, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T11:32:42.812095"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10906.557, "latencies_ms": [10906.557], "images_per_second": 0.092, "prompt_tokens": 36, "response_tokens_est": 75, "n_tiles": 16, "output_text": "The image depicts a person standing under a black umbrella with the words \"Sopas Moni\" written on it, in a corridor with red walls and a reflective floor. The lighting is dim, with a mix of natural light coming from the doorway and artificial light reflecting off the walls, creating a moody atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24545.4, "ram_available_mb": 38295.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24541.6, "ram_available_mb": 38299.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.829, "power_cpu_cv_mean_watts": 1.903, "power_sys_5v0_mean_watts": 8.851}, "timestamp": "2026-01-23T11:32:55.776037"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11455.111, "latencies_ms": [11455.111], "images_per_second": 0.087, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a man is standing in front of a wooden gate with a sign that has Chinese characters on it. He is wearing a red shirt and a backpack, and is holding a walking stick. The gate is located in a garden with a stone pathway and a stone wall. There are trees and bushes in the background, and a person in a yellow robe is", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 24541.6, "ram_available_mb": 38299.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.421, "power_cpu_cv_mean_watts": 1.94, "power_sys_5v0_mean_watts": 8.798}, "timestamp": "2026-01-23T11:33:09.286390"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7620.037, "latencies_ms": [7620.037], "images_per_second": 0.131, "prompt_tokens": 39, "response_tokens_est": 45, "n_tiles": 16, "output_text": "person: 2, rock: 10, sign: 1, staircase: 1, railing: 1, plant: 5, path: 1, backpack: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 24549.5, "ram_available_mb": 38291.4, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24555.6, "ram_available_mb": 38285.3, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.672, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 8.891}, "timestamp": "2026-01-23T11:33:18.966772"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10693.778, "latencies_ms": [10693.778], "images_per_second": 0.094, "prompt_tokens": 44, "response_tokens_est": 73, "n_tiles": 16, "output_text": "In the foreground, there is a person with a backpack standing on a gravel path, looking upwards. Behind this individual, there is a wooden railing with a person in a yellow robe standing on a higher platform to the left. The background is filled with lush greenery and a signpost with multiple directional arrows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24555.6, "ram_available_mb": 38285.3, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10660.0, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.709, "power_cpu_cv_mean_watts": 1.908, "power_sys_5v0_mean_watts": 8.85}, "timestamp": "2026-01-23T11:33:31.679768"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 10246.431, "latencies_ms": [10246.431], "images_per_second": 0.098, "prompt_tokens": 37, "response_tokens_est": 68, "n_tiles": 16, "output_text": "The image depicts a serene outdoor setting with a man in a red shirt and backpack standing on a gravel path, looking up at a signpost with various directions. In the background, there is a person dressed in a yellow robe, possibly a monk, standing on a wooden bridge or platform.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24553.9, "ram_available_mb": 38287.0, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 24561.7, "ram_available_mb": 38279.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10645.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.155, "power_cpu_cv_mean_watts": 1.841, "power_sys_5v0_mean_watts": 8.828}, "timestamp": "2026-01-23T11:33:43.971851"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 10307.699, "latencies_ms": [10307.699], "images_per_second": 0.097, "prompt_tokens": 36, "response_tokens_est": 70, "n_tiles": 16, "output_text": "The image depicts a scene with a person in a yellow robe standing on a wooden bridge with a railing, and another person in a red shirt with a backpack and trekking pole standing on the ground below. The environment is lush with greenery, and the lighting suggests it is taken during the day.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 24561.7, "ram_available_mb": 38279.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 24564.2, "ram_available_mb": 38276.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.971, "power_cpu_cv_mean_watts": 2.326, "power_sys_5v0_mean_watts": 8.924}, "timestamp": "2026-01-23T11:33:56.294223"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 12562.781, "latencies_ms": [12562.781], "images_per_second": 0.08, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a moment of camaraderie among four men in a room that exudes a casual, possibly social atmosphere. The man on the far left, clad in a white shirt and khaki pants, stands with a relaxed posture. Next to him, the man in the center sports a red tie and a white shirt, his smile suggesting a", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 24563.0, "ram_available_mb": 38277.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 24600.2, "ram_available_mb": 38240.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11882.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.784, "power_cpu_cv_mean_watts": 2.099, "power_sys_5v0_mean_watts": 9.08}, "timestamp": "2026-01-23T11:34:10.910224"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 11114.276, "latencies_ms": [11114.276], "images_per_second": 0.09, "prompt_tokens": 39, "response_tokens_est": 64, "n_tiles": 16, "output_text": "- Chair: 2\n\n- Table: 1\n\n- Bottle: 10\n\n- Glass: 5\n\n- Armchair: 1\n\n- Jacket: 1\n\n- Shirt: 4\n\n- Suit: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24600.2, "ram_available_mb": 38240.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 24588.7, "ram_available_mb": 38252.2, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11917.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.632, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 9.043}, "timestamp": "2026-01-23T11:34:24.043310"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11258.639, "latencies_ms": [11258.639], "images_per_second": 0.089, "prompt_tokens": 44, "response_tokens_est": 67, "n_tiles": 16, "output_text": "In the foreground, there are four individuals standing close together, with one person slightly in front of the others, creating a sense of depth. In the background, there is a bar area with a counter and bottles, which appears smaller due to the perspective, indicating it is further away from the viewpoint of the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24588.7, "ram_available_mb": 38252.2, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 24585.0, "ram_available_mb": 38255.9, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11927.9, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.343, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 9.09}, "timestamp": "2026-01-23T11:34:37.354620"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9869.269, "latencies_ms": [9869.269], "images_per_second": 0.101, "prompt_tokens": 37, "response_tokens_est": 53, "n_tiles": 16, "output_text": "Four men are standing together in a room that appears to be a bar or a similar social setting, with a bar counter and bottles visible in the background. They are all dressed in business casual attire and seem to be posing for a photo.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24585.0, "ram_available_mb": 38255.9, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24582.2, "ram_available_mb": 38258.7, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11911.5, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.07, "power_cpu_cv_mean_watts": 1.559, "power_sys_5v0_mean_watts": 9.05}, "timestamp": "2026-01-23T11:34:49.249288"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8644.395, "latencies_ms": [8644.395], "images_per_second": 0.116, "prompt_tokens": 36, "response_tokens_est": 45, "n_tiles": 16, "output_text": "The image shows four individuals standing indoors with a warm and soft lighting that suggests an indoor setting. The walls are painted in a light color, and there is a red accent wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 24582.2, "ram_available_mb": 38258.7, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 24583.3, "ram_available_mb": 38257.6, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 11909.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.788, "power_cpu_cv_mean_watts": 1.514, "power_sys_5v0_mean_watts": 9.167}, "timestamp": "2026-01-23T11:34:59.934813"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11406.558, "latencies_ms": [11406.558], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "The image captures a vibrant street scene in what appears to be a European city. The street is bustling with activity, with cars and buses moving along the road. The buildings lining the street are a mix of brick and stone, painted in a variety of colors, adding to the charm of the scene. The sky overhead is overcast, casting a soft light over the", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 24583.3, "ram_available_mb": 38257.6, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 24556.4, "ram_available_mb": 38284.5, "ram_percent": 39.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10643.6, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.502, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.803}, "timestamp": "2026-01-23T11:35:13.385875"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10007.482, "latencies_ms": [10007.482], "images_per_second": 0.1, "prompt_tokens": 39, "response_tokens_est": 65, "n_tiles": 16, "output_text": "- Buildings: 10\n\n- Cars: 4\n\n- Traffic lights: 1\n\n- Signs: 1\n\n- Pole: 1\n\n- Tree: 0\n\n- Pedestrians: 2\n\n- Bus: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 24556.4, "ram_available_mb": 38284.5, "ram_percent": 39.1}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 24697.0, "ram_available_mb": 38143.9, "ram_percent": 39.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10673.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.182, "power_cpu_cv_mean_watts": 1.905, "power_sys_5v0_mean_watts": 8.797}, "timestamp": "2026-01-23T11:35:25.406269"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 11327.01, "latencies_ms": [11327.01], "images_per_second": 0.088, "prompt_tokens": 44, "response_tokens_est": 74, "n_tiles": 16, "output_text": "In the foreground, there is a yellow sign mounted on a black pole, positioned on the right side of the image. The background features a street scene with buildings on the left, a red traffic light in the middle distance, and vehicles on the road. The sign is near the curb, and the pole appears to be damaged at the base.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 24697.0, "ram_available_mb": 38143.9, "ram_percent": 39.3}, "sys_after": {"cpu_percent": 31.7, "ram_used_mb": 25388.1, "ram_available_mb": 37452.8, "ram_percent": 40.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10683.1, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.631, "power_cpu_cv_mean_watts": 5.767, "power_sys_5v0_mean_watts": 8.973}, "timestamp": "2026-01-23T11:35:38.792532"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9294.811, "latencies_ms": [9294.811], "images_per_second": 0.108, "prompt_tokens": 37, "response_tokens_est": 59, "n_tiles": 16, "output_text": "The image depicts a city street scene with a yellow sign mounted on a pole, which appears to be damaged and leaning to one side. The street is busy with various vehicles, including cars and buses, and there are buildings on both sides, suggesting an urban environment.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 25388.1, "ram_available_mb": 37452.8, "ram_percent": 40.4}, "sys_after": {"cpu_percent": 14.0, "ram_used_mb": 25453.2, "ram_available_mb": 37387.7, "ram_percent": 40.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10669.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.622, "power_cpu_cv_mean_watts": 3.69, "power_sys_5v0_mean_watts": 8.901}, "timestamp": "2026-01-23T11:35:50.105863"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6926.508, "latencies_ms": [6926.508], "images_per_second": 0.144, "prompt_tokens": 36, "response_tokens_est": 40, "n_tiles": 16, "output_text": "The image shows a street scene with a yellow sign mounted on a black pole. The weather appears to be overcast with a cloudy sky, and the street is wet, suggesting recent rain.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 25453.2, "ram_available_mb": 37387.7, "ram_percent": 40.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 25452.9, "ram_available_mb": 37388.0, "ram_percent": 40.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10667.3, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.025, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.956}, "timestamp": "2026-01-23T11:35:59.072174"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Describe this image in detail.", "latency_ms": 11349.042, "latencies_ms": [11349.042], "images_per_second": 0.088, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 16, "output_text": "In the image, a young man is standing on a tennis court, holding a tennis racket and preparing to hit a tennis ball. He is wearing a white shirt and black shorts. The court is surrounded by a fence, and there are two red signs on the fence. One sign reads \"VOX SPORTS\" and the other reads \"Believe it,", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 25452.9, "ram_available_mb": 37388.0, "ram_percent": 40.5}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 25472.4, "ram_available_mb": 37368.5, "ram_percent": 40.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10621.2, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.555, "power_cpu_cv_mean_watts": 2.064, "power_sys_5v0_mean_watts": 8.855}, "timestamp": "2026-01-23T11:36:12.460233"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7910.398, "latencies_ms": [7910.398], "images_per_second": 0.126, "prompt_tokens": 39, "response_tokens_est": 47, "n_tiles": 16, "output_text": "fence: 4\nsign: 2\nbench: 1\ntennis court: 1\nplayer: 1\nracket: 1\nball: 0\nbottle: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 25472.4, "ram_available_mb": 37368.5, "ram_percent": 40.5}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 25443.4, "ram_available_mb": 37397.5, "ram_percent": 40.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 7918.4, "gpu_mem_reserved_mb": 17658.0, "gpu_max_mem_alloc_mb": 10651.4, "gpu_max_mem_reserved_mb": 17658.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.31, "power_cpu_cv_mean_watts": 2.033, "power_sys_5v0_mean_watts": 8.906}, "timestamp": "2026-01-23T11:36:22.415395"}
