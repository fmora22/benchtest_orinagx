{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3002.705, "latencies_ms": [3002.705], "images_per_second": 0.333, "prompt_tokens_est": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image depicts a brightly lit, modern living room with a yellow wall, a wooden floor, and a dining area with a table and chairs.", "error": null, "sys_before": {"cpu_percent": 9.8, "ram_used_mb": 14725.3, "ram_available_mb": 48115.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14727.9, "ram_available_mb": 48113.0, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.91, "peak": 2.81, "min": 0.8}, "VIN_SYS_5V0": {"avg": 8.22, "peak": 9.69, "min": 7.66}, "VDD_GPU_SOC": {"avg": 23.34, "peak": 34.87, "min": 16.03}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 25, "duration_seconds": 3.004}, "timestamp": "2026-01-09T16:29:19.363782"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 16876.99, "latencies_ms": [16876.99], "images_per_second": 0.059, "prompt_tokens_est": 26, "response_tokens_est": 257, "n_tiles": 6, "output_text": "- table: 1\n- vase: 1\n- chair: 3\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14727.9, "ram_available_mb": 48113.0, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 14607.4, "ram_available_mb": 48233.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.31, "peak": 2.81, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.8, "peak": 9.29, "min": 4.64}, "VDD_GPU_SOC": {"avg": 16.75, "peak": 33.65, "min": 6.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 144, "duration_seconds": 16.878}, "timestamp": "2026-01-09T16:29:38.300863"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6447.424, "latencies_ms": [6447.424], "images_per_second": 0.155, "prompt_tokens_est": 30, "response_tokens_est": 86, "n_tiles": 6, "output_text": "The main objects in the image are a dining table and chairs, a vase with a flower, a television, a refrigerator, and a wall-mounted cabinet. The dining table and chairs are positioned in the foreground, with the vase and flower placed near the table. The television is on the left side of the image, and the refrigerator is in the background. The wall-mounted cabinet is located near the television.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14607.4, "ram_available_mb": 48233.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14608.4, "ram_available_mb": 48232.5, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.02, "peak": 2.81, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.76, "peak": 9.39, "min": 4.94}, "VDD_GPU_SOC": {"avg": 18.08, "peak": 33.65, "min": 8.01}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 54, "duration_seconds": 6.448}, "timestamp": "2026-01-09T16:29:46.802531"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6064.355, "latencies_ms": [6064.355], "images_per_second": 0.165, "prompt_tokens_est": 24, "response_tokens_est": 81, "n_tiles": 6, "output_text": "The image depicts a brightly lit, modern living room with a warm yellow and orange color scheme. The room features a wooden floor, a large dining table with chairs, a television on a stand, a vase with a pink flower on a table, and a green vase on a table. There is a person visible in the background, seemingly engaged in an activity near the kitchen area.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 14608.4, "ram_available_mb": 48232.5, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 14596.3, "ram_available_mb": 48244.6, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.04, "peak": 2.81, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.81, "peak": 9.39, "min": 4.94}, "VDD_GPU_SOC": {"avg": 18.71, "peak": 33.65, "min": 8.01}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 51, "duration_seconds": 6.065}, "timestamp": "2026-01-09T16:29:54.890440"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5138.977, "latencies_ms": [5138.977], "images_per_second": 0.195, "prompt_tokens_est": 22, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The room is brightly lit with natural light streaming in through large windows, creating a warm and inviting atmosphere. The walls are painted in a soft yellow, complemented by a green accent wall. The wooden floor adds warmth to the space, and the furniture is made of a combination of materials, including wood and metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14596.3, "ram_available_mb": 48244.6, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 14599.1, "ram_available_mb": 48241.8, "ram_percent": 23.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.93, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.77, "peak": 9.39, "min": 4.64}, "VDD_GPU_SOC": {"avg": 19.16, "peak": 33.25, "min": 6.01}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 43, "duration_seconds": 5.14}, "timestamp": "2026-01-09T16:30:02.089607"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2493.161, "latencies_ms": [2493.161], "images_per_second": 0.401, "prompt_tokens_est": 12, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The image features a close-up of a brown bear with a soft, fluffy fur coat, sitting on a grassy surface, displaying a calm and curious expression.", "error": null, "sys_before": {"cpu_percent": 16.9, "ram_used_mb": 14599.1, "ram_available_mb": 48241.8, "ram_percent": 23.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14696.3, "ram_available_mb": 48144.6, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.81, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 6.59, "peak": 7.16, "min": 4.73}, "VDD_GPU_SOC": {"avg": 9.14, "peak": 10.02, "min": 7.21}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 21, "duration_seconds": 2.494}, "timestamp": "2026-01-09T16:30:06.674659"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1010.801, "latencies_ms": [1010.801], "images_per_second": 0.989, "prompt_tokens_est": 26, "response_tokens_est": 11, "n_tiles": 1, "output_text": "bear: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14696.3, "ram_available_mb": 48144.6, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14692.2, "ram_available_mb": 48148.7, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.03, "peak": 1.6, "min": 0.4}, "VIN_SYS_5V0": {"avg": 6.02, "peak": 6.75, "min": 5.04}, "VDD_GPU_SOC": {"avg": 9.38, "peak": 10.41, "min": 8.81}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 7, "duration_seconds": 1.012}, "timestamp": "2026-01-09T16:30:09.718468"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3328.996, "latencies_ms": [3328.996], "images_per_second": 0.3, "prompt_tokens_est": 30, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main object in the image is a brown bear. The bear is positioned in the foreground, with its head and upper body visible. The background consists of a grassy area, indicating that the bear is likely in a natural habitat.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14692.2, "ram_available_mb": 48148.7, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14692.6, "ram_available_mb": 48148.3, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.82, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 6.83, "peak": 7.16, "min": 5.04}, "VDD_GPU_SOC": {"avg": 9.42, "peak": 11.22, "min": 8.81}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 27, "duration_seconds": 3.33}, "timestamp": "2026-01-09T16:30:15.077953"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3462.594, "latencies_ms": [3462.594], "images_per_second": 0.289, "prompt_tokens_est": 24, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The image depicts a brown bear sitting on a grassy surface, likely in a natural habitat. The bear appears to be calm and relaxed, with its eyes slightly open and its mouth slightly open, possibly indicating a moment of rest or curiosity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14692.6, "ram_available_mb": 48148.3, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 14679.1, "ram_available_mb": 48161.8, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.03, "peak": 2.81, "min": 0.4}, "VIN_SYS_5V0": {"avg": 6.84, "peak": 7.16, "min": 5.04}, "VDD_GPU_SOC": {"avg": 9.39, "peak": 10.82, "min": 8.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 28, "duration_seconds": 3.463}, "timestamp": "2026-01-09T16:30:20.556632"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3133.331, "latencies_ms": [3133.331], "images_per_second": 0.319, "prompt_tokens_est": 22, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The image features a brown bear with a textured fur coat, standing on a grassy surface. The lighting is natural, casting soft shadows on the bear's face, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14678.5, "ram_available_mb": 48162.4, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 14679.0, "ram_available_mb": 48161.9, "ram_percent": 23.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.94, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 6.82, "peak": 7.16, "min": 5.04}, "VDD_GPU_SOC": {"avg": 9.39, "peak": 10.81, "min": 8.81}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 26, "duration_seconds": 3.134}, "timestamp": "2026-01-09T16:30:25.741352"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5008.961, "latencies_ms": [5008.961], "images_per_second": 0.2, "prompt_tokens_est": 12, "response_tokens_est": 33, "n_tiles": 12, "output_text": "The image depicts a cozy bedroom with a large window that allows natural light to flood the room, illuminating the space and creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 52.2, "ram_used_mb": 14679.0, "ram_available_mb": 48161.9, "ram_percent": 23.4}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 16986.1, "ram_available_mb": 45854.8, "ram_percent": 27.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 10140.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 10140.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.67, "peak": 4.01, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.44, "peak": 9.79, "min": 5.04}, "VDD_GPU_SOC": {"avg": 25.64, "peak": 35.66, "min": 7.61}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 42, "duration_seconds": 5.009}, "timestamp": "2026-01-09T16:30:32.893000"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5213.378, "latencies_ms": [5213.378], "images_per_second": 0.192, "prompt_tokens_est": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "bed: 1\ndresser: 1\nbookshelf: 1\nwindow: 1\nplant: 1\nchair: 1\nbasket: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 16986.1, "ram_available_mb": 45854.8, "ram_percent": 27.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 18700.2, "ram_available_mb": 44140.7, "ram_percent": 29.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 11854.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 11854.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.48, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.53, "peak": 9.89, "min": 4.43}, "VDD_GPU_SOC": {"avg": 25.95, "peak": 36.07, "min": 5.21}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 44, "duration_seconds": 5.214}, "timestamp": "2026-01-09T16:30:40.161022"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7731.501, "latencies_ms": [7731.501], "images_per_second": 0.129, "prompt_tokens_est": 30, "response_tokens_est": 81, "n_tiles": 12, "output_text": "The main objects in the image are a bed, a dresser, a bookshelf, and a window. The bed is positioned in the foreground, with its headboard and footboard visible. The dresser is situated to the left of the bed, and the bookshelf is positioned to the right of the bed. The window is in the background, allowing natural light to illuminate the room.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 18700.2, "ram_available_mb": 44140.7, "ram_percent": 29.8}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 19806.6, "ram_available_mb": 43034.3, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.9, "peak": 2.81, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.65, "peak": 9.89, "min": 5.23}, "VDD_GPU_SOC": {"avg": 24.88, "peak": 35.27, "min": 8.01}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 65, "duration_seconds": 7.732}, "timestamp": "2026-01-09T16:30:49.945470"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7578.095, "latencies_ms": [7578.095], "images_per_second": 0.132, "prompt_tokens_est": 24, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The image depicts a cozy, well-organized bedroom with a large window that allows natural light to flood the room. The room is filled with various items, including a wooden dresser, a bookshelf filled with books, a small potted plant, a cushioned chair, and a basket. The overall atmosphere is warm and inviting, suggesting a comfortable and lived-in space.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 19806.6, "ram_available_mb": 43034.3, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 19816.4, "ram_available_mb": 43024.5, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.92, "peak": 3.61, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.62, "peak": 9.89, "min": 4.23}, "VDD_GPU_SOC": {"avg": 24.74, "peak": 36.46, "min": 4.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 64, "duration_seconds": 7.579}, "timestamp": "2026-01-09T16:30:59.567832"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5149.458, "latencies_ms": [5149.458], "images_per_second": 0.194, "prompt_tokens_est": 22, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The room is bathed in natural light, creating a warm and inviting atmosphere. The walls are adorned with a floral wallpaper pattern, adding a touch of elegance to the space.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 19816.4, "ram_available_mb": 43024.5, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 19821.8, "ram_available_mb": 43019.1, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.69, "peak": 2.81, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.7, "peak": 9.89, "min": 4.53}, "VDD_GPU_SOC": {"avg": 26.35, "peak": 36.07, "min": 5.61}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 43, "duration_seconds": 5.15}, "timestamp": "2026-01-09T16:31:06.746166"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4161.451, "latencies_ms": [4161.451], "images_per_second": 0.24, "prompt_tokens_est": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "A red stop sign is mounted on a post, with a clear blue sky and green trees in the background.", "error": null, "sys_before": {"cpu_percent": 31.9, "ram_used_mb": 19821.8, "ram_available_mb": 43019.1, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 19823.3, "ram_available_mb": 43017.6, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.04, "peak": 2.0, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.62, "peak": 9.89, "min": 4.63}, "VDD_GPU_SOC": {"avg": 27.48, "peak": 35.67, "min": 6.01}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 35, "duration_seconds": 4.162}, "timestamp": "2026-01-09T16:31:13.068729"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4834.712, "latencies_ms": [4834.712], "images_per_second": 0.207, "prompt_tokens_est": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "stop sign: 1\ntree: 1\ntrash can: 1\nbuilding: 1\nroad: 1\npole: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19823.3, "ram_available_mb": 43017.6, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 19823.5, "ram_available_mb": 43017.4, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.25, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.66, "peak": 9.89, "min": 4.43}, "VDD_GPU_SOC": {"avg": 26.7, "peak": 36.07, "min": 4.8}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 41, "duration_seconds": 4.835}, "timestamp": "2026-01-09T16:31:19.947066"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7140.982, "latencies_ms": [7140.982], "images_per_second": 0.14, "prompt_tokens_est": 30, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The main objects in the image are a stop sign and a street lamp. The stop sign is positioned in the foreground, near the sidewalk, while the street lamp is situated in the background, slightly to the left. The stop sign is closer to the viewer, while the street lamp is further away, creating a clear spatial relationship between the two objects.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 19823.5, "ram_available_mb": 43017.4, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 19806.9, "ram_available_mb": 43034.0, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.77, "peak": 3.21, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.66, "peak": 9.89, "min": 4.43}, "VDD_GPU_SOC": {"avg": 25.07, "peak": 36.06, "min": 5.2}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 60, "duration_seconds": 7.142}, "timestamp": "2026-01-09T16:31:29.138498"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7664.095, "latencies_ms": [7664.095], "images_per_second": 0.13, "prompt_tokens_est": 24, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The image depicts a street scene with a stop sign prominently displayed in the foreground. The sign is red with white lettering, and it is mounted on a metal pole. In the background, there is a clear blue sky, a few trees, and a parked white truck. The setting appears to be a suburban or urban area with a well-maintained sidewalk and greenery.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 19806.9, "ram_available_mb": 43034.0, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 19810.6, "ram_available_mb": 43030.3, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.9, "peak": 3.21, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.69, "peak": 9.89, "min": 4.23}, "VDD_GPU_SOC": {"avg": 24.74, "peak": 36.06, "min": 4.0}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 64, "duration_seconds": 7.665}, "timestamp": "2026-01-09T16:31:38.825472"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6783.703, "latencies_ms": [6783.703], "images_per_second": 0.147, "prompt_tokens_est": 22, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image features a red stop sign with white lettering, mounted on a metal pole. The sign is set against a backdrop of a clear blue sky with scattered clouds, indicating a sunny day. The surrounding area includes green trees, a sidewalk, and a road with a parked car, suggesting a suburban or urban setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 19810.6, "ram_available_mb": 43030.3, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 19811.1, "ram_available_mb": 43029.8, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.75, "peak": 3.21, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.69, "peak": 9.89, "min": 4.33}, "VDD_GPU_SOC": {"avg": 25.21, "peak": 36.46, "min": 4.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 57, "duration_seconds": 6.784}, "timestamp": "2026-01-09T16:31:47.666901"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3387.891, "latencies_ms": [3387.891], "images_per_second": 0.295, "prompt_tokens_est": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "The image shows a close-up of two teddy bears, one in a light brown color and the other in a darker shade, both with soft, fuzzy textures and round ears.", "error": null, "sys_before": {"cpu_percent": 31.4, "ram_used_mb": 19811.1, "ram_available_mb": 43029.8, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 19810.6, "ram_available_mb": 43030.3, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.73, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.84, "peak": 9.39, "min": 4.53}, "VDD_GPU_SOC": {"avg": 21.04, "peak": 33.67, "min": 5.21}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 29, "duration_seconds": 3.389}, "timestamp": "2026-01-09T16:31:53.178398"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4530.144, "latencies_ms": [4530.144], "images_per_second": 0.221, "prompt_tokens_est": 26, "response_tokens_est": 56, "n_tiles": 6, "output_text": "1. Brown teddy bear\n2. Brown teddy bear\n3. Brown teddy bear\n4. Brown teddy bear\n5. Brown teddy bear\n6. Brown teddy bear\n7. Brown teddy bear\n8. Brown teddy bear", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 19810.6, "ram_available_mb": 43030.3, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 19812.1, "ram_available_mb": 43028.8, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.93, "peak": 3.21, "min": 0.8}, "VIN_SYS_5V0": {"avg": 7.91, "peak": 9.49, "min": 5.04}, "VDD_GPU_SOC": {"avg": 19.97, "peak": 34.45, "min": 8.4}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 38, "duration_seconds": 4.531}, "timestamp": "2026-01-09T16:31:59.724741"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5499.403, "latencies_ms": [5499.403], "images_per_second": 0.182, "prompt_tokens_est": 30, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The main objects in the image are two teddy bears. The teddy bear on the left is in the foreground, while the teddy bear on the right is slightly behind and to the right of the left one. The teddy bear on the left is closer to the viewer, while the teddy bear on the right is further away.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 19812.1, "ram_available_mb": 43028.8, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 19813.9, "ram_available_mb": 43027.0, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.0, "peak": 3.21, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.85, "peak": 9.39, "min": 4.73}, "VDD_GPU_SOC": {"avg": 18.54, "peak": 33.67, "min": 6.0}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 47, "duration_seconds": 5.5}, "timestamp": "2026-01-09T16:32:07.260617"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5482.091, "latencies_ms": [5482.091], "images_per_second": 0.182, "prompt_tokens_est": 24, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The image depicts a cozy scene featuring two teddy bears. One bear is lying on its back, while the other is positioned close to it, both appearing to be in a comfortable and relaxed state. The setting seems to be indoors, possibly in a bedroom or living room, with soft lighting that enhances the warm and inviting atmosphere of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19813.9, "ram_available_mb": 43027.0, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 19814.3, "ram_available_mb": 43026.6, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.98, "peak": 3.21, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.88, "peak": 9.39, "min": 4.73}, "VDD_GPU_SOC": {"avg": 19.03, "peak": 33.65, "min": 6.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 47, "duration_seconds": 5.483}, "timestamp": "2026-01-09T16:32:14.775158"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4870.782, "latencies_ms": [4870.782], "images_per_second": 0.205, "prompt_tokens_est": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image features two teddy bears with a warm, earthy brown color palette. The lighting is soft and diffused, casting gentle shadows and highlighting the plush texture of the bears. The weather appears to be overcast, as the overall lighting is subdued and the shadows are soft.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19814.3, "ram_available_mb": 43026.6, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 19833.6, "ram_available_mb": 43007.3, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.96, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.89, "peak": 9.49, "min": 4.84}, "VDD_GPU_SOC": {"avg": 19.5, "peak": 34.05, "min": 7.61}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 40, "duration_seconds": 4.871}, "timestamp": "2026-01-09T16:32:21.660283"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3338.982, "latencies_ms": [3338.982], "images_per_second": 0.299, "prompt_tokens_est": 12, "response_tokens_est": 36, "n_tiles": 6, "output_text": "A person is skiing down a snowy slope, wearing a red jacket, black pants, and a black beanie, with blue and red skis and ski poles.", "error": null, "sys_before": {"cpu_percent": 36.8, "ram_used_mb": 19834.1, "ram_available_mb": 43006.8, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 19834.5, "ram_available_mb": 43006.4, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.53, "peak": 3.6, "min": 2.0}, "VIN_SYS_5V0": {"avg": 7.95, "peak": 9.59, "min": 5.24}, "VDD_GPU_SOC": {"avg": 21.22, "peak": 33.25, "min": 8.8}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 28, "duration_seconds": 3.34}, "timestamp": "2026-01-09T16:32:27.116226"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3591.632, "latencies_ms": [3591.632], "images_per_second": 0.278, "prompt_tokens_est": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19834.5, "ram_available_mb": 43006.4, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 19834.4, "ram_available_mb": 43006.5, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.76, "peak": 2.81, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.89, "peak": 9.39, "min": 4.74}, "VDD_GPU_SOC": {"avg": 21.0, "peak": 34.05, "min": 6.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 30, "duration_seconds": 3.592}, "timestamp": "2026-01-09T16:32:32.771706"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4778.144, "latencies_ms": [4778.144], "images_per_second": 0.209, "prompt_tokens_est": 30, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The main object in the foreground is a person skiing, wearing a red jacket, black pants, and a black beanie. They are holding ski poles and standing on skis. The background features a snowy landscape with a hill and a fence, indicating a ski resort setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 19834.4, "ram_available_mb": 43006.5, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 19834.8, "ram_available_mb": 43006.1, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.9, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.88, "peak": 9.49, "min": 4.84}, "VDD_GPU_SOC": {"avg": 19.17, "peak": 33.65, "min": 6.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 40, "duration_seconds": 4.779}, "timestamp": "2026-01-09T16:32:39.569733"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5134.586, "latencies_ms": [5134.586], "images_per_second": 0.195, "prompt_tokens_est": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a person skiing down a snowy slope. The individual is dressed in a red jacket, black pants, and a black beanie, with blue ski boots and black gloves. The snowy landscape is marked by orange poles and a clear sky, suggesting a sunny day suitable for skiing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19834.8, "ram_available_mb": 43006.1, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 19827.8, "ram_available_mb": 43013.1, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.93, "peak": 3.21, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.88, "peak": 9.39, "min": 4.84}, "VDD_GPU_SOC": {"avg": 18.63, "peak": 33.65, "min": 7.61}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 44, "duration_seconds": 5.135}, "timestamp": "2026-01-09T16:32:46.749303"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4883.905, "latencies_ms": [4883.905], "images_per_second": 0.205, "prompt_tokens_est": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The notable visual attributes of the image include a person dressed in a red jacket and black pants, wearing a black and white striped beanie, and blue and red ski boots. The person is skiing on a snowy slope, with a bright and clear sky overhead, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 19827.8, "ram_available_mb": 43013.1, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 19820.9, "ram_available_mb": 43020.0, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.99, "peak": 3.21, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.89, "peak": 9.49, "min": 5.04}, "VDD_GPU_SOC": {"avg": 19.42, "peak": 33.67, "min": 8.01}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 41, "duration_seconds": 4.885}, "timestamp": "2026-01-09T16:32:53.690000"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2764.723, "latencies_ms": [2764.723], "images_per_second": 0.362, "prompt_tokens_est": 12, "response_tokens_est": 27, "n_tiles": 6, "output_text": "The image shows a kitchen with a white refrigerator, wooden cabinets, and a white stove, all set against a beige wall.", "error": null, "sys_before": {"cpu_percent": 30.7, "ram_used_mb": 19820.9, "ram_available_mb": 43020.0, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 19823.8, "ram_available_mb": 43017.1, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.4, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.9, "peak": 9.49, "min": 5.04}, "VDD_GPU_SOC": {"avg": 22.64, "peak": 34.05, "min": 8.4}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 22, "duration_seconds": 2.765}, "timestamp": "2026-01-09T16:32:58.549946"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3572.714, "latencies_ms": [3572.714], "images_per_second": 0.28, "prompt_tokens_est": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 19823.8, "ram_available_mb": 43017.1, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 19820.8, "ram_available_mb": 43020.1, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.62, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.85, "peak": 9.39, "min": 4.53}, "VDD_GPU_SOC": {"avg": 21.01, "peak": 33.27, "min": 5.61}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 29, "duration_seconds": 3.573}, "timestamp": "2026-01-09T16:33:04.139835"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4363.241, "latencies_ms": [4363.241], "images_per_second": 0.229, "prompt_tokens_est": 30, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The main objects in the image are a white refrigerator and a white stove. The refrigerator is located to the right of the stove, and the stove is positioned in the foreground. The refrigerator is closer to the foreground, while the stove is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19820.8, "ram_available_mb": 43020.1, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 19820.3, "ram_available_mb": 43020.6, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.79, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.87, "peak": 9.39, "min": 4.63}, "VDD_GPU_SOC": {"avg": 19.73, "peak": 33.67, "min": 5.6}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 37, "duration_seconds": 4.364}, "timestamp": "2026-01-09T16:33:10.526289"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3287.658, "latencies_ms": [3287.658], "images_per_second": 0.304, "prompt_tokens_est": 24, "response_tokens_est": 35, "n_tiles": 6, "output_text": "The image depicts a small kitchen with a white refrigerator and a wooden cabinet. The kitchen is well-lit, and the scene appears to be in a residential setting.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 19820.3, "ram_available_mb": 43020.6, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 19812.7, "ram_available_mb": 43028.2, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.59, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.88, "peak": 9.49, "min": 4.94}, "VDD_GPU_SOC": {"avg": 21.3, "peak": 33.65, "min": 7.61}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 27, "duration_seconds": 3.288}, "timestamp": "2026-01-09T16:33:15.861947"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3526.815, "latencies_ms": [3526.815], "images_per_second": 0.284, "prompt_tokens_est": 22, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The kitchen features a warm, beige color scheme with wooden cabinets and a white refrigerator. The lighting is soft and natural, likely from a nearby window, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 19812.7, "ram_available_mb": 43028.2, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 19811.9, "ram_available_mb": 43029.0, "ram_percent": 31.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.63, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.87, "peak": 9.39, "min": 4.63}, "VDD_GPU_SOC": {"avg": 20.97, "peak": 33.27, "min": 6.0}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 29, "duration_seconds": 3.527}, "timestamp": "2026-01-09T16:33:21.454388"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3582.174, "latencies_ms": [3582.174], "images_per_second": 0.279, "prompt_tokens_est": 12, "response_tokens_est": 52, "n_tiles": 1, "output_text": "Two baseball players are in the midst of a game, with one player in a white shirt and blue helmet running towards first base while the other player in a green shirt and blue cap is running towards second base, both wearing gloves and focused on the game.", "error": null, "sys_before": {"cpu_percent": 17.2, "ram_used_mb": 19811.9, "ram_available_mb": 43029.0, "ram_percent": 31.5}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 19836.0, "ram_available_mb": 43004.9, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.07, "peak": 2.8, "min": 0.4}, "VIN_SYS_5V0": {"avg": 6.93, "peak": 7.26, "min": 4.83}, "VDD_GPU_SOC": {"avg": 9.23, "peak": 10.02, "min": 7.21}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 30, "duration_seconds": 3.583}, "timestamp": "2026-01-09T16:33:27.092469"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 16436.239, "latencies_ms": [16436.239], "images_per_second": 0.061, "prompt_tokens_est": 26, "response_tokens_est": 257, "n_tiles": 1, "output_text": "- baseball player: 2\n- baseball: 1\n- baseball glove: 1\n- baseball uniform: 1\n- baseball cap: 1\n- baseball bat: 1\n- baseball field: 1\n- baseball glove: 1\n- baseball: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 19836.0, "ram_available_mb": 43004.9, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 19837.1, "ram_available_mb": 43003.8, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.49, "peak": 3.21, "min": 0.8}, "VIN_SYS_5V0": {"avg": 7.22, "peak": 7.36, "min": 5.04}, "VDD_GPU_SOC": {"avg": 9.89, "peak": 11.62, "min": 8.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 140, "duration_seconds": 16.437}, "timestamp": "2026-01-09T16:33:45.547993"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6294.011, "latencies_ms": [6294.011], "images_per_second": 0.159, "prompt_tokens_est": 30, "response_tokens_est": 94, "n_tiles": 1, "output_text": "In the image, the main object, a baseball player in the foreground, is positioned near the center of the frame. The player is wearing a white shirt, gray pants, and a blue helmet. In the background, another player is seen running towards the left side of the frame. The second player is wearing a green shirt and a green cap. The player in the background is slightly farther away from the main subject, creating a sense of depth in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19837.1, "ram_available_mb": 43003.8, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 19834.3, "ram_available_mb": 43006.6, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.13, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.09, "peak": 7.36, "min": 5.04}, "VDD_GPU_SOC": {"avg": 9.36, "peak": 10.81, "min": 8.81}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 54, "duration_seconds": 6.295}, "timestamp": "2026-01-09T16:33:53.878865"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5803.486, "latencies_ms": [5803.486], "images_per_second": 0.172, "prompt_tokens_est": 24, "response_tokens_est": 87, "n_tiles": 1, "output_text": "The image captures a dynamic moment during a baseball game, with two players in mid-action on the field. One player, wearing a white shirt and blue helmet, is running towards first base while the other, dressed in a green shirt and blue cap, is running towards second base. The background features lush green trees and a well-maintained grassy area, indicating that the game is taking place in a park or recreational field.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 19834.3, "ram_available_mb": 43006.6, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 19843.7, "ram_available_mb": 42997.2, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.11, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.03, "peak": 7.26, "min": 4.94}, "VDD_GPU_SOC": {"avg": 9.41, "peak": 10.42, "min": 8.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 49, "duration_seconds": 5.805}, "timestamp": "2026-01-09T16:34:01.703469"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2723.587, "latencies_ms": [2723.587], "images_per_second": 0.367, "prompt_tokens_est": 22, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The image depicts a baseball game with players in white and gray uniforms, running on a dirt field. The scene is brightly lit by natural sunlight, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19843.7, "ram_available_mb": 42997.2, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 19836.4, "ram_available_mb": 43004.5, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.02, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 6.78, "peak": 7.16, "min": 5.14}, "VDD_GPU_SOC": {"avg": 9.89, "peak": 11.61, "min": 8.81}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 22, "duration_seconds": 2.724}, "timestamp": "2026-01-09T16:34:06.441238"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3401.858, "latencies_ms": [3401.858], "images_per_second": 0.294, "prompt_tokens_est": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "A tennis player is in the midst of a powerful serve, with his body leaning forward and his racket in motion, as he attempts to hit the ball with precision and power.", "error": null, "sys_before": {"cpu_percent": 28.4, "ram_used_mb": 19836.4, "ram_available_mb": 43004.5, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 19837.7, "ram_available_mb": 43003.2, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.63, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.89, "peak": 9.49, "min": 4.94}, "VDD_GPU_SOC": {"avg": 21.19, "peak": 33.65, "min": 7.21}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 28, "duration_seconds": 3.403}, "timestamp": "2026-01-09T16:34:11.977702"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3803.152, "latencies_ms": [3803.152], "images_per_second": 0.263, "prompt_tokens_est": 26, "response_tokens_est": 44, "n_tiles": 6, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Tennis court\n5. Spectator\n6. Advertisement board\n7. Advertisement board\n8. Advertisement board", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 19837.7, "ram_available_mb": 43003.2, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 19837.5, "ram_available_mb": 43003.4, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.69, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.98, "peak": 9.49, "min": 4.73}, "VDD_GPU_SOC": {"avg": 20.89, "peak": 33.27, "min": 6.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 31, "duration_seconds": 3.804}, "timestamp": "2026-01-09T16:34:17.799156"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6816.969, "latencies_ms": [6816.969], "images_per_second": 0.147, "prompt_tokens_est": 30, "response_tokens_est": 93, "n_tiles": 6, "output_text": "The main object in the foreground is a tennis player in a white and blue outfit, who is in the process of hitting a tennis ball. The player is positioned on the left side of the image, with the tennis ball in the middle. The background features a blue barrier with the word \"POLO\" written on it, and a person standing near the barrier. The player's shadow is cast on the tennis court, indicating the direction of the light source.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19837.5, "ram_available_mb": 43003.4, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 19838.3, "ram_available_mb": 43002.6, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.02, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.88, "peak": 9.39, "min": 4.74}, "VDD_GPU_SOC": {"avg": 18.4, "peak": 33.65, "min": 6.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 59, "duration_seconds": 6.818}, "timestamp": "2026-01-09T16:34:26.651325"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6620.714, "latencies_ms": [6620.714], "images_per_second": 0.151, "prompt_tokens_est": 24, "response_tokens_est": 88, "n_tiles": 6, "output_text": "The image captures a moment during a tennis match on a well-maintained court. The player, dressed in a white shirt and blue shorts, is in the midst of a powerful serve, with his body leaning forward and his racket extended towards the ball. The background features a blue barrier with the \"J.P. Morgan\" logo, indicating sponsorship, and a few spectators are seated on the sidelines, observing the match.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19838.3, "ram_available_mb": 43002.6, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 19835.1, "ram_available_mb": 43005.8, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.08, "peak": 3.21, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.87, "peak": 9.49, "min": 4.94}, "VDD_GPU_SOC": {"avg": 18.49, "peak": 33.65, "min": 7.61}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 55, "duration_seconds": 6.621}, "timestamp": "2026-01-09T16:34:35.303004"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7121.81, "latencies_ms": [7121.81], "images_per_second": 0.14, "prompt_tokens_est": 22, "response_tokens_est": 96, "n_tiles": 6, "output_text": "The image captures a tennis match on a bright, sunny day. The court is marked with white lines, and the players are dressed in athletic attire, with the player in the foreground wearing a white shirt and blue shorts, and the other player in a dark shirt and white shorts. The lighting is natural, casting shadows on the court, and the colors are vivid, with the green of the court contrasting against the players' clothing and the blue of the advertisement boards.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 19835.1, "ram_available_mb": 43005.8, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 19835.3, "ram_available_mb": 43005.6, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 2.11, "peak": 3.21, "min": 0.4}, "VIN_SYS_5V0": {"avg": 7.86, "peak": 9.29, "min": 4.74}, "VDD_GPU_SOC": {"avg": 18.18, "peak": 32.85, "min": 6.0}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 60, "duration_seconds": 7.122}, "timestamp": "2026-01-09T16:34:44.454035"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4098.681, "latencies_ms": [4098.681], "images_per_second": 0.244, "prompt_tokens_est": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "The image shows a group of young tennis players and their coach posing for a photo on a tennis court.", "error": null, "sys_before": {"cpu_percent": 28.0, "ram_used_mb": 19835.3, "ram_available_mb": 43005.6, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 19836.3, "ram_available_mb": 43004.6, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.18, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.72, "peak": 10.01, "min": 4.63}, "VDD_GPU_SOC": {"avg": 27.66, "peak": 36.06, "min": 5.2}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 34, "duration_seconds": 4.099}, "timestamp": "2026-01-09T16:34:50.733984"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5505.955, "latencies_ms": [5505.955], "images_per_second": 0.182, "prompt_tokens_est": 26, "response_tokens_est": 44, "n_tiles": 12, "output_text": "1. Tennis players\n2. Tennis rackets\n3. Tennis balls\n4. Tennis net\n5. Tennis court\n6. Tennis court net\n7. Tennis court net\n8. Tennis court net", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 19836.3, "ram_available_mb": 43004.6, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 19834.6, "ram_available_mb": 43006.3, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.54, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.7, "peak": 10.01, "min": 4.43}, "VDD_GPU_SOC": {"avg": 26.01, "peak": 36.06, "min": 4.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 46, "duration_seconds": 5.507}, "timestamp": "2026-01-09T16:34:58.276864"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6461.777, "latencies_ms": [6461.777], "images_per_second": 0.155, "prompt_tokens_est": 30, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The main objects in the image are a group of young boys and girls standing on a tennis court. The boys are positioned in the foreground, with the girls slightly behind them. The tennis court is surrounded by a green fence, and the background features trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19834.6, "ram_available_mb": 43006.3, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 19835.3, "ram_available_mb": 43005.6, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.62, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.64, "peak": 9.69, "min": 4.23}, "VDD_GPU_SOC": {"avg": 25.22, "peak": 36.04, "min": 4.0}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 54, "duration_seconds": 6.462}, "timestamp": "2026-01-09T16:35:06.757482"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6961.774, "latencies_ms": [6961.774], "images_per_second": 0.144, "prompt_tokens_est": 24, "response_tokens_est": 68, "n_tiles": 12, "output_text": "The scene depicts a group of young tennis players and their coach standing on a tennis court, likely after a match or practice session. The players are dressed in athletic attire, with some holding tennis rackets, and the coach is holding a trophy. The setting is outdoors, with trees and a green fence visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19835.3, "ram_available_mb": 43005.6, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 19837.3, "ram_available_mb": 43003.6, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.66, "peak": 2.4, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.72, "peak": 10.01, "min": 4.33}, "VDD_GPU_SOC": {"avg": 25.13, "peak": 36.04, "min": 4.41}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 59, "duration_seconds": 6.962}, "timestamp": "2026-01-09T16:35:15.743524"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6358.286, "latencies_ms": [6358.286], "images_per_second": 0.157, "prompt_tokens_est": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a group of young athletes standing on a tennis court, with a blue surface and a green fence in the background. The lighting is bright, indicating it is a sunny day, and the shadows are cast on the court, suggesting the sun is high in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 19837.3, "ram_available_mb": 43003.6, "ram_percent": 31.6}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 19844.5, "ram_available_mb": 42996.4, "ram_percent": 31.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12968.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12968.0}, "power_stats": {"method": "tegrastats", "power_rails": {"VDD_CPU_CV": {"avg": 1.71, "peak": 4.01, "min": 0.4}, "VIN_SYS_5V0": {"avg": 8.73, "peak": 10.01, "min": 4.53}, "VDD_GPU_SOC": {"avg": 25.55, "peak": 36.44, "min": 5.2}}, "power_watts_avg": null, "power_watts_peak": null, "energy_joules_est": null, "sample_count": 54, "duration_seconds": 6.359}, "timestamp": "2026-01-09T16:35:24.151865"}
